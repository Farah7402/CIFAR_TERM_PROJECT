{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446b2ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "391\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'               \n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "root_dir = 'drive/app/cifar10/'\n",
    "default_directory = 'drive/app/torch/save_modelsWideresnet'\n",
    "\n",
    "# Data Augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),               \n",
    "    transforms.RandomHorizontalFlip(),                  \n",
    "    transforms.ToTensor(),                              \n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), \n",
    "                         std=(0.2471, 0.2436, 0.2616))  \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                              \n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), \n",
    "                         std=(0.2471, 0.2436, 0.2616))  \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,           \n",
    "                                           num_workers=4)           \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,           \n",
    "                                          num_workers=4) \n",
    "\n",
    "n_total_step = len(train_loader)\n",
    "print(n_total_step)                                  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a189f3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n"
     ]
    }
   ],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class wide_basic(nn.Module):\n",
    "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
    "        super(wide_basic, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Wide_ResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
    "        super(Wide_ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth-4)/6\n",
    "        k = widen_factor\n",
    "\n",
    "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
    "        nStages = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = conv3x3(3,nStages[0])\n",
    "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
    "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
    "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
    "        self.linear = nn.Linear(nStages[3], num_classes)\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "model = Wide_ResNet(28, 10, 0.3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09bdc2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE 1 GPUs!\n",
      "Epoch: 0 | Batch_idx: 0 |  Loss: (2.3317) | Acc: (8.59%) (11/128)\n",
      "Epoch: 0 | Batch_idx: 10 |  Loss: (2.3001) | Acc: (10.87%) (153/1408)\n",
      "Epoch: 0 | Batch_idx: 20 |  Loss: (2.2823) | Acc: (14.10%) (379/2688)\n",
      "Epoch: 0 | Batch_idx: 30 |  Loss: (2.2590) | Acc: (15.98%) (634/3968)\n",
      "Epoch: 0 | Batch_idx: 40 |  Loss: (2.2353) | Acc: (17.05%) (895/5248)\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (2.2134) | Acc: (17.83%) (1164/6528)\n",
      "Epoch: 0 | Batch_idx: 60 |  Loss: (2.1927) | Acc: (18.88%) (1474/7808)\n",
      "Epoch: 0 | Batch_idx: 70 |  Loss: (2.1762) | Acc: (19.36%) (1759/9088)\n",
      "Epoch: 0 | Batch_idx: 80 |  Loss: (2.1613) | Acc: (19.88%) (2061/10368)\n",
      "Epoch: 0 | Batch_idx: 90 |  Loss: (2.1465) | Acc: (20.38%) (2374/11648)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (2.1319) | Acc: (21.02%) (2717/12928)\n",
      "Epoch: 0 | Batch_idx: 110 |  Loss: (2.1188) | Acc: (21.45%) (3047/14208)\n",
      "Epoch: 0 | Batch_idx: 120 |  Loss: (2.1038) | Acc: (22.04%) (3414/15488)\n",
      "Epoch: 0 | Batch_idx: 130 |  Loss: (2.0910) | Acc: (22.43%) (3761/16768)\n",
      "Epoch: 0 | Batch_idx: 140 |  Loss: (2.0800) | Acc: (22.81%) (4117/18048)\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (2.0705) | Acc: (23.07%) (4459/19328)\n",
      "Epoch: 0 | Batch_idx: 160 |  Loss: (2.0585) | Acc: (23.57%) (4857/20608)\n",
      "Epoch: 0 | Batch_idx: 170 |  Loss: (2.0474) | Acc: (24.06%) (5266/21888)\n",
      "Epoch: 0 | Batch_idx: 180 |  Loss: (2.0373) | Acc: (24.36%) (5644/23168)\n",
      "Epoch: 0 | Batch_idx: 190 |  Loss: (2.0281) | Acc: (24.59%) (6011/24448)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (2.0210) | Acc: (24.84%) (6391/25728)\n",
      "Epoch: 0 | Batch_idx: 210 |  Loss: (2.0109) | Acc: (25.21%) (6809/27008)\n",
      "Epoch: 0 | Batch_idx: 220 |  Loss: (2.0027) | Acc: (25.56%) (7230/28288)\n",
      "Epoch: 0 | Batch_idx: 230 |  Loss: (1.9943) | Acc: (25.89%) (7656/29568)\n",
      "Epoch: 0 | Batch_idx: 240 |  Loss: (1.9867) | Acc: (26.22%) (8088/30848)\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (1.9793) | Acc: (26.50%) (8515/32128)\n",
      "Epoch: 0 | Batch_idx: 260 |  Loss: (1.9711) | Acc: (26.73%) (8931/33408)\n",
      "Epoch: 0 | Batch_idx: 270 |  Loss: (1.9638) | Acc: (26.98%) (9359/34688)\n",
      "Epoch: 0 | Batch_idx: 280 |  Loss: (1.9555) | Acc: (27.27%) (9808/35968)\n",
      "Epoch: 0 | Batch_idx: 290 |  Loss: (1.9485) | Acc: (27.51%) (10246/37248)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (1.9408) | Acc: (27.74%) (10687/38528)\n",
      "Epoch: 0 | Batch_idx: 310 |  Loss: (1.9342) | Acc: (28.00%) (11147/39808)\n",
      "Epoch: 0 | Batch_idx: 320 |  Loss: (1.9277) | Acc: (28.20%) (11588/41088)\n",
      "Epoch: 0 | Batch_idx: 330 |  Loss: (1.9217) | Acc: (28.40%) (12031/42368)\n",
      "Epoch: 0 | Batch_idx: 340 |  Loss: (1.9148) | Acc: (28.64%) (12499/43648)\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (1.9080) | Acc: (28.90%) (12982/44928)\n",
      "Epoch: 0 | Batch_idx: 360 |  Loss: (1.9015) | Acc: (29.13%) (13462/46208)\n",
      "Epoch: 0 | Batch_idx: 370 |  Loss: (1.8952) | Acc: (29.39%) (13956/47488)\n",
      "Epoch: 0 | Batch_idx: 380 |  Loss: (1.8895) | Acc: (29.58%) (14425/48768)\n",
      "Epoch: 0 | Batch_idx: 390 |  Loss: (1.8833) | Acc: (29.78%) (14891/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (2.1091) | Acc: (26.52%) (2652/10000)\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (1.7078) | Acc: (39.06%) (50/128)\n",
      "Epoch: 1 | Batch_idx: 10 |  Loss: (1.6798) | Acc: (37.50%) (528/1408)\n",
      "Epoch: 1 | Batch_idx: 20 |  Loss: (1.6838) | Acc: (37.20%) (1000/2688)\n",
      "Epoch: 1 | Batch_idx: 30 |  Loss: (1.6746) | Acc: (37.53%) (1489/3968)\n",
      "Epoch: 1 | Batch_idx: 40 |  Loss: (1.6553) | Acc: (38.07%) (1998/5248)\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (1.6469) | Acc: (38.48%) (2512/6528)\n",
      "Epoch: 1 | Batch_idx: 60 |  Loss: (1.6395) | Acc: (38.56%) (3011/7808)\n",
      "Epoch: 1 | Batch_idx: 70 |  Loss: (1.6418) | Acc: (38.28%) (3479/9088)\n",
      "Epoch: 1 | Batch_idx: 80 |  Loss: (1.6362) | Acc: (38.60%) (4002/10368)\n",
      "Epoch: 1 | Batch_idx: 90 |  Loss: (1.6378) | Acc: (38.27%) (4458/11648)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (1.6309) | Acc: (38.54%) (4982/12928)\n",
      "Epoch: 1 | Batch_idx: 110 |  Loss: (1.6288) | Acc: (38.82%) (5515/14208)\n",
      "Epoch: 1 | Batch_idx: 120 |  Loss: (1.6241) | Acc: (39.02%) (6043/15488)\n",
      "Epoch: 1 | Batch_idx: 130 |  Loss: (1.6196) | Acc: (39.25%) (6582/16768)\n",
      "Epoch: 1 | Batch_idx: 140 |  Loss: (1.6163) | Acc: (39.37%) (7106/18048)\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (1.6137) | Acc: (39.44%) (7623/19328)\n",
      "Epoch: 1 | Batch_idx: 160 |  Loss: (1.6092) | Acc: (39.72%) (8186/20608)\n",
      "Epoch: 1 | Batch_idx: 170 |  Loss: (1.6078) | Acc: (39.72%) (8695/21888)\n",
      "Epoch: 1 | Batch_idx: 180 |  Loss: (1.6041) | Acc: (39.82%) (9225/23168)\n",
      "Epoch: 1 | Batch_idx: 190 |  Loss: (1.6022) | Acc: (39.85%) (9742/24448)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (1.6014) | Acc: (39.95%) (10278/25728)\n",
      "Epoch: 1 | Batch_idx: 210 |  Loss: (1.5995) | Acc: (40.01%) (10805/27008)\n",
      "Epoch: 1 | Batch_idx: 220 |  Loss: (1.5976) | Acc: (40.07%) (11335/28288)\n",
      "Epoch: 1 | Batch_idx: 230 |  Loss: (1.5958) | Acc: (40.11%) (11860/29568)\n",
      "Epoch: 1 | Batch_idx: 240 |  Loss: (1.5930) | Acc: (40.24%) (12412/30848)\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (1.5909) | Acc: (40.35%) (12965/32128)\n",
      "Epoch: 1 | Batch_idx: 260 |  Loss: (1.5884) | Acc: (40.47%) (13519/33408)\n",
      "Epoch: 1 | Batch_idx: 270 |  Loss: (1.5846) | Acc: (40.62%) (14091/34688)\n",
      "Epoch: 1 | Batch_idx: 280 |  Loss: (1.5797) | Acc: (40.83%) (14686/35968)\n",
      "Epoch: 1 | Batch_idx: 290 |  Loss: (1.5785) | Acc: (40.90%) (15233/37248)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (1.5761) | Acc: (41.00%) (15796/38528)\n",
      "Epoch: 1 | Batch_idx: 310 |  Loss: (1.5737) | Acc: (41.14%) (16379/39808)\n",
      "Epoch: 1 | Batch_idx: 320 |  Loss: (1.5718) | Acc: (41.27%) (16957/41088)\n",
      "Epoch: 1 | Batch_idx: 330 |  Loss: (1.5683) | Acc: (41.38%) (17531/42368)\n",
      "Epoch: 1 | Batch_idx: 340 |  Loss: (1.5651) | Acc: (41.45%) (18094/43648)\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (1.5621) | Acc: (41.55%) (18669/44928)\n",
      "Epoch: 1 | Batch_idx: 360 |  Loss: (1.5592) | Acc: (41.69%) (19262/46208)\n",
      "Epoch: 1 | Batch_idx: 370 |  Loss: (1.5573) | Acc: (41.79%) (19844/47488)\n",
      "Epoch: 1 | Batch_idx: 380 |  Loss: (1.5551) | Acc: (41.93%) (20446/48768)\n",
      "Epoch: 1 | Batch_idx: 390 |  Loss: (1.5519) | Acc: (42.02%) (21010/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.7878) | Acc: (39.63%) (3963/10000)\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (1.4056) | Acc: (46.88%) (60/128)\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (1.4322) | Acc: (47.51%) (669/1408)\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (1.4229) | Acc: (48.40%) (1301/2688)\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (1.4221) | Acc: (47.91%) (1901/3968)\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (1.4090) | Acc: (48.49%) (2545/5248)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (1.4073) | Acc: (48.24%) (3149/6528)\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (1.4078) | Acc: (48.22%) (3765/7808)\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (1.4120) | Acc: (48.03%) (4365/9088)\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (1.4066) | Acc: (48.13%) (4990/10368)\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (1.4083) | Acc: (48.06%) (5598/11648)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (1.4071) | Acc: (48.24%) (6236/12928)\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (1.4033) | Acc: (48.36%) (6871/14208)\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (1.4044) | Acc: (48.34%) (7487/15488)\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (1.4044) | Acc: (48.38%) (8113/16768)\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (1.3987) | Acc: (48.66%) (8782/18048)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (1.3957) | Acc: (48.83%) (9438/19328)\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (1.3961) | Acc: (48.84%) (10064/20608)\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (1.3925) | Acc: (48.99%) (10722/21888)\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (1.3877) | Acc: (49.14%) (11384/23168)\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (1.3877) | Acc: (49.19%) (12025/24448)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (1.3842) | Acc: (49.34%) (12694/25728)\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (1.3830) | Acc: (49.37%) (13334/27008)\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (1.3804) | Acc: (49.49%) (13999/28288)\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (1.3774) | Acc: (49.57%) (14657/29568)\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (1.3737) | Acc: (49.69%) (15329/30848)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (1.3706) | Acc: (49.80%) (16000/32128)\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (1.3683) | Acc: (49.89%) (16666/33408)\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (1.3661) | Acc: (50.01%) (17346/34688)\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (1.3625) | Acc: (50.14%) (18034/35968)\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (1.3600) | Acc: (50.24%) (18713/37248)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (1.3591) | Acc: (50.23%) (19351/38528)\n",
      "Epoch: 2 | Batch_idx: 310 |  Loss: (1.3563) | Acc: (50.37%) (20053/39808)\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (1.3559) | Acc: (50.42%) (20718/41088)\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (1.3552) | Acc: (50.50%) (21396/42368)\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (1.3517) | Acc: (50.63%) (22101/43648)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (1.3493) | Acc: (50.67%) (22766/44928)\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (1.3461) | Acc: (50.82%) (23484/46208)\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (1.3460) | Acc: (50.80%) (24123/47488)\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (1.3426) | Acc: (50.94%) (24841/48768)\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (1.3412) | Acc: (50.97%) (25486/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.6815) | Acc: (45.88%) (4588/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (1.2652) | Acc: (51.56%) (66/128)\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (1.2531) | Acc: (55.40%) (780/1408)\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (1.2592) | Acc: (54.72%) (1471/2688)\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (1.2517) | Acc: (54.99%) (2182/3968)\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (1.2456) | Acc: (55.32%) (2903/5248)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (1.2278) | Acc: (55.96%) (3653/6528)\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (1.2194) | Acc: (56.21%) (4389/7808)\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (1.2215) | Acc: (56.04%) (5093/9088)\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (1.2205) | Acc: (56.03%) (5809/10368)\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (1.2161) | Acc: (56.29%) (6557/11648)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (1.2156) | Acc: (56.17%) (7262/12928)\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (1.2168) | Acc: (56.14%) (7976/14208)\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (1.2127) | Acc: (56.31%) (8721/15488)\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (1.2126) | Acc: (56.18%) (9420/16768)\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (1.2156) | Acc: (56.16%) (10136/18048)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (1.2131) | Acc: (56.09%) (10841/19328)\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (1.2126) | Acc: (56.16%) (11573/20608)\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (1.2069) | Acc: (56.36%) (12336/21888)\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (1.2032) | Acc: (56.49%) (13088/23168)\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (1.2016) | Acc: (56.56%) (13828/24448)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (1.2004) | Acc: (56.58%) (14556/25728)\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (1.2011) | Acc: (56.56%) (15275/27008)\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (1.1988) | Acc: (56.63%) (16019/28288)\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (1.1986) | Acc: (56.59%) (16733/29568)\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (1.1948) | Acc: (56.79%) (17520/30848)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (1.1941) | Acc: (56.86%) (18267/32128)\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (1.1917) | Acc: (56.91%) (19011/33408)\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (1.1906) | Acc: (56.97%) (19762/34688)\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (1.1886) | Acc: (56.98%) (20495/35968)\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (1.1886) | Acc: (56.98%) (21225/37248)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (1.1862) | Acc: (57.11%) (22002/38528)\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (1.1861) | Acc: (57.15%) (22752/39808)\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (1.1848) | Acc: (57.27%) (23530/41088)\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (1.1836) | Acc: (57.29%) (24273/42368)\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (1.1822) | Acc: (57.36%) (25035/43648)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (1.1806) | Acc: (57.38%) (25779/44928)\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (1.1781) | Acc: (57.47%) (26558/46208)\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (1.1744) | Acc: (57.62%) (27364/47488)\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (1.1727) | Acc: (57.70%) (28138/48768)\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (1.1719) | Acc: (57.75%) (28875/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.5683) | Acc: (50.69%) (5069/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (1.0220) | Acc: (66.41%) (85/128)\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (1.0878) | Acc: (60.51%) (852/1408)\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (1.1067) | Acc: (60.01%) (1613/2688)\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (1.1006) | Acc: (60.06%) (2383/3968)\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (1.1007) | Acc: (60.12%) (3155/5248)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (1.0957) | Acc: (60.19%) (3929/6528)\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (1.0962) | Acc: (60.13%) (4695/7808)\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (1.0925) | Acc: (60.28%) (5478/9088)\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (1.0895) | Acc: (60.47%) (6270/10368)\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (1.0864) | Acc: (60.64%) (7063/11648)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (1.0824) | Acc: (60.88%) (7870/12928)\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (1.0824) | Acc: (60.74%) (8630/14208)\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (1.0798) | Acc: (60.78%) (9414/15488)\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (1.0761) | Acc: (60.96%) (10222/16768)\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (1.0732) | Acc: (61.19%) (11043/18048)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (1.0731) | Acc: (61.17%) (11823/19328)\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (1.0718) | Acc: (61.24%) (12620/20608)\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (1.0715) | Acc: (61.24%) (13404/21888)\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (1.0711) | Acc: (61.25%) (14191/23168)\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (1.0706) | Acc: (61.30%) (14987/24448)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (1.0688) | Acc: (61.38%) (15791/25728)\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (1.0671) | Acc: (61.51%) (16612/27008)\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (1.0639) | Acc: (61.59%) (17422/28288)\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (1.0626) | Acc: (61.63%) (18224/29568)\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (1.0600) | Acc: (61.71%) (19035/30848)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (1.0573) | Acc: (61.80%) (19856/32128)\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (1.0558) | Acc: (61.86%) (20667/33408)\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (1.0540) | Acc: (61.98%) (21499/34688)\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (1.0525) | Acc: (62.10%) (22336/35968)\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (1.0520) | Acc: (62.07%) (23119/37248)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (1.0518) | Acc: (62.07%) (23913/38528)\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (1.0511) | Acc: (62.13%) (24731/39808)\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (1.0503) | Acc: (62.18%) (25547/41088)\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (1.0487) | Acc: (62.25%) (26372/42368)\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (1.0481) | Acc: (62.26%) (27177/43648)\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (1.0474) | Acc: (62.34%) (28006/44928)\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (1.0464) | Acc: (62.39%) (28828/46208)\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (1.0456) | Acc: (62.42%) (29641/47488)\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (1.0440) | Acc: (62.47%) (30467/48768)\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (1.0431) | Acc: (62.52%) (31259/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.2602) | Acc: (59.58%) (5958/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (0.9941) | Acc: (64.84%) (83/128)\n",
      "Epoch: 5 | Batch_idx: 10 |  Loss: (0.9803) | Acc: (66.34%) (934/1408)\n",
      "Epoch: 5 | Batch_idx: 20 |  Loss: (0.9765) | Acc: (64.96%) (1746/2688)\n",
      "Epoch: 5 | Batch_idx: 30 |  Loss: (0.9826) | Acc: (64.72%) (2568/3968)\n",
      "Epoch: 5 | Batch_idx: 40 |  Loss: (0.9737) | Acc: (65.13%) (3418/5248)\n",
      "Epoch: 5 | Batch_idx: 50 |  Loss: (0.9720) | Acc: (65.13%) (4252/6528)\n",
      "Epoch: 5 | Batch_idx: 60 |  Loss: (0.9807) | Acc: (64.65%) (5048/7808)\n",
      "Epoch: 5 | Batch_idx: 70 |  Loss: (0.9763) | Acc: (64.95%) (5903/9088)\n",
      "Epoch: 5 | Batch_idx: 80 |  Loss: (0.9773) | Acc: (64.89%) (6728/10368)\n",
      "Epoch: 5 | Batch_idx: 90 |  Loss: (0.9751) | Acc: (65.08%) (7580/11648)\n",
      "Epoch: 5 | Batch_idx: 100 |  Loss: (0.9705) | Acc: (65.34%) (8447/12928)\n",
      "Epoch: 5 | Batch_idx: 110 |  Loss: (0.9700) | Acc: (65.27%) (9274/14208)\n",
      "Epoch: 5 | Batch_idx: 120 |  Loss: (0.9717) | Acc: (65.10%) (10083/15488)\n",
      "Epoch: 5 | Batch_idx: 130 |  Loss: (0.9718) | Acc: (65.15%) (10924/16768)\n",
      "Epoch: 5 | Batch_idx: 140 |  Loss: (0.9707) | Acc: (65.25%) (11776/18048)\n",
      "Epoch: 5 | Batch_idx: 150 |  Loss: (0.9705) | Acc: (65.22%) (12605/19328)\n",
      "Epoch: 5 | Batch_idx: 160 |  Loss: (0.9685) | Acc: (65.25%) (13447/20608)\n",
      "Epoch: 5 | Batch_idx: 170 |  Loss: (0.9692) | Acc: (65.31%) (14294/21888)\n",
      "Epoch: 5 | Batch_idx: 180 |  Loss: (0.9677) | Acc: (65.40%) (15153/23168)\n",
      "Epoch: 5 | Batch_idx: 190 |  Loss: (0.9677) | Acc: (65.42%) (15993/24448)\n",
      "Epoch: 5 | Batch_idx: 200 |  Loss: (0.9671) | Acc: (65.43%) (16833/25728)\n",
      "Epoch: 5 | Batch_idx: 210 |  Loss: (0.9685) | Acc: (65.40%) (17662/27008)\n",
      "Epoch: 5 | Batch_idx: 220 |  Loss: (0.9679) | Acc: (65.45%) (18514/28288)\n",
      "Epoch: 5 | Batch_idx: 230 |  Loss: (0.9653) | Acc: (65.51%) (19369/29568)\n",
      "Epoch: 5 | Batch_idx: 240 |  Loss: (0.9659) | Acc: (65.47%) (20196/30848)\n",
      "Epoch: 5 | Batch_idx: 250 |  Loss: (0.9648) | Acc: (65.53%) (21052/32128)\n",
      "Epoch: 5 | Batch_idx: 260 |  Loss: (0.9622) | Acc: (65.58%) (21908/33408)\n",
      "Epoch: 5 | Batch_idx: 270 |  Loss: (0.9638) | Acc: (65.50%) (22720/34688)\n",
      "Epoch: 5 | Batch_idx: 280 |  Loss: (0.9620) | Acc: (65.58%) (23587/35968)\n",
      "Epoch: 5 | Batch_idx: 290 |  Loss: (0.9616) | Acc: (65.55%) (24417/37248)\n",
      "Epoch: 5 | Batch_idx: 300 |  Loss: (0.9591) | Acc: (65.62%) (25283/38528)\n",
      "Epoch: 5 | Batch_idx: 310 |  Loss: (0.9580) | Acc: (65.73%) (26164/39808)\n",
      "Epoch: 5 | Batch_idx: 320 |  Loss: (0.9585) | Acc: (65.67%) (26983/41088)\n",
      "Epoch: 5 | Batch_idx: 330 |  Loss: (0.9567) | Acc: (65.74%) (27851/42368)\n",
      "Epoch: 5 | Batch_idx: 340 |  Loss: (0.9565) | Acc: (65.73%) (28692/43648)\n",
      "Epoch: 5 | Batch_idx: 350 |  Loss: (0.9561) | Acc: (65.75%) (29539/44928)\n",
      "Epoch: 5 | Batch_idx: 360 |  Loss: (0.9557) | Acc: (65.75%) (30381/46208)\n",
      "Epoch: 5 | Batch_idx: 370 |  Loss: (0.9549) | Acc: (65.77%) (31232/47488)\n",
      "Epoch: 5 | Batch_idx: 380 |  Loss: (0.9540) | Acc: (65.82%) (32099/48768)\n",
      "Epoch: 5 | Batch_idx: 390 |  Loss: (0.9536) | Acc: (65.81%) (32907/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.2093) | Acc: (62.43%) (6243/10000)\n",
      "Epoch: 6 | Batch_idx: 0 |  Loss: (1.0594) | Acc: (63.28%) (81/128)\n",
      "Epoch: 6 | Batch_idx: 10 |  Loss: (0.9383) | Acc: (67.12%) (945/1408)\n",
      "Epoch: 6 | Batch_idx: 20 |  Loss: (0.8956) | Acc: (68.12%) (1831/2688)\n",
      "Epoch: 6 | Batch_idx: 30 |  Loss: (0.9042) | Acc: (67.77%) (2689/3968)\n",
      "Epoch: 6 | Batch_idx: 40 |  Loss: (0.9123) | Acc: (67.61%) (3548/5248)\n",
      "Epoch: 6 | Batch_idx: 50 |  Loss: (0.9107) | Acc: (67.82%) (4427/6528)\n",
      "Epoch: 6 | Batch_idx: 60 |  Loss: (0.9051) | Acc: (67.82%) (5295/7808)\n",
      "Epoch: 6 | Batch_idx: 70 |  Loss: (0.9028) | Acc: (68.09%) (6188/9088)\n",
      "Epoch: 6 | Batch_idx: 80 |  Loss: (0.9025) | Acc: (68.21%) (7072/10368)\n",
      "Epoch: 6 | Batch_idx: 90 |  Loss: (0.9053) | Acc: (68.14%) (7937/11648)\n",
      "Epoch: 6 | Batch_idx: 100 |  Loss: (0.9058) | Acc: (68.02%) (8793/12928)\n",
      "Epoch: 6 | Batch_idx: 110 |  Loss: (0.9009) | Acc: (68.13%) (9680/14208)\n",
      "Epoch: 6 | Batch_idx: 120 |  Loss: (0.8972) | Acc: (68.25%) (10570/15488)\n",
      "Epoch: 6 | Batch_idx: 130 |  Loss: (0.8989) | Acc: (68.27%) (11447/16768)\n",
      "Epoch: 6 | Batch_idx: 140 |  Loss: (0.8946) | Acc: (68.40%) (12345/18048)\n",
      "Epoch: 6 | Batch_idx: 150 |  Loss: (0.8944) | Acc: (68.42%) (13225/19328)\n",
      "Epoch: 6 | Batch_idx: 160 |  Loss: (0.8949) | Acc: (68.33%) (14082/20608)\n",
      "Epoch: 6 | Batch_idx: 170 |  Loss: (0.8951) | Acc: (68.37%) (14965/21888)\n",
      "Epoch: 6 | Batch_idx: 180 |  Loss: (0.8965) | Acc: (68.37%) (15841/23168)\n",
      "Epoch: 6 | Batch_idx: 190 |  Loss: (0.8947) | Acc: (68.40%) (16723/24448)\n",
      "Epoch: 6 | Batch_idx: 200 |  Loss: (0.8947) | Acc: (68.39%) (17596/25728)\n",
      "Epoch: 6 | Batch_idx: 210 |  Loss: (0.8961) | Acc: (68.31%) (18449/27008)\n",
      "Epoch: 6 | Batch_idx: 220 |  Loss: (0.8955) | Acc: (68.28%) (19316/28288)\n",
      "Epoch: 6 | Batch_idx: 230 |  Loss: (0.8951) | Acc: (68.32%) (20202/29568)\n",
      "Epoch: 6 | Batch_idx: 240 |  Loss: (0.8920) | Acc: (68.49%) (21128/30848)\n",
      "Epoch: 6 | Batch_idx: 250 |  Loss: (0.8910) | Acc: (68.46%) (21996/32128)\n",
      "Epoch: 6 | Batch_idx: 260 |  Loss: (0.8898) | Acc: (68.48%) (22879/33408)\n",
      "Epoch: 6 | Batch_idx: 270 |  Loss: (0.8886) | Acc: (68.50%) (23761/34688)\n",
      "Epoch: 6 | Batch_idx: 280 |  Loss: (0.8886) | Acc: (68.52%) (24647/35968)\n",
      "Epoch: 6 | Batch_idx: 290 |  Loss: (0.8864) | Acc: (68.59%) (25549/37248)\n",
      "Epoch: 6 | Batch_idx: 300 |  Loss: (0.8839) | Acc: (68.68%) (26461/38528)\n",
      "Epoch: 6 | Batch_idx: 310 |  Loss: (0.8822) | Acc: (68.78%) (27380/39808)\n",
      "Epoch: 6 | Batch_idx: 320 |  Loss: (0.8814) | Acc: (68.77%) (28258/41088)\n",
      "Epoch: 6 | Batch_idx: 330 |  Loss: (0.8825) | Acc: (68.72%) (29116/42368)\n",
      "Epoch: 6 | Batch_idx: 340 |  Loss: (0.8814) | Acc: (68.71%) (29992/43648)\n",
      "Epoch: 6 | Batch_idx: 350 |  Loss: (0.8811) | Acc: (68.72%) (30873/44928)\n",
      "Epoch: 6 | Batch_idx: 360 |  Loss: (0.8799) | Acc: (68.72%) (31754/46208)\n",
      "Epoch: 6 | Batch_idx: 370 |  Loss: (0.8780) | Acc: (68.77%) (32657/47488)\n",
      "Epoch: 6 | Batch_idx: 380 |  Loss: (0.8771) | Acc: (68.77%) (33540/48768)\n",
      "Epoch: 6 | Batch_idx: 390 |  Loss: (0.8767) | Acc: (68.81%) (34404/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1130) | Acc: (65.22%) (6522/10000)\n",
      "Epoch: 7 | Batch_idx: 0 |  Loss: (0.7789) | Acc: (71.09%) (91/128)\n",
      "Epoch: 7 | Batch_idx: 10 |  Loss: (0.8047) | Acc: (71.24%) (1003/1408)\n",
      "Epoch: 7 | Batch_idx: 20 |  Loss: (0.7893) | Acc: (71.06%) (1910/2688)\n",
      "Epoch: 7 | Batch_idx: 30 |  Loss: (0.7968) | Acc: (71.22%) (2826/3968)\n",
      "Epoch: 7 | Batch_idx: 40 |  Loss: (0.8034) | Acc: (71.30%) (3742/5248)\n",
      "Epoch: 7 | Batch_idx: 50 |  Loss: (0.8072) | Acc: (71.23%) (4650/6528)\n",
      "Epoch: 7 | Batch_idx: 60 |  Loss: (0.8142) | Acc: (71.09%) (5551/7808)\n",
      "Epoch: 7 | Batch_idx: 70 |  Loss: (0.8244) | Acc: (70.71%) (6426/9088)\n",
      "Epoch: 7 | Batch_idx: 80 |  Loss: (0.8221) | Acc: (70.84%) (7345/10368)\n",
      "Epoch: 7 | Batch_idx: 90 |  Loss: (0.8242) | Acc: (70.81%) (8248/11648)\n",
      "Epoch: 7 | Batch_idx: 100 |  Loss: (0.8271) | Acc: (70.71%) (9142/12928)\n",
      "Epoch: 7 | Batch_idx: 110 |  Loss: (0.8273) | Acc: (70.73%) (10050/14208)\n",
      "Epoch: 7 | Batch_idx: 120 |  Loss: (0.8286) | Acc: (70.83%) (10970/15488)\n",
      "Epoch: 7 | Batch_idx: 130 |  Loss: (0.8272) | Acc: (70.89%) (11886/16768)\n",
      "Epoch: 7 | Batch_idx: 140 |  Loss: (0.8271) | Acc: (70.87%) (12791/18048)\n",
      "Epoch: 7 | Batch_idx: 150 |  Loss: (0.8282) | Acc: (70.86%) (13695/19328)\n",
      "Epoch: 7 | Batch_idx: 160 |  Loss: (0.8264) | Acc: (70.96%) (14624/20608)\n",
      "Epoch: 7 | Batch_idx: 170 |  Loss: (0.8244) | Acc: (71.04%) (15549/21888)\n",
      "Epoch: 7 | Batch_idx: 180 |  Loss: (0.8240) | Acc: (70.98%) (16445/23168)\n",
      "Epoch: 7 | Batch_idx: 190 |  Loss: (0.8231) | Acc: (70.94%) (17343/24448)\n",
      "Epoch: 7 | Batch_idx: 200 |  Loss: (0.8237) | Acc: (70.95%) (18255/25728)\n",
      "Epoch: 7 | Batch_idx: 210 |  Loss: (0.8238) | Acc: (70.93%) (19157/27008)\n",
      "Epoch: 7 | Batch_idx: 220 |  Loss: (0.8214) | Acc: (70.98%) (20078/28288)\n",
      "Epoch: 7 | Batch_idx: 230 |  Loss: (0.8221) | Acc: (70.92%) (20971/29568)\n",
      "Epoch: 7 | Batch_idx: 240 |  Loss: (0.8225) | Acc: (70.94%) (21883/30848)\n",
      "Epoch: 7 | Batch_idx: 250 |  Loss: (0.8211) | Acc: (70.97%) (22801/32128)\n",
      "Epoch: 7 | Batch_idx: 260 |  Loss: (0.8198) | Acc: (71.01%) (23724/33408)\n",
      "Epoch: 7 | Batch_idx: 270 |  Loss: (0.8191) | Acc: (71.02%) (24636/34688)\n",
      "Epoch: 7 | Batch_idx: 280 |  Loss: (0.8181) | Acc: (71.05%) (25555/35968)\n",
      "Epoch: 7 | Batch_idx: 290 |  Loss: (0.8178) | Acc: (71.02%) (26455/37248)\n",
      "Epoch: 7 | Batch_idx: 300 |  Loss: (0.8170) | Acc: (71.01%) (27357/38528)\n",
      "Epoch: 7 | Batch_idx: 310 |  Loss: (0.8164) | Acc: (71.05%) (28285/39808)\n",
      "Epoch: 7 | Batch_idx: 320 |  Loss: (0.8159) | Acc: (71.08%) (29206/41088)\n",
      "Epoch: 7 | Batch_idx: 330 |  Loss: (0.8156) | Acc: (71.09%) (30118/42368)\n",
      "Epoch: 7 | Batch_idx: 340 |  Loss: (0.8147) | Acc: (71.10%) (31032/43648)\n",
      "Epoch: 7 | Batch_idx: 350 |  Loss: (0.8146) | Acc: (71.14%) (31963/44928)\n",
      "Epoch: 7 | Batch_idx: 360 |  Loss: (0.8140) | Acc: (71.16%) (32882/46208)\n",
      "Epoch: 7 | Batch_idx: 370 |  Loss: (0.8146) | Acc: (71.15%) (33789/47488)\n",
      "Epoch: 7 | Batch_idx: 380 |  Loss: (0.8142) | Acc: (71.20%) (34723/48768)\n",
      "Epoch: 7 | Batch_idx: 390 |  Loss: (0.8129) | Acc: (71.25%) (35626/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.2346) | Acc: (61.59%) (6159/10000)\n",
      "Epoch: 8 | Batch_idx: 0 |  Loss: (0.8621) | Acc: (69.53%) (89/128)\n",
      "Epoch: 8 | Batch_idx: 10 |  Loss: (0.7552) | Acc: (73.51%) (1035/1408)\n",
      "Epoch: 8 | Batch_idx: 20 |  Loss: (0.7487) | Acc: (73.55%) (1977/2688)\n",
      "Epoch: 8 | Batch_idx: 30 |  Loss: (0.7597) | Acc: (72.78%) (2888/3968)\n",
      "Epoch: 8 | Batch_idx: 40 |  Loss: (0.7623) | Acc: (72.64%) (3812/5248)\n",
      "Epoch: 8 | Batch_idx: 50 |  Loss: (0.7590) | Acc: (72.81%) (4753/6528)\n",
      "Epoch: 8 | Batch_idx: 60 |  Loss: (0.7607) | Acc: (72.64%) (5672/7808)\n",
      "Epoch: 8 | Batch_idx: 70 |  Loss: (0.7676) | Acc: (72.59%) (6597/9088)\n",
      "Epoch: 8 | Batch_idx: 80 |  Loss: (0.7691) | Acc: (72.44%) (7511/10368)\n",
      "Epoch: 8 | Batch_idx: 90 |  Loss: (0.7662) | Acc: (72.59%) (8455/11648)\n",
      "Epoch: 8 | Batch_idx: 100 |  Loss: (0.7724) | Acc: (72.30%) (9347/12928)\n",
      "Epoch: 8 | Batch_idx: 110 |  Loss: (0.7718) | Acc: (72.46%) (10295/14208)\n",
      "Epoch: 8 | Batch_idx: 120 |  Loss: (0.7744) | Acc: (72.42%) (11216/15488)\n",
      "Epoch: 8 | Batch_idx: 130 |  Loss: (0.7750) | Acc: (72.36%) (12134/16768)\n",
      "Epoch: 8 | Batch_idx: 140 |  Loss: (0.7766) | Acc: (72.39%) (13065/18048)\n",
      "Epoch: 8 | Batch_idx: 150 |  Loss: (0.7732) | Acc: (72.57%) (14027/19328)\n",
      "Epoch: 8 | Batch_idx: 160 |  Loss: (0.7708) | Acc: (72.73%) (14988/20608)\n",
      "Epoch: 8 | Batch_idx: 170 |  Loss: (0.7695) | Acc: (72.74%) (15921/21888)\n",
      "Epoch: 8 | Batch_idx: 180 |  Loss: (0.7718) | Acc: (72.66%) (16833/23168)\n",
      "Epoch: 8 | Batch_idx: 190 |  Loss: (0.7736) | Acc: (72.58%) (17744/24448)\n",
      "Epoch: 8 | Batch_idx: 200 |  Loss: (0.7719) | Acc: (72.68%) (18700/25728)\n",
      "Epoch: 8 | Batch_idx: 210 |  Loss: (0.7725) | Acc: (72.71%) (19638/27008)\n",
      "Epoch: 8 | Batch_idx: 220 |  Loss: (0.7711) | Acc: (72.77%) (20584/28288)\n",
      "Epoch: 8 | Batch_idx: 230 |  Loss: (0.7681) | Acc: (72.90%) (21554/29568)\n",
      "Epoch: 8 | Batch_idx: 240 |  Loss: (0.7674) | Acc: (72.95%) (22503/30848)\n",
      "Epoch: 8 | Batch_idx: 250 |  Loss: (0.7668) | Acc: (72.96%) (23442/32128)\n",
      "Epoch: 8 | Batch_idx: 260 |  Loss: (0.7660) | Acc: (73.01%) (24391/33408)\n",
      "Epoch: 8 | Batch_idx: 270 |  Loss: (0.7676) | Acc: (72.92%) (25296/34688)\n",
      "Epoch: 8 | Batch_idx: 280 |  Loss: (0.7685) | Acc: (72.91%) (26223/35968)\n",
      "Epoch: 8 | Batch_idx: 290 |  Loss: (0.7671) | Acc: (72.94%) (27168/37248)\n",
      "Epoch: 8 | Batch_idx: 300 |  Loss: (0.7654) | Acc: (73.00%) (28125/38528)\n",
      "Epoch: 8 | Batch_idx: 310 |  Loss: (0.7655) | Acc: (72.99%) (29056/39808)\n",
      "Epoch: 8 | Batch_idx: 320 |  Loss: (0.7644) | Acc: (73.03%) (30006/41088)\n",
      "Epoch: 8 | Batch_idx: 330 |  Loss: (0.7656) | Acc: (72.98%) (30919/42368)\n",
      "Epoch: 8 | Batch_idx: 340 |  Loss: (0.7661) | Acc: (72.96%) (31845/43648)\n",
      "Epoch: 8 | Batch_idx: 350 |  Loss: (0.7646) | Acc: (73.02%) (32805/44928)\n",
      "Epoch: 8 | Batch_idx: 360 |  Loss: (0.7636) | Acc: (73.08%) (33769/46208)\n",
      "Epoch: 8 | Batch_idx: 370 |  Loss: (0.7618) | Acc: (73.12%) (34723/47488)\n",
      "Epoch: 8 | Batch_idx: 380 |  Loss: (0.7610) | Acc: (73.13%) (35663/48768)\n",
      "Epoch: 8 | Batch_idx: 390 |  Loss: (0.7610) | Acc: (73.14%) (36572/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1101) | Acc: (65.70%) (6570/10000)\n",
      "Epoch: 9 | Batch_idx: 0 |  Loss: (0.7200) | Acc: (77.34%) (99/128)\n",
      "Epoch: 9 | Batch_idx: 10 |  Loss: (0.7120) | Acc: (76.21%) (1073/1408)\n",
      "Epoch: 9 | Batch_idx: 20 |  Loss: (0.7165) | Acc: (75.41%) (2027/2688)\n",
      "Epoch: 9 | Batch_idx: 30 |  Loss: (0.7120) | Acc: (75.40%) (2992/3968)\n",
      "Epoch: 9 | Batch_idx: 40 |  Loss: (0.7093) | Acc: (75.32%) (3953/5248)\n",
      "Epoch: 9 | Batch_idx: 50 |  Loss: (0.7185) | Acc: (75.17%) (4907/6528)\n",
      "Epoch: 9 | Batch_idx: 60 |  Loss: (0.7168) | Acc: (75.18%) (5870/7808)\n",
      "Epoch: 9 | Batch_idx: 70 |  Loss: (0.7169) | Acc: (75.17%) (6831/9088)\n",
      "Epoch: 9 | Batch_idx: 80 |  Loss: (0.7207) | Acc: (75.07%) (7783/10368)\n",
      "Epoch: 9 | Batch_idx: 90 |  Loss: (0.7189) | Acc: (75.02%) (8738/11648)\n",
      "Epoch: 9 | Batch_idx: 100 |  Loss: (0.7197) | Acc: (74.98%) (9694/12928)\n",
      "Epoch: 9 | Batch_idx: 110 |  Loss: (0.7178) | Acc: (75.06%) (10665/14208)\n",
      "Epoch: 9 | Batch_idx: 120 |  Loss: (0.7187) | Acc: (75.01%) (11617/15488)\n",
      "Epoch: 9 | Batch_idx: 130 |  Loss: (0.7207) | Acc: (74.86%) (12552/16768)\n",
      "Epoch: 9 | Batch_idx: 140 |  Loss: (0.7214) | Acc: (74.82%) (13503/18048)\n",
      "Epoch: 9 | Batch_idx: 150 |  Loss: (0.7243) | Acc: (74.77%) (14452/19328)\n",
      "Epoch: 9 | Batch_idx: 160 |  Loss: (0.7231) | Acc: (74.83%) (15421/20608)\n",
      "Epoch: 9 | Batch_idx: 170 |  Loss: (0.7200) | Acc: (74.92%) (16399/21888)\n",
      "Epoch: 9 | Batch_idx: 180 |  Loss: (0.7202) | Acc: (74.96%) (17366/23168)\n",
      "Epoch: 9 | Batch_idx: 190 |  Loss: (0.7187) | Acc: (75.01%) (18338/24448)\n",
      "Epoch: 9 | Batch_idx: 200 |  Loss: (0.7192) | Acc: (75.03%) (19305/25728)\n",
      "Epoch: 9 | Batch_idx: 210 |  Loss: (0.7169) | Acc: (75.06%) (20273/27008)\n",
      "Epoch: 9 | Batch_idx: 220 |  Loss: (0.7173) | Acc: (75.05%) (21229/28288)\n",
      "Epoch: 9 | Batch_idx: 230 |  Loss: (0.7174) | Acc: (75.00%) (22177/29568)\n",
      "Epoch: 9 | Batch_idx: 240 |  Loss: (0.7175) | Acc: (74.99%) (23133/30848)\n",
      "Epoch: 9 | Batch_idx: 250 |  Loss: (0.7167) | Acc: (75.04%) (24109/32128)\n",
      "Epoch: 9 | Batch_idx: 260 |  Loss: (0.7162) | Acc: (75.04%) (25071/33408)\n",
      "Epoch: 9 | Batch_idx: 270 |  Loss: (0.7150) | Acc: (75.01%) (26018/34688)\n",
      "Epoch: 9 | Batch_idx: 280 |  Loss: (0.7137) | Acc: (75.07%) (27001/35968)\n",
      "Epoch: 9 | Batch_idx: 290 |  Loss: (0.7131) | Acc: (75.06%) (27958/37248)\n",
      "Epoch: 9 | Batch_idx: 300 |  Loss: (0.7115) | Acc: (75.09%) (28931/38528)\n",
      "Epoch: 9 | Batch_idx: 310 |  Loss: (0.7118) | Acc: (75.10%) (29894/39808)\n",
      "Epoch: 9 | Batch_idx: 320 |  Loss: (0.7121) | Acc: (75.08%) (30847/41088)\n",
      "Epoch: 9 | Batch_idx: 330 |  Loss: (0.7109) | Acc: (75.13%) (31829/42368)\n",
      "Epoch: 9 | Batch_idx: 340 |  Loss: (0.7094) | Acc: (75.15%) (32801/43648)\n",
      "Epoch: 9 | Batch_idx: 350 |  Loss: (0.7108) | Acc: (75.13%) (33754/44928)\n",
      "Epoch: 9 | Batch_idx: 360 |  Loss: (0.7096) | Acc: (75.15%) (34724/46208)\n",
      "Epoch: 9 | Batch_idx: 370 |  Loss: (0.7092) | Acc: (75.15%) (35685/47488)\n",
      "Epoch: 9 | Batch_idx: 380 |  Loss: (0.7096) | Acc: (75.12%) (36636/48768)\n",
      "Epoch: 9 | Batch_idx: 390 |  Loss: (0.7101) | Acc: (75.12%) (37558/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9371) | Acc: (71.84%) (7184/10000)\n",
      "Epoch: 10 | Batch_idx: 0 |  Loss: (0.6375) | Acc: (73.44%) (94/128)\n",
      "Epoch: 10 | Batch_idx: 10 |  Loss: (0.6766) | Acc: (76.07%) (1071/1408)\n",
      "Epoch: 10 | Batch_idx: 20 |  Loss: (0.6709) | Acc: (76.45%) (2055/2688)\n",
      "Epoch: 10 | Batch_idx: 30 |  Loss: (0.6760) | Acc: (75.81%) (3008/3968)\n",
      "Epoch: 10 | Batch_idx: 40 |  Loss: (0.6852) | Acc: (75.51%) (3963/5248)\n",
      "Epoch: 10 | Batch_idx: 50 |  Loss: (0.6776) | Acc: (76.07%) (4966/6528)\n",
      "Epoch: 10 | Batch_idx: 60 |  Loss: (0.6750) | Acc: (76.46%) (5970/7808)\n",
      "Epoch: 10 | Batch_idx: 70 |  Loss: (0.6694) | Acc: (76.71%) (6971/9088)\n",
      "Epoch: 10 | Batch_idx: 80 |  Loss: (0.6728) | Acc: (76.66%) (7948/10368)\n",
      "Epoch: 10 | Batch_idx: 90 |  Loss: (0.6735) | Acc: (76.55%) (8917/11648)\n",
      "Epoch: 10 | Batch_idx: 100 |  Loss: (0.6766) | Acc: (76.38%) (9875/12928)\n",
      "Epoch: 10 | Batch_idx: 110 |  Loss: (0.6726) | Acc: (76.53%) (10873/14208)\n",
      "Epoch: 10 | Batch_idx: 120 |  Loss: (0.6719) | Acc: (76.52%) (11851/15488)\n",
      "Epoch: 10 | Batch_idx: 130 |  Loss: (0.6708) | Acc: (76.62%) (12848/16768)\n",
      "Epoch: 10 | Batch_idx: 140 |  Loss: (0.6728) | Acc: (76.56%) (13817/18048)\n",
      "Epoch: 10 | Batch_idx: 150 |  Loss: (0.6750) | Acc: (76.43%) (14773/19328)\n",
      "Epoch: 10 | Batch_idx: 160 |  Loss: (0.6755) | Acc: (76.40%) (15744/20608)\n",
      "Epoch: 10 | Batch_idx: 170 |  Loss: (0.6735) | Acc: (76.47%) (16737/21888)\n",
      "Epoch: 10 | Batch_idx: 180 |  Loss: (0.6745) | Acc: (76.38%) (17696/23168)\n",
      "Epoch: 10 | Batch_idx: 190 |  Loss: (0.6747) | Acc: (76.40%) (18678/24448)\n",
      "Epoch: 10 | Batch_idx: 200 |  Loss: (0.6751) | Acc: (76.41%) (19660/25728)\n",
      "Epoch: 10 | Batch_idx: 210 |  Loss: (0.6734) | Acc: (76.49%) (20658/27008)\n",
      "Epoch: 10 | Batch_idx: 220 |  Loss: (0.6731) | Acc: (76.50%) (21639/28288)\n",
      "Epoch: 10 | Batch_idx: 230 |  Loss: (0.6716) | Acc: (76.55%) (22633/29568)\n",
      "Epoch: 10 | Batch_idx: 240 |  Loss: (0.6703) | Acc: (76.62%) (23636/30848)\n",
      "Epoch: 10 | Batch_idx: 250 |  Loss: (0.6706) | Acc: (76.61%) (24612/32128)\n",
      "Epoch: 10 | Batch_idx: 260 |  Loss: (0.6698) | Acc: (76.62%) (25596/33408)\n",
      "Epoch: 10 | Batch_idx: 270 |  Loss: (0.6685) | Acc: (76.65%) (26588/34688)\n",
      "Epoch: 10 | Batch_idx: 280 |  Loss: (0.6688) | Acc: (76.67%) (27578/35968)\n",
      "Epoch: 10 | Batch_idx: 290 |  Loss: (0.6678) | Acc: (76.69%) (28566/37248)\n",
      "Epoch: 10 | Batch_idx: 300 |  Loss: (0.6674) | Acc: (76.71%) (29555/38528)\n",
      "Epoch: 10 | Batch_idx: 310 |  Loss: (0.6650) | Acc: (76.81%) (30577/39808)\n",
      "Epoch: 10 | Batch_idx: 320 |  Loss: (0.6626) | Acc: (76.88%) (31589/41088)\n",
      "Epoch: 10 | Batch_idx: 330 |  Loss: (0.6624) | Acc: (76.86%) (32562/42368)\n",
      "Epoch: 10 | Batch_idx: 340 |  Loss: (0.6608) | Acc: (76.89%) (33562/43648)\n",
      "Epoch: 10 | Batch_idx: 350 |  Loss: (0.6611) | Acc: (76.91%) (34554/44928)\n",
      "Epoch: 10 | Batch_idx: 360 |  Loss: (0.6603) | Acc: (76.93%) (35548/46208)\n",
      "Epoch: 10 | Batch_idx: 370 |  Loss: (0.6596) | Acc: (76.94%) (36536/47488)\n",
      "Epoch: 10 | Batch_idx: 380 |  Loss: (0.6600) | Acc: (76.92%) (37512/48768)\n",
      "Epoch: 10 | Batch_idx: 390 |  Loss: (0.6608) | Acc: (76.91%) (38454/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9669) | Acc: (70.16%) (7016/10000)\n",
      "Epoch: 11 | Batch_idx: 0 |  Loss: (0.5835) | Acc: (77.34%) (99/128)\n",
      "Epoch: 11 | Batch_idx: 10 |  Loss: (0.6320) | Acc: (77.20%) (1087/1408)\n",
      "Epoch: 11 | Batch_idx: 20 |  Loss: (0.6119) | Acc: (78.31%) (2105/2688)\n",
      "Epoch: 11 | Batch_idx: 30 |  Loss: (0.6337) | Acc: (77.32%) (3068/3968)\n",
      "Epoch: 11 | Batch_idx: 40 |  Loss: (0.6393) | Acc: (77.06%) (4044/5248)\n",
      "Epoch: 11 | Batch_idx: 50 |  Loss: (0.6294) | Acc: (77.56%) (5063/6528)\n",
      "Epoch: 11 | Batch_idx: 60 |  Loss: (0.6202) | Acc: (78.00%) (6090/7808)\n",
      "Epoch: 11 | Batch_idx: 70 |  Loss: (0.6226) | Acc: (78.10%) (7098/9088)\n",
      "Epoch: 11 | Batch_idx: 80 |  Loss: (0.6263) | Acc: (78.05%) (8092/10368)\n",
      "Epoch: 11 | Batch_idx: 90 |  Loss: (0.6266) | Acc: (78.07%) (9094/11648)\n",
      "Epoch: 11 | Batch_idx: 100 |  Loss: (0.6227) | Acc: (78.17%) (10106/12928)\n",
      "Epoch: 11 | Batch_idx: 110 |  Loss: (0.6227) | Acc: (78.27%) (11120/14208)\n",
      "Epoch: 11 | Batch_idx: 120 |  Loss: (0.6248) | Acc: (78.23%) (12116/15488)\n",
      "Epoch: 11 | Batch_idx: 130 |  Loss: (0.6221) | Acc: (78.30%) (13129/16768)\n",
      "Epoch: 11 | Batch_idx: 140 |  Loss: (0.6183) | Acc: (78.46%) (14161/18048)\n",
      "Epoch: 11 | Batch_idx: 150 |  Loss: (0.6188) | Acc: (78.50%) (15172/19328)\n",
      "Epoch: 11 | Batch_idx: 160 |  Loss: (0.6197) | Acc: (78.46%) (16170/20608)\n",
      "Epoch: 11 | Batch_idx: 170 |  Loss: (0.6209) | Acc: (78.39%) (17159/21888)\n",
      "Epoch: 11 | Batch_idx: 180 |  Loss: (0.6208) | Acc: (78.41%) (18165/23168)\n",
      "Epoch: 11 | Batch_idx: 190 |  Loss: (0.6198) | Acc: (78.44%) (19176/24448)\n",
      "Epoch: 11 | Batch_idx: 200 |  Loss: (0.6187) | Acc: (78.49%) (20195/25728)\n",
      "Epoch: 11 | Batch_idx: 210 |  Loss: (0.6184) | Acc: (78.44%) (21185/27008)\n",
      "Epoch: 11 | Batch_idx: 220 |  Loss: (0.6163) | Acc: (78.49%) (22204/28288)\n",
      "Epoch: 11 | Batch_idx: 230 |  Loss: (0.6181) | Acc: (78.48%) (23206/29568)\n",
      "Epoch: 11 | Batch_idx: 240 |  Loss: (0.6186) | Acc: (78.47%) (24205/30848)\n",
      "Epoch: 11 | Batch_idx: 250 |  Loss: (0.6174) | Acc: (78.49%) (25217/32128)\n",
      "Epoch: 11 | Batch_idx: 260 |  Loss: (0.6166) | Acc: (78.52%) (26231/33408)\n",
      "Epoch: 11 | Batch_idx: 270 |  Loss: (0.6166) | Acc: (78.53%) (27242/34688)\n",
      "Epoch: 11 | Batch_idx: 280 |  Loss: (0.6166) | Acc: (78.58%) (28265/35968)\n",
      "Epoch: 11 | Batch_idx: 290 |  Loss: (0.6165) | Acc: (78.58%) (29269/37248)\n",
      "Epoch: 11 | Batch_idx: 300 |  Loss: (0.6169) | Acc: (78.54%) (30258/38528)\n",
      "Epoch: 11 | Batch_idx: 310 |  Loss: (0.6157) | Acc: (78.57%) (31277/39808)\n",
      "Epoch: 11 | Batch_idx: 320 |  Loss: (0.6167) | Acc: (78.54%) (32269/41088)\n",
      "Epoch: 11 | Batch_idx: 330 |  Loss: (0.6173) | Acc: (78.53%) (33270/42368)\n",
      "Epoch: 11 | Batch_idx: 340 |  Loss: (0.6176) | Acc: (78.49%) (34261/43648)\n",
      "Epoch: 11 | Batch_idx: 350 |  Loss: (0.6178) | Acc: (78.49%) (35262/44928)\n",
      "Epoch: 11 | Batch_idx: 360 |  Loss: (0.6180) | Acc: (78.45%) (36248/46208)\n",
      "Epoch: 11 | Batch_idx: 370 |  Loss: (0.6169) | Acc: (78.50%) (37276/47488)\n",
      "Epoch: 11 | Batch_idx: 380 |  Loss: (0.6166) | Acc: (78.49%) (38278/48768)\n",
      "Epoch: 11 | Batch_idx: 390 |  Loss: (0.6168) | Acc: (78.44%) (39222/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1017) | Acc: (66.79%) (6679/10000)\n",
      "Epoch: 12 | Batch_idx: 0 |  Loss: (0.5118) | Acc: (83.59%) (107/128)\n",
      "Epoch: 12 | Batch_idx: 10 |  Loss: (0.5959) | Acc: (79.33%) (1117/1408)\n",
      "Epoch: 12 | Batch_idx: 20 |  Loss: (0.5745) | Acc: (80.02%) (2151/2688)\n",
      "Epoch: 12 | Batch_idx: 30 |  Loss: (0.5774) | Acc: (79.74%) (3164/3968)\n",
      "Epoch: 12 | Batch_idx: 40 |  Loss: (0.5826) | Acc: (79.84%) (4190/5248)\n",
      "Epoch: 12 | Batch_idx: 50 |  Loss: (0.5837) | Acc: (79.64%) (5199/6528)\n",
      "Epoch: 12 | Batch_idx: 60 |  Loss: (0.5819) | Acc: (79.67%) (6221/7808)\n",
      "Epoch: 12 | Batch_idx: 70 |  Loss: (0.5817) | Acc: (79.67%) (7240/9088)\n",
      "Epoch: 12 | Batch_idx: 80 |  Loss: (0.5808) | Acc: (79.75%) (8268/10368)\n",
      "Epoch: 12 | Batch_idx: 90 |  Loss: (0.5775) | Acc: (79.88%) (9304/11648)\n",
      "Epoch: 12 | Batch_idx: 100 |  Loss: (0.5795) | Acc: (79.80%) (10316/12928)\n",
      "Epoch: 12 | Batch_idx: 110 |  Loss: (0.5764) | Acc: (79.95%) (11360/14208)\n",
      "Epoch: 12 | Batch_idx: 120 |  Loss: (0.5739) | Acc: (80.05%) (12398/15488)\n",
      "Epoch: 12 | Batch_idx: 130 |  Loss: (0.5769) | Acc: (79.93%) (13402/16768)\n",
      "Epoch: 12 | Batch_idx: 140 |  Loss: (0.5769) | Acc: (79.97%) (14433/18048)\n",
      "Epoch: 12 | Batch_idx: 150 |  Loss: (0.5766) | Acc: (80.05%) (15473/19328)\n",
      "Epoch: 12 | Batch_idx: 160 |  Loss: (0.5770) | Acc: (79.99%) (16484/20608)\n",
      "Epoch: 12 | Batch_idx: 170 |  Loss: (0.5760) | Acc: (80.03%) (17516/21888)\n",
      "Epoch: 12 | Batch_idx: 180 |  Loss: (0.5766) | Acc: (79.97%) (18528/23168)\n",
      "Epoch: 12 | Batch_idx: 190 |  Loss: (0.5745) | Acc: (80.03%) (19566/24448)\n",
      "Epoch: 12 | Batch_idx: 200 |  Loss: (0.5757) | Acc: (80.03%) (20589/25728)\n",
      "Epoch: 12 | Batch_idx: 210 |  Loss: (0.5769) | Acc: (79.95%) (21593/27008)\n",
      "Epoch: 12 | Batch_idx: 220 |  Loss: (0.5769) | Acc: (79.89%) (22600/28288)\n",
      "Epoch: 12 | Batch_idx: 230 |  Loss: (0.5773) | Acc: (79.86%) (23613/29568)\n",
      "Epoch: 12 | Batch_idx: 240 |  Loss: (0.5784) | Acc: (79.81%) (24619/30848)\n",
      "Epoch: 12 | Batch_idx: 250 |  Loss: (0.5784) | Acc: (79.85%) (25654/32128)\n",
      "Epoch: 12 | Batch_idx: 260 |  Loss: (0.5790) | Acc: (79.79%) (26655/33408)\n",
      "Epoch: 12 | Batch_idx: 270 |  Loss: (0.5785) | Acc: (79.83%) (27690/34688)\n",
      "Epoch: 12 | Batch_idx: 280 |  Loss: (0.5773) | Acc: (79.88%) (28733/35968)\n",
      "Epoch: 12 | Batch_idx: 290 |  Loss: (0.5787) | Acc: (79.81%) (29729/37248)\n",
      "Epoch: 12 | Batch_idx: 300 |  Loss: (0.5789) | Acc: (79.78%) (30736/38528)\n",
      "Epoch: 12 | Batch_idx: 310 |  Loss: (0.5782) | Acc: (79.82%) (31774/39808)\n",
      "Epoch: 12 | Batch_idx: 320 |  Loss: (0.5789) | Acc: (79.81%) (32792/41088)\n",
      "Epoch: 12 | Batch_idx: 330 |  Loss: (0.5787) | Acc: (79.83%) (33822/42368)\n",
      "Epoch: 12 | Batch_idx: 340 |  Loss: (0.5792) | Acc: (79.83%) (34846/43648)\n",
      "Epoch: 12 | Batch_idx: 350 |  Loss: (0.5790) | Acc: (79.81%) (35859/44928)\n",
      "Epoch: 12 | Batch_idx: 360 |  Loss: (0.5803) | Acc: (79.76%) (36857/46208)\n",
      "Epoch: 12 | Batch_idx: 370 |  Loss: (0.5804) | Acc: (79.74%) (37867/47488)\n",
      "Epoch: 12 | Batch_idx: 380 |  Loss: (0.5793) | Acc: (79.80%) (38916/48768)\n",
      "Epoch: 12 | Batch_idx: 390 |  Loss: (0.5809) | Acc: (79.75%) (39877/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8920) | Acc: (72.89%) (7289/10000)\n",
      "Epoch: 13 | Batch_idx: 0 |  Loss: (0.6495) | Acc: (80.47%) (103/128)\n",
      "Epoch: 13 | Batch_idx: 10 |  Loss: (0.5638) | Acc: (80.54%) (1134/1408)\n",
      "Epoch: 13 | Batch_idx: 20 |  Loss: (0.5635) | Acc: (80.73%) (2170/2688)\n",
      "Epoch: 13 | Batch_idx: 30 |  Loss: (0.5532) | Acc: (81.10%) (3218/3968)\n",
      "Epoch: 13 | Batch_idx: 40 |  Loss: (0.5490) | Acc: (81.46%) (4275/5248)\n",
      "Epoch: 13 | Batch_idx: 50 |  Loss: (0.5447) | Acc: (81.59%) (5326/6528)\n",
      "Epoch: 13 | Batch_idx: 60 |  Loss: (0.5441) | Acc: (81.48%) (6362/7808)\n",
      "Epoch: 13 | Batch_idx: 70 |  Loss: (0.5449) | Acc: (81.28%) (7387/9088)\n",
      "Epoch: 13 | Batch_idx: 80 |  Loss: (0.5465) | Acc: (81.10%) (8408/10368)\n",
      "Epoch: 13 | Batch_idx: 90 |  Loss: (0.5426) | Acc: (81.30%) (9470/11648)\n",
      "Epoch: 13 | Batch_idx: 100 |  Loss: (0.5419) | Acc: (81.30%) (10510/12928)\n",
      "Epoch: 13 | Batch_idx: 110 |  Loss: (0.5445) | Acc: (81.10%) (11523/14208)\n",
      "Epoch: 13 | Batch_idx: 120 |  Loss: (0.5414) | Acc: (81.23%) (12581/15488)\n",
      "Epoch: 13 | Batch_idx: 130 |  Loss: (0.5411) | Acc: (81.24%) (13623/16768)\n",
      "Epoch: 13 | Batch_idx: 140 |  Loss: (0.5438) | Acc: (81.19%) (14653/18048)\n",
      "Epoch: 13 | Batch_idx: 150 |  Loss: (0.5461) | Acc: (81.07%) (15669/19328)\n",
      "Epoch: 13 | Batch_idx: 160 |  Loss: (0.5453) | Acc: (81.12%) (16717/20608)\n",
      "Epoch: 13 | Batch_idx: 170 |  Loss: (0.5418) | Acc: (81.23%) (17780/21888)\n",
      "Epoch: 13 | Batch_idx: 180 |  Loss: (0.5402) | Acc: (81.25%) (18824/23168)\n",
      "Epoch: 13 | Batch_idx: 190 |  Loss: (0.5375) | Acc: (81.38%) (19895/24448)\n",
      "Epoch: 13 | Batch_idx: 200 |  Loss: (0.5390) | Acc: (81.29%) (20914/25728)\n",
      "Epoch: 13 | Batch_idx: 210 |  Loss: (0.5384) | Acc: (81.26%) (21947/27008)\n",
      "Epoch: 13 | Batch_idx: 220 |  Loss: (0.5372) | Acc: (81.37%) (23018/28288)\n",
      "Epoch: 13 | Batch_idx: 230 |  Loss: (0.5393) | Acc: (81.29%) (24036/29568)\n",
      "Epoch: 13 | Batch_idx: 240 |  Loss: (0.5403) | Acc: (81.28%) (25072/30848)\n",
      "Epoch: 13 | Batch_idx: 250 |  Loss: (0.5402) | Acc: (81.27%) (26111/32128)\n",
      "Epoch: 13 | Batch_idx: 260 |  Loss: (0.5402) | Acc: (81.28%) (27155/33408)\n",
      "Epoch: 13 | Batch_idx: 270 |  Loss: (0.5384) | Acc: (81.40%) (28236/34688)\n",
      "Epoch: 13 | Batch_idx: 280 |  Loss: (0.5372) | Acc: (81.48%) (29306/35968)\n",
      "Epoch: 13 | Batch_idx: 290 |  Loss: (0.5390) | Acc: (81.46%) (30341/37248)\n",
      "Epoch: 13 | Batch_idx: 300 |  Loss: (0.5397) | Acc: (81.39%) (31359/38528)\n",
      "Epoch: 13 | Batch_idx: 310 |  Loss: (0.5410) | Acc: (81.37%) (32391/39808)\n",
      "Epoch: 13 | Batch_idx: 320 |  Loss: (0.5410) | Acc: (81.38%) (33439/41088)\n",
      "Epoch: 13 | Batch_idx: 330 |  Loss: (0.5421) | Acc: (81.34%) (34464/42368)\n",
      "Epoch: 13 | Batch_idx: 340 |  Loss: (0.5420) | Acc: (81.37%) (35516/43648)\n",
      "Epoch: 13 | Batch_idx: 350 |  Loss: (0.5418) | Acc: (81.36%) (36554/44928)\n",
      "Epoch: 13 | Batch_idx: 360 |  Loss: (0.5415) | Acc: (81.37%) (37600/46208)\n",
      "Epoch: 13 | Batch_idx: 370 |  Loss: (0.5419) | Acc: (81.36%) (38637/47488)\n",
      "Epoch: 13 | Batch_idx: 380 |  Loss: (0.5408) | Acc: (81.37%) (39684/48768)\n",
      "Epoch: 13 | Batch_idx: 390 |  Loss: (0.5403) | Acc: (81.39%) (40695/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8146) | Acc: (75.09%) (7509/10000)\n",
      "Epoch: 14 | Batch_idx: 0 |  Loss: (0.4097) | Acc: (85.16%) (109/128)\n",
      "Epoch: 14 | Batch_idx: 10 |  Loss: (0.4863) | Acc: (83.45%) (1175/1408)\n",
      "Epoch: 14 | Batch_idx: 20 |  Loss: (0.5165) | Acc: (82.55%) (2219/2688)\n",
      "Epoch: 14 | Batch_idx: 30 |  Loss: (0.5233) | Acc: (82.28%) (3265/3968)\n",
      "Epoch: 14 | Batch_idx: 40 |  Loss: (0.5340) | Acc: (81.73%) (4289/5248)\n",
      "Epoch: 14 | Batch_idx: 50 |  Loss: (0.5283) | Acc: (81.79%) (5339/6528)\n",
      "Epoch: 14 | Batch_idx: 60 |  Loss: (0.5280) | Acc: (81.72%) (6381/7808)\n",
      "Epoch: 14 | Batch_idx: 70 |  Loss: (0.5234) | Acc: (81.80%) (7434/9088)\n",
      "Epoch: 14 | Batch_idx: 80 |  Loss: (0.5253) | Acc: (81.74%) (8475/10368)\n",
      "Epoch: 14 | Batch_idx: 90 |  Loss: (0.5259) | Acc: (81.85%) (9534/11648)\n",
      "Epoch: 14 | Batch_idx: 100 |  Loss: (0.5266) | Acc: (81.79%) (10574/12928)\n",
      "Epoch: 14 | Batch_idx: 110 |  Loss: (0.5222) | Acc: (81.89%) (11635/14208)\n",
      "Epoch: 14 | Batch_idx: 120 |  Loss: (0.5192) | Acc: (82.02%) (12703/15488)\n",
      "Epoch: 14 | Batch_idx: 130 |  Loss: (0.5194) | Acc: (82.00%) (13749/16768)\n",
      "Epoch: 14 | Batch_idx: 140 |  Loss: (0.5211) | Acc: (81.94%) (14788/18048)\n",
      "Epoch: 14 | Batch_idx: 150 |  Loss: (0.5209) | Acc: (81.94%) (15838/19328)\n",
      "Epoch: 14 | Batch_idx: 160 |  Loss: (0.5191) | Acc: (81.96%) (16891/20608)\n",
      "Epoch: 14 | Batch_idx: 170 |  Loss: (0.5198) | Acc: (81.94%) (17936/21888)\n",
      "Epoch: 14 | Batch_idx: 180 |  Loss: (0.5201) | Acc: (81.97%) (18991/23168)\n",
      "Epoch: 14 | Batch_idx: 190 |  Loss: (0.5197) | Acc: (82.00%) (20047/24448)\n",
      "Epoch: 14 | Batch_idx: 200 |  Loss: (0.5197) | Acc: (82.04%) (21107/25728)\n",
      "Epoch: 14 | Batch_idx: 210 |  Loss: (0.5182) | Acc: (82.09%) (22171/27008)\n",
      "Epoch: 14 | Batch_idx: 220 |  Loss: (0.5168) | Acc: (82.14%) (23236/28288)\n",
      "Epoch: 14 | Batch_idx: 230 |  Loss: (0.5163) | Acc: (82.13%) (24284/29568)\n",
      "Epoch: 14 | Batch_idx: 240 |  Loss: (0.5146) | Acc: (82.23%) (25366/30848)\n",
      "Epoch: 14 | Batch_idx: 250 |  Loss: (0.5141) | Acc: (82.28%) (26435/32128)\n",
      "Epoch: 14 | Batch_idx: 260 |  Loss: (0.5135) | Acc: (82.27%) (27486/33408)\n",
      "Epoch: 14 | Batch_idx: 270 |  Loss: (0.5122) | Acc: (82.32%) (28556/34688)\n",
      "Epoch: 14 | Batch_idx: 280 |  Loss: (0.5126) | Acc: (82.34%) (29617/35968)\n",
      "Epoch: 14 | Batch_idx: 290 |  Loss: (0.5112) | Acc: (82.35%) (30672/37248)\n",
      "Epoch: 14 | Batch_idx: 300 |  Loss: (0.5110) | Acc: (82.33%) (31721/38528)\n",
      "Epoch: 14 | Batch_idx: 310 |  Loss: (0.5121) | Acc: (82.30%) (32760/39808)\n",
      "Epoch: 14 | Batch_idx: 320 |  Loss: (0.5117) | Acc: (82.33%) (33827/41088)\n",
      "Epoch: 14 | Batch_idx: 330 |  Loss: (0.5111) | Acc: (82.35%) (34891/42368)\n",
      "Epoch: 14 | Batch_idx: 340 |  Loss: (0.5097) | Acc: (82.39%) (35960/43648)\n",
      "Epoch: 14 | Batch_idx: 350 |  Loss: (0.5108) | Acc: (82.38%) (37012/44928)\n",
      "Epoch: 14 | Batch_idx: 360 |  Loss: (0.5113) | Acc: (82.39%) (38071/46208)\n",
      "Epoch: 14 | Batch_idx: 370 |  Loss: (0.5115) | Acc: (82.40%) (39129/47488)\n",
      "Epoch: 14 | Batch_idx: 380 |  Loss: (0.5104) | Acc: (82.43%) (40199/48768)\n",
      "Epoch: 14 | Batch_idx: 390 |  Loss: (0.5106) | Acc: (82.42%) (41208/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7227) | Acc: (77.13%) (7713/10000)\n",
      "Epoch: 15 | Batch_idx: 0 |  Loss: (0.5815) | Acc: (81.25%) (104/128)\n",
      "Epoch: 15 | Batch_idx: 10 |  Loss: (0.5247) | Acc: (81.61%) (1149/1408)\n",
      "Epoch: 15 | Batch_idx: 20 |  Loss: (0.5028) | Acc: (82.70%) (2223/2688)\n",
      "Epoch: 15 | Batch_idx: 30 |  Loss: (0.4909) | Acc: (83.29%) (3305/3968)\n",
      "Epoch: 15 | Batch_idx: 40 |  Loss: (0.4907) | Acc: (83.54%) (4384/5248)\n",
      "Epoch: 15 | Batch_idx: 50 |  Loss: (0.4960) | Acc: (83.03%) (5420/6528)\n",
      "Epoch: 15 | Batch_idx: 60 |  Loss: (0.4960) | Acc: (83.02%) (6482/7808)\n",
      "Epoch: 15 | Batch_idx: 70 |  Loss: (0.4933) | Acc: (82.99%) (7542/9088)\n",
      "Epoch: 15 | Batch_idx: 80 |  Loss: (0.4907) | Acc: (82.90%) (8595/10368)\n",
      "Epoch: 15 | Batch_idx: 90 |  Loss: (0.4894) | Acc: (82.92%) (9659/11648)\n",
      "Epoch: 15 | Batch_idx: 100 |  Loss: (0.4880) | Acc: (82.94%) (10723/12928)\n",
      "Epoch: 15 | Batch_idx: 110 |  Loss: (0.4924) | Acc: (82.81%) (11765/14208)\n",
      "Epoch: 15 | Batch_idx: 120 |  Loss: (0.4931) | Acc: (82.83%) (12828/15488)\n",
      "Epoch: 15 | Batch_idx: 130 |  Loss: (0.4947) | Acc: (82.76%) (13878/16768)\n",
      "Epoch: 15 | Batch_idx: 140 |  Loss: (0.4946) | Acc: (82.75%) (14935/18048)\n",
      "Epoch: 15 | Batch_idx: 150 |  Loss: (0.4936) | Acc: (82.80%) (16004/19328)\n",
      "Epoch: 15 | Batch_idx: 160 |  Loss: (0.4959) | Acc: (82.77%) (17058/20608)\n",
      "Epoch: 15 | Batch_idx: 170 |  Loss: (0.4959) | Acc: (82.79%) (18122/21888)\n",
      "Epoch: 15 | Batch_idx: 180 |  Loss: (0.4973) | Acc: (82.74%) (19170/23168)\n",
      "Epoch: 15 | Batch_idx: 190 |  Loss: (0.4958) | Acc: (82.80%) (20244/24448)\n",
      "Epoch: 15 | Batch_idx: 200 |  Loss: (0.4960) | Acc: (82.74%) (21288/25728)\n",
      "Epoch: 15 | Batch_idx: 210 |  Loss: (0.4958) | Acc: (82.75%) (22349/27008)\n",
      "Epoch: 15 | Batch_idx: 220 |  Loss: (0.4943) | Acc: (82.84%) (23433/28288)\n",
      "Epoch: 15 | Batch_idx: 230 |  Loss: (0.4961) | Acc: (82.80%) (24483/29568)\n",
      "Epoch: 15 | Batch_idx: 240 |  Loss: (0.4939) | Acc: (82.87%) (25564/30848)\n",
      "Epoch: 15 | Batch_idx: 250 |  Loss: (0.4942) | Acc: (82.81%) (26605/32128)\n",
      "Epoch: 15 | Batch_idx: 260 |  Loss: (0.4925) | Acc: (82.91%) (27700/33408)\n",
      "Epoch: 15 | Batch_idx: 270 |  Loss: (0.4898) | Acc: (83.01%) (28794/34688)\n",
      "Epoch: 15 | Batch_idx: 280 |  Loss: (0.4880) | Acc: (83.05%) (29873/35968)\n",
      "Epoch: 15 | Batch_idx: 290 |  Loss: (0.4878) | Acc: (83.09%) (30950/37248)\n",
      "Epoch: 15 | Batch_idx: 300 |  Loss: (0.4882) | Acc: (83.07%) (32004/38528)\n",
      "Epoch: 15 | Batch_idx: 310 |  Loss: (0.4890) | Acc: (83.03%) (33052/39808)\n",
      "Epoch: 15 | Batch_idx: 320 |  Loss: (0.4873) | Acc: (83.07%) (34132/41088)\n",
      "Epoch: 15 | Batch_idx: 330 |  Loss: (0.4873) | Acc: (83.07%) (35193/42368)\n",
      "Epoch: 15 | Batch_idx: 340 |  Loss: (0.4878) | Acc: (83.02%) (36238/43648)\n",
      "Epoch: 15 | Batch_idx: 350 |  Loss: (0.4877) | Acc: (83.05%) (37311/44928)\n",
      "Epoch: 15 | Batch_idx: 360 |  Loss: (0.4875) | Acc: (83.06%) (38380/46208)\n",
      "Epoch: 15 | Batch_idx: 370 |  Loss: (0.4873) | Acc: (83.05%) (39441/47488)\n",
      "Epoch: 15 | Batch_idx: 380 |  Loss: (0.4878) | Acc: (83.05%) (40500/48768)\n",
      "Epoch: 15 | Batch_idx: 390 |  Loss: (0.4882) | Acc: (83.05%) (41523/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7352) | Acc: (77.26%) (7726/10000)\n",
      "Epoch: 16 | Batch_idx: 0 |  Loss: (0.4573) | Acc: (86.72%) (111/128)\n",
      "Epoch: 16 | Batch_idx: 10 |  Loss: (0.4350) | Acc: (85.09%) (1198/1408)\n",
      "Epoch: 16 | Batch_idx: 20 |  Loss: (0.4510) | Acc: (84.49%) (2271/2688)\n",
      "Epoch: 16 | Batch_idx: 30 |  Loss: (0.4439) | Acc: (84.48%) (3352/3968)\n",
      "Epoch: 16 | Batch_idx: 40 |  Loss: (0.4387) | Acc: (84.60%) (4440/5248)\n",
      "Epoch: 16 | Batch_idx: 50 |  Loss: (0.4415) | Acc: (84.42%) (5511/6528)\n",
      "Epoch: 16 | Batch_idx: 60 |  Loss: (0.4390) | Acc: (84.54%) (6601/7808)\n",
      "Epoch: 16 | Batch_idx: 70 |  Loss: (0.4446) | Acc: (84.49%) (7678/9088)\n",
      "Epoch: 16 | Batch_idx: 80 |  Loss: (0.4494) | Acc: (84.31%) (8741/10368)\n",
      "Epoch: 16 | Batch_idx: 90 |  Loss: (0.4483) | Acc: (84.38%) (9829/11648)\n",
      "Epoch: 16 | Batch_idx: 100 |  Loss: (0.4473) | Acc: (84.43%) (10915/12928)\n",
      "Epoch: 16 | Batch_idx: 110 |  Loss: (0.4499) | Acc: (84.38%) (11988/14208)\n",
      "Epoch: 16 | Batch_idx: 120 |  Loss: (0.4520) | Acc: (84.28%) (13053/15488)\n",
      "Epoch: 16 | Batch_idx: 130 |  Loss: (0.4520) | Acc: (84.34%) (14142/16768)\n",
      "Epoch: 16 | Batch_idx: 140 |  Loss: (0.4559) | Acc: (84.23%) (15201/18048)\n",
      "Epoch: 16 | Batch_idx: 150 |  Loss: (0.4543) | Acc: (84.29%) (16291/19328)\n",
      "Epoch: 16 | Batch_idx: 160 |  Loss: (0.4562) | Acc: (84.16%) (17344/20608)\n",
      "Epoch: 16 | Batch_idx: 170 |  Loss: (0.4571) | Acc: (84.18%) (18425/21888)\n",
      "Epoch: 16 | Batch_idx: 180 |  Loss: (0.4548) | Acc: (84.23%) (19514/23168)\n",
      "Epoch: 16 | Batch_idx: 190 |  Loss: (0.4576) | Acc: (84.16%) (20575/24448)\n",
      "Epoch: 16 | Batch_idx: 200 |  Loss: (0.4591) | Acc: (84.11%) (21640/25728)\n",
      "Epoch: 16 | Batch_idx: 210 |  Loss: (0.4571) | Acc: (84.20%) (22742/27008)\n",
      "Epoch: 16 | Batch_idx: 220 |  Loss: (0.4579) | Acc: (84.19%) (23816/28288)\n",
      "Epoch: 16 | Batch_idx: 230 |  Loss: (0.4569) | Acc: (84.22%) (24903/29568)\n",
      "Epoch: 16 | Batch_idx: 240 |  Loss: (0.4590) | Acc: (84.13%) (25952/30848)\n",
      "Epoch: 16 | Batch_idx: 250 |  Loss: (0.4590) | Acc: (84.18%) (27046/32128)\n",
      "Epoch: 16 | Batch_idx: 260 |  Loss: (0.4590) | Acc: (84.21%) (28134/33408)\n",
      "Epoch: 16 | Batch_idx: 270 |  Loss: (0.4590) | Acc: (84.25%) (29226/34688)\n",
      "Epoch: 16 | Batch_idx: 280 |  Loss: (0.4600) | Acc: (84.19%) (30281/35968)\n",
      "Epoch: 16 | Batch_idx: 290 |  Loss: (0.4601) | Acc: (84.18%) (31354/37248)\n",
      "Epoch: 16 | Batch_idx: 300 |  Loss: (0.4615) | Acc: (84.14%) (32416/38528)\n",
      "Epoch: 16 | Batch_idx: 310 |  Loss: (0.4608) | Acc: (84.13%) (33491/39808)\n",
      "Epoch: 16 | Batch_idx: 320 |  Loss: (0.4611) | Acc: (84.08%) (34545/41088)\n",
      "Epoch: 16 | Batch_idx: 330 |  Loss: (0.4606) | Acc: (84.08%) (35623/42368)\n",
      "Epoch: 16 | Batch_idx: 340 |  Loss: (0.4616) | Acc: (84.04%) (36683/43648)\n",
      "Epoch: 16 | Batch_idx: 350 |  Loss: (0.4616) | Acc: (84.05%) (37762/44928)\n",
      "Epoch: 16 | Batch_idx: 360 |  Loss: (0.4625) | Acc: (84.01%) (38819/46208)\n",
      "Epoch: 16 | Batch_idx: 370 |  Loss: (0.4614) | Acc: (84.05%) (39915/47488)\n",
      "Epoch: 16 | Batch_idx: 380 |  Loss: (0.4611) | Acc: (84.06%) (40992/48768)\n",
      "Epoch: 16 | Batch_idx: 390 |  Loss: (0.4604) | Acc: (84.09%) (42047/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7036) | Acc: (79.73%) (7973/10000)\n",
      "Epoch: 17 | Batch_idx: 0 |  Loss: (0.4379) | Acc: (83.59%) (107/128)\n",
      "Epoch: 17 | Batch_idx: 10 |  Loss: (0.4503) | Acc: (84.52%) (1190/1408)\n",
      "Epoch: 17 | Batch_idx: 20 |  Loss: (0.4477) | Acc: (84.71%) (2277/2688)\n",
      "Epoch: 17 | Batch_idx: 30 |  Loss: (0.4411) | Acc: (85.01%) (3373/3968)\n",
      "Epoch: 17 | Batch_idx: 40 |  Loss: (0.4439) | Acc: (84.76%) (4448/5248)\n",
      "Epoch: 17 | Batch_idx: 50 |  Loss: (0.4391) | Acc: (84.90%) (5542/6528)\n",
      "Epoch: 17 | Batch_idx: 60 |  Loss: (0.4430) | Acc: (84.87%) (6627/7808)\n",
      "Epoch: 17 | Batch_idx: 70 |  Loss: (0.4439) | Acc: (84.74%) (7701/9088)\n",
      "Epoch: 17 | Batch_idx: 80 |  Loss: (0.4450) | Acc: (84.57%) (8768/10368)\n",
      "Epoch: 17 | Batch_idx: 90 |  Loss: (0.4468) | Acc: (84.52%) (9845/11648)\n",
      "Epoch: 17 | Batch_idx: 100 |  Loss: (0.4475) | Acc: (84.48%) (10921/12928)\n",
      "Epoch: 17 | Batch_idx: 110 |  Loss: (0.4445) | Acc: (84.54%) (12012/14208)\n",
      "Epoch: 17 | Batch_idx: 120 |  Loss: (0.4449) | Acc: (84.56%) (13097/15488)\n",
      "Epoch: 17 | Batch_idx: 130 |  Loss: (0.4458) | Acc: (84.49%) (14168/16768)\n",
      "Epoch: 17 | Batch_idx: 140 |  Loss: (0.4441) | Acc: (84.52%) (15254/18048)\n",
      "Epoch: 17 | Batch_idx: 150 |  Loss: (0.4466) | Acc: (84.41%) (16314/19328)\n",
      "Epoch: 17 | Batch_idx: 160 |  Loss: (0.4468) | Acc: (84.38%) (17390/20608)\n",
      "Epoch: 17 | Batch_idx: 170 |  Loss: (0.4459) | Acc: (84.41%) (18476/21888)\n",
      "Epoch: 17 | Batch_idx: 180 |  Loss: (0.4457) | Acc: (84.39%) (19552/23168)\n",
      "Epoch: 17 | Batch_idx: 190 |  Loss: (0.4449) | Acc: (84.39%) (20631/24448)\n",
      "Epoch: 17 | Batch_idx: 200 |  Loss: (0.4465) | Acc: (84.32%) (21694/25728)\n",
      "Epoch: 17 | Batch_idx: 210 |  Loss: (0.4458) | Acc: (84.39%) (22793/27008)\n",
      "Epoch: 17 | Batch_idx: 220 |  Loss: (0.4468) | Acc: (84.33%) (23855/28288)\n",
      "Epoch: 17 | Batch_idx: 230 |  Loss: (0.4473) | Acc: (84.31%) (24930/29568)\n",
      "Epoch: 17 | Batch_idx: 240 |  Loss: (0.4472) | Acc: (84.31%) (26007/30848)\n",
      "Epoch: 17 | Batch_idx: 250 |  Loss: (0.4463) | Acc: (84.33%) (27092/32128)\n",
      "Epoch: 17 | Batch_idx: 260 |  Loss: (0.4463) | Acc: (84.32%) (28171/33408)\n",
      "Epoch: 17 | Batch_idx: 270 |  Loss: (0.4448) | Acc: (84.37%) (29267/34688)\n",
      "Epoch: 17 | Batch_idx: 280 |  Loss: (0.4445) | Acc: (84.40%) (30357/35968)\n",
      "Epoch: 17 | Batch_idx: 290 |  Loss: (0.4446) | Acc: (84.39%) (31433/37248)\n",
      "Epoch: 17 | Batch_idx: 300 |  Loss: (0.4442) | Acc: (84.40%) (32517/38528)\n",
      "Epoch: 17 | Batch_idx: 310 |  Loss: (0.4427) | Acc: (84.47%) (33624/39808)\n",
      "Epoch: 17 | Batch_idx: 320 |  Loss: (0.4431) | Acc: (84.45%) (34700/41088)\n",
      "Epoch: 17 | Batch_idx: 330 |  Loss: (0.4428) | Acc: (84.47%) (35789/42368)\n",
      "Epoch: 17 | Batch_idx: 340 |  Loss: (0.4427) | Acc: (84.48%) (36874/43648)\n",
      "Epoch: 17 | Batch_idx: 350 |  Loss: (0.4418) | Acc: (84.52%) (37972/44928)\n",
      "Epoch: 17 | Batch_idx: 360 |  Loss: (0.4408) | Acc: (84.55%) (39070/46208)\n",
      "Epoch: 17 | Batch_idx: 370 |  Loss: (0.4408) | Acc: (84.56%) (40155/47488)\n",
      "Epoch: 17 | Batch_idx: 380 |  Loss: (0.4416) | Acc: (84.55%) (41233/48768)\n",
      "Epoch: 17 | Batch_idx: 390 |  Loss: (0.4413) | Acc: (84.57%) (42285/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7244) | Acc: (78.83%) (7883/10000)\n",
      "Epoch: 18 | Batch_idx: 0 |  Loss: (0.3678) | Acc: (87.50%) (112/128)\n",
      "Epoch: 18 | Batch_idx: 10 |  Loss: (0.4401) | Acc: (84.45%) (1189/1408)\n",
      "Epoch: 18 | Batch_idx: 20 |  Loss: (0.4260) | Acc: (85.60%) (2301/2688)\n",
      "Epoch: 18 | Batch_idx: 30 |  Loss: (0.4239) | Acc: (85.81%) (3405/3968)\n",
      "Epoch: 18 | Batch_idx: 40 |  Loss: (0.4183) | Acc: (85.84%) (4505/5248)\n",
      "Epoch: 18 | Batch_idx: 50 |  Loss: (0.4177) | Acc: (85.68%) (5593/6528)\n",
      "Epoch: 18 | Batch_idx: 60 |  Loss: (0.4146) | Acc: (85.99%) (6714/7808)\n",
      "Epoch: 18 | Batch_idx: 70 |  Loss: (0.4145) | Acc: (85.88%) (7805/9088)\n",
      "Epoch: 18 | Batch_idx: 80 |  Loss: (0.4194) | Acc: (85.77%) (8893/10368)\n",
      "Epoch: 18 | Batch_idx: 90 |  Loss: (0.4206) | Acc: (85.71%) (9983/11648)\n",
      "Epoch: 18 | Batch_idx: 100 |  Loss: (0.4213) | Acc: (85.62%) (11069/12928)\n",
      "Epoch: 18 | Batch_idx: 110 |  Loss: (0.4217) | Acc: (85.56%) (12157/14208)\n",
      "Epoch: 18 | Batch_idx: 120 |  Loss: (0.4213) | Acc: (85.54%) (13248/15488)\n",
      "Epoch: 18 | Batch_idx: 130 |  Loss: (0.4186) | Acc: (85.68%) (14367/16768)\n",
      "Epoch: 18 | Batch_idx: 140 |  Loss: (0.4205) | Acc: (85.61%) (15451/18048)\n",
      "Epoch: 18 | Batch_idx: 150 |  Loss: (0.4205) | Acc: (85.68%) (16561/19328)\n",
      "Epoch: 18 | Batch_idx: 160 |  Loss: (0.4185) | Acc: (85.70%) (17662/20608)\n",
      "Epoch: 18 | Batch_idx: 170 |  Loss: (0.4194) | Acc: (85.71%) (18761/21888)\n",
      "Epoch: 18 | Batch_idx: 180 |  Loss: (0.4188) | Acc: (85.68%) (19851/23168)\n",
      "Epoch: 18 | Batch_idx: 190 |  Loss: (0.4207) | Acc: (85.57%) (20921/24448)\n",
      "Epoch: 18 | Batch_idx: 200 |  Loss: (0.4222) | Acc: (85.51%) (22001/25728)\n",
      "Epoch: 18 | Batch_idx: 210 |  Loss: (0.4215) | Acc: (85.53%) (23101/27008)\n",
      "Epoch: 18 | Batch_idx: 220 |  Loss: (0.4227) | Acc: (85.52%) (24192/28288)\n",
      "Epoch: 18 | Batch_idx: 230 |  Loss: (0.4253) | Acc: (85.39%) (25249/29568)\n",
      "Epoch: 18 | Batch_idx: 240 |  Loss: (0.4256) | Acc: (85.39%) (26342/30848)\n",
      "Epoch: 18 | Batch_idx: 250 |  Loss: (0.4263) | Acc: (85.42%) (27444/32128)\n",
      "Epoch: 18 | Batch_idx: 260 |  Loss: (0.4246) | Acc: (85.45%) (28546/33408)\n",
      "Epoch: 18 | Batch_idx: 270 |  Loss: (0.4237) | Acc: (85.47%) (29647/34688)\n",
      "Epoch: 18 | Batch_idx: 280 |  Loss: (0.4241) | Acc: (85.43%) (30729/35968)\n",
      "Epoch: 18 | Batch_idx: 290 |  Loss: (0.4239) | Acc: (85.44%) (31823/37248)\n",
      "Epoch: 18 | Batch_idx: 300 |  Loss: (0.4246) | Acc: (85.45%) (32921/38528)\n",
      "Epoch: 18 | Batch_idx: 310 |  Loss: (0.4254) | Acc: (85.44%) (34010/39808)\n",
      "Epoch: 18 | Batch_idx: 320 |  Loss: (0.4247) | Acc: (85.45%) (35108/41088)\n",
      "Epoch: 18 | Batch_idx: 330 |  Loss: (0.4229) | Acc: (85.50%) (36225/42368)\n",
      "Epoch: 18 | Batch_idx: 340 |  Loss: (0.4226) | Acc: (85.52%) (37326/43648)\n",
      "Epoch: 18 | Batch_idx: 350 |  Loss: (0.4232) | Acc: (85.51%) (38418/44928)\n",
      "Epoch: 18 | Batch_idx: 360 |  Loss: (0.4236) | Acc: (85.50%) (39508/46208)\n",
      "Epoch: 18 | Batch_idx: 370 |  Loss: (0.4232) | Acc: (85.52%) (40611/47488)\n",
      "Epoch: 18 | Batch_idx: 380 |  Loss: (0.4234) | Acc: (85.50%) (41695/48768)\n",
      "Epoch: 18 | Batch_idx: 390 |  Loss: (0.4236) | Acc: (85.51%) (42755/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6800) | Acc: (80.81%) (8081/10000)\n",
      "Epoch: 19 | Batch_idx: 0 |  Loss: (0.4005) | Acc: (85.94%) (110/128)\n",
      "Epoch: 19 | Batch_idx: 10 |  Loss: (0.3717) | Acc: (86.86%) (1223/1408)\n",
      "Epoch: 19 | Batch_idx: 20 |  Loss: (0.3692) | Acc: (87.02%) (2339/2688)\n",
      "Epoch: 19 | Batch_idx: 30 |  Loss: (0.3680) | Acc: (87.37%) (3467/3968)\n",
      "Epoch: 19 | Batch_idx: 40 |  Loss: (0.3837) | Acc: (86.72%) (4551/5248)\n",
      "Epoch: 19 | Batch_idx: 50 |  Loss: (0.3855) | Acc: (86.78%) (5665/6528)\n",
      "Epoch: 19 | Batch_idx: 60 |  Loss: (0.3910) | Acc: (86.55%) (6758/7808)\n",
      "Epoch: 19 | Batch_idx: 70 |  Loss: (0.3834) | Acc: (86.77%) (7886/9088)\n",
      "Epoch: 19 | Batch_idx: 80 |  Loss: (0.3843) | Acc: (86.85%) (9005/10368)\n",
      "Epoch: 19 | Batch_idx: 90 |  Loss: (0.3864) | Acc: (86.70%) (10099/11648)\n",
      "Epoch: 19 | Batch_idx: 100 |  Loss: (0.3877) | Acc: (86.66%) (11203/12928)\n",
      "Epoch: 19 | Batch_idx: 110 |  Loss: (0.3866) | Acc: (86.66%) (12312/14208)\n",
      "Epoch: 19 | Batch_idx: 120 |  Loss: (0.3904) | Acc: (86.56%) (13406/15488)\n",
      "Epoch: 19 | Batch_idx: 130 |  Loss: (0.3907) | Acc: (86.63%) (14526/16768)\n",
      "Epoch: 19 | Batch_idx: 140 |  Loss: (0.3909) | Acc: (86.64%) (15637/18048)\n",
      "Epoch: 19 | Batch_idx: 150 |  Loss: (0.3906) | Acc: (86.64%) (16746/19328)\n",
      "Epoch: 19 | Batch_idx: 160 |  Loss: (0.3922) | Acc: (86.55%) (17836/20608)\n",
      "Epoch: 19 | Batch_idx: 170 |  Loss: (0.3943) | Acc: (86.51%) (18936/21888)\n",
      "Epoch: 19 | Batch_idx: 180 |  Loss: (0.3953) | Acc: (86.48%) (20035/23168)\n",
      "Epoch: 19 | Batch_idx: 190 |  Loss: (0.3971) | Acc: (86.40%) (21124/24448)\n",
      "Epoch: 19 | Batch_idx: 200 |  Loss: (0.3987) | Acc: (86.29%) (22201/25728)\n",
      "Epoch: 19 | Batch_idx: 210 |  Loss: (0.3979) | Acc: (86.29%) (23304/27008)\n",
      "Epoch: 19 | Batch_idx: 220 |  Loss: (0.3989) | Acc: (86.25%) (24397/28288)\n",
      "Epoch: 19 | Batch_idx: 230 |  Loss: (0.3984) | Acc: (86.25%) (25503/29568)\n",
      "Epoch: 19 | Batch_idx: 240 |  Loss: (0.3999) | Acc: (86.19%) (26587/30848)\n",
      "Epoch: 19 | Batch_idx: 250 |  Loss: (0.4001) | Acc: (86.21%) (27696/32128)\n",
      "Epoch: 19 | Batch_idx: 260 |  Loss: (0.4005) | Acc: (86.18%) (28790/33408)\n",
      "Epoch: 19 | Batch_idx: 270 |  Loss: (0.4015) | Acc: (86.16%) (29887/34688)\n",
      "Epoch: 19 | Batch_idx: 280 |  Loss: (0.4016) | Acc: (86.14%) (30984/35968)\n",
      "Epoch: 19 | Batch_idx: 290 |  Loss: (0.4012) | Acc: (86.19%) (32103/37248)\n",
      "Epoch: 19 | Batch_idx: 300 |  Loss: (0.4005) | Acc: (86.22%) (33218/38528)\n",
      "Epoch: 19 | Batch_idx: 310 |  Loss: (0.4010) | Acc: (86.17%) (34303/39808)\n",
      "Epoch: 19 | Batch_idx: 320 |  Loss: (0.4001) | Acc: (86.21%) (35424/41088)\n",
      "Epoch: 19 | Batch_idx: 330 |  Loss: (0.4015) | Acc: (86.18%) (36511/42368)\n",
      "Epoch: 19 | Batch_idx: 340 |  Loss: (0.4030) | Acc: (86.13%) (37596/43648)\n",
      "Epoch: 19 | Batch_idx: 350 |  Loss: (0.4028) | Acc: (86.13%) (38695/44928)\n",
      "Epoch: 19 | Batch_idx: 360 |  Loss: (0.4033) | Acc: (86.11%) (39790/46208)\n",
      "Epoch: 19 | Batch_idx: 370 |  Loss: (0.4029) | Acc: (86.13%) (40900/47488)\n",
      "Epoch: 19 | Batch_idx: 380 |  Loss: (0.4026) | Acc: (86.14%) (42008/48768)\n",
      "Epoch: 19 | Batch_idx: 390 |  Loss: (0.4024) | Acc: (86.12%) (43059/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7815) | Acc: (79.56%) (7956/10000)\n",
      "Epoch: 20 | Batch_idx: 0 |  Loss: (0.2963) | Acc: (89.06%) (114/128)\n",
      "Epoch: 20 | Batch_idx: 10 |  Loss: (0.3940) | Acc: (85.87%) (1209/1408)\n",
      "Epoch: 20 | Batch_idx: 20 |  Loss: (0.4047) | Acc: (85.83%) (2307/2688)\n",
      "Epoch: 20 | Batch_idx: 30 |  Loss: (0.4056) | Acc: (85.96%) (3411/3968)\n",
      "Epoch: 20 | Batch_idx: 40 |  Loss: (0.3951) | Acc: (86.47%) (4538/5248)\n",
      "Epoch: 20 | Batch_idx: 50 |  Loss: (0.3915) | Acc: (86.58%) (5652/6528)\n",
      "Epoch: 20 | Batch_idx: 60 |  Loss: (0.3898) | Acc: (86.65%) (6766/7808)\n",
      "Epoch: 20 | Batch_idx: 70 |  Loss: (0.3879) | Acc: (86.75%) (7884/9088)\n",
      "Epoch: 20 | Batch_idx: 80 |  Loss: (0.3812) | Acc: (87.08%) (9028/10368)\n",
      "Epoch: 20 | Batch_idx: 90 |  Loss: (0.3826) | Acc: (87.10%) (10145/11648)\n",
      "Epoch: 20 | Batch_idx: 100 |  Loss: (0.3878) | Acc: (86.95%) (11241/12928)\n",
      "Epoch: 20 | Batch_idx: 110 |  Loss: (0.3871) | Acc: (86.94%) (12352/14208)\n",
      "Epoch: 20 | Batch_idx: 120 |  Loss: (0.3862) | Acc: (86.93%) (13463/15488)\n",
      "Epoch: 20 | Batch_idx: 130 |  Loss: (0.3845) | Acc: (86.96%) (14582/16768)\n",
      "Epoch: 20 | Batch_idx: 140 |  Loss: (0.3824) | Acc: (87.02%) (15705/18048)\n",
      "Epoch: 20 | Batch_idx: 150 |  Loss: (0.3852) | Acc: (86.95%) (16806/19328)\n",
      "Epoch: 20 | Batch_idx: 160 |  Loss: (0.3849) | Acc: (86.95%) (17918/20608)\n",
      "Epoch: 20 | Batch_idx: 170 |  Loss: (0.3843) | Acc: (86.99%) (19040/21888)\n",
      "Epoch: 20 | Batch_idx: 180 |  Loss: (0.3849) | Acc: (86.93%) (20140/23168)\n",
      "Epoch: 20 | Batch_idx: 190 |  Loss: (0.3861) | Acc: (86.87%) (21238/24448)\n",
      "Epoch: 20 | Batch_idx: 200 |  Loss: (0.3868) | Acc: (86.80%) (22332/25728)\n",
      "Epoch: 20 | Batch_idx: 210 |  Loss: (0.3861) | Acc: (86.78%) (23437/27008)\n",
      "Epoch: 20 | Batch_idx: 220 |  Loss: (0.3864) | Acc: (86.73%) (24533/28288)\n",
      "Epoch: 20 | Batch_idx: 230 |  Loss: (0.3854) | Acc: (86.80%) (25666/29568)\n",
      "Epoch: 20 | Batch_idx: 240 |  Loss: (0.3852) | Acc: (86.83%) (26786/30848)\n",
      "Epoch: 20 | Batch_idx: 250 |  Loss: (0.3863) | Acc: (86.84%) (27899/32128)\n",
      "Epoch: 20 | Batch_idx: 260 |  Loss: (0.3869) | Acc: (86.84%) (29010/33408)\n",
      "Epoch: 20 | Batch_idx: 270 |  Loss: (0.3871) | Acc: (86.87%) (30132/34688)\n",
      "Epoch: 20 | Batch_idx: 280 |  Loss: (0.3877) | Acc: (86.83%) (31232/35968)\n",
      "Epoch: 20 | Batch_idx: 290 |  Loss: (0.3892) | Acc: (86.80%) (32332/37248)\n",
      "Epoch: 20 | Batch_idx: 300 |  Loss: (0.3879) | Acc: (86.82%) (33450/38528)\n",
      "Epoch: 20 | Batch_idx: 310 |  Loss: (0.3889) | Acc: (86.78%) (34545/39808)\n",
      "Epoch: 20 | Batch_idx: 320 |  Loss: (0.3889) | Acc: (86.77%) (35654/41088)\n",
      "Epoch: 20 | Batch_idx: 330 |  Loss: (0.3888) | Acc: (86.81%) (36779/42368)\n",
      "Epoch: 20 | Batch_idx: 340 |  Loss: (0.3873) | Acc: (86.84%) (37903/43648)\n",
      "Epoch: 20 | Batch_idx: 350 |  Loss: (0.3871) | Acc: (86.85%) (39018/44928)\n",
      "Epoch: 20 | Batch_idx: 360 |  Loss: (0.3878) | Acc: (86.82%) (40117/46208)\n",
      "Epoch: 20 | Batch_idx: 370 |  Loss: (0.3873) | Acc: (86.82%) (41228/47488)\n",
      "Epoch: 20 | Batch_idx: 380 |  Loss: (0.3875) | Acc: (86.81%) (42334/48768)\n",
      "Epoch: 20 | Batch_idx: 390 |  Loss: (0.3871) | Acc: (86.82%) (43409/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8044) | Acc: (77.53%) (7753/10000)\n",
      "Epoch: 21 | Batch_idx: 0 |  Loss: (0.3634) | Acc: (87.50%) (112/128)\n",
      "Epoch: 21 | Batch_idx: 10 |  Loss: (0.3653) | Acc: (87.71%) (1235/1408)\n",
      "Epoch: 21 | Batch_idx: 20 |  Loss: (0.3636) | Acc: (87.54%) (2353/2688)\n",
      "Epoch: 21 | Batch_idx: 30 |  Loss: (0.3521) | Acc: (87.85%) (3486/3968)\n",
      "Epoch: 21 | Batch_idx: 40 |  Loss: (0.3482) | Acc: (88.15%) (4626/5248)\n",
      "Epoch: 21 | Batch_idx: 50 |  Loss: (0.3460) | Acc: (88.20%) (5758/6528)\n",
      "Epoch: 21 | Batch_idx: 60 |  Loss: (0.3525) | Acc: (88.00%) (6871/7808)\n",
      "Epoch: 21 | Batch_idx: 70 |  Loss: (0.3536) | Acc: (87.91%) (7989/9088)\n",
      "Epoch: 21 | Batch_idx: 80 |  Loss: (0.3542) | Acc: (87.87%) (9110/10368)\n",
      "Epoch: 21 | Batch_idx: 90 |  Loss: (0.3530) | Acc: (87.88%) (10236/11648)\n",
      "Epoch: 21 | Batch_idx: 100 |  Loss: (0.3539) | Acc: (87.87%) (11360/12928)\n",
      "Epoch: 21 | Batch_idx: 110 |  Loss: (0.3569) | Acc: (87.68%) (12457/14208)\n",
      "Epoch: 21 | Batch_idx: 120 |  Loss: (0.3586) | Acc: (87.64%) (13573/15488)\n",
      "Epoch: 21 | Batch_idx: 130 |  Loss: (0.3566) | Acc: (87.72%) (14709/16768)\n",
      "Epoch: 21 | Batch_idx: 140 |  Loss: (0.3586) | Acc: (87.69%) (15827/18048)\n",
      "Epoch: 21 | Batch_idx: 150 |  Loss: (0.3626) | Acc: (87.60%) (16932/19328)\n",
      "Epoch: 21 | Batch_idx: 160 |  Loss: (0.3640) | Acc: (87.55%) (18042/20608)\n",
      "Epoch: 21 | Batch_idx: 170 |  Loss: (0.3666) | Acc: (87.41%) (19133/21888)\n",
      "Epoch: 21 | Batch_idx: 180 |  Loss: (0.3664) | Acc: (87.43%) (20256/23168)\n",
      "Epoch: 21 | Batch_idx: 190 |  Loss: (0.3662) | Acc: (87.42%) (21373/24448)\n",
      "Epoch: 21 | Batch_idx: 200 |  Loss: (0.3651) | Acc: (87.42%) (22492/25728)\n",
      "Epoch: 21 | Batch_idx: 210 |  Loss: (0.3662) | Acc: (87.37%) (23596/27008)\n",
      "Epoch: 21 | Batch_idx: 220 |  Loss: (0.3672) | Acc: (87.32%) (24702/28288)\n",
      "Epoch: 21 | Batch_idx: 230 |  Loss: (0.3667) | Acc: (87.32%) (25818/29568)\n",
      "Epoch: 21 | Batch_idx: 240 |  Loss: (0.3665) | Acc: (87.33%) (26941/30848)\n",
      "Epoch: 21 | Batch_idx: 250 |  Loss: (0.3666) | Acc: (87.34%) (28060/32128)\n",
      "Epoch: 21 | Batch_idx: 260 |  Loss: (0.3667) | Acc: (87.33%) (29176/33408)\n",
      "Epoch: 21 | Batch_idx: 270 |  Loss: (0.3672) | Acc: (87.27%) (30271/34688)\n",
      "Epoch: 21 | Batch_idx: 280 |  Loss: (0.3676) | Acc: (87.25%) (31382/35968)\n",
      "Epoch: 21 | Batch_idx: 290 |  Loss: (0.3685) | Acc: (87.19%) (32475/37248)\n",
      "Epoch: 21 | Batch_idx: 300 |  Loss: (0.3676) | Acc: (87.23%) (33607/38528)\n",
      "Epoch: 21 | Batch_idx: 310 |  Loss: (0.3678) | Acc: (87.22%) (34722/39808)\n",
      "Epoch: 21 | Batch_idx: 320 |  Loss: (0.3685) | Acc: (87.17%) (35817/41088)\n",
      "Epoch: 21 | Batch_idx: 330 |  Loss: (0.3690) | Acc: (87.16%) (36928/42368)\n",
      "Epoch: 21 | Batch_idx: 340 |  Loss: (0.3690) | Acc: (87.17%) (38047/43648)\n",
      "Epoch: 21 | Batch_idx: 350 |  Loss: (0.3695) | Acc: (87.15%) (39154/44928)\n",
      "Epoch: 21 | Batch_idx: 360 |  Loss: (0.3692) | Acc: (87.17%) (40281/46208)\n",
      "Epoch: 21 | Batch_idx: 370 |  Loss: (0.3694) | Acc: (87.17%) (41394/47488)\n",
      "Epoch: 21 | Batch_idx: 380 |  Loss: (0.3706) | Acc: (87.14%) (42496/48768)\n",
      "Epoch: 21 | Batch_idx: 390 |  Loss: (0.3707) | Acc: (87.15%) (43573/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6104) | Acc: (81.71%) (8171/10000)\n",
      "Epoch: 22 | Batch_idx: 0 |  Loss: (0.3852) | Acc: (86.72%) (111/128)\n",
      "Epoch: 22 | Batch_idx: 10 |  Loss: (0.3604) | Acc: (87.22%) (1228/1408)\n",
      "Epoch: 22 | Batch_idx: 20 |  Loss: (0.3413) | Acc: (88.06%) (2367/2688)\n",
      "Epoch: 22 | Batch_idx: 30 |  Loss: (0.3436) | Acc: (87.88%) (3487/3968)\n",
      "Epoch: 22 | Batch_idx: 40 |  Loss: (0.3404) | Acc: (87.84%) (4610/5248)\n",
      "Epoch: 22 | Batch_idx: 50 |  Loss: (0.3448) | Acc: (87.78%) (5730/6528)\n",
      "Epoch: 22 | Batch_idx: 60 |  Loss: (0.3366) | Acc: (88.14%) (6882/7808)\n",
      "Epoch: 22 | Batch_idx: 70 |  Loss: (0.3422) | Acc: (88.04%) (8001/9088)\n",
      "Epoch: 22 | Batch_idx: 80 |  Loss: (0.3418) | Acc: (87.95%) (9119/10368)\n",
      "Epoch: 22 | Batch_idx: 90 |  Loss: (0.3433) | Acc: (87.90%) (10239/11648)\n",
      "Epoch: 22 | Batch_idx: 100 |  Loss: (0.3447) | Acc: (87.86%) (11359/12928)\n",
      "Epoch: 22 | Batch_idx: 110 |  Loss: (0.3467) | Acc: (87.85%) (12482/14208)\n",
      "Epoch: 22 | Batch_idx: 120 |  Loss: (0.3482) | Acc: (87.84%) (13604/15488)\n",
      "Epoch: 22 | Batch_idx: 130 |  Loss: (0.3494) | Acc: (87.76%) (14716/16768)\n",
      "Epoch: 22 | Batch_idx: 140 |  Loss: (0.3493) | Acc: (87.75%) (15838/18048)\n",
      "Epoch: 22 | Batch_idx: 150 |  Loss: (0.3482) | Acc: (87.74%) (16959/19328)\n",
      "Epoch: 22 | Batch_idx: 160 |  Loss: (0.3495) | Acc: (87.66%) (18065/20608)\n",
      "Epoch: 22 | Batch_idx: 170 |  Loss: (0.3506) | Acc: (87.59%) (19172/21888)\n",
      "Epoch: 22 | Batch_idx: 180 |  Loss: (0.3488) | Acc: (87.61%) (20297/23168)\n",
      "Epoch: 22 | Batch_idx: 190 |  Loss: (0.3477) | Acc: (87.64%) (21427/24448)\n",
      "Epoch: 22 | Batch_idx: 200 |  Loss: (0.3479) | Acc: (87.63%) (22546/25728)\n",
      "Epoch: 22 | Batch_idx: 210 |  Loss: (0.3478) | Acc: (87.68%) (23680/27008)\n",
      "Epoch: 22 | Batch_idx: 220 |  Loss: (0.3482) | Acc: (87.67%) (24800/28288)\n",
      "Epoch: 22 | Batch_idx: 230 |  Loss: (0.3495) | Acc: (87.65%) (25915/29568)\n",
      "Epoch: 22 | Batch_idx: 240 |  Loss: (0.3509) | Acc: (87.60%) (27023/30848)\n",
      "Epoch: 22 | Batch_idx: 250 |  Loss: (0.3519) | Acc: (87.60%) (28145/32128)\n",
      "Epoch: 22 | Batch_idx: 260 |  Loss: (0.3513) | Acc: (87.66%) (29284/33408)\n",
      "Epoch: 22 | Batch_idx: 270 |  Loss: (0.3506) | Acc: (87.70%) (30420/34688)\n",
      "Epoch: 22 | Batch_idx: 280 |  Loss: (0.3513) | Acc: (87.66%) (31528/35968)\n",
      "Epoch: 22 | Batch_idx: 290 |  Loss: (0.3512) | Acc: (87.70%) (32667/37248)\n",
      "Epoch: 22 | Batch_idx: 300 |  Loss: (0.3507) | Acc: (87.71%) (33791/38528)\n",
      "Epoch: 22 | Batch_idx: 310 |  Loss: (0.3505) | Acc: (87.72%) (34918/39808)\n",
      "Epoch: 22 | Batch_idx: 320 |  Loss: (0.3501) | Acc: (87.75%) (36054/41088)\n",
      "Epoch: 22 | Batch_idx: 330 |  Loss: (0.3507) | Acc: (87.72%) (37166/42368)\n",
      "Epoch: 22 | Batch_idx: 340 |  Loss: (0.3513) | Acc: (87.70%) (38279/43648)\n",
      "Epoch: 22 | Batch_idx: 350 |  Loss: (0.3519) | Acc: (87.70%) (39401/44928)\n",
      "Epoch: 22 | Batch_idx: 360 |  Loss: (0.3524) | Acc: (87.70%) (40524/46208)\n",
      "Epoch: 22 | Batch_idx: 370 |  Loss: (0.3516) | Acc: (87.74%) (41668/47488)\n",
      "Epoch: 22 | Batch_idx: 380 |  Loss: (0.3515) | Acc: (87.74%) (42791/48768)\n",
      "Epoch: 22 | Batch_idx: 390 |  Loss: (0.3525) | Acc: (87.71%) (43853/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7050) | Acc: (80.05%) (8005/10000)\n",
      "Epoch: 23 | Batch_idx: 0 |  Loss: (0.2905) | Acc: (89.84%) (115/128)\n",
      "Epoch: 23 | Batch_idx: 10 |  Loss: (0.3278) | Acc: (88.57%) (1247/1408)\n",
      "Epoch: 23 | Batch_idx: 20 |  Loss: (0.3378) | Acc: (87.91%) (2363/2688)\n",
      "Epoch: 23 | Batch_idx: 30 |  Loss: (0.3378) | Acc: (88.05%) (3494/3968)\n",
      "Epoch: 23 | Batch_idx: 40 |  Loss: (0.3437) | Acc: (87.90%) (4613/5248)\n",
      "Epoch: 23 | Batch_idx: 50 |  Loss: (0.3435) | Acc: (87.91%) (5739/6528)\n",
      "Epoch: 23 | Batch_idx: 60 |  Loss: (0.3425) | Acc: (88.03%) (6873/7808)\n",
      "Epoch: 23 | Batch_idx: 70 |  Loss: (0.3461) | Acc: (88.04%) (8001/9088)\n",
      "Epoch: 23 | Batch_idx: 80 |  Loss: (0.3468) | Acc: (88.11%) (9135/10368)\n",
      "Epoch: 23 | Batch_idx: 90 |  Loss: (0.3496) | Acc: (87.92%) (10241/11648)\n",
      "Epoch: 23 | Batch_idx: 100 |  Loss: (0.3455) | Acc: (88.08%) (11387/12928)\n",
      "Epoch: 23 | Batch_idx: 110 |  Loss: (0.3413) | Acc: (88.26%) (12540/14208)\n",
      "Epoch: 23 | Batch_idx: 120 |  Loss: (0.3443) | Acc: (88.11%) (13646/15488)\n",
      "Epoch: 23 | Batch_idx: 130 |  Loss: (0.3448) | Acc: (88.06%) (14766/16768)\n",
      "Epoch: 23 | Batch_idx: 140 |  Loss: (0.3427) | Acc: (88.18%) (15915/18048)\n",
      "Epoch: 23 | Batch_idx: 150 |  Loss: (0.3399) | Acc: (88.27%) (17060/19328)\n",
      "Epoch: 23 | Batch_idx: 160 |  Loss: (0.3402) | Acc: (88.23%) (18183/20608)\n",
      "Epoch: 23 | Batch_idx: 170 |  Loss: (0.3399) | Acc: (88.20%) (19306/21888)\n",
      "Epoch: 23 | Batch_idx: 180 |  Loss: (0.3413) | Acc: (88.17%) (20427/23168)\n",
      "Epoch: 23 | Batch_idx: 190 |  Loss: (0.3410) | Acc: (88.19%) (21561/24448)\n",
      "Epoch: 23 | Batch_idx: 200 |  Loss: (0.3413) | Acc: (88.14%) (22676/25728)\n",
      "Epoch: 23 | Batch_idx: 210 |  Loss: (0.3411) | Acc: (88.15%) (23807/27008)\n",
      "Epoch: 23 | Batch_idx: 220 |  Loss: (0.3420) | Acc: (88.10%) (24921/28288)\n",
      "Epoch: 23 | Batch_idx: 230 |  Loss: (0.3421) | Acc: (88.10%) (26050/29568)\n",
      "Epoch: 23 | Batch_idx: 240 |  Loss: (0.3414) | Acc: (88.14%) (27188/30848)\n",
      "Epoch: 23 | Batch_idx: 250 |  Loss: (0.3405) | Acc: (88.18%) (28329/32128)\n",
      "Epoch: 23 | Batch_idx: 260 |  Loss: (0.3401) | Acc: (88.18%) (29459/33408)\n",
      "Epoch: 23 | Batch_idx: 270 |  Loss: (0.3420) | Acc: (88.13%) (30569/34688)\n",
      "Epoch: 23 | Batch_idx: 280 |  Loss: (0.3428) | Acc: (88.13%) (31700/35968)\n",
      "Epoch: 23 | Batch_idx: 290 |  Loss: (0.3438) | Acc: (88.11%) (32821/37248)\n",
      "Epoch: 23 | Batch_idx: 300 |  Loss: (0.3438) | Acc: (88.11%) (33947/38528)\n",
      "Epoch: 23 | Batch_idx: 310 |  Loss: (0.3434) | Acc: (88.13%) (35081/39808)\n",
      "Epoch: 23 | Batch_idx: 320 |  Loss: (0.3440) | Acc: (88.12%) (36207/41088)\n",
      "Epoch: 23 | Batch_idx: 330 |  Loss: (0.3434) | Acc: (88.14%) (37343/42368)\n",
      "Epoch: 23 | Batch_idx: 340 |  Loss: (0.3444) | Acc: (88.10%) (38453/43648)\n",
      "Epoch: 23 | Batch_idx: 350 |  Loss: (0.3451) | Acc: (88.05%) (39561/44928)\n",
      "Epoch: 23 | Batch_idx: 360 |  Loss: (0.3442) | Acc: (88.08%) (40702/46208)\n",
      "Epoch: 23 | Batch_idx: 370 |  Loss: (0.3435) | Acc: (88.12%) (41848/47488)\n",
      "Epoch: 23 | Batch_idx: 380 |  Loss: (0.3437) | Acc: (88.12%) (42974/48768)\n",
      "Epoch: 23 | Batch_idx: 390 |  Loss: (0.3446) | Acc: (88.08%) (44042/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6061) | Acc: (82.80%) (8280/10000)\n",
      "Epoch: 24 | Batch_idx: 0 |  Loss: (0.3247) | Acc: (88.28%) (113/128)\n",
      "Epoch: 24 | Batch_idx: 10 |  Loss: (0.3529) | Acc: (87.36%) (1230/1408)\n",
      "Epoch: 24 | Batch_idx: 20 |  Loss: (0.3395) | Acc: (88.28%) (2373/2688)\n",
      "Epoch: 24 | Batch_idx: 30 |  Loss: (0.3403) | Acc: (88.08%) (3495/3968)\n",
      "Epoch: 24 | Batch_idx: 40 |  Loss: (0.3318) | Acc: (88.43%) (4641/5248)\n",
      "Epoch: 24 | Batch_idx: 50 |  Loss: (0.3284) | Acc: (88.56%) (5781/6528)\n",
      "Epoch: 24 | Batch_idx: 60 |  Loss: (0.3316) | Acc: (88.47%) (6908/7808)\n",
      "Epoch: 24 | Batch_idx: 70 |  Loss: (0.3315) | Acc: (88.45%) (8038/9088)\n",
      "Epoch: 24 | Batch_idx: 80 |  Loss: (0.3285) | Acc: (88.52%) (9178/10368)\n",
      "Epoch: 24 | Batch_idx: 90 |  Loss: (0.3269) | Acc: (88.57%) (10317/11648)\n",
      "Epoch: 24 | Batch_idx: 100 |  Loss: (0.3302) | Acc: (88.54%) (11446/12928)\n",
      "Epoch: 24 | Batch_idx: 110 |  Loss: (0.3310) | Acc: (88.51%) (12576/14208)\n",
      "Epoch: 24 | Batch_idx: 120 |  Loss: (0.3321) | Acc: (88.49%) (13706/15488)\n",
      "Epoch: 24 | Batch_idx: 130 |  Loss: (0.3319) | Acc: (88.42%) (14827/16768)\n",
      "Epoch: 24 | Batch_idx: 140 |  Loss: (0.3305) | Acc: (88.53%) (15977/18048)\n",
      "Epoch: 24 | Batch_idx: 150 |  Loss: (0.3322) | Acc: (88.43%) (17092/19328)\n",
      "Epoch: 24 | Batch_idx: 160 |  Loss: (0.3323) | Acc: (88.38%) (18214/20608)\n",
      "Epoch: 24 | Batch_idx: 170 |  Loss: (0.3320) | Acc: (88.41%) (19351/21888)\n",
      "Epoch: 24 | Batch_idx: 180 |  Loss: (0.3338) | Acc: (88.29%) (20456/23168)\n",
      "Epoch: 24 | Batch_idx: 190 |  Loss: (0.3333) | Acc: (88.33%) (21596/24448)\n",
      "Epoch: 24 | Batch_idx: 200 |  Loss: (0.3342) | Acc: (88.28%) (22713/25728)\n",
      "Epoch: 24 | Batch_idx: 210 |  Loss: (0.3362) | Acc: (88.21%) (23824/27008)\n",
      "Epoch: 24 | Batch_idx: 220 |  Loss: (0.3351) | Acc: (88.22%) (24956/28288)\n",
      "Epoch: 24 | Batch_idx: 230 |  Loss: (0.3348) | Acc: (88.23%) (26089/29568)\n",
      "Epoch: 24 | Batch_idx: 240 |  Loss: (0.3354) | Acc: (88.23%) (27216/30848)\n",
      "Epoch: 24 | Batch_idx: 250 |  Loss: (0.3351) | Acc: (88.23%) (28348/32128)\n",
      "Epoch: 24 | Batch_idx: 260 |  Loss: (0.3343) | Acc: (88.26%) (29485/33408)\n",
      "Epoch: 24 | Batch_idx: 270 |  Loss: (0.3350) | Acc: (88.26%) (30615/34688)\n",
      "Epoch: 24 | Batch_idx: 280 |  Loss: (0.3347) | Acc: (88.30%) (31759/35968)\n",
      "Epoch: 24 | Batch_idx: 290 |  Loss: (0.3349) | Acc: (88.33%) (32901/37248)\n",
      "Epoch: 24 | Batch_idx: 300 |  Loss: (0.3343) | Acc: (88.34%) (34034/38528)\n",
      "Epoch: 24 | Batch_idx: 310 |  Loss: (0.3328) | Acc: (88.39%) (35185/39808)\n",
      "Epoch: 24 | Batch_idx: 320 |  Loss: (0.3325) | Acc: (88.39%) (36316/41088)\n",
      "Epoch: 24 | Batch_idx: 330 |  Loss: (0.3323) | Acc: (88.37%) (37442/42368)\n",
      "Epoch: 24 | Batch_idx: 340 |  Loss: (0.3315) | Acc: (88.39%) (38580/43648)\n",
      "Epoch: 24 | Batch_idx: 350 |  Loss: (0.3315) | Acc: (88.38%) (39706/44928)\n",
      "Epoch: 24 | Batch_idx: 360 |  Loss: (0.3316) | Acc: (88.37%) (40833/46208)\n",
      "Epoch: 24 | Batch_idx: 370 |  Loss: (0.3321) | Acc: (88.38%) (41968/47488)\n",
      "Epoch: 24 | Batch_idx: 380 |  Loss: (0.3324) | Acc: (88.36%) (43093/48768)\n",
      "Epoch: 24 | Batch_idx: 390 |  Loss: (0.3314) | Acc: (88.41%) (44205/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6634) | Acc: (80.56%) (8056/10000)\n",
      "Epoch: 25 | Batch_idx: 0 |  Loss: (0.3208) | Acc: (89.06%) (114/128)\n",
      "Epoch: 25 | Batch_idx: 10 |  Loss: (0.3173) | Acc: (89.06%) (1254/1408)\n",
      "Epoch: 25 | Batch_idx: 20 |  Loss: (0.3169) | Acc: (88.99%) (2392/2688)\n",
      "Epoch: 25 | Batch_idx: 30 |  Loss: (0.3097) | Acc: (89.36%) (3546/3968)\n",
      "Epoch: 25 | Batch_idx: 40 |  Loss: (0.3015) | Acc: (89.67%) (4706/5248)\n",
      "Epoch: 25 | Batch_idx: 50 |  Loss: (0.3022) | Acc: (89.75%) (5859/6528)\n",
      "Epoch: 25 | Batch_idx: 60 |  Loss: (0.3057) | Acc: (89.47%) (6986/7808)\n",
      "Epoch: 25 | Batch_idx: 70 |  Loss: (0.3091) | Acc: (89.38%) (8123/9088)\n",
      "Epoch: 25 | Batch_idx: 80 |  Loss: (0.3087) | Acc: (89.43%) (9272/10368)\n",
      "Epoch: 25 | Batch_idx: 90 |  Loss: (0.3115) | Acc: (89.35%) (10407/11648)\n",
      "Epoch: 25 | Batch_idx: 100 |  Loss: (0.3107) | Acc: (89.38%) (11555/12928)\n",
      "Epoch: 25 | Batch_idx: 110 |  Loss: (0.3121) | Acc: (89.29%) (12686/14208)\n",
      "Epoch: 25 | Batch_idx: 120 |  Loss: (0.3123) | Acc: (89.34%) (13837/15488)\n",
      "Epoch: 25 | Batch_idx: 130 |  Loss: (0.3091) | Acc: (89.49%) (15005/16768)\n",
      "Epoch: 25 | Batch_idx: 140 |  Loss: (0.3103) | Acc: (89.43%) (16140/18048)\n",
      "Epoch: 25 | Batch_idx: 150 |  Loss: (0.3137) | Acc: (89.29%) (17258/19328)\n",
      "Epoch: 25 | Batch_idx: 160 |  Loss: (0.3126) | Acc: (89.27%) (18396/20608)\n",
      "Epoch: 25 | Batch_idx: 170 |  Loss: (0.3146) | Acc: (89.19%) (19522/21888)\n",
      "Epoch: 25 | Batch_idx: 180 |  Loss: (0.3142) | Acc: (89.24%) (20676/23168)\n",
      "Epoch: 25 | Batch_idx: 190 |  Loss: (0.3143) | Acc: (89.28%) (21828/24448)\n",
      "Epoch: 25 | Batch_idx: 200 |  Loss: (0.3133) | Acc: (89.35%) (22987/25728)\n",
      "Epoch: 25 | Batch_idx: 210 |  Loss: (0.3126) | Acc: (89.36%) (24134/27008)\n",
      "Epoch: 25 | Batch_idx: 220 |  Loss: (0.3129) | Acc: (89.29%) (25259/28288)\n",
      "Epoch: 25 | Batch_idx: 230 |  Loss: (0.3120) | Acc: (89.31%) (26407/29568)\n",
      "Epoch: 25 | Batch_idx: 240 |  Loss: (0.3112) | Acc: (89.32%) (27552/30848)\n",
      "Epoch: 25 | Batch_idx: 250 |  Loss: (0.3113) | Acc: (89.31%) (28694/32128)\n",
      "Epoch: 25 | Batch_idx: 260 |  Loss: (0.3121) | Acc: (89.29%) (29830/33408)\n",
      "Epoch: 25 | Batch_idx: 270 |  Loss: (0.3127) | Acc: (89.27%) (30965/34688)\n",
      "Epoch: 25 | Batch_idx: 280 |  Loss: (0.3119) | Acc: (89.30%) (32121/35968)\n",
      "Epoch: 25 | Batch_idx: 290 |  Loss: (0.3135) | Acc: (89.28%) (33254/37248)\n",
      "Epoch: 25 | Batch_idx: 300 |  Loss: (0.3142) | Acc: (89.26%) (34391/38528)\n",
      "Epoch: 25 | Batch_idx: 310 |  Loss: (0.3147) | Acc: (89.24%) (35523/39808)\n",
      "Epoch: 25 | Batch_idx: 320 |  Loss: (0.3158) | Acc: (89.18%) (36643/41088)\n",
      "Epoch: 25 | Batch_idx: 330 |  Loss: (0.3140) | Acc: (89.27%) (37820/42368)\n",
      "Epoch: 25 | Batch_idx: 340 |  Loss: (0.3149) | Acc: (89.24%) (38953/43648)\n",
      "Epoch: 25 | Batch_idx: 350 |  Loss: (0.3161) | Acc: (89.20%) (40077/44928)\n",
      "Epoch: 25 | Batch_idx: 360 |  Loss: (0.3166) | Acc: (89.18%) (41208/46208)\n",
      "Epoch: 25 | Batch_idx: 370 |  Loss: (0.3171) | Acc: (89.13%) (42328/47488)\n",
      "Epoch: 25 | Batch_idx: 380 |  Loss: (0.3166) | Acc: (89.15%) (43479/48768)\n",
      "Epoch: 25 | Batch_idx: 390 |  Loss: (0.3165) | Acc: (89.15%) (44575/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5483) | Acc: (84.38%) (8438/10000)\n",
      "Epoch: 26 | Batch_idx: 0 |  Loss: (0.2693) | Acc: (91.41%) (117/128)\n",
      "Epoch: 26 | Batch_idx: 10 |  Loss: (0.2799) | Acc: (89.77%) (1264/1408)\n",
      "Epoch: 26 | Batch_idx: 20 |  Loss: (0.2794) | Acc: (90.40%) (2430/2688)\n",
      "Epoch: 26 | Batch_idx: 30 |  Loss: (0.2983) | Acc: (89.87%) (3566/3968)\n",
      "Epoch: 26 | Batch_idx: 40 |  Loss: (0.3061) | Acc: (89.33%) (4688/5248)\n",
      "Epoch: 26 | Batch_idx: 50 |  Loss: (0.3076) | Acc: (89.51%) (5843/6528)\n",
      "Epoch: 26 | Batch_idx: 60 |  Loss: (0.3104) | Acc: (89.37%) (6978/7808)\n",
      "Epoch: 26 | Batch_idx: 70 |  Loss: (0.3065) | Acc: (89.57%) (8140/9088)\n",
      "Epoch: 26 | Batch_idx: 80 |  Loss: (0.3076) | Acc: (89.51%) (9280/10368)\n",
      "Epoch: 26 | Batch_idx: 90 |  Loss: (0.3049) | Acc: (89.60%) (10437/11648)\n",
      "Epoch: 26 | Batch_idx: 100 |  Loss: (0.3061) | Acc: (89.57%) (11579/12928)\n",
      "Epoch: 26 | Batch_idx: 110 |  Loss: (0.3052) | Acc: (89.65%) (12737/14208)\n",
      "Epoch: 26 | Batch_idx: 120 |  Loss: (0.3054) | Acc: (89.63%) (13882/15488)\n",
      "Epoch: 26 | Batch_idx: 130 |  Loss: (0.3036) | Acc: (89.68%) (15037/16768)\n",
      "Epoch: 26 | Batch_idx: 140 |  Loss: (0.3037) | Acc: (89.67%) (16183/18048)\n",
      "Epoch: 26 | Batch_idx: 150 |  Loss: (0.3022) | Acc: (89.74%) (17345/19328)\n",
      "Epoch: 26 | Batch_idx: 160 |  Loss: (0.3016) | Acc: (89.78%) (18502/20608)\n",
      "Epoch: 26 | Batch_idx: 170 |  Loss: (0.3000) | Acc: (89.86%) (19669/21888)\n",
      "Epoch: 26 | Batch_idx: 180 |  Loss: (0.3011) | Acc: (89.74%) (20791/23168)\n",
      "Epoch: 26 | Batch_idx: 190 |  Loss: (0.3016) | Acc: (89.74%) (21940/24448)\n",
      "Epoch: 26 | Batch_idx: 200 |  Loss: (0.3012) | Acc: (89.73%) (23087/25728)\n",
      "Epoch: 26 | Batch_idx: 210 |  Loss: (0.3016) | Acc: (89.68%) (24221/27008)\n",
      "Epoch: 26 | Batch_idx: 220 |  Loss: (0.3008) | Acc: (89.66%) (25363/28288)\n",
      "Epoch: 26 | Batch_idx: 230 |  Loss: (0.3009) | Acc: (89.68%) (26516/29568)\n",
      "Epoch: 26 | Batch_idx: 240 |  Loss: (0.3026) | Acc: (89.59%) (27637/30848)\n",
      "Epoch: 26 | Batch_idx: 250 |  Loss: (0.3026) | Acc: (89.55%) (28771/32128)\n",
      "Epoch: 26 | Batch_idx: 260 |  Loss: (0.3040) | Acc: (89.51%) (29904/33408)\n",
      "Epoch: 26 | Batch_idx: 270 |  Loss: (0.3038) | Acc: (89.52%) (31053/34688)\n",
      "Epoch: 26 | Batch_idx: 280 |  Loss: (0.3040) | Acc: (89.53%) (32202/35968)\n",
      "Epoch: 26 | Batch_idx: 290 |  Loss: (0.3030) | Acc: (89.59%) (33369/37248)\n",
      "Epoch: 26 | Batch_idx: 300 |  Loss: (0.3041) | Acc: (89.51%) (34488/38528)\n",
      "Epoch: 26 | Batch_idx: 310 |  Loss: (0.3048) | Acc: (89.50%) (35629/39808)\n",
      "Epoch: 26 | Batch_idx: 320 |  Loss: (0.3053) | Acc: (89.50%) (36774/41088)\n",
      "Epoch: 26 | Batch_idx: 330 |  Loss: (0.3051) | Acc: (89.51%) (37925/42368)\n",
      "Epoch: 26 | Batch_idx: 340 |  Loss: (0.3047) | Acc: (89.52%) (39075/43648)\n",
      "Epoch: 26 | Batch_idx: 350 |  Loss: (0.3045) | Acc: (89.55%) (40232/44928)\n",
      "Epoch: 26 | Batch_idx: 360 |  Loss: (0.3045) | Acc: (89.56%) (41384/46208)\n",
      "Epoch: 26 | Batch_idx: 370 |  Loss: (0.3038) | Acc: (89.57%) (42534/47488)\n",
      "Epoch: 26 | Batch_idx: 380 |  Loss: (0.3033) | Acc: (89.61%) (43699/48768)\n",
      "Epoch: 26 | Batch_idx: 390 |  Loss: (0.3033) | Acc: (89.60%) (44800/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5457) | Acc: (84.56%) (8456/10000)\n",
      "Epoch: 27 | Batch_idx: 0 |  Loss: (0.2208) | Acc: (94.53%) (121/128)\n",
      "Epoch: 27 | Batch_idx: 10 |  Loss: (0.2863) | Acc: (90.27%) (1271/1408)\n",
      "Epoch: 27 | Batch_idx: 20 |  Loss: (0.2940) | Acc: (90.03%) (2420/2688)\n",
      "Epoch: 27 | Batch_idx: 30 |  Loss: (0.2934) | Acc: (89.99%) (3571/3968)\n",
      "Epoch: 27 | Batch_idx: 40 |  Loss: (0.2934) | Acc: (90.15%) (4731/5248)\n",
      "Epoch: 27 | Batch_idx: 50 |  Loss: (0.2952) | Acc: (90.12%) (5883/6528)\n",
      "Epoch: 27 | Batch_idx: 60 |  Loss: (0.2988) | Acc: (90.05%) (7031/7808)\n",
      "Epoch: 27 | Batch_idx: 70 |  Loss: (0.2960) | Acc: (90.05%) (8184/9088)\n",
      "Epoch: 27 | Batch_idx: 80 |  Loss: (0.3012) | Acc: (89.88%) (9319/10368)\n",
      "Epoch: 27 | Batch_idx: 90 |  Loss: (0.2990) | Acc: (89.84%) (10464/11648)\n",
      "Epoch: 27 | Batch_idx: 100 |  Loss: (0.2994) | Acc: (89.82%) (11612/12928)\n",
      "Epoch: 27 | Batch_idx: 110 |  Loss: (0.3021) | Acc: (89.72%) (12748/14208)\n",
      "Epoch: 27 | Batch_idx: 120 |  Loss: (0.3012) | Acc: (89.78%) (13905/15488)\n",
      "Epoch: 27 | Batch_idx: 130 |  Loss: (0.3018) | Acc: (89.74%) (15047/16768)\n",
      "Epoch: 27 | Batch_idx: 140 |  Loss: (0.3025) | Acc: (89.64%) (16179/18048)\n",
      "Epoch: 27 | Batch_idx: 150 |  Loss: (0.3038) | Acc: (89.55%) (17309/19328)\n",
      "Epoch: 27 | Batch_idx: 160 |  Loss: (0.3018) | Acc: (89.60%) (18464/20608)\n",
      "Epoch: 27 | Batch_idx: 170 |  Loss: (0.3005) | Acc: (89.62%) (19616/21888)\n",
      "Epoch: 27 | Batch_idx: 180 |  Loss: (0.3006) | Acc: (89.63%) (20766/23168)\n",
      "Epoch: 27 | Batch_idx: 190 |  Loss: (0.3007) | Acc: (89.61%) (21907/24448)\n",
      "Epoch: 27 | Batch_idx: 200 |  Loss: (0.3013) | Acc: (89.57%) (23045/25728)\n",
      "Epoch: 27 | Batch_idx: 210 |  Loss: (0.3004) | Acc: (89.61%) (24202/27008)\n",
      "Epoch: 27 | Batch_idx: 220 |  Loss: (0.2999) | Acc: (89.57%) (25337/28288)\n",
      "Epoch: 27 | Batch_idx: 230 |  Loss: (0.2995) | Acc: (89.57%) (26485/29568)\n",
      "Epoch: 27 | Batch_idx: 240 |  Loss: (0.3000) | Acc: (89.53%) (27617/30848)\n",
      "Epoch: 27 | Batch_idx: 250 |  Loss: (0.3001) | Acc: (89.53%) (28763/32128)\n",
      "Epoch: 27 | Batch_idx: 260 |  Loss: (0.3000) | Acc: (89.51%) (29904/33408)\n",
      "Epoch: 27 | Batch_idx: 270 |  Loss: (0.2989) | Acc: (89.53%) (31056/34688)\n",
      "Epoch: 27 | Batch_idx: 280 |  Loss: (0.2985) | Acc: (89.56%) (32214/35968)\n",
      "Epoch: 27 | Batch_idx: 290 |  Loss: (0.2976) | Acc: (89.59%) (33370/37248)\n",
      "Epoch: 27 | Batch_idx: 300 |  Loss: (0.2966) | Acc: (89.63%) (34533/38528)\n",
      "Epoch: 27 | Batch_idx: 310 |  Loss: (0.2973) | Acc: (89.62%) (35675/39808)\n",
      "Epoch: 27 | Batch_idx: 320 |  Loss: (0.2972) | Acc: (89.61%) (36821/41088)\n",
      "Epoch: 27 | Batch_idx: 330 |  Loss: (0.2961) | Acc: (89.67%) (37993/42368)\n",
      "Epoch: 27 | Batch_idx: 340 |  Loss: (0.2956) | Acc: (89.68%) (39143/43648)\n",
      "Epoch: 27 | Batch_idx: 350 |  Loss: (0.2962) | Acc: (89.66%) (40283/44928)\n",
      "Epoch: 27 | Batch_idx: 360 |  Loss: (0.2963) | Acc: (89.66%) (41428/46208)\n",
      "Epoch: 27 | Batch_idx: 370 |  Loss: (0.2955) | Acc: (89.68%) (42587/47488)\n",
      "Epoch: 27 | Batch_idx: 380 |  Loss: (0.2951) | Acc: (89.70%) (43746/48768)\n",
      "Epoch: 27 | Batch_idx: 390 |  Loss: (0.2950) | Acc: (89.70%) (44848/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6393) | Acc: (82.60%) (8260/10000)\n",
      "Epoch: 28 | Batch_idx: 0 |  Loss: (0.1823) | Acc: (96.09%) (123/128)\n",
      "Epoch: 28 | Batch_idx: 10 |  Loss: (0.2743) | Acc: (90.55%) (1275/1408)\n",
      "Epoch: 28 | Batch_idx: 20 |  Loss: (0.2619) | Acc: (90.81%) (2441/2688)\n",
      "Epoch: 28 | Batch_idx: 30 |  Loss: (0.2730) | Acc: (90.68%) (3598/3968)\n",
      "Epoch: 28 | Batch_idx: 40 |  Loss: (0.2707) | Acc: (90.66%) (4758/5248)\n",
      "Epoch: 28 | Batch_idx: 50 |  Loss: (0.2710) | Acc: (90.64%) (5917/6528)\n",
      "Epoch: 28 | Batch_idx: 60 |  Loss: (0.2688) | Acc: (90.77%) (7087/7808)\n",
      "Epoch: 28 | Batch_idx: 70 |  Loss: (0.2697) | Acc: (90.70%) (8243/9088)\n",
      "Epoch: 28 | Batch_idx: 80 |  Loss: (0.2733) | Acc: (90.59%) (9392/10368)\n",
      "Epoch: 28 | Batch_idx: 90 |  Loss: (0.2689) | Acc: (90.81%) (10578/11648)\n",
      "Epoch: 28 | Batch_idx: 100 |  Loss: (0.2723) | Acc: (90.73%) (11729/12928)\n",
      "Epoch: 28 | Batch_idx: 110 |  Loss: (0.2742) | Acc: (90.68%) (12884/14208)\n",
      "Epoch: 28 | Batch_idx: 120 |  Loss: (0.2758) | Acc: (90.65%) (14040/15488)\n",
      "Epoch: 28 | Batch_idx: 130 |  Loss: (0.2774) | Acc: (90.55%) (15183/16768)\n",
      "Epoch: 28 | Batch_idx: 140 |  Loss: (0.2785) | Acc: (90.49%) (16332/18048)\n",
      "Epoch: 28 | Batch_idx: 150 |  Loss: (0.2788) | Acc: (90.53%) (17498/19328)\n",
      "Epoch: 28 | Batch_idx: 160 |  Loss: (0.2783) | Acc: (90.54%) (18659/20608)\n",
      "Epoch: 28 | Batch_idx: 170 |  Loss: (0.2785) | Acc: (90.53%) (19816/21888)\n",
      "Epoch: 28 | Batch_idx: 180 |  Loss: (0.2789) | Acc: (90.49%) (20965/23168)\n",
      "Epoch: 28 | Batch_idx: 190 |  Loss: (0.2802) | Acc: (90.39%) (22099/24448)\n",
      "Epoch: 28 | Batch_idx: 200 |  Loss: (0.2808) | Acc: (90.39%) (23255/25728)\n",
      "Epoch: 28 | Batch_idx: 210 |  Loss: (0.2799) | Acc: (90.41%) (24419/27008)\n",
      "Epoch: 28 | Batch_idx: 220 |  Loss: (0.2807) | Acc: (90.36%) (25560/28288)\n",
      "Epoch: 28 | Batch_idx: 230 |  Loss: (0.2804) | Acc: (90.36%) (26718/29568)\n",
      "Epoch: 28 | Batch_idx: 240 |  Loss: (0.2803) | Acc: (90.36%) (27874/30848)\n",
      "Epoch: 28 | Batch_idx: 250 |  Loss: (0.2819) | Acc: (90.31%) (29014/32128)\n",
      "Epoch: 28 | Batch_idx: 260 |  Loss: (0.2823) | Acc: (90.29%) (30164/33408)\n",
      "Epoch: 28 | Batch_idx: 270 |  Loss: (0.2823) | Acc: (90.28%) (31318/34688)\n",
      "Epoch: 28 | Batch_idx: 280 |  Loss: (0.2840) | Acc: (90.21%) (32446/35968)\n",
      "Epoch: 28 | Batch_idx: 290 |  Loss: (0.2838) | Acc: (90.21%) (33603/37248)\n",
      "Epoch: 28 | Batch_idx: 300 |  Loss: (0.2844) | Acc: (90.17%) (34739/38528)\n",
      "Epoch: 28 | Batch_idx: 310 |  Loss: (0.2841) | Acc: (90.18%) (35899/39808)\n",
      "Epoch: 28 | Batch_idx: 320 |  Loss: (0.2843) | Acc: (90.18%) (37055/41088)\n",
      "Epoch: 28 | Batch_idx: 330 |  Loss: (0.2845) | Acc: (90.16%) (38200/42368)\n",
      "Epoch: 28 | Batch_idx: 340 |  Loss: (0.2840) | Acc: (90.17%) (39359/43648)\n",
      "Epoch: 28 | Batch_idx: 350 |  Loss: (0.2839) | Acc: (90.16%) (40508/44928)\n",
      "Epoch: 28 | Batch_idx: 360 |  Loss: (0.2840) | Acc: (90.17%) (41665/46208)\n",
      "Epoch: 28 | Batch_idx: 370 |  Loss: (0.2832) | Acc: (90.19%) (42828/47488)\n",
      "Epoch: 28 | Batch_idx: 380 |  Loss: (0.2831) | Acc: (90.19%) (43986/48768)\n",
      "Epoch: 28 | Batch_idx: 390 |  Loss: (0.2833) | Acc: (90.17%) (45086/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7269) | Acc: (80.71%) (8071/10000)\n",
      "Epoch: 29 | Batch_idx: 0 |  Loss: (0.2479) | Acc: (91.41%) (117/128)\n",
      "Epoch: 29 | Batch_idx: 10 |  Loss: (0.2446) | Acc: (91.55%) (1289/1408)\n",
      "Epoch: 29 | Batch_idx: 20 |  Loss: (0.2625) | Acc: (90.89%) (2443/2688)\n",
      "Epoch: 29 | Batch_idx: 30 |  Loss: (0.2585) | Acc: (91.18%) (3618/3968)\n",
      "Epoch: 29 | Batch_idx: 40 |  Loss: (0.2575) | Acc: (91.01%) (4776/5248)\n",
      "Epoch: 29 | Batch_idx: 50 |  Loss: (0.2628) | Acc: (90.70%) (5921/6528)\n",
      "Epoch: 29 | Batch_idx: 60 |  Loss: (0.2655) | Acc: (90.51%) (7067/7808)\n",
      "Epoch: 29 | Batch_idx: 70 |  Loss: (0.2609) | Acc: (90.70%) (8243/9088)\n",
      "Epoch: 29 | Batch_idx: 80 |  Loss: (0.2619) | Acc: (90.69%) (9403/10368)\n",
      "Epoch: 29 | Batch_idx: 90 |  Loss: (0.2617) | Acc: (90.68%) (10562/11648)\n",
      "Epoch: 29 | Batch_idx: 100 |  Loss: (0.2652) | Acc: (90.62%) (11716/12928)\n",
      "Epoch: 29 | Batch_idx: 110 |  Loss: (0.2672) | Acc: (90.62%) (12875/14208)\n",
      "Epoch: 29 | Batch_idx: 120 |  Loss: (0.2662) | Acc: (90.68%) (14045/15488)\n",
      "Epoch: 29 | Batch_idx: 130 |  Loss: (0.2650) | Acc: (90.77%) (15221/16768)\n",
      "Epoch: 29 | Batch_idx: 140 |  Loss: (0.2660) | Acc: (90.76%) (16381/18048)\n",
      "Epoch: 29 | Batch_idx: 150 |  Loss: (0.2671) | Acc: (90.70%) (17530/19328)\n",
      "Epoch: 29 | Batch_idx: 160 |  Loss: (0.2678) | Acc: (90.68%) (18687/20608)\n",
      "Epoch: 29 | Batch_idx: 170 |  Loss: (0.2661) | Acc: (90.79%) (19873/21888)\n",
      "Epoch: 29 | Batch_idx: 180 |  Loss: (0.2662) | Acc: (90.83%) (21044/23168)\n",
      "Epoch: 29 | Batch_idx: 190 |  Loss: (0.2670) | Acc: (90.80%) (22200/24448)\n",
      "Epoch: 29 | Batch_idx: 200 |  Loss: (0.2667) | Acc: (90.81%) (23363/25728)\n",
      "Epoch: 29 | Batch_idx: 210 |  Loss: (0.2681) | Acc: (90.79%) (24521/27008)\n",
      "Epoch: 29 | Batch_idx: 220 |  Loss: (0.2686) | Acc: (90.79%) (25683/28288)\n",
      "Epoch: 29 | Batch_idx: 230 |  Loss: (0.2689) | Acc: (90.78%) (26843/29568)\n",
      "Epoch: 29 | Batch_idx: 240 |  Loss: (0.2683) | Acc: (90.79%) (28008/30848)\n",
      "Epoch: 29 | Batch_idx: 250 |  Loss: (0.2660) | Acc: (90.90%) (29204/32128)\n",
      "Epoch: 29 | Batch_idx: 260 |  Loss: (0.2667) | Acc: (90.87%) (30359/33408)\n",
      "Epoch: 29 | Batch_idx: 270 |  Loss: (0.2667) | Acc: (90.88%) (31525/34688)\n",
      "Epoch: 29 | Batch_idx: 280 |  Loss: (0.2677) | Acc: (90.85%) (32678/35968)\n",
      "Epoch: 29 | Batch_idx: 290 |  Loss: (0.2687) | Acc: (90.79%) (33818/37248)\n",
      "Epoch: 29 | Batch_idx: 300 |  Loss: (0.2682) | Acc: (90.81%) (34987/38528)\n",
      "Epoch: 29 | Batch_idx: 310 |  Loss: (0.2687) | Acc: (90.77%) (36135/39808)\n",
      "Epoch: 29 | Batch_idx: 320 |  Loss: (0.2690) | Acc: (90.76%) (37290/41088)\n",
      "Epoch: 29 | Batch_idx: 330 |  Loss: (0.2702) | Acc: (90.70%) (38426/42368)\n",
      "Epoch: 29 | Batch_idx: 340 |  Loss: (0.2703) | Acc: (90.68%) (39578/43648)\n",
      "Epoch: 29 | Batch_idx: 350 |  Loss: (0.2709) | Acc: (90.65%) (40726/44928)\n",
      "Epoch: 29 | Batch_idx: 360 |  Loss: (0.2714) | Acc: (90.62%) (41875/46208)\n",
      "Epoch: 29 | Batch_idx: 370 |  Loss: (0.2711) | Acc: (90.64%) (43042/47488)\n",
      "Epoch: 29 | Batch_idx: 380 |  Loss: (0.2715) | Acc: (90.62%) (44193/48768)\n",
      "Epoch: 29 | Batch_idx: 390 |  Loss: (0.2716) | Acc: (90.60%) (45301/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7728) | Acc: (79.89%) (7989/10000)\n",
      "Epoch: 30 | Batch_idx: 0 |  Loss: (0.2634) | Acc: (90.62%) (116/128)\n",
      "Epoch: 30 | Batch_idx: 10 |  Loss: (0.2867) | Acc: (88.99%) (1253/1408)\n",
      "Epoch: 30 | Batch_idx: 20 |  Loss: (0.2664) | Acc: (89.96%) (2418/2688)\n",
      "Epoch: 30 | Batch_idx: 30 |  Loss: (0.2603) | Acc: (90.42%) (3588/3968)\n",
      "Epoch: 30 | Batch_idx: 40 |  Loss: (0.2615) | Acc: (90.42%) (4745/5248)\n",
      "Epoch: 30 | Batch_idx: 50 |  Loss: (0.2743) | Acc: (90.00%) (5875/6528)\n",
      "Epoch: 30 | Batch_idx: 60 |  Loss: (0.2685) | Acc: (90.23%) (7045/7808)\n",
      "Epoch: 30 | Batch_idx: 70 |  Loss: (0.2679) | Acc: (90.27%) (8204/9088)\n",
      "Epoch: 30 | Batch_idx: 80 |  Loss: (0.2679) | Acc: (90.35%) (9367/10368)\n",
      "Epoch: 30 | Batch_idx: 90 |  Loss: (0.2632) | Acc: (90.56%) (10548/11648)\n",
      "Epoch: 30 | Batch_idx: 100 |  Loss: (0.2619) | Acc: (90.59%) (11712/12928)\n",
      "Epoch: 30 | Batch_idx: 110 |  Loss: (0.2611) | Acc: (90.62%) (12875/14208)\n",
      "Epoch: 30 | Batch_idx: 120 |  Loss: (0.2603) | Acc: (90.72%) (14050/15488)\n",
      "Epoch: 30 | Batch_idx: 130 |  Loss: (0.2600) | Acc: (90.70%) (15208/16768)\n",
      "Epoch: 30 | Batch_idx: 140 |  Loss: (0.2592) | Acc: (90.74%) (16377/18048)\n",
      "Epoch: 30 | Batch_idx: 150 |  Loss: (0.2594) | Acc: (90.77%) (17544/19328)\n",
      "Epoch: 30 | Batch_idx: 160 |  Loss: (0.2581) | Acc: (90.83%) (18719/20608)\n",
      "Epoch: 30 | Batch_idx: 170 |  Loss: (0.2589) | Acc: (90.82%) (19879/21888)\n",
      "Epoch: 30 | Batch_idx: 180 |  Loss: (0.2601) | Acc: (90.80%) (21036/23168)\n",
      "Epoch: 30 | Batch_idx: 190 |  Loss: (0.2612) | Acc: (90.78%) (22193/24448)\n",
      "Epoch: 30 | Batch_idx: 200 |  Loss: (0.2614) | Acc: (90.81%) (23363/25728)\n",
      "Epoch: 30 | Batch_idx: 210 |  Loss: (0.2610) | Acc: (90.80%) (24522/27008)\n",
      "Epoch: 30 | Batch_idx: 220 |  Loss: (0.2616) | Acc: (90.79%) (25683/28288)\n",
      "Epoch: 30 | Batch_idx: 230 |  Loss: (0.2611) | Acc: (90.75%) (26832/29568)\n",
      "Epoch: 30 | Batch_idx: 240 |  Loss: (0.2617) | Acc: (90.72%) (27985/30848)\n",
      "Epoch: 30 | Batch_idx: 250 |  Loss: (0.2621) | Acc: (90.72%) (29146/32128)\n",
      "Epoch: 30 | Batch_idx: 260 |  Loss: (0.2632) | Acc: (90.68%) (30294/33408)\n",
      "Epoch: 30 | Batch_idx: 270 |  Loss: (0.2636) | Acc: (90.67%) (31450/34688)\n",
      "Epoch: 30 | Batch_idx: 280 |  Loss: (0.2645) | Acc: (90.63%) (32599/35968)\n",
      "Epoch: 30 | Batch_idx: 290 |  Loss: (0.2631) | Acc: (90.67%) (33774/37248)\n",
      "Epoch: 30 | Batch_idx: 300 |  Loss: (0.2643) | Acc: (90.64%) (34922/38528)\n",
      "Epoch: 30 | Batch_idx: 310 |  Loss: (0.2641) | Acc: (90.66%) (36089/39808)\n",
      "Epoch: 30 | Batch_idx: 320 |  Loss: (0.2645) | Acc: (90.64%) (37244/41088)\n",
      "Epoch: 30 | Batch_idx: 330 |  Loss: (0.2641) | Acc: (90.66%) (38409/42368)\n",
      "Epoch: 30 | Batch_idx: 340 |  Loss: (0.2649) | Acc: (90.62%) (39554/43648)\n",
      "Epoch: 30 | Batch_idx: 350 |  Loss: (0.2648) | Acc: (90.61%) (40711/44928)\n",
      "Epoch: 30 | Batch_idx: 360 |  Loss: (0.2648) | Acc: (90.62%) (41872/46208)\n",
      "Epoch: 30 | Batch_idx: 370 |  Loss: (0.2644) | Acc: (90.64%) (43045/47488)\n",
      "Epoch: 30 | Batch_idx: 380 |  Loss: (0.2642) | Acc: (90.66%) (44212/48768)\n",
      "Epoch: 30 | Batch_idx: 390 |  Loss: (0.2639) | Acc: (90.67%) (45337/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5435) | Acc: (83.93%) (8393/10000)\n",
      "Epoch: 31 | Batch_idx: 0 |  Loss: (0.2820) | Acc: (88.28%) (113/128)\n",
      "Epoch: 31 | Batch_idx: 10 |  Loss: (0.2684) | Acc: (90.70%) (1277/1408)\n",
      "Epoch: 31 | Batch_idx: 20 |  Loss: (0.2702) | Acc: (90.44%) (2431/2688)\n",
      "Epoch: 31 | Batch_idx: 30 |  Loss: (0.2652) | Acc: (90.73%) (3600/3968)\n",
      "Epoch: 31 | Batch_idx: 40 |  Loss: (0.2567) | Acc: (90.97%) (4774/5248)\n",
      "Epoch: 31 | Batch_idx: 50 |  Loss: (0.2535) | Acc: (91.13%) (5949/6528)\n",
      "Epoch: 31 | Batch_idx: 60 |  Loss: (0.2541) | Acc: (91.05%) (7109/7808)\n",
      "Epoch: 31 | Batch_idx: 70 |  Loss: (0.2469) | Acc: (91.38%) (8305/9088)\n",
      "Epoch: 31 | Batch_idx: 80 |  Loss: (0.2518) | Acc: (91.29%) (9465/10368)\n",
      "Epoch: 31 | Batch_idx: 90 |  Loss: (0.2518) | Acc: (91.29%) (10633/11648)\n",
      "Epoch: 31 | Batch_idx: 100 |  Loss: (0.2522) | Acc: (91.28%) (11801/12928)\n",
      "Epoch: 31 | Batch_idx: 110 |  Loss: (0.2538) | Acc: (91.25%) (12965/14208)\n",
      "Epoch: 31 | Batch_idx: 120 |  Loss: (0.2519) | Acc: (91.31%) (14142/15488)\n",
      "Epoch: 31 | Batch_idx: 130 |  Loss: (0.2536) | Acc: (91.23%) (15298/16768)\n",
      "Epoch: 31 | Batch_idx: 140 |  Loss: (0.2549) | Acc: (91.21%) (16461/18048)\n",
      "Epoch: 31 | Batch_idx: 150 |  Loss: (0.2545) | Acc: (91.23%) (17632/19328)\n",
      "Epoch: 31 | Batch_idx: 160 |  Loss: (0.2548) | Acc: (91.25%) (18805/20608)\n",
      "Epoch: 31 | Batch_idx: 170 |  Loss: (0.2527) | Acc: (91.29%) (19981/21888)\n",
      "Epoch: 31 | Batch_idx: 180 |  Loss: (0.2530) | Acc: (91.26%) (21143/23168)\n",
      "Epoch: 31 | Batch_idx: 190 |  Loss: (0.2527) | Acc: (91.27%) (22313/24448)\n",
      "Epoch: 31 | Batch_idx: 200 |  Loss: (0.2526) | Acc: (91.24%) (23473/25728)\n",
      "Epoch: 31 | Batch_idx: 210 |  Loss: (0.2520) | Acc: (91.27%) (24650/27008)\n",
      "Epoch: 31 | Batch_idx: 220 |  Loss: (0.2519) | Acc: (91.29%) (25824/28288)\n",
      "Epoch: 31 | Batch_idx: 230 |  Loss: (0.2514) | Acc: (91.30%) (26995/29568)\n",
      "Epoch: 31 | Batch_idx: 240 |  Loss: (0.2532) | Acc: (91.23%) (28144/30848)\n",
      "Epoch: 31 | Batch_idx: 250 |  Loss: (0.2546) | Acc: (91.19%) (29298/32128)\n",
      "Epoch: 31 | Batch_idx: 260 |  Loss: (0.2542) | Acc: (91.19%) (30466/33408)\n",
      "Epoch: 31 | Batch_idx: 270 |  Loss: (0.2539) | Acc: (91.19%) (31632/34688)\n",
      "Epoch: 31 | Batch_idx: 280 |  Loss: (0.2533) | Acc: (91.19%) (32800/35968)\n",
      "Epoch: 31 | Batch_idx: 290 |  Loss: (0.2532) | Acc: (91.21%) (33974/37248)\n",
      "Epoch: 31 | Batch_idx: 300 |  Loss: (0.2540) | Acc: (91.17%) (35127/38528)\n",
      "Epoch: 31 | Batch_idx: 310 |  Loss: (0.2540) | Acc: (91.18%) (36298/39808)\n",
      "Epoch: 31 | Batch_idx: 320 |  Loss: (0.2544) | Acc: (91.16%) (37456/41088)\n",
      "Epoch: 31 | Batch_idx: 330 |  Loss: (0.2539) | Acc: (91.17%) (38627/42368)\n",
      "Epoch: 31 | Batch_idx: 340 |  Loss: (0.2540) | Acc: (91.19%) (39804/43648)\n",
      "Epoch: 31 | Batch_idx: 350 |  Loss: (0.2531) | Acc: (91.22%) (40985/44928)\n",
      "Epoch: 31 | Batch_idx: 360 |  Loss: (0.2542) | Acc: (91.19%) (42136/46208)\n",
      "Epoch: 31 | Batch_idx: 370 |  Loss: (0.2540) | Acc: (91.20%) (43307/47488)\n",
      "Epoch: 31 | Batch_idx: 380 |  Loss: (0.2543) | Acc: (91.16%) (44457/48768)\n",
      "Epoch: 31 | Batch_idx: 390 |  Loss: (0.2547) | Acc: (91.16%) (45578/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6117) | Acc: (83.30%) (8330/10000)\n",
      "Epoch: 32 | Batch_idx: 0 |  Loss: (0.3031) | Acc: (89.06%) (114/128)\n",
      "Epoch: 32 | Batch_idx: 10 |  Loss: (0.2224) | Acc: (92.05%) (1296/1408)\n",
      "Epoch: 32 | Batch_idx: 20 |  Loss: (0.2290) | Acc: (91.78%) (2467/2688)\n",
      "Epoch: 32 | Batch_idx: 30 |  Loss: (0.2286) | Acc: (92.09%) (3654/3968)\n",
      "Epoch: 32 | Batch_idx: 40 |  Loss: (0.2319) | Acc: (91.83%) (4819/5248)\n",
      "Epoch: 32 | Batch_idx: 50 |  Loss: (0.2279) | Acc: (91.91%) (6000/6528)\n",
      "Epoch: 32 | Batch_idx: 60 |  Loss: (0.2296) | Acc: (91.92%) (7177/7808)\n",
      "Epoch: 32 | Batch_idx: 70 |  Loss: (0.2310) | Acc: (91.80%) (8343/9088)\n",
      "Epoch: 32 | Batch_idx: 80 |  Loss: (0.2341) | Acc: (91.72%) (9510/10368)\n",
      "Epoch: 32 | Batch_idx: 90 |  Loss: (0.2326) | Acc: (91.73%) (10685/11648)\n",
      "Epoch: 32 | Batch_idx: 100 |  Loss: (0.2324) | Acc: (91.73%) (11859/12928)\n",
      "Epoch: 32 | Batch_idx: 110 |  Loss: (0.2344) | Acc: (91.72%) (13031/14208)\n",
      "Epoch: 32 | Batch_idx: 120 |  Loss: (0.2365) | Acc: (91.69%) (14201/15488)\n",
      "Epoch: 32 | Batch_idx: 130 |  Loss: (0.2401) | Acc: (91.56%) (15353/16768)\n",
      "Epoch: 32 | Batch_idx: 140 |  Loss: (0.2421) | Acc: (91.50%) (16514/18048)\n",
      "Epoch: 32 | Batch_idx: 150 |  Loss: (0.2419) | Acc: (91.51%) (17687/19328)\n",
      "Epoch: 32 | Batch_idx: 160 |  Loss: (0.2406) | Acc: (91.55%) (18867/20608)\n",
      "Epoch: 32 | Batch_idx: 170 |  Loss: (0.2415) | Acc: (91.53%) (20035/21888)\n",
      "Epoch: 32 | Batch_idx: 180 |  Loss: (0.2413) | Acc: (91.50%) (21198/23168)\n",
      "Epoch: 32 | Batch_idx: 190 |  Loss: (0.2419) | Acc: (91.47%) (22362/24448)\n",
      "Epoch: 32 | Batch_idx: 200 |  Loss: (0.2423) | Acc: (91.50%) (23540/25728)\n",
      "Epoch: 32 | Batch_idx: 210 |  Loss: (0.2424) | Acc: (91.52%) (24717/27008)\n",
      "Epoch: 32 | Batch_idx: 220 |  Loss: (0.2416) | Acc: (91.53%) (25892/28288)\n",
      "Epoch: 32 | Batch_idx: 230 |  Loss: (0.2419) | Acc: (91.52%) (27061/29568)\n",
      "Epoch: 32 | Batch_idx: 240 |  Loss: (0.2416) | Acc: (91.55%) (28241/30848)\n",
      "Epoch: 32 | Batch_idx: 250 |  Loss: (0.2428) | Acc: (91.49%) (29394/32128)\n",
      "Epoch: 32 | Batch_idx: 260 |  Loss: (0.2424) | Acc: (91.54%) (30582/33408)\n",
      "Epoch: 32 | Batch_idx: 270 |  Loss: (0.2429) | Acc: (91.52%) (31746/34688)\n",
      "Epoch: 32 | Batch_idx: 280 |  Loss: (0.2441) | Acc: (91.48%) (32904/35968)\n",
      "Epoch: 32 | Batch_idx: 290 |  Loss: (0.2434) | Acc: (91.50%) (34082/37248)\n",
      "Epoch: 32 | Batch_idx: 300 |  Loss: (0.2432) | Acc: (91.54%) (35269/38528)\n",
      "Epoch: 32 | Batch_idx: 310 |  Loss: (0.2431) | Acc: (91.56%) (36448/39808)\n",
      "Epoch: 32 | Batch_idx: 320 |  Loss: (0.2446) | Acc: (91.49%) (37590/41088)\n",
      "Epoch: 32 | Batch_idx: 330 |  Loss: (0.2448) | Acc: (91.46%) (38751/42368)\n",
      "Epoch: 32 | Batch_idx: 340 |  Loss: (0.2450) | Acc: (91.46%) (39921/43648)\n",
      "Epoch: 32 | Batch_idx: 350 |  Loss: (0.2463) | Acc: (91.43%) (41076/44928)\n",
      "Epoch: 32 | Batch_idx: 360 |  Loss: (0.2464) | Acc: (91.47%) (42266/46208)\n",
      "Epoch: 32 | Batch_idx: 370 |  Loss: (0.2461) | Acc: (91.46%) (43434/47488)\n",
      "Epoch: 32 | Batch_idx: 380 |  Loss: (0.2463) | Acc: (91.47%) (44610/48768)\n",
      "Epoch: 32 | Batch_idx: 390 |  Loss: (0.2469) | Acc: (91.45%) (45727/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5926) | Acc: (84.12%) (8412/10000)\n",
      "Epoch: 33 | Batch_idx: 0 |  Loss: (0.1980) | Acc: (94.53%) (121/128)\n",
      "Epoch: 33 | Batch_idx: 10 |  Loss: (0.2326) | Acc: (92.19%) (1298/1408)\n",
      "Epoch: 33 | Batch_idx: 20 |  Loss: (0.2319) | Acc: (92.22%) (2479/2688)\n",
      "Epoch: 33 | Batch_idx: 30 |  Loss: (0.2426) | Acc: (91.96%) (3649/3968)\n",
      "Epoch: 33 | Batch_idx: 40 |  Loss: (0.2368) | Acc: (92.04%) (4830/5248)\n",
      "Epoch: 33 | Batch_idx: 50 |  Loss: (0.2349) | Acc: (92.06%) (6010/6528)\n",
      "Epoch: 33 | Batch_idx: 60 |  Loss: (0.2342) | Acc: (92.05%) (7187/7808)\n",
      "Epoch: 33 | Batch_idx: 70 |  Loss: (0.2330) | Acc: (92.04%) (8365/9088)\n",
      "Epoch: 33 | Batch_idx: 80 |  Loss: (0.2336) | Acc: (91.98%) (9537/10368)\n",
      "Epoch: 33 | Batch_idx: 90 |  Loss: (0.2311) | Acc: (92.09%) (10727/11648)\n",
      "Epoch: 33 | Batch_idx: 100 |  Loss: (0.2329) | Acc: (92.03%) (11897/12928)\n",
      "Epoch: 33 | Batch_idx: 110 |  Loss: (0.2343) | Acc: (91.98%) (13069/14208)\n",
      "Epoch: 33 | Batch_idx: 120 |  Loss: (0.2353) | Acc: (91.91%) (14235/15488)\n",
      "Epoch: 33 | Batch_idx: 130 |  Loss: (0.2343) | Acc: (91.98%) (15424/16768)\n",
      "Epoch: 33 | Batch_idx: 140 |  Loss: (0.2339) | Acc: (91.99%) (16602/18048)\n",
      "Epoch: 33 | Batch_idx: 150 |  Loss: (0.2324) | Acc: (92.04%) (17790/19328)\n",
      "Epoch: 33 | Batch_idx: 160 |  Loss: (0.2332) | Acc: (92.00%) (18960/20608)\n",
      "Epoch: 33 | Batch_idx: 170 |  Loss: (0.2325) | Acc: (91.98%) (20132/21888)\n",
      "Epoch: 33 | Batch_idx: 180 |  Loss: (0.2330) | Acc: (91.89%) (21289/23168)\n",
      "Epoch: 33 | Batch_idx: 190 |  Loss: (0.2336) | Acc: (91.90%) (22468/24448)\n",
      "Epoch: 33 | Batch_idx: 200 |  Loss: (0.2344) | Acc: (91.90%) (23644/25728)\n",
      "Epoch: 33 | Batch_idx: 210 |  Loss: (0.2345) | Acc: (91.91%) (24823/27008)\n",
      "Epoch: 33 | Batch_idx: 220 |  Loss: (0.2349) | Acc: (91.88%) (25991/28288)\n",
      "Epoch: 33 | Batch_idx: 230 |  Loss: (0.2364) | Acc: (91.85%) (27159/29568)\n",
      "Epoch: 33 | Batch_idx: 240 |  Loss: (0.2369) | Acc: (91.84%) (28330/30848)\n",
      "Epoch: 33 | Batch_idx: 250 |  Loss: (0.2382) | Acc: (91.80%) (29495/32128)\n",
      "Epoch: 33 | Batch_idx: 260 |  Loss: (0.2392) | Acc: (91.75%) (30652/33408)\n",
      "Epoch: 33 | Batch_idx: 270 |  Loss: (0.2389) | Acc: (91.77%) (31833/34688)\n",
      "Epoch: 33 | Batch_idx: 280 |  Loss: (0.2388) | Acc: (91.75%) (33000/35968)\n",
      "Epoch: 33 | Batch_idx: 290 |  Loss: (0.2397) | Acc: (91.72%) (34164/37248)\n",
      "Epoch: 33 | Batch_idx: 300 |  Loss: (0.2402) | Acc: (91.72%) (35337/38528)\n",
      "Epoch: 33 | Batch_idx: 310 |  Loss: (0.2409) | Acc: (91.69%) (36498/39808)\n",
      "Epoch: 33 | Batch_idx: 320 |  Loss: (0.2404) | Acc: (91.66%) (37663/41088)\n",
      "Epoch: 33 | Batch_idx: 330 |  Loss: (0.2409) | Acc: (91.67%) (38840/42368)\n",
      "Epoch: 33 | Batch_idx: 340 |  Loss: (0.2403) | Acc: (91.69%) (40022/43648)\n",
      "Epoch: 33 | Batch_idx: 350 |  Loss: (0.2409) | Acc: (91.68%) (41190/44928)\n",
      "Epoch: 33 | Batch_idx: 360 |  Loss: (0.2406) | Acc: (91.71%) (42378/46208)\n",
      "Epoch: 33 | Batch_idx: 370 |  Loss: (0.2403) | Acc: (91.73%) (43563/47488)\n",
      "Epoch: 33 | Batch_idx: 380 |  Loss: (0.2408) | Acc: (91.71%) (44725/48768)\n",
      "Epoch: 33 | Batch_idx: 390 |  Loss: (0.2408) | Acc: (91.71%) (45856/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7645) | Acc: (81.64%) (8164/10000)\n",
      "Epoch: 34 | Batch_idx: 0 |  Loss: (0.2065) | Acc: (92.19%) (118/128)\n",
      "Epoch: 34 | Batch_idx: 10 |  Loss: (0.2089) | Acc: (93.25%) (1313/1408)\n",
      "Epoch: 34 | Batch_idx: 20 |  Loss: (0.2085) | Acc: (93.04%) (2501/2688)\n",
      "Epoch: 34 | Batch_idx: 30 |  Loss: (0.2121) | Acc: (92.84%) (3684/3968)\n",
      "Epoch: 34 | Batch_idx: 40 |  Loss: (0.2144) | Acc: (92.53%) (4856/5248)\n",
      "Epoch: 34 | Batch_idx: 50 |  Loss: (0.2141) | Acc: (92.29%) (6025/6528)\n",
      "Epoch: 34 | Batch_idx: 60 |  Loss: (0.2184) | Acc: (92.20%) (7199/7808)\n",
      "Epoch: 34 | Batch_idx: 70 |  Loss: (0.2156) | Acc: (92.20%) (8379/9088)\n",
      "Epoch: 34 | Batch_idx: 80 |  Loss: (0.2172) | Acc: (92.13%) (9552/10368)\n",
      "Epoch: 34 | Batch_idx: 90 |  Loss: (0.2185) | Acc: (92.14%) (10733/11648)\n",
      "Epoch: 34 | Batch_idx: 100 |  Loss: (0.2182) | Acc: (92.16%) (11915/12928)\n",
      "Epoch: 34 | Batch_idx: 110 |  Loss: (0.2190) | Acc: (92.18%) (13097/14208)\n",
      "Epoch: 34 | Batch_idx: 120 |  Loss: (0.2200) | Acc: (92.17%) (14276/15488)\n",
      "Epoch: 34 | Batch_idx: 130 |  Loss: (0.2205) | Acc: (92.12%) (15446/16768)\n",
      "Epoch: 34 | Batch_idx: 140 |  Loss: (0.2203) | Acc: (92.17%) (16634/18048)\n",
      "Epoch: 34 | Batch_idx: 150 |  Loss: (0.2211) | Acc: (92.15%) (17811/19328)\n",
      "Epoch: 34 | Batch_idx: 160 |  Loss: (0.2230) | Acc: (92.09%) (18977/20608)\n",
      "Epoch: 34 | Batch_idx: 170 |  Loss: (0.2238) | Acc: (92.04%) (20145/21888)\n",
      "Epoch: 34 | Batch_idx: 180 |  Loss: (0.2252) | Acc: (92.02%) (21319/23168)\n",
      "Epoch: 34 | Batch_idx: 190 |  Loss: (0.2263) | Acc: (92.00%) (22491/24448)\n",
      "Epoch: 34 | Batch_idx: 200 |  Loss: (0.2279) | Acc: (91.97%) (23662/25728)\n",
      "Epoch: 34 | Batch_idx: 210 |  Loss: (0.2296) | Acc: (91.92%) (24825/27008)\n",
      "Epoch: 34 | Batch_idx: 220 |  Loss: (0.2301) | Acc: (91.95%) (26011/28288)\n",
      "Epoch: 34 | Batch_idx: 230 |  Loss: (0.2298) | Acc: (91.98%) (27198/29568)\n",
      "Epoch: 34 | Batch_idx: 240 |  Loss: (0.2287) | Acc: (92.03%) (28388/30848)\n",
      "Epoch: 34 | Batch_idx: 250 |  Loss: (0.2284) | Acc: (92.03%) (29568/32128)\n",
      "Epoch: 34 | Batch_idx: 260 |  Loss: (0.2287) | Acc: (92.01%) (30740/33408)\n",
      "Epoch: 34 | Batch_idx: 270 |  Loss: (0.2275) | Acc: (92.06%) (31935/34688)\n",
      "Epoch: 34 | Batch_idx: 280 |  Loss: (0.2277) | Acc: (92.07%) (33117/35968)\n",
      "Epoch: 34 | Batch_idx: 290 |  Loss: (0.2277) | Acc: (92.07%) (34294/37248)\n",
      "Epoch: 34 | Batch_idx: 300 |  Loss: (0.2280) | Acc: (92.09%) (35479/38528)\n",
      "Epoch: 34 | Batch_idx: 310 |  Loss: (0.2286) | Acc: (92.07%) (36650/39808)\n",
      "Epoch: 34 | Batch_idx: 320 |  Loss: (0.2276) | Acc: (92.11%) (37847/41088)\n",
      "Epoch: 34 | Batch_idx: 330 |  Loss: (0.2276) | Acc: (92.10%) (39022/42368)\n",
      "Epoch: 34 | Batch_idx: 340 |  Loss: (0.2280) | Acc: (92.09%) (40197/43648)\n",
      "Epoch: 34 | Batch_idx: 350 |  Loss: (0.2285) | Acc: (92.07%) (41364/44928)\n",
      "Epoch: 34 | Batch_idx: 360 |  Loss: (0.2290) | Acc: (92.07%) (42544/46208)\n",
      "Epoch: 34 | Batch_idx: 370 |  Loss: (0.2296) | Acc: (92.05%) (43713/47488)\n",
      "Epoch: 34 | Batch_idx: 380 |  Loss: (0.2294) | Acc: (92.04%) (44886/48768)\n",
      "Epoch: 34 | Batch_idx: 390 |  Loss: (0.2288) | Acc: (92.08%) (46038/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7021) | Acc: (82.98%) (8298/10000)\n",
      "Epoch: 35 | Batch_idx: 0 |  Loss: (0.2141) | Acc: (92.97%) (119/128)\n",
      "Epoch: 35 | Batch_idx: 10 |  Loss: (0.2263) | Acc: (92.68%) (1305/1408)\n",
      "Epoch: 35 | Batch_idx: 20 |  Loss: (0.2210) | Acc: (92.93%) (2498/2688)\n",
      "Epoch: 35 | Batch_idx: 30 |  Loss: (0.2268) | Acc: (92.72%) (3679/3968)\n",
      "Epoch: 35 | Batch_idx: 40 |  Loss: (0.2244) | Acc: (92.70%) (4865/5248)\n",
      "Epoch: 35 | Batch_idx: 50 |  Loss: (0.2316) | Acc: (92.28%) (6024/6528)\n",
      "Epoch: 35 | Batch_idx: 60 |  Loss: (0.2271) | Acc: (92.33%) (7209/7808)\n",
      "Epoch: 35 | Batch_idx: 70 |  Loss: (0.2239) | Acc: (92.45%) (8402/9088)\n",
      "Epoch: 35 | Batch_idx: 80 |  Loss: (0.2204) | Acc: (92.42%) (9582/10368)\n",
      "Epoch: 35 | Batch_idx: 90 |  Loss: (0.2218) | Acc: (92.44%) (10767/11648)\n",
      "Epoch: 35 | Batch_idx: 100 |  Loss: (0.2215) | Acc: (92.41%) (11947/12928)\n",
      "Epoch: 35 | Batch_idx: 110 |  Loss: (0.2215) | Acc: (92.39%) (13127/14208)\n",
      "Epoch: 35 | Batch_idx: 120 |  Loss: (0.2231) | Acc: (92.35%) (14303/15488)\n",
      "Epoch: 35 | Batch_idx: 130 |  Loss: (0.2193) | Acc: (92.51%) (15512/16768)\n",
      "Epoch: 35 | Batch_idx: 140 |  Loss: (0.2203) | Acc: (92.39%) (16674/18048)\n",
      "Epoch: 35 | Batch_idx: 150 |  Loss: (0.2209) | Acc: (92.39%) (17858/19328)\n",
      "Epoch: 35 | Batch_idx: 160 |  Loss: (0.2226) | Acc: (92.34%) (19029/20608)\n",
      "Epoch: 35 | Batch_idx: 170 |  Loss: (0.2228) | Acc: (92.33%) (20210/21888)\n",
      "Epoch: 35 | Batch_idx: 180 |  Loss: (0.2235) | Acc: (92.30%) (21384/23168)\n",
      "Epoch: 35 | Batch_idx: 190 |  Loss: (0.2238) | Acc: (92.31%) (22568/24448)\n",
      "Epoch: 35 | Batch_idx: 200 |  Loss: (0.2233) | Acc: (92.32%) (23752/25728)\n",
      "Epoch: 35 | Batch_idx: 210 |  Loss: (0.2221) | Acc: (92.38%) (24951/27008)\n",
      "Epoch: 35 | Batch_idx: 220 |  Loss: (0.2222) | Acc: (92.37%) (26131/28288)\n",
      "Epoch: 35 | Batch_idx: 230 |  Loss: (0.2219) | Acc: (92.38%) (27314/29568)\n",
      "Epoch: 35 | Batch_idx: 240 |  Loss: (0.2224) | Acc: (92.33%) (28482/30848)\n",
      "Epoch: 35 | Batch_idx: 250 |  Loss: (0.2219) | Acc: (92.35%) (29669/32128)\n",
      "Epoch: 35 | Batch_idx: 260 |  Loss: (0.2235) | Acc: (92.29%) (30833/33408)\n",
      "Epoch: 35 | Batch_idx: 270 |  Loss: (0.2238) | Acc: (92.31%) (32019/34688)\n",
      "Epoch: 35 | Batch_idx: 280 |  Loss: (0.2235) | Acc: (92.32%) (33205/35968)\n",
      "Epoch: 35 | Batch_idx: 290 |  Loss: (0.2236) | Acc: (92.31%) (34384/37248)\n",
      "Epoch: 35 | Batch_idx: 300 |  Loss: (0.2236) | Acc: (92.33%) (35572/38528)\n",
      "Epoch: 35 | Batch_idx: 310 |  Loss: (0.2254) | Acc: (92.26%) (36725/39808)\n",
      "Epoch: 35 | Batch_idx: 320 |  Loss: (0.2250) | Acc: (92.27%) (37910/41088)\n",
      "Epoch: 35 | Batch_idx: 330 |  Loss: (0.2242) | Acc: (92.30%) (39105/42368)\n",
      "Epoch: 35 | Batch_idx: 340 |  Loss: (0.2248) | Acc: (92.29%) (40282/43648)\n",
      "Epoch: 35 | Batch_idx: 350 |  Loss: (0.2249) | Acc: (92.27%) (41456/44928)\n",
      "Epoch: 35 | Batch_idx: 360 |  Loss: (0.2251) | Acc: (92.25%) (42625/46208)\n",
      "Epoch: 35 | Batch_idx: 370 |  Loss: (0.2261) | Acc: (92.20%) (43785/47488)\n",
      "Epoch: 35 | Batch_idx: 380 |  Loss: (0.2255) | Acc: (92.23%) (44979/48768)\n",
      "Epoch: 35 | Batch_idx: 390 |  Loss: (0.2255) | Acc: (92.22%) (46110/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6518) | Acc: (83.41%) (8341/10000)\n",
      "Epoch: 36 | Batch_idx: 0 |  Loss: (0.2045) | Acc: (90.62%) (116/128)\n",
      "Epoch: 36 | Batch_idx: 10 |  Loss: (0.1973) | Acc: (92.97%) (1309/1408)\n",
      "Epoch: 36 | Batch_idx: 20 |  Loss: (0.2040) | Acc: (92.34%) (2482/2688)\n",
      "Epoch: 36 | Batch_idx: 30 |  Loss: (0.1993) | Acc: (92.64%) (3676/3968)\n",
      "Epoch: 36 | Batch_idx: 40 |  Loss: (0.1996) | Acc: (92.64%) (4862/5248)\n",
      "Epoch: 36 | Batch_idx: 50 |  Loss: (0.2035) | Acc: (92.62%) (6046/6528)\n",
      "Epoch: 36 | Batch_idx: 60 |  Loss: (0.2018) | Acc: (92.74%) (7241/7808)\n",
      "Epoch: 36 | Batch_idx: 70 |  Loss: (0.2005) | Acc: (92.75%) (8429/9088)\n",
      "Epoch: 36 | Batch_idx: 80 |  Loss: (0.2020) | Acc: (92.74%) (9615/10368)\n",
      "Epoch: 36 | Batch_idx: 90 |  Loss: (0.2021) | Acc: (92.72%) (10800/11648)\n",
      "Epoch: 36 | Batch_idx: 100 |  Loss: (0.2024) | Acc: (92.72%) (11987/12928)\n",
      "Epoch: 36 | Batch_idx: 110 |  Loss: (0.2022) | Acc: (92.76%) (13180/14208)\n",
      "Epoch: 36 | Batch_idx: 120 |  Loss: (0.2026) | Acc: (92.77%) (14368/15488)\n",
      "Epoch: 36 | Batch_idx: 130 |  Loss: (0.2029) | Acc: (92.80%) (15561/16768)\n",
      "Epoch: 36 | Batch_idx: 140 |  Loss: (0.2041) | Acc: (92.81%) (16751/18048)\n",
      "Epoch: 36 | Batch_idx: 150 |  Loss: (0.2049) | Acc: (92.83%) (17942/19328)\n",
      "Epoch: 36 | Batch_idx: 160 |  Loss: (0.2050) | Acc: (92.80%) (19124/20608)\n",
      "Epoch: 36 | Batch_idx: 170 |  Loss: (0.2052) | Acc: (92.77%) (20305/21888)\n",
      "Epoch: 36 | Batch_idx: 180 |  Loss: (0.2065) | Acc: (92.79%) (21498/23168)\n",
      "Epoch: 36 | Batch_idx: 190 |  Loss: (0.2078) | Acc: (92.71%) (22666/24448)\n",
      "Epoch: 36 | Batch_idx: 200 |  Loss: (0.2071) | Acc: (92.74%) (23860/25728)\n",
      "Epoch: 36 | Batch_idx: 210 |  Loss: (0.2067) | Acc: (92.76%) (25052/27008)\n",
      "Epoch: 36 | Batch_idx: 220 |  Loss: (0.2065) | Acc: (92.76%) (26241/28288)\n",
      "Epoch: 36 | Batch_idx: 230 |  Loss: (0.2081) | Acc: (92.70%) (27411/29568)\n",
      "Epoch: 36 | Batch_idx: 240 |  Loss: (0.2076) | Acc: (92.72%) (28602/30848)\n",
      "Epoch: 36 | Batch_idx: 250 |  Loss: (0.2095) | Acc: (92.65%) (29766/32128)\n",
      "Epoch: 36 | Batch_idx: 260 |  Loss: (0.2097) | Acc: (92.66%) (30955/33408)\n",
      "Epoch: 36 | Batch_idx: 270 |  Loss: (0.2104) | Acc: (92.66%) (32141/34688)\n",
      "Epoch: 36 | Batch_idx: 280 |  Loss: (0.2106) | Acc: (92.65%) (33325/35968)\n",
      "Epoch: 36 | Batch_idx: 290 |  Loss: (0.2117) | Acc: (92.60%) (34493/37248)\n",
      "Epoch: 36 | Batch_idx: 300 |  Loss: (0.2129) | Acc: (92.55%) (35657/38528)\n",
      "Epoch: 36 | Batch_idx: 310 |  Loss: (0.2128) | Acc: (92.54%) (36839/39808)\n",
      "Epoch: 36 | Batch_idx: 320 |  Loss: (0.2132) | Acc: (92.54%) (38022/41088)\n",
      "Epoch: 36 | Batch_idx: 330 |  Loss: (0.2137) | Acc: (92.53%) (39203/42368)\n",
      "Epoch: 36 | Batch_idx: 340 |  Loss: (0.2139) | Acc: (92.52%) (40381/43648)\n",
      "Epoch: 36 | Batch_idx: 350 |  Loss: (0.2136) | Acc: (92.53%) (41574/44928)\n",
      "Epoch: 36 | Batch_idx: 360 |  Loss: (0.2131) | Acc: (92.56%) (42769/46208)\n",
      "Epoch: 36 | Batch_idx: 370 |  Loss: (0.2130) | Acc: (92.56%) (43957/47488)\n",
      "Epoch: 36 | Batch_idx: 380 |  Loss: (0.2132) | Acc: (92.56%) (45141/48768)\n",
      "Epoch: 36 | Batch_idx: 390 |  Loss: (0.2127) | Acc: (92.57%) (46284/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6602) | Acc: (82.93%) (8293/10000)\n",
      "Epoch: 37 | Batch_idx: 0 |  Loss: (0.1972) | Acc: (91.41%) (117/128)\n",
      "Epoch: 37 | Batch_idx: 10 |  Loss: (0.1745) | Acc: (93.82%) (1321/1408)\n",
      "Epoch: 37 | Batch_idx: 20 |  Loss: (0.2017) | Acc: (93.01%) (2500/2688)\n",
      "Epoch: 37 | Batch_idx: 30 |  Loss: (0.2033) | Acc: (92.89%) (3686/3968)\n",
      "Epoch: 37 | Batch_idx: 40 |  Loss: (0.2069) | Acc: (92.93%) (4877/5248)\n",
      "Epoch: 37 | Batch_idx: 50 |  Loss: (0.2040) | Acc: (93.08%) (6076/6528)\n",
      "Epoch: 37 | Batch_idx: 60 |  Loss: (0.2010) | Acc: (93.14%) (7272/7808)\n",
      "Epoch: 37 | Batch_idx: 70 |  Loss: (0.1973) | Acc: (93.32%) (8481/9088)\n",
      "Epoch: 37 | Batch_idx: 80 |  Loss: (0.1983) | Acc: (93.27%) (9670/10368)\n",
      "Epoch: 37 | Batch_idx: 90 |  Loss: (0.1985) | Acc: (93.29%) (10867/11648)\n",
      "Epoch: 37 | Batch_idx: 100 |  Loss: (0.1978) | Acc: (93.25%) (12056/12928)\n",
      "Epoch: 37 | Batch_idx: 110 |  Loss: (0.1984) | Acc: (93.30%) (13256/14208)\n",
      "Epoch: 37 | Batch_idx: 120 |  Loss: (0.2014) | Acc: (93.19%) (14433/15488)\n",
      "Epoch: 37 | Batch_idx: 130 |  Loss: (0.1989) | Acc: (93.28%) (15642/16768)\n",
      "Epoch: 37 | Batch_idx: 140 |  Loss: (0.2004) | Acc: (93.21%) (16823/18048)\n",
      "Epoch: 37 | Batch_idx: 150 |  Loss: (0.2012) | Acc: (93.15%) (18004/19328)\n",
      "Epoch: 37 | Batch_idx: 160 |  Loss: (0.2016) | Acc: (93.09%) (19184/20608)\n",
      "Epoch: 37 | Batch_idx: 170 |  Loss: (0.2027) | Acc: (93.02%) (20360/21888)\n",
      "Epoch: 37 | Batch_idx: 180 |  Loss: (0.2018) | Acc: (93.05%) (21557/23168)\n",
      "Epoch: 37 | Batch_idx: 190 |  Loss: (0.2032) | Acc: (93.03%) (22743/24448)\n",
      "Epoch: 37 | Batch_idx: 200 |  Loss: (0.2047) | Acc: (92.97%) (23919/25728)\n",
      "Epoch: 37 | Batch_idx: 210 |  Loss: (0.2050) | Acc: (92.95%) (25104/27008)\n",
      "Epoch: 37 | Batch_idx: 220 |  Loss: (0.2054) | Acc: (92.92%) (26285/28288)\n",
      "Epoch: 37 | Batch_idx: 230 |  Loss: (0.2056) | Acc: (92.90%) (27468/29568)\n",
      "Epoch: 37 | Batch_idx: 240 |  Loss: (0.2054) | Acc: (92.89%) (28654/30848)\n",
      "Epoch: 37 | Batch_idx: 250 |  Loss: (0.2052) | Acc: (92.88%) (29839/32128)\n",
      "Epoch: 37 | Batch_idx: 260 |  Loss: (0.2055) | Acc: (92.85%) (31020/33408)\n",
      "Epoch: 37 | Batch_idx: 270 |  Loss: (0.2064) | Acc: (92.81%) (32195/34688)\n",
      "Epoch: 37 | Batch_idx: 280 |  Loss: (0.2062) | Acc: (92.82%) (33386/35968)\n",
      "Epoch: 37 | Batch_idx: 290 |  Loss: (0.2064) | Acc: (92.81%) (34571/37248)\n",
      "Epoch: 37 | Batch_idx: 300 |  Loss: (0.2052) | Acc: (92.86%) (35778/38528)\n",
      "Epoch: 37 | Batch_idx: 310 |  Loss: (0.2054) | Acc: (92.84%) (36956/39808)\n",
      "Epoch: 37 | Batch_idx: 320 |  Loss: (0.2052) | Acc: (92.86%) (38154/41088)\n",
      "Epoch: 37 | Batch_idx: 330 |  Loss: (0.2049) | Acc: (92.88%) (39351/42368)\n",
      "Epoch: 37 | Batch_idx: 340 |  Loss: (0.2057) | Acc: (92.85%) (40527/43648)\n",
      "Epoch: 37 | Batch_idx: 350 |  Loss: (0.2058) | Acc: (92.85%) (41717/44928)\n",
      "Epoch: 37 | Batch_idx: 360 |  Loss: (0.2059) | Acc: (92.86%) (42910/46208)\n",
      "Epoch: 37 | Batch_idx: 370 |  Loss: (0.2066) | Acc: (92.84%) (44086/47488)\n",
      "Epoch: 37 | Batch_idx: 380 |  Loss: (0.2063) | Acc: (92.84%) (45278/48768)\n",
      "Epoch: 37 | Batch_idx: 390 |  Loss: (0.2057) | Acc: (92.89%) (46444/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6596) | Acc: (83.07%) (8307/10000)\n",
      "Epoch: 38 | Batch_idx: 0 |  Loss: (0.1449) | Acc: (95.31%) (122/128)\n",
      "Epoch: 38 | Batch_idx: 10 |  Loss: (0.1970) | Acc: (93.39%) (1315/1408)\n",
      "Epoch: 38 | Batch_idx: 20 |  Loss: (0.1928) | Acc: (93.60%) (2516/2688)\n",
      "Epoch: 38 | Batch_idx: 30 |  Loss: (0.1983) | Acc: (93.40%) (3706/3968)\n",
      "Epoch: 38 | Batch_idx: 40 |  Loss: (0.1960) | Acc: (93.37%) (4900/5248)\n",
      "Epoch: 38 | Batch_idx: 50 |  Loss: (0.1897) | Acc: (93.57%) (6108/6528)\n",
      "Epoch: 38 | Batch_idx: 60 |  Loss: (0.1940) | Acc: (93.39%) (7292/7808)\n",
      "Epoch: 38 | Batch_idx: 70 |  Loss: (0.1971) | Acc: (93.23%) (8473/9088)\n",
      "Epoch: 38 | Batch_idx: 80 |  Loss: (0.1944) | Acc: (93.37%) (9681/10368)\n",
      "Epoch: 38 | Batch_idx: 90 |  Loss: (0.1957) | Acc: (93.29%) (10867/11648)\n",
      "Epoch: 38 | Batch_idx: 100 |  Loss: (0.1965) | Acc: (93.20%) (12049/12928)\n",
      "Epoch: 38 | Batch_idx: 110 |  Loss: (0.1956) | Acc: (93.20%) (13242/14208)\n",
      "Epoch: 38 | Batch_idx: 120 |  Loss: (0.1952) | Acc: (93.21%) (14437/15488)\n",
      "Epoch: 38 | Batch_idx: 130 |  Loss: (0.1955) | Acc: (93.20%) (15628/16768)\n",
      "Epoch: 38 | Batch_idx: 140 |  Loss: (0.1963) | Acc: (93.17%) (16815/18048)\n",
      "Epoch: 38 | Batch_idx: 150 |  Loss: (0.1965) | Acc: (93.16%) (18005/19328)\n",
      "Epoch: 38 | Batch_idx: 160 |  Loss: (0.1977) | Acc: (93.14%) (19195/20608)\n",
      "Epoch: 38 | Batch_idx: 170 |  Loss: (0.1993) | Acc: (93.13%) (20384/21888)\n",
      "Epoch: 38 | Batch_idx: 180 |  Loss: (0.2004) | Acc: (93.10%) (21570/23168)\n",
      "Epoch: 38 | Batch_idx: 190 |  Loss: (0.2004) | Acc: (93.10%) (22761/24448)\n",
      "Epoch: 38 | Batch_idx: 200 |  Loss: (0.2005) | Acc: (93.11%) (23955/25728)\n",
      "Epoch: 38 | Batch_idx: 210 |  Loss: (0.2017) | Acc: (93.08%) (25139/27008)\n",
      "Epoch: 38 | Batch_idx: 220 |  Loss: (0.2021) | Acc: (93.07%) (26328/28288)\n",
      "Epoch: 38 | Batch_idx: 230 |  Loss: (0.2020) | Acc: (93.03%) (27508/29568)\n",
      "Epoch: 38 | Batch_idx: 240 |  Loss: (0.2017) | Acc: (93.01%) (28692/30848)\n",
      "Epoch: 38 | Batch_idx: 250 |  Loss: (0.2008) | Acc: (93.04%) (29892/32128)\n",
      "Epoch: 38 | Batch_idx: 260 |  Loss: (0.2014) | Acc: (93.01%) (31072/33408)\n",
      "Epoch: 38 | Batch_idx: 270 |  Loss: (0.2011) | Acc: (93.03%) (32270/34688)\n",
      "Epoch: 38 | Batch_idx: 280 |  Loss: (0.2011) | Acc: (93.02%) (33459/35968)\n",
      "Epoch: 38 | Batch_idx: 290 |  Loss: (0.2012) | Acc: (93.03%) (34650/37248)\n",
      "Epoch: 38 | Batch_idx: 300 |  Loss: (0.2007) | Acc: (93.02%) (35840/38528)\n",
      "Epoch: 38 | Batch_idx: 310 |  Loss: (0.2005) | Acc: (93.03%) (37033/39808)\n",
      "Epoch: 38 | Batch_idx: 320 |  Loss: (0.2008) | Acc: (93.00%) (38213/41088)\n",
      "Epoch: 38 | Batch_idx: 330 |  Loss: (0.2012) | Acc: (92.99%) (39400/42368)\n",
      "Epoch: 38 | Batch_idx: 340 |  Loss: (0.2014) | Acc: (93.00%) (40594/43648)\n",
      "Epoch: 38 | Batch_idx: 350 |  Loss: (0.2014) | Acc: (93.00%) (41783/44928)\n",
      "Epoch: 38 | Batch_idx: 360 |  Loss: (0.2016) | Acc: (93.02%) (42981/46208)\n",
      "Epoch: 38 | Batch_idx: 370 |  Loss: (0.2016) | Acc: (93.02%) (44174/47488)\n",
      "Epoch: 38 | Batch_idx: 380 |  Loss: (0.2017) | Acc: (93.03%) (45369/48768)\n",
      "Epoch: 38 | Batch_idx: 390 |  Loss: (0.2011) | Acc: (93.05%) (46525/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5485) | Acc: (85.94%) (8594/10000)\n",
      "Epoch: 39 | Batch_idx: 0 |  Loss: (0.1884) | Acc: (93.75%) (120/128)\n",
      "Epoch: 39 | Batch_idx: 10 |  Loss: (0.1849) | Acc: (94.03%) (1324/1408)\n",
      "Epoch: 39 | Batch_idx: 20 |  Loss: (0.1790) | Acc: (93.90%) (2524/2688)\n",
      "Epoch: 39 | Batch_idx: 30 |  Loss: (0.1839) | Acc: (93.62%) (3715/3968)\n",
      "Epoch: 39 | Batch_idx: 40 |  Loss: (0.1869) | Acc: (93.67%) (4916/5248)\n",
      "Epoch: 39 | Batch_idx: 50 |  Loss: (0.1901) | Acc: (93.49%) (6103/6528)\n",
      "Epoch: 39 | Batch_idx: 60 |  Loss: (0.1891) | Acc: (93.57%) (7306/7808)\n",
      "Epoch: 39 | Batch_idx: 70 |  Loss: (0.1869) | Acc: (93.64%) (8510/9088)\n",
      "Epoch: 39 | Batch_idx: 80 |  Loss: (0.1906) | Acc: (93.49%) (9693/10368)\n",
      "Epoch: 39 | Batch_idx: 90 |  Loss: (0.1900) | Acc: (93.54%) (10896/11648)\n",
      "Epoch: 39 | Batch_idx: 100 |  Loss: (0.1871) | Acc: (93.55%) (12094/12928)\n",
      "Epoch: 39 | Batch_idx: 110 |  Loss: (0.1868) | Acc: (93.55%) (13292/14208)\n",
      "Epoch: 39 | Batch_idx: 120 |  Loss: (0.1879) | Acc: (93.50%) (14482/15488)\n",
      "Epoch: 39 | Batch_idx: 130 |  Loss: (0.1893) | Acc: (93.48%) (15675/16768)\n",
      "Epoch: 39 | Batch_idx: 140 |  Loss: (0.1908) | Acc: (93.43%) (16862/18048)\n",
      "Epoch: 39 | Batch_idx: 150 |  Loss: (0.1917) | Acc: (93.38%) (18049/19328)\n",
      "Epoch: 39 | Batch_idx: 160 |  Loss: (0.1915) | Acc: (93.38%) (19243/20608)\n",
      "Epoch: 39 | Batch_idx: 170 |  Loss: (0.1921) | Acc: (93.33%) (20429/21888)\n",
      "Epoch: 39 | Batch_idx: 180 |  Loss: (0.1926) | Acc: (93.31%) (21618/23168)\n",
      "Epoch: 39 | Batch_idx: 190 |  Loss: (0.1904) | Acc: (93.39%) (22831/24448)\n",
      "Epoch: 39 | Batch_idx: 200 |  Loss: (0.1903) | Acc: (93.40%) (24030/25728)\n",
      "Epoch: 39 | Batch_idx: 210 |  Loss: (0.1905) | Acc: (93.41%) (25228/27008)\n",
      "Epoch: 39 | Batch_idx: 220 |  Loss: (0.1908) | Acc: (93.41%) (26423/28288)\n",
      "Epoch: 39 | Batch_idx: 230 |  Loss: (0.1905) | Acc: (93.41%) (27620/29568)\n",
      "Epoch: 39 | Batch_idx: 240 |  Loss: (0.1902) | Acc: (93.42%) (28819/30848)\n",
      "Epoch: 39 | Batch_idx: 250 |  Loss: (0.1900) | Acc: (93.42%) (30015/32128)\n",
      "Epoch: 39 | Batch_idx: 260 |  Loss: (0.1901) | Acc: (93.39%) (31200/33408)\n",
      "Epoch: 39 | Batch_idx: 270 |  Loss: (0.1898) | Acc: (93.41%) (32403/34688)\n",
      "Epoch: 39 | Batch_idx: 280 |  Loss: (0.1907) | Acc: (93.37%) (33584/35968)\n",
      "Epoch: 39 | Batch_idx: 290 |  Loss: (0.1908) | Acc: (93.38%) (34783/37248)\n",
      "Epoch: 39 | Batch_idx: 300 |  Loss: (0.1911) | Acc: (93.37%) (35974/38528)\n",
      "Epoch: 39 | Batch_idx: 310 |  Loss: (0.1923) | Acc: (93.34%) (37158/39808)\n",
      "Epoch: 39 | Batch_idx: 320 |  Loss: (0.1923) | Acc: (93.35%) (38356/41088)\n",
      "Epoch: 39 | Batch_idx: 330 |  Loss: (0.1933) | Acc: (93.33%) (39540/42368)\n",
      "Epoch: 39 | Batch_idx: 340 |  Loss: (0.1930) | Acc: (93.34%) (40743/43648)\n",
      "Epoch: 39 | Batch_idx: 350 |  Loss: (0.1935) | Acc: (93.32%) (41926/44928)\n",
      "Epoch: 39 | Batch_idx: 360 |  Loss: (0.1930) | Acc: (93.32%) (43123/46208)\n",
      "Epoch: 39 | Batch_idx: 370 |  Loss: (0.1940) | Acc: (93.29%) (44300/47488)\n",
      "Epoch: 39 | Batch_idx: 380 |  Loss: (0.1946) | Acc: (93.26%) (45479/48768)\n",
      "Epoch: 39 | Batch_idx: 390 |  Loss: (0.1946) | Acc: (93.25%) (46623/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6340) | Acc: (83.89%) (8389/10000)\n",
      "Epoch: 40 | Batch_idx: 0 |  Loss: (0.2323) | Acc: (90.62%) (116/128)\n",
      "Epoch: 40 | Batch_idx: 10 |  Loss: (0.2077) | Acc: (92.76%) (1306/1408)\n",
      "Epoch: 40 | Batch_idx: 20 |  Loss: (0.2001) | Acc: (92.97%) (2499/2688)\n",
      "Epoch: 40 | Batch_idx: 30 |  Loss: (0.1901) | Acc: (93.50%) (3710/3968)\n",
      "Epoch: 40 | Batch_idx: 40 |  Loss: (0.1897) | Acc: (93.45%) (4904/5248)\n",
      "Epoch: 40 | Batch_idx: 50 |  Loss: (0.1865) | Acc: (93.66%) (6114/6528)\n",
      "Epoch: 40 | Batch_idx: 60 |  Loss: (0.1841) | Acc: (93.51%) (7301/7808)\n",
      "Epoch: 40 | Batch_idx: 70 |  Loss: (0.1832) | Acc: (93.55%) (8502/9088)\n",
      "Epoch: 40 | Batch_idx: 80 |  Loss: (0.1801) | Acc: (93.66%) (9711/10368)\n",
      "Epoch: 40 | Batch_idx: 90 |  Loss: (0.1800) | Acc: (93.65%) (10908/11648)\n",
      "Epoch: 40 | Batch_idx: 100 |  Loss: (0.1821) | Acc: (93.56%) (12095/12928)\n",
      "Epoch: 40 | Batch_idx: 110 |  Loss: (0.1805) | Acc: (93.60%) (13298/14208)\n",
      "Epoch: 40 | Batch_idx: 120 |  Loss: (0.1804) | Acc: (93.61%) (14498/15488)\n",
      "Epoch: 40 | Batch_idx: 130 |  Loss: (0.1801) | Acc: (93.67%) (15707/16768)\n",
      "Epoch: 40 | Batch_idx: 140 |  Loss: (0.1813) | Acc: (93.62%) (16897/18048)\n",
      "Epoch: 40 | Batch_idx: 150 |  Loss: (0.1823) | Acc: (93.63%) (18097/19328)\n",
      "Epoch: 40 | Batch_idx: 160 |  Loss: (0.1825) | Acc: (93.65%) (19299/20608)\n",
      "Epoch: 40 | Batch_idx: 170 |  Loss: (0.1827) | Acc: (93.63%) (20493/21888)\n",
      "Epoch: 40 | Batch_idx: 180 |  Loss: (0.1831) | Acc: (93.63%) (21692/23168)\n",
      "Epoch: 40 | Batch_idx: 190 |  Loss: (0.1836) | Acc: (93.63%) (22891/24448)\n",
      "Epoch: 40 | Batch_idx: 200 |  Loss: (0.1861) | Acc: (93.51%) (24059/25728)\n",
      "Epoch: 40 | Batch_idx: 210 |  Loss: (0.1862) | Acc: (93.51%) (25256/27008)\n",
      "Epoch: 40 | Batch_idx: 220 |  Loss: (0.1862) | Acc: (93.55%) (26463/28288)\n",
      "Epoch: 40 | Batch_idx: 230 |  Loss: (0.1862) | Acc: (93.56%) (27664/29568)\n",
      "Epoch: 40 | Batch_idx: 240 |  Loss: (0.1865) | Acc: (93.57%) (28864/30848)\n",
      "Epoch: 40 | Batch_idx: 250 |  Loss: (0.1859) | Acc: (93.59%) (30068/32128)\n",
      "Epoch: 40 | Batch_idx: 260 |  Loss: (0.1859) | Acc: (93.58%) (31263/33408)\n",
      "Epoch: 40 | Batch_idx: 270 |  Loss: (0.1861) | Acc: (93.58%) (32461/34688)\n",
      "Epoch: 40 | Batch_idx: 280 |  Loss: (0.1855) | Acc: (93.61%) (33668/35968)\n",
      "Epoch: 40 | Batch_idx: 290 |  Loss: (0.1855) | Acc: (93.62%) (34871/37248)\n",
      "Epoch: 40 | Batch_idx: 300 |  Loss: (0.1861) | Acc: (93.60%) (36063/38528)\n",
      "Epoch: 40 | Batch_idx: 310 |  Loss: (0.1865) | Acc: (93.59%) (37255/39808)\n",
      "Epoch: 40 | Batch_idx: 320 |  Loss: (0.1865) | Acc: (93.58%) (38449/41088)\n",
      "Epoch: 40 | Batch_idx: 330 |  Loss: (0.1861) | Acc: (93.60%) (39656/42368)\n",
      "Epoch: 40 | Batch_idx: 340 |  Loss: (0.1858) | Acc: (93.62%) (40862/43648)\n",
      "Epoch: 40 | Batch_idx: 350 |  Loss: (0.1866) | Acc: (93.57%) (42040/44928)\n",
      "Epoch: 40 | Batch_idx: 360 |  Loss: (0.1869) | Acc: (93.54%) (43225/46208)\n",
      "Epoch: 40 | Batch_idx: 370 |  Loss: (0.1873) | Acc: (93.55%) (44423/47488)\n",
      "Epoch: 40 | Batch_idx: 380 |  Loss: (0.1875) | Acc: (93.55%) (45622/48768)\n",
      "Epoch: 40 | Batch_idx: 390 |  Loss: (0.1877) | Acc: (93.54%) (46772/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5600) | Acc: (85.23%) (8523/10000)\n",
      "Epoch: 41 | Batch_idx: 0 |  Loss: (0.0832) | Acc: (98.44%) (126/128)\n",
      "Epoch: 41 | Batch_idx: 10 |  Loss: (0.1651) | Acc: (94.82%) (1335/1408)\n",
      "Epoch: 41 | Batch_idx: 20 |  Loss: (0.1659) | Acc: (95.05%) (2555/2688)\n",
      "Epoch: 41 | Batch_idx: 30 |  Loss: (0.1692) | Acc: (94.68%) (3757/3968)\n",
      "Epoch: 41 | Batch_idx: 40 |  Loss: (0.1729) | Acc: (94.57%) (4963/5248)\n",
      "Epoch: 41 | Batch_idx: 50 |  Loss: (0.1728) | Acc: (94.41%) (6163/6528)\n",
      "Epoch: 41 | Batch_idx: 60 |  Loss: (0.1718) | Acc: (94.36%) (7368/7808)\n",
      "Epoch: 41 | Batch_idx: 70 |  Loss: (0.1754) | Acc: (94.20%) (8561/9088)\n",
      "Epoch: 41 | Batch_idx: 80 |  Loss: (0.1757) | Acc: (94.16%) (9762/10368)\n",
      "Epoch: 41 | Batch_idx: 90 |  Loss: (0.1782) | Acc: (94.02%) (10951/11648)\n",
      "Epoch: 41 | Batch_idx: 100 |  Loss: (0.1770) | Acc: (94.04%) (12158/12928)\n",
      "Epoch: 41 | Batch_idx: 110 |  Loss: (0.1771) | Acc: (94.04%) (13361/14208)\n",
      "Epoch: 41 | Batch_idx: 120 |  Loss: (0.1767) | Acc: (94.00%) (14558/15488)\n",
      "Epoch: 41 | Batch_idx: 130 |  Loss: (0.1771) | Acc: (93.96%) (15756/16768)\n",
      "Epoch: 41 | Batch_idx: 140 |  Loss: (0.1772) | Acc: (93.99%) (16964/18048)\n",
      "Epoch: 41 | Batch_idx: 150 |  Loss: (0.1756) | Acc: (94.03%) (18174/19328)\n",
      "Epoch: 41 | Batch_idx: 160 |  Loss: (0.1774) | Acc: (93.92%) (19356/20608)\n",
      "Epoch: 41 | Batch_idx: 170 |  Loss: (0.1784) | Acc: (93.91%) (20556/21888)\n",
      "Epoch: 41 | Batch_idx: 180 |  Loss: (0.1787) | Acc: (93.91%) (21757/23168)\n",
      "Epoch: 41 | Batch_idx: 190 |  Loss: (0.1780) | Acc: (93.91%) (22960/24448)\n",
      "Epoch: 41 | Batch_idx: 200 |  Loss: (0.1772) | Acc: (93.96%) (24173/25728)\n",
      "Epoch: 41 | Batch_idx: 210 |  Loss: (0.1767) | Acc: (93.97%) (25379/27008)\n",
      "Epoch: 41 | Batch_idx: 220 |  Loss: (0.1771) | Acc: (93.94%) (26573/28288)\n",
      "Epoch: 41 | Batch_idx: 230 |  Loss: (0.1767) | Acc: (93.92%) (27770/29568)\n",
      "Epoch: 41 | Batch_idx: 240 |  Loss: (0.1771) | Acc: (93.92%) (28971/30848)\n",
      "Epoch: 41 | Batch_idx: 250 |  Loss: (0.1773) | Acc: (93.92%) (30176/32128)\n",
      "Epoch: 41 | Batch_idx: 260 |  Loss: (0.1767) | Acc: (93.96%) (31391/33408)\n",
      "Epoch: 41 | Batch_idx: 270 |  Loss: (0.1768) | Acc: (93.98%) (32599/34688)\n",
      "Epoch: 41 | Batch_idx: 280 |  Loss: (0.1767) | Acc: (93.98%) (33801/35968)\n",
      "Epoch: 41 | Batch_idx: 290 |  Loss: (0.1770) | Acc: (93.96%) (35000/37248)\n",
      "Epoch: 41 | Batch_idx: 300 |  Loss: (0.1775) | Acc: (93.94%) (36194/38528)\n",
      "Epoch: 41 | Batch_idx: 310 |  Loss: (0.1785) | Acc: (93.88%) (37372/39808)\n",
      "Epoch: 41 | Batch_idx: 320 |  Loss: (0.1795) | Acc: (93.83%) (38552/41088)\n",
      "Epoch: 41 | Batch_idx: 330 |  Loss: (0.1795) | Acc: (93.83%) (39753/42368)\n",
      "Epoch: 41 | Batch_idx: 340 |  Loss: (0.1805) | Acc: (93.78%) (40935/43648)\n",
      "Epoch: 41 | Batch_idx: 350 |  Loss: (0.1807) | Acc: (93.80%) (42143/44928)\n",
      "Epoch: 41 | Batch_idx: 360 |  Loss: (0.1809) | Acc: (93.80%) (43341/46208)\n",
      "Epoch: 41 | Batch_idx: 370 |  Loss: (0.1807) | Acc: (93.79%) (44539/47488)\n",
      "Epoch: 41 | Batch_idx: 380 |  Loss: (0.1808) | Acc: (93.78%) (45735/48768)\n",
      "Epoch: 41 | Batch_idx: 390 |  Loss: (0.1813) | Acc: (93.77%) (46883/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5272) | Acc: (86.17%) (8617/10000)\n",
      "Epoch: 42 | Batch_idx: 0 |  Loss: (0.1459) | Acc: (96.88%) (124/128)\n",
      "Epoch: 42 | Batch_idx: 10 |  Loss: (0.1492) | Acc: (95.45%) (1344/1408)\n",
      "Epoch: 42 | Batch_idx: 20 |  Loss: (0.1581) | Acc: (94.83%) (2549/2688)\n",
      "Epoch: 42 | Batch_idx: 30 |  Loss: (0.1577) | Acc: (94.76%) (3760/3968)\n",
      "Epoch: 42 | Batch_idx: 40 |  Loss: (0.1678) | Acc: (94.38%) (4953/5248)\n",
      "Epoch: 42 | Batch_idx: 50 |  Loss: (0.1722) | Acc: (94.27%) (6154/6528)\n",
      "Epoch: 42 | Batch_idx: 60 |  Loss: (0.1751) | Acc: (94.08%) (7346/7808)\n",
      "Epoch: 42 | Batch_idx: 70 |  Loss: (0.1721) | Acc: (94.18%) (8559/9088)\n",
      "Epoch: 42 | Batch_idx: 80 |  Loss: (0.1733) | Acc: (94.08%) (9754/10368)\n",
      "Epoch: 42 | Batch_idx: 90 |  Loss: (0.1727) | Acc: (94.10%) (10961/11648)\n",
      "Epoch: 42 | Batch_idx: 100 |  Loss: (0.1740) | Acc: (94.01%) (12154/12928)\n",
      "Epoch: 42 | Batch_idx: 110 |  Loss: (0.1713) | Acc: (94.15%) (13377/14208)\n",
      "Epoch: 42 | Batch_idx: 120 |  Loss: (0.1711) | Acc: (94.14%) (14581/15488)\n",
      "Epoch: 42 | Batch_idx: 130 |  Loss: (0.1726) | Acc: (94.07%) (15774/16768)\n",
      "Epoch: 42 | Batch_idx: 140 |  Loss: (0.1716) | Acc: (94.12%) (16987/18048)\n",
      "Epoch: 42 | Batch_idx: 150 |  Loss: (0.1701) | Acc: (94.17%) (18201/19328)\n",
      "Epoch: 42 | Batch_idx: 160 |  Loss: (0.1699) | Acc: (94.17%) (19407/20608)\n",
      "Epoch: 42 | Batch_idx: 170 |  Loss: (0.1682) | Acc: (94.24%) (20628/21888)\n",
      "Epoch: 42 | Batch_idx: 180 |  Loss: (0.1686) | Acc: (94.21%) (21827/23168)\n",
      "Epoch: 42 | Batch_idx: 190 |  Loss: (0.1684) | Acc: (94.21%) (23033/24448)\n",
      "Epoch: 42 | Batch_idx: 200 |  Loss: (0.1686) | Acc: (94.22%) (24240/25728)\n",
      "Epoch: 42 | Batch_idx: 210 |  Loss: (0.1689) | Acc: (94.20%) (25442/27008)\n",
      "Epoch: 42 | Batch_idx: 220 |  Loss: (0.1687) | Acc: (94.18%) (26643/28288)\n",
      "Epoch: 42 | Batch_idx: 230 |  Loss: (0.1690) | Acc: (94.18%) (27846/29568)\n",
      "Epoch: 42 | Batch_idx: 240 |  Loss: (0.1692) | Acc: (94.16%) (29045/30848)\n",
      "Epoch: 42 | Batch_idx: 250 |  Loss: (0.1702) | Acc: (94.12%) (30240/32128)\n",
      "Epoch: 42 | Batch_idx: 260 |  Loss: (0.1710) | Acc: (94.11%) (31441/33408)\n",
      "Epoch: 42 | Batch_idx: 270 |  Loss: (0.1708) | Acc: (94.11%) (32646/34688)\n",
      "Epoch: 42 | Batch_idx: 280 |  Loss: (0.1713) | Acc: (94.10%) (33847/35968)\n",
      "Epoch: 42 | Batch_idx: 290 |  Loss: (0.1715) | Acc: (94.11%) (35053/37248)\n",
      "Epoch: 42 | Batch_idx: 300 |  Loss: (0.1717) | Acc: (94.08%) (36249/38528)\n",
      "Epoch: 42 | Batch_idx: 310 |  Loss: (0.1724) | Acc: (94.07%) (37446/39808)\n",
      "Epoch: 42 | Batch_idx: 320 |  Loss: (0.1729) | Acc: (94.04%) (38640/41088)\n",
      "Epoch: 42 | Batch_idx: 330 |  Loss: (0.1738) | Acc: (93.98%) (39818/42368)\n",
      "Epoch: 42 | Batch_idx: 340 |  Loss: (0.1740) | Acc: (93.98%) (41021/43648)\n",
      "Epoch: 42 | Batch_idx: 350 |  Loss: (0.1751) | Acc: (93.96%) (42214/44928)\n",
      "Epoch: 42 | Batch_idx: 360 |  Loss: (0.1751) | Acc: (93.96%) (43415/46208)\n",
      "Epoch: 42 | Batch_idx: 370 |  Loss: (0.1756) | Acc: (93.95%) (44614/47488)\n",
      "Epoch: 42 | Batch_idx: 380 |  Loss: (0.1767) | Acc: (93.87%) (45779/48768)\n",
      "Epoch: 42 | Batch_idx: 390 |  Loss: (0.1767) | Acc: (93.87%) (46934/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5102) | Acc: (86.85%) (8685/10000)\n",
      "Epoch: 43 | Batch_idx: 0 |  Loss: (0.1089) | Acc: (95.31%) (122/128)\n",
      "Epoch: 43 | Batch_idx: 10 |  Loss: (0.1664) | Acc: (94.39%) (1329/1408)\n",
      "Epoch: 43 | Batch_idx: 20 |  Loss: (0.1683) | Acc: (94.12%) (2530/2688)\n",
      "Epoch: 43 | Batch_idx: 30 |  Loss: (0.1663) | Acc: (94.10%) (3734/3968)\n",
      "Epoch: 43 | Batch_idx: 40 |  Loss: (0.1690) | Acc: (94.02%) (4934/5248)\n",
      "Epoch: 43 | Batch_idx: 50 |  Loss: (0.1654) | Acc: (94.24%) (6152/6528)\n",
      "Epoch: 43 | Batch_idx: 60 |  Loss: (0.1643) | Acc: (94.20%) (7355/7808)\n",
      "Epoch: 43 | Batch_idx: 70 |  Loss: (0.1673) | Acc: (94.19%) (8560/9088)\n",
      "Epoch: 43 | Batch_idx: 80 |  Loss: (0.1639) | Acc: (94.35%) (9782/10368)\n",
      "Epoch: 43 | Batch_idx: 90 |  Loss: (0.1638) | Acc: (94.28%) (10982/11648)\n",
      "Epoch: 43 | Batch_idx: 100 |  Loss: (0.1616) | Acc: (94.32%) (12194/12928)\n",
      "Epoch: 43 | Batch_idx: 110 |  Loss: (0.1598) | Acc: (94.44%) (13418/14208)\n",
      "Epoch: 43 | Batch_idx: 120 |  Loss: (0.1596) | Acc: (94.47%) (14631/15488)\n",
      "Epoch: 43 | Batch_idx: 130 |  Loss: (0.1588) | Acc: (94.51%) (15847/16768)\n",
      "Epoch: 43 | Batch_idx: 140 |  Loss: (0.1586) | Acc: (94.46%) (17048/18048)\n",
      "Epoch: 43 | Batch_idx: 150 |  Loss: (0.1589) | Acc: (94.48%) (18262/19328)\n",
      "Epoch: 43 | Batch_idx: 160 |  Loss: (0.1584) | Acc: (94.52%) (19478/20608)\n",
      "Epoch: 43 | Batch_idx: 170 |  Loss: (0.1605) | Acc: (94.46%) (20676/21888)\n",
      "Epoch: 43 | Batch_idx: 180 |  Loss: (0.1615) | Acc: (94.41%) (21874/23168)\n",
      "Epoch: 43 | Batch_idx: 190 |  Loss: (0.1620) | Acc: (94.36%) (23069/24448)\n",
      "Epoch: 43 | Batch_idx: 200 |  Loss: (0.1632) | Acc: (94.34%) (24273/25728)\n",
      "Epoch: 43 | Batch_idx: 210 |  Loss: (0.1650) | Acc: (94.29%) (25466/27008)\n",
      "Epoch: 43 | Batch_idx: 220 |  Loss: (0.1648) | Acc: (94.29%) (26674/28288)\n",
      "Epoch: 43 | Batch_idx: 230 |  Loss: (0.1647) | Acc: (94.27%) (27873/29568)\n",
      "Epoch: 43 | Batch_idx: 240 |  Loss: (0.1655) | Acc: (94.25%) (29074/30848)\n",
      "Epoch: 43 | Batch_idx: 250 |  Loss: (0.1664) | Acc: (94.22%) (30271/32128)\n",
      "Epoch: 43 | Batch_idx: 260 |  Loss: (0.1670) | Acc: (94.17%) (31460/33408)\n",
      "Epoch: 43 | Batch_idx: 270 |  Loss: (0.1672) | Acc: (94.17%) (32665/34688)\n",
      "Epoch: 43 | Batch_idx: 280 |  Loss: (0.1667) | Acc: (94.20%) (33882/35968)\n",
      "Epoch: 43 | Batch_idx: 290 |  Loss: (0.1672) | Acc: (94.19%) (35085/37248)\n",
      "Epoch: 43 | Batch_idx: 300 |  Loss: (0.1677) | Acc: (94.19%) (36289/38528)\n",
      "Epoch: 43 | Batch_idx: 310 |  Loss: (0.1683) | Acc: (94.16%) (37484/39808)\n",
      "Epoch: 43 | Batch_idx: 320 |  Loss: (0.1682) | Acc: (94.17%) (38694/41088)\n",
      "Epoch: 43 | Batch_idx: 330 |  Loss: (0.1675) | Acc: (94.20%) (39912/42368)\n",
      "Epoch: 43 | Batch_idx: 340 |  Loss: (0.1669) | Acc: (94.22%) (41127/43648)\n",
      "Epoch: 43 | Batch_idx: 350 |  Loss: (0.1681) | Acc: (94.18%) (42314/44928)\n",
      "Epoch: 43 | Batch_idx: 360 |  Loss: (0.1684) | Acc: (94.17%) (43516/46208)\n",
      "Epoch: 43 | Batch_idx: 370 |  Loss: (0.1690) | Acc: (94.14%) (44703/47488)\n",
      "Epoch: 43 | Batch_idx: 380 |  Loss: (0.1685) | Acc: (94.15%) (45916/48768)\n",
      "Epoch: 43 | Batch_idx: 390 |  Loss: (0.1689) | Acc: (94.13%) (47064/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5812) | Acc: (85.58%) (8558/10000)\n",
      "Epoch: 44 | Batch_idx: 0 |  Loss: (0.0926) | Acc: (97.66%) (125/128)\n",
      "Epoch: 44 | Batch_idx: 10 |  Loss: (0.1748) | Acc: (94.60%) (1332/1408)\n",
      "Epoch: 44 | Batch_idx: 20 |  Loss: (0.1585) | Acc: (94.79%) (2548/2688)\n",
      "Epoch: 44 | Batch_idx: 30 |  Loss: (0.1631) | Acc: (94.53%) (3751/3968)\n",
      "Epoch: 44 | Batch_idx: 40 |  Loss: (0.1576) | Acc: (94.76%) (4973/5248)\n",
      "Epoch: 44 | Batch_idx: 50 |  Loss: (0.1532) | Acc: (94.87%) (6193/6528)\n",
      "Epoch: 44 | Batch_idx: 60 |  Loss: (0.1560) | Acc: (94.83%) (7404/7808)\n",
      "Epoch: 44 | Batch_idx: 70 |  Loss: (0.1562) | Acc: (94.71%) (8607/9088)\n",
      "Epoch: 44 | Batch_idx: 80 |  Loss: (0.1547) | Acc: (94.73%) (9822/10368)\n",
      "Epoch: 44 | Batch_idx: 90 |  Loss: (0.1547) | Acc: (94.74%) (11035/11648)\n",
      "Epoch: 44 | Batch_idx: 100 |  Loss: (0.1548) | Acc: (94.74%) (12248/12928)\n",
      "Epoch: 44 | Batch_idx: 110 |  Loss: (0.1552) | Acc: (94.74%) (13460/14208)\n",
      "Epoch: 44 | Batch_idx: 120 |  Loss: (0.1554) | Acc: (94.72%) (14671/15488)\n",
      "Epoch: 44 | Batch_idx: 130 |  Loss: (0.1549) | Acc: (94.78%) (15892/16768)\n",
      "Epoch: 44 | Batch_idx: 140 |  Loss: (0.1574) | Acc: (94.71%) (17093/18048)\n",
      "Epoch: 44 | Batch_idx: 150 |  Loss: (0.1588) | Acc: (94.67%) (18298/19328)\n",
      "Epoch: 44 | Batch_idx: 160 |  Loss: (0.1593) | Acc: (94.62%) (19500/20608)\n",
      "Epoch: 44 | Batch_idx: 170 |  Loss: (0.1604) | Acc: (94.55%) (20696/21888)\n",
      "Epoch: 44 | Batch_idx: 180 |  Loss: (0.1606) | Acc: (94.53%) (21901/23168)\n",
      "Epoch: 44 | Batch_idx: 190 |  Loss: (0.1611) | Acc: (94.49%) (23102/24448)\n",
      "Epoch: 44 | Batch_idx: 200 |  Loss: (0.1610) | Acc: (94.49%) (24311/25728)\n",
      "Epoch: 44 | Batch_idx: 210 |  Loss: (0.1608) | Acc: (94.48%) (25517/27008)\n",
      "Epoch: 44 | Batch_idx: 220 |  Loss: (0.1617) | Acc: (94.43%) (26712/28288)\n",
      "Epoch: 44 | Batch_idx: 230 |  Loss: (0.1611) | Acc: (94.43%) (27922/29568)\n",
      "Epoch: 44 | Batch_idx: 240 |  Loss: (0.1604) | Acc: (94.47%) (29142/30848)\n",
      "Epoch: 44 | Batch_idx: 250 |  Loss: (0.1602) | Acc: (94.45%) (30345/32128)\n",
      "Epoch: 44 | Batch_idx: 260 |  Loss: (0.1601) | Acc: (94.45%) (31555/33408)\n",
      "Epoch: 44 | Batch_idx: 270 |  Loss: (0.1595) | Acc: (94.50%) (32781/34688)\n",
      "Epoch: 44 | Batch_idx: 280 |  Loss: (0.1605) | Acc: (94.43%) (33964/35968)\n",
      "Epoch: 44 | Batch_idx: 290 |  Loss: (0.1614) | Acc: (94.39%) (35160/37248)\n",
      "Epoch: 44 | Batch_idx: 300 |  Loss: (0.1616) | Acc: (94.39%) (36366/38528)\n",
      "Epoch: 44 | Batch_idx: 310 |  Loss: (0.1614) | Acc: (94.41%) (37581/39808)\n",
      "Epoch: 44 | Batch_idx: 320 |  Loss: (0.1617) | Acc: (94.39%) (38785/41088)\n",
      "Epoch: 44 | Batch_idx: 330 |  Loss: (0.1616) | Acc: (94.40%) (39994/42368)\n",
      "Epoch: 44 | Batch_idx: 340 |  Loss: (0.1624) | Acc: (94.35%) (41184/43648)\n",
      "Epoch: 44 | Batch_idx: 350 |  Loss: (0.1636) | Acc: (94.31%) (42370/44928)\n",
      "Epoch: 44 | Batch_idx: 360 |  Loss: (0.1638) | Acc: (94.30%) (43572/46208)\n",
      "Epoch: 44 | Batch_idx: 370 |  Loss: (0.1638) | Acc: (94.30%) (44780/47488)\n",
      "Epoch: 44 | Batch_idx: 380 |  Loss: (0.1641) | Acc: (94.28%) (45978/48768)\n",
      "Epoch: 44 | Batch_idx: 390 |  Loss: (0.1643) | Acc: (94.27%) (47134/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4716) | Acc: (87.65%) (8765/10000)\n",
      "Epoch: 45 | Batch_idx: 0 |  Loss: (0.1316) | Acc: (93.75%) (120/128)\n",
      "Epoch: 45 | Batch_idx: 10 |  Loss: (0.1536) | Acc: (95.03%) (1338/1408)\n",
      "Epoch: 45 | Batch_idx: 20 |  Loss: (0.1423) | Acc: (95.39%) (2564/2688)\n",
      "Epoch: 45 | Batch_idx: 30 |  Loss: (0.1486) | Acc: (94.86%) (3764/3968)\n",
      "Epoch: 45 | Batch_idx: 40 |  Loss: (0.1469) | Acc: (95.03%) (4987/5248)\n",
      "Epoch: 45 | Batch_idx: 50 |  Loss: (0.1458) | Acc: (94.98%) (6200/6528)\n",
      "Epoch: 45 | Batch_idx: 60 |  Loss: (0.1508) | Acc: (94.81%) (7403/7808)\n",
      "Epoch: 45 | Batch_idx: 70 |  Loss: (0.1533) | Acc: (94.73%) (8609/9088)\n",
      "Epoch: 45 | Batch_idx: 80 |  Loss: (0.1556) | Acc: (94.64%) (9812/10368)\n",
      "Epoch: 45 | Batch_idx: 90 |  Loss: (0.1573) | Acc: (94.49%) (11006/11648)\n",
      "Epoch: 45 | Batch_idx: 100 |  Loss: (0.1574) | Acc: (94.43%) (12208/12928)\n",
      "Epoch: 45 | Batch_idx: 110 |  Loss: (0.1573) | Acc: (94.43%) (13417/14208)\n",
      "Epoch: 45 | Batch_idx: 120 |  Loss: (0.1602) | Acc: (94.25%) (14598/15488)\n",
      "Epoch: 45 | Batch_idx: 130 |  Loss: (0.1591) | Acc: (94.33%) (15817/16768)\n",
      "Epoch: 45 | Batch_idx: 140 |  Loss: (0.1599) | Acc: (94.27%) (17014/18048)\n",
      "Epoch: 45 | Batch_idx: 150 |  Loss: (0.1602) | Acc: (94.23%) (18212/19328)\n",
      "Epoch: 45 | Batch_idx: 160 |  Loss: (0.1598) | Acc: (94.26%) (19426/20608)\n",
      "Epoch: 45 | Batch_idx: 170 |  Loss: (0.1596) | Acc: (94.30%) (20640/21888)\n",
      "Epoch: 45 | Batch_idx: 180 |  Loss: (0.1598) | Acc: (94.32%) (21853/23168)\n",
      "Epoch: 45 | Batch_idx: 190 |  Loss: (0.1599) | Acc: (94.35%) (23066/24448)\n",
      "Epoch: 45 | Batch_idx: 200 |  Loss: (0.1603) | Acc: (94.34%) (24273/25728)\n",
      "Epoch: 45 | Batch_idx: 210 |  Loss: (0.1599) | Acc: (94.35%) (25483/27008)\n",
      "Epoch: 45 | Batch_idx: 220 |  Loss: (0.1592) | Acc: (94.41%) (26706/28288)\n",
      "Epoch: 45 | Batch_idx: 230 |  Loss: (0.1595) | Acc: (94.39%) (27910/29568)\n",
      "Epoch: 45 | Batch_idx: 240 |  Loss: (0.1586) | Acc: (94.43%) (29130/30848)\n",
      "Epoch: 45 | Batch_idx: 250 |  Loss: (0.1582) | Acc: (94.43%) (30340/32128)\n",
      "Epoch: 45 | Batch_idx: 260 |  Loss: (0.1583) | Acc: (94.45%) (31553/33408)\n",
      "Epoch: 45 | Batch_idx: 270 |  Loss: (0.1588) | Acc: (94.45%) (32762/34688)\n",
      "Epoch: 45 | Batch_idx: 280 |  Loss: (0.1589) | Acc: (94.44%) (33967/35968)\n",
      "Epoch: 45 | Batch_idx: 290 |  Loss: (0.1585) | Acc: (94.46%) (35183/37248)\n",
      "Epoch: 45 | Batch_idx: 300 |  Loss: (0.1587) | Acc: (94.46%) (36394/38528)\n",
      "Epoch: 45 | Batch_idx: 310 |  Loss: (0.1596) | Acc: (94.41%) (37581/39808)\n",
      "Epoch: 45 | Batch_idx: 320 |  Loss: (0.1596) | Acc: (94.42%) (38795/41088)\n",
      "Epoch: 45 | Batch_idx: 330 |  Loss: (0.1595) | Acc: (94.42%) (40003/42368)\n",
      "Epoch: 45 | Batch_idx: 340 |  Loss: (0.1597) | Acc: (94.41%) (41210/43648)\n",
      "Epoch: 45 | Batch_idx: 350 |  Loss: (0.1593) | Acc: (94.44%) (42428/44928)\n",
      "Epoch: 45 | Batch_idx: 360 |  Loss: (0.1604) | Acc: (94.40%) (43621/46208)\n",
      "Epoch: 45 | Batch_idx: 370 |  Loss: (0.1605) | Acc: (94.38%) (44820/47488)\n",
      "Epoch: 45 | Batch_idx: 380 |  Loss: (0.1600) | Acc: (94.40%) (46037/48768)\n",
      "Epoch: 45 | Batch_idx: 390 |  Loss: (0.1592) | Acc: (94.45%) (47224/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6296) | Acc: (85.18%) (8518/10000)\n",
      "Epoch: 46 | Batch_idx: 0 |  Loss: (0.2169) | Acc: (94.53%) (121/128)\n",
      "Epoch: 46 | Batch_idx: 10 |  Loss: (0.1665) | Acc: (94.53%) (1331/1408)\n",
      "Epoch: 46 | Batch_idx: 20 |  Loss: (0.1477) | Acc: (95.20%) (2559/2688)\n",
      "Epoch: 46 | Batch_idx: 30 |  Loss: (0.1522) | Acc: (94.96%) (3768/3968)\n",
      "Epoch: 46 | Batch_idx: 40 |  Loss: (0.1521) | Acc: (94.99%) (4985/5248)\n",
      "Epoch: 46 | Batch_idx: 50 |  Loss: (0.1487) | Acc: (95.17%) (6213/6528)\n",
      "Epoch: 46 | Batch_idx: 60 |  Loss: (0.1433) | Acc: (95.36%) (7446/7808)\n",
      "Epoch: 46 | Batch_idx: 70 |  Loss: (0.1435) | Acc: (95.32%) (8663/9088)\n",
      "Epoch: 46 | Batch_idx: 80 |  Loss: (0.1408) | Acc: (95.40%) (9891/10368)\n",
      "Epoch: 46 | Batch_idx: 90 |  Loss: (0.1407) | Acc: (95.39%) (11111/11648)\n",
      "Epoch: 46 | Batch_idx: 100 |  Loss: (0.1407) | Acc: (95.44%) (12339/12928)\n",
      "Epoch: 46 | Batch_idx: 110 |  Loss: (0.1424) | Acc: (95.42%) (13557/14208)\n",
      "Epoch: 46 | Batch_idx: 120 |  Loss: (0.1427) | Acc: (95.37%) (14771/15488)\n",
      "Epoch: 46 | Batch_idx: 130 |  Loss: (0.1434) | Acc: (95.34%) (15987/16768)\n",
      "Epoch: 46 | Batch_idx: 140 |  Loss: (0.1424) | Acc: (95.34%) (17207/18048)\n",
      "Epoch: 46 | Batch_idx: 150 |  Loss: (0.1427) | Acc: (95.31%) (18421/19328)\n",
      "Epoch: 46 | Batch_idx: 160 |  Loss: (0.1430) | Acc: (95.29%) (19637/20608)\n",
      "Epoch: 46 | Batch_idx: 170 |  Loss: (0.1436) | Acc: (95.27%) (20853/21888)\n",
      "Epoch: 46 | Batch_idx: 180 |  Loss: (0.1452) | Acc: (95.20%) (22056/23168)\n",
      "Epoch: 46 | Batch_idx: 190 |  Loss: (0.1451) | Acc: (95.22%) (23279/24448)\n",
      "Epoch: 46 | Batch_idx: 200 |  Loss: (0.1464) | Acc: (95.15%) (24480/25728)\n",
      "Epoch: 46 | Batch_idx: 210 |  Loss: (0.1467) | Acc: (95.11%) (25688/27008)\n",
      "Epoch: 46 | Batch_idx: 220 |  Loss: (0.1465) | Acc: (95.10%) (26903/28288)\n",
      "Epoch: 46 | Batch_idx: 230 |  Loss: (0.1475) | Acc: (95.06%) (28108/29568)\n",
      "Epoch: 46 | Batch_idx: 240 |  Loss: (0.1482) | Acc: (95.01%) (29308/30848)\n",
      "Epoch: 46 | Batch_idx: 250 |  Loss: (0.1490) | Acc: (94.95%) (30506/32128)\n",
      "Epoch: 46 | Batch_idx: 260 |  Loss: (0.1502) | Acc: (94.91%) (31709/33408)\n",
      "Epoch: 46 | Batch_idx: 270 |  Loss: (0.1505) | Acc: (94.93%) (32931/34688)\n",
      "Epoch: 46 | Batch_idx: 280 |  Loss: (0.1510) | Acc: (94.93%) (34143/35968)\n",
      "Epoch: 46 | Batch_idx: 290 |  Loss: (0.1508) | Acc: (94.93%) (35359/37248)\n",
      "Epoch: 46 | Batch_idx: 300 |  Loss: (0.1513) | Acc: (94.88%) (36556/38528)\n",
      "Epoch: 46 | Batch_idx: 310 |  Loss: (0.1520) | Acc: (94.86%) (37763/39808)\n",
      "Epoch: 46 | Batch_idx: 320 |  Loss: (0.1520) | Acc: (94.86%) (38976/41088)\n",
      "Epoch: 46 | Batch_idx: 330 |  Loss: (0.1526) | Acc: (94.83%) (40177/42368)\n",
      "Epoch: 46 | Batch_idx: 340 |  Loss: (0.1525) | Acc: (94.84%) (41394/43648)\n",
      "Epoch: 46 | Batch_idx: 350 |  Loss: (0.1528) | Acc: (94.83%) (42603/44928)\n",
      "Epoch: 46 | Batch_idx: 360 |  Loss: (0.1524) | Acc: (94.84%) (43824/46208)\n",
      "Epoch: 46 | Batch_idx: 370 |  Loss: (0.1527) | Acc: (94.83%) (45031/47488)\n",
      "Epoch: 46 | Batch_idx: 380 |  Loss: (0.1528) | Acc: (94.82%) (46241/48768)\n",
      "Epoch: 46 | Batch_idx: 390 |  Loss: (0.1531) | Acc: (94.81%) (47405/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6050) | Acc: (86.08%) (8608/10000)\n",
      "Epoch: 47 | Batch_idx: 0 |  Loss: (0.1227) | Acc: (95.31%) (122/128)\n",
      "Epoch: 47 | Batch_idx: 10 |  Loss: (0.1318) | Acc: (95.24%) (1341/1408)\n",
      "Epoch: 47 | Batch_idx: 20 |  Loss: (0.1337) | Acc: (95.13%) (2557/2688)\n",
      "Epoch: 47 | Batch_idx: 30 |  Loss: (0.1413) | Acc: (95.16%) (3776/3968)\n",
      "Epoch: 47 | Batch_idx: 40 |  Loss: (0.1391) | Acc: (95.14%) (4993/5248)\n",
      "Epoch: 47 | Batch_idx: 50 |  Loss: (0.1418) | Acc: (95.04%) (6204/6528)\n",
      "Epoch: 47 | Batch_idx: 60 |  Loss: (0.1408) | Acc: (95.16%) (7430/7808)\n",
      "Epoch: 47 | Batch_idx: 70 |  Loss: (0.1394) | Acc: (95.16%) (8648/9088)\n",
      "Epoch: 47 | Batch_idx: 80 |  Loss: (0.1383) | Acc: (95.17%) (9867/10368)\n",
      "Epoch: 47 | Batch_idx: 90 |  Loss: (0.1371) | Acc: (95.27%) (11097/11648)\n",
      "Epoch: 47 | Batch_idx: 100 |  Loss: (0.1377) | Acc: (95.24%) (12312/12928)\n",
      "Epoch: 47 | Batch_idx: 110 |  Loss: (0.1377) | Acc: (95.16%) (13521/14208)\n",
      "Epoch: 47 | Batch_idx: 120 |  Loss: (0.1394) | Acc: (95.10%) (14729/15488)\n",
      "Epoch: 47 | Batch_idx: 130 |  Loss: (0.1400) | Acc: (95.10%) (15946/16768)\n",
      "Epoch: 47 | Batch_idx: 140 |  Loss: (0.1409) | Acc: (95.08%) (17160/18048)\n",
      "Epoch: 47 | Batch_idx: 150 |  Loss: (0.1412) | Acc: (95.09%) (18379/19328)\n",
      "Epoch: 47 | Batch_idx: 160 |  Loss: (0.1418) | Acc: (95.06%) (19590/20608)\n",
      "Epoch: 47 | Batch_idx: 170 |  Loss: (0.1425) | Acc: (95.06%) (20807/21888)\n",
      "Epoch: 47 | Batch_idx: 180 |  Loss: (0.1425) | Acc: (95.08%) (22028/23168)\n",
      "Epoch: 47 | Batch_idx: 190 |  Loss: (0.1441) | Acc: (95.01%) (23227/24448)\n",
      "Epoch: 47 | Batch_idx: 200 |  Loss: (0.1449) | Acc: (94.98%) (24436/25728)\n",
      "Epoch: 47 | Batch_idx: 210 |  Loss: (0.1454) | Acc: (94.95%) (25644/27008)\n",
      "Epoch: 47 | Batch_idx: 220 |  Loss: (0.1462) | Acc: (94.90%) (26844/28288)\n",
      "Epoch: 47 | Batch_idx: 230 |  Loss: (0.1468) | Acc: (94.87%) (28051/29568)\n",
      "Epoch: 47 | Batch_idx: 240 |  Loss: (0.1473) | Acc: (94.86%) (29261/30848)\n",
      "Epoch: 47 | Batch_idx: 250 |  Loss: (0.1464) | Acc: (94.89%) (30485/32128)\n",
      "Epoch: 47 | Batch_idx: 260 |  Loss: (0.1466) | Acc: (94.86%) (31690/33408)\n",
      "Epoch: 47 | Batch_idx: 270 |  Loss: (0.1470) | Acc: (94.84%) (32897/34688)\n",
      "Epoch: 47 | Batch_idx: 280 |  Loss: (0.1474) | Acc: (94.83%) (34108/35968)\n",
      "Epoch: 47 | Batch_idx: 290 |  Loss: (0.1480) | Acc: (94.82%) (35317/37248)\n",
      "Epoch: 47 | Batch_idx: 300 |  Loss: (0.1475) | Acc: (94.85%) (36543/38528)\n",
      "Epoch: 47 | Batch_idx: 310 |  Loss: (0.1489) | Acc: (94.79%) (37733/39808)\n",
      "Epoch: 47 | Batch_idx: 320 |  Loss: (0.1487) | Acc: (94.81%) (38956/41088)\n",
      "Epoch: 47 | Batch_idx: 330 |  Loss: (0.1487) | Acc: (94.82%) (40172/42368)\n",
      "Epoch: 47 | Batch_idx: 340 |  Loss: (0.1487) | Acc: (94.81%) (41384/43648)\n",
      "Epoch: 47 | Batch_idx: 350 |  Loss: (0.1484) | Acc: (94.81%) (42598/44928)\n",
      "Epoch: 47 | Batch_idx: 360 |  Loss: (0.1475) | Acc: (94.84%) (43823/46208)\n",
      "Epoch: 47 | Batch_idx: 370 |  Loss: (0.1480) | Acc: (94.81%) (45025/47488)\n",
      "Epoch: 47 | Batch_idx: 380 |  Loss: (0.1481) | Acc: (94.80%) (46232/48768)\n",
      "Epoch: 47 | Batch_idx: 390 |  Loss: (0.1486) | Acc: (94.78%) (47391/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5551) | Acc: (87.23%) (8723/10000)\n",
      "Epoch: 48 | Batch_idx: 0 |  Loss: (0.1276) | Acc: (96.09%) (123/128)\n",
      "Epoch: 48 | Batch_idx: 10 |  Loss: (0.1260) | Acc: (95.95%) (1351/1408)\n",
      "Epoch: 48 | Batch_idx: 20 |  Loss: (0.1386) | Acc: (95.20%) (2559/2688)\n",
      "Epoch: 48 | Batch_idx: 30 |  Loss: (0.1334) | Acc: (95.34%) (3783/3968)\n",
      "Epoch: 48 | Batch_idx: 40 |  Loss: (0.1342) | Acc: (95.24%) (4998/5248)\n",
      "Epoch: 48 | Batch_idx: 50 |  Loss: (0.1336) | Acc: (95.33%) (6223/6528)\n",
      "Epoch: 48 | Batch_idx: 60 |  Loss: (0.1341) | Acc: (95.48%) (7455/7808)\n",
      "Epoch: 48 | Batch_idx: 70 |  Loss: (0.1363) | Acc: (95.41%) (8671/9088)\n",
      "Epoch: 48 | Batch_idx: 80 |  Loss: (0.1357) | Acc: (95.37%) (9888/10368)\n",
      "Epoch: 48 | Batch_idx: 90 |  Loss: (0.1357) | Acc: (95.38%) (11110/11648)\n",
      "Epoch: 48 | Batch_idx: 100 |  Loss: (0.1364) | Acc: (95.32%) (12323/12928)\n",
      "Epoch: 48 | Batch_idx: 110 |  Loss: (0.1359) | Acc: (95.30%) (13540/14208)\n",
      "Epoch: 48 | Batch_idx: 120 |  Loss: (0.1345) | Acc: (95.40%) (14776/15488)\n",
      "Epoch: 48 | Batch_idx: 130 |  Loss: (0.1360) | Acc: (95.32%) (15983/16768)\n",
      "Epoch: 48 | Batch_idx: 140 |  Loss: (0.1350) | Acc: (95.37%) (17213/18048)\n",
      "Epoch: 48 | Batch_idx: 150 |  Loss: (0.1366) | Acc: (95.31%) (18422/19328)\n",
      "Epoch: 48 | Batch_idx: 160 |  Loss: (0.1370) | Acc: (95.28%) (19636/20608)\n",
      "Epoch: 48 | Batch_idx: 170 |  Loss: (0.1394) | Acc: (95.15%) (20827/21888)\n",
      "Epoch: 48 | Batch_idx: 180 |  Loss: (0.1387) | Acc: (95.17%) (22048/23168)\n",
      "Epoch: 48 | Batch_idx: 190 |  Loss: (0.1385) | Acc: (95.17%) (23267/24448)\n",
      "Epoch: 48 | Batch_idx: 200 |  Loss: (0.1371) | Acc: (95.24%) (24503/25728)\n",
      "Epoch: 48 | Batch_idx: 210 |  Loss: (0.1363) | Acc: (95.28%) (25734/27008)\n",
      "Epoch: 48 | Batch_idx: 220 |  Loss: (0.1362) | Acc: (95.28%) (26953/28288)\n",
      "Epoch: 48 | Batch_idx: 230 |  Loss: (0.1359) | Acc: (95.29%) (28176/29568)\n",
      "Epoch: 48 | Batch_idx: 240 |  Loss: (0.1366) | Acc: (95.27%) (29390/30848)\n",
      "Epoch: 48 | Batch_idx: 250 |  Loss: (0.1368) | Acc: (95.29%) (30615/32128)\n",
      "Epoch: 48 | Batch_idx: 260 |  Loss: (0.1368) | Acc: (95.29%) (31835/33408)\n",
      "Epoch: 48 | Batch_idx: 270 |  Loss: (0.1375) | Acc: (95.27%) (33046/34688)\n",
      "Epoch: 48 | Batch_idx: 280 |  Loss: (0.1381) | Acc: (95.26%) (34263/35968)\n",
      "Epoch: 48 | Batch_idx: 290 |  Loss: (0.1386) | Acc: (95.22%) (35467/37248)\n",
      "Epoch: 48 | Batch_idx: 300 |  Loss: (0.1381) | Acc: (95.24%) (36694/38528)\n",
      "Epoch: 48 | Batch_idx: 310 |  Loss: (0.1389) | Acc: (95.18%) (37890/39808)\n",
      "Epoch: 48 | Batch_idx: 320 |  Loss: (0.1392) | Acc: (95.17%) (39104/41088)\n",
      "Epoch: 48 | Batch_idx: 330 |  Loss: (0.1393) | Acc: (95.18%) (40324/42368)\n",
      "Epoch: 48 | Batch_idx: 340 |  Loss: (0.1395) | Acc: (95.17%) (41541/43648)\n",
      "Epoch: 48 | Batch_idx: 350 |  Loss: (0.1403) | Acc: (95.12%) (42736/44928)\n",
      "Epoch: 48 | Batch_idx: 360 |  Loss: (0.1408) | Acc: (95.10%) (43945/46208)\n",
      "Epoch: 48 | Batch_idx: 370 |  Loss: (0.1411) | Acc: (95.10%) (45159/47488)\n",
      "Epoch: 48 | Batch_idx: 380 |  Loss: (0.1415) | Acc: (95.08%) (46371/48768)\n",
      "Epoch: 48 | Batch_idx: 390 |  Loss: (0.1416) | Acc: (95.07%) (47535/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6496) | Acc: (85.01%) (8501/10000)\n",
      "Epoch: 49 | Batch_idx: 0 |  Loss: (0.1650) | Acc: (95.31%) (122/128)\n",
      "Epoch: 49 | Batch_idx: 10 |  Loss: (0.1373) | Acc: (95.67%) (1347/1408)\n",
      "Epoch: 49 | Batch_idx: 20 |  Loss: (0.1341) | Acc: (95.68%) (2572/2688)\n",
      "Epoch: 49 | Batch_idx: 30 |  Loss: (0.1401) | Acc: (95.46%) (3788/3968)\n",
      "Epoch: 49 | Batch_idx: 40 |  Loss: (0.1409) | Acc: (95.20%) (4996/5248)\n",
      "Epoch: 49 | Batch_idx: 50 |  Loss: (0.1423) | Acc: (95.14%) (6211/6528)\n",
      "Epoch: 49 | Batch_idx: 60 |  Loss: (0.1416) | Acc: (95.21%) (7434/7808)\n",
      "Epoch: 49 | Batch_idx: 70 |  Loss: (0.1373) | Acc: (95.39%) (8669/9088)\n",
      "Epoch: 49 | Batch_idx: 80 |  Loss: (0.1354) | Acc: (95.43%) (9894/10368)\n",
      "Epoch: 49 | Batch_idx: 90 |  Loss: (0.1386) | Acc: (95.30%) (11101/11648)\n",
      "Epoch: 49 | Batch_idx: 100 |  Loss: (0.1389) | Acc: (95.27%) (12316/12928)\n",
      "Epoch: 49 | Batch_idx: 110 |  Loss: (0.1382) | Acc: (95.27%) (13536/14208)\n",
      "Epoch: 49 | Batch_idx: 120 |  Loss: (0.1360) | Acc: (95.33%) (14765/15488)\n",
      "Epoch: 49 | Batch_idx: 130 |  Loss: (0.1363) | Acc: (95.32%) (15983/16768)\n",
      "Epoch: 49 | Batch_idx: 140 |  Loss: (0.1360) | Acc: (95.30%) (17200/18048)\n",
      "Epoch: 49 | Batch_idx: 150 |  Loss: (0.1365) | Acc: (95.28%) (18415/19328)\n",
      "Epoch: 49 | Batch_idx: 160 |  Loss: (0.1369) | Acc: (95.26%) (19632/20608)\n",
      "Epoch: 49 | Batch_idx: 170 |  Loss: (0.1373) | Acc: (95.27%) (20852/21888)\n",
      "Epoch: 49 | Batch_idx: 180 |  Loss: (0.1375) | Acc: (95.23%) (22064/23168)\n",
      "Epoch: 49 | Batch_idx: 190 |  Loss: (0.1372) | Acc: (95.26%) (23288/24448)\n",
      "Epoch: 49 | Batch_idx: 200 |  Loss: (0.1379) | Acc: (95.25%) (24506/25728)\n",
      "Epoch: 49 | Batch_idx: 210 |  Loss: (0.1382) | Acc: (95.22%) (25717/27008)\n",
      "Epoch: 49 | Batch_idx: 220 |  Loss: (0.1375) | Acc: (95.26%) (26946/28288)\n",
      "Epoch: 49 | Batch_idx: 230 |  Loss: (0.1379) | Acc: (95.22%) (28155/29568)\n",
      "Epoch: 49 | Batch_idx: 240 |  Loss: (0.1387) | Acc: (95.22%) (29375/30848)\n",
      "Epoch: 49 | Batch_idx: 250 |  Loss: (0.1394) | Acc: (95.19%) (30582/32128)\n",
      "Epoch: 49 | Batch_idx: 260 |  Loss: (0.1400) | Acc: (95.18%) (31798/33408)\n",
      "Epoch: 49 | Batch_idx: 270 |  Loss: (0.1394) | Acc: (95.22%) (33029/34688)\n",
      "Epoch: 49 | Batch_idx: 280 |  Loss: (0.1391) | Acc: (95.22%) (34247/35968)\n",
      "Epoch: 49 | Batch_idx: 290 |  Loss: (0.1403) | Acc: (95.16%) (35446/37248)\n",
      "Epoch: 49 | Batch_idx: 300 |  Loss: (0.1410) | Acc: (95.13%) (36652/38528)\n",
      "Epoch: 49 | Batch_idx: 310 |  Loss: (0.1405) | Acc: (95.15%) (37877/39808)\n",
      "Epoch: 49 | Batch_idx: 320 |  Loss: (0.1406) | Acc: (95.15%) (39096/41088)\n",
      "Epoch: 49 | Batch_idx: 330 |  Loss: (0.1407) | Acc: (95.15%) (40312/42368)\n",
      "Epoch: 49 | Batch_idx: 340 |  Loss: (0.1406) | Acc: (95.15%) (41529/43648)\n",
      "Epoch: 49 | Batch_idx: 350 |  Loss: (0.1401) | Acc: (95.15%) (42747/44928)\n",
      "Epoch: 49 | Batch_idx: 360 |  Loss: (0.1403) | Acc: (95.13%) (43957/46208)\n",
      "Epoch: 49 | Batch_idx: 370 |  Loss: (0.1408) | Acc: (95.11%) (45164/47488)\n",
      "Epoch: 49 | Batch_idx: 380 |  Loss: (0.1412) | Acc: (95.08%) (46368/48768)\n",
      "Epoch: 49 | Batch_idx: 390 |  Loss: (0.1411) | Acc: (95.09%) (47543/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5145) | Acc: (87.36%) (8736/10000)\n",
      "Epoch: 50 | Batch_idx: 0 |  Loss: (0.1536) | Acc: (94.53%) (121/128)\n",
      "Epoch: 50 | Batch_idx: 10 |  Loss: (0.1322) | Acc: (95.45%) (1344/1408)\n",
      "Epoch: 50 | Batch_idx: 20 |  Loss: (0.1260) | Acc: (95.42%) (2565/2688)\n",
      "Epoch: 50 | Batch_idx: 30 |  Loss: (0.1266) | Acc: (95.41%) (3786/3968)\n",
      "Epoch: 50 | Batch_idx: 40 |  Loss: (0.1328) | Acc: (95.03%) (4987/5248)\n",
      "Epoch: 50 | Batch_idx: 50 |  Loss: (0.1306) | Acc: (95.27%) (6219/6528)\n",
      "Epoch: 50 | Batch_idx: 60 |  Loss: (0.1315) | Acc: (95.30%) (7441/7808)\n",
      "Epoch: 50 | Batch_idx: 70 |  Loss: (0.1336) | Acc: (95.20%) (8652/9088)\n",
      "Epoch: 50 | Batch_idx: 80 |  Loss: (0.1345) | Acc: (95.17%) (9867/10368)\n",
      "Epoch: 50 | Batch_idx: 90 |  Loss: (0.1317) | Acc: (95.30%) (11101/11648)\n",
      "Epoch: 50 | Batch_idx: 100 |  Loss: (0.1324) | Acc: (95.27%) (12317/12928)\n",
      "Epoch: 50 | Batch_idx: 110 |  Loss: (0.1324) | Acc: (95.28%) (13537/14208)\n",
      "Epoch: 50 | Batch_idx: 120 |  Loss: (0.1332) | Acc: (95.24%) (14750/15488)\n",
      "Epoch: 50 | Batch_idx: 130 |  Loss: (0.1311) | Acc: (95.34%) (15987/16768)\n",
      "Epoch: 50 | Batch_idx: 140 |  Loss: (0.1317) | Acc: (95.32%) (17204/18048)\n",
      "Epoch: 50 | Batch_idx: 150 |  Loss: (0.1324) | Acc: (95.30%) (18420/19328)\n",
      "Epoch: 50 | Batch_idx: 160 |  Loss: (0.1312) | Acc: (95.36%) (19651/20608)\n",
      "Epoch: 50 | Batch_idx: 170 |  Loss: (0.1322) | Acc: (95.33%) (20865/21888)\n",
      "Epoch: 50 | Batch_idx: 180 |  Loss: (0.1325) | Acc: (95.32%) (22084/23168)\n",
      "Epoch: 50 | Batch_idx: 190 |  Loss: (0.1331) | Acc: (95.32%) (23303/24448)\n",
      "Epoch: 50 | Batch_idx: 200 |  Loss: (0.1332) | Acc: (95.31%) (24521/25728)\n",
      "Epoch: 50 | Batch_idx: 210 |  Loss: (0.1334) | Acc: (95.33%) (25746/27008)\n",
      "Epoch: 50 | Batch_idx: 220 |  Loss: (0.1341) | Acc: (95.28%) (26953/28288)\n",
      "Epoch: 50 | Batch_idx: 230 |  Loss: (0.1344) | Acc: (95.27%) (28170/29568)\n",
      "Epoch: 50 | Batch_idx: 240 |  Loss: (0.1339) | Acc: (95.28%) (29392/30848)\n",
      "Epoch: 50 | Batch_idx: 250 |  Loss: (0.1349) | Acc: (95.23%) (30597/32128)\n",
      "Epoch: 50 | Batch_idx: 260 |  Loss: (0.1339) | Acc: (95.27%) (31829/33408)\n",
      "Epoch: 50 | Batch_idx: 270 |  Loss: (0.1340) | Acc: (95.26%) (33045/34688)\n",
      "Epoch: 50 | Batch_idx: 280 |  Loss: (0.1338) | Acc: (95.29%) (34273/35968)\n",
      "Epoch: 50 | Batch_idx: 290 |  Loss: (0.1337) | Acc: (95.28%) (35490/37248)\n",
      "Epoch: 50 | Batch_idx: 300 |  Loss: (0.1343) | Acc: (95.24%) (36695/38528)\n",
      "Epoch: 50 | Batch_idx: 310 |  Loss: (0.1341) | Acc: (95.26%) (37921/39808)\n",
      "Epoch: 50 | Batch_idx: 320 |  Loss: (0.1340) | Acc: (95.27%) (39146/41088)\n",
      "Epoch: 50 | Batch_idx: 330 |  Loss: (0.1342) | Acc: (95.29%) (40371/42368)\n",
      "Epoch: 50 | Batch_idx: 340 |  Loss: (0.1343) | Acc: (95.28%) (41588/43648)\n",
      "Epoch: 50 | Batch_idx: 350 |  Loss: (0.1350) | Acc: (95.27%) (42801/44928)\n",
      "Epoch: 50 | Batch_idx: 360 |  Loss: (0.1351) | Acc: (95.28%) (44026/46208)\n",
      "Epoch: 50 | Batch_idx: 370 |  Loss: (0.1349) | Acc: (95.28%) (45247/47488)\n",
      "Epoch: 50 | Batch_idx: 380 |  Loss: (0.1361) | Acc: (95.24%) (46446/48768)\n",
      "Epoch: 50 | Batch_idx: 390 |  Loss: (0.1361) | Acc: (95.24%) (47620/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6265) | Acc: (85.53%) (8553/10000)\n",
      "Epoch: 51 | Batch_idx: 0 |  Loss: (0.1255) | Acc: (96.88%) (124/128)\n",
      "Epoch: 51 | Batch_idx: 10 |  Loss: (0.1533) | Acc: (94.60%) (1332/1408)\n",
      "Epoch: 51 | Batch_idx: 20 |  Loss: (0.1349) | Acc: (95.20%) (2559/2688)\n",
      "Epoch: 51 | Batch_idx: 30 |  Loss: (0.1317) | Acc: (95.41%) (3786/3968)\n",
      "Epoch: 51 | Batch_idx: 40 |  Loss: (0.1323) | Acc: (95.39%) (5006/5248)\n",
      "Epoch: 51 | Batch_idx: 50 |  Loss: (0.1301) | Acc: (95.44%) (6230/6528)\n",
      "Epoch: 51 | Batch_idx: 60 |  Loss: (0.1256) | Acc: (95.66%) (7469/7808)\n",
      "Epoch: 51 | Batch_idx: 70 |  Loss: (0.1253) | Acc: (95.69%) (8696/9088)\n",
      "Epoch: 51 | Batch_idx: 80 |  Loss: (0.1260) | Acc: (95.69%) (9921/10368)\n",
      "Epoch: 51 | Batch_idx: 90 |  Loss: (0.1248) | Acc: (95.72%) (11150/11648)\n",
      "Epoch: 51 | Batch_idx: 100 |  Loss: (0.1251) | Acc: (95.70%) (12372/12928)\n",
      "Epoch: 51 | Batch_idx: 110 |  Loss: (0.1269) | Acc: (95.60%) (13583/14208)\n",
      "Epoch: 51 | Batch_idx: 120 |  Loss: (0.1278) | Acc: (95.58%) (14804/15488)\n",
      "Epoch: 51 | Batch_idx: 130 |  Loss: (0.1281) | Acc: (95.58%) (16027/16768)\n",
      "Epoch: 51 | Batch_idx: 140 |  Loss: (0.1279) | Acc: (95.59%) (17252/18048)\n",
      "Epoch: 51 | Batch_idx: 150 |  Loss: (0.1277) | Acc: (95.58%) (18474/19328)\n",
      "Epoch: 51 | Batch_idx: 160 |  Loss: (0.1289) | Acc: (95.55%) (19691/20608)\n",
      "Epoch: 51 | Batch_idx: 170 |  Loss: (0.1299) | Acc: (95.55%) (20914/21888)\n",
      "Epoch: 51 | Batch_idx: 180 |  Loss: (0.1297) | Acc: (95.56%) (22139/23168)\n",
      "Epoch: 51 | Batch_idx: 190 |  Loss: (0.1287) | Acc: (95.59%) (23371/24448)\n",
      "Epoch: 51 | Batch_idx: 200 |  Loss: (0.1282) | Acc: (95.63%) (24603/25728)\n",
      "Epoch: 51 | Batch_idx: 210 |  Loss: (0.1288) | Acc: (95.61%) (25821/27008)\n",
      "Epoch: 51 | Batch_idx: 220 |  Loss: (0.1303) | Acc: (95.56%) (27031/28288)\n",
      "Epoch: 51 | Batch_idx: 230 |  Loss: (0.1294) | Acc: (95.60%) (28267/29568)\n",
      "Epoch: 51 | Batch_idx: 240 |  Loss: (0.1301) | Acc: (95.56%) (29479/30848)\n",
      "Epoch: 51 | Batch_idx: 250 |  Loss: (0.1302) | Acc: (95.56%) (30700/32128)\n",
      "Epoch: 51 | Batch_idx: 260 |  Loss: (0.1308) | Acc: (95.52%) (31911/33408)\n",
      "Epoch: 51 | Batch_idx: 270 |  Loss: (0.1310) | Acc: (95.49%) (33124/34688)\n",
      "Epoch: 51 | Batch_idx: 280 |  Loss: (0.1314) | Acc: (95.50%) (34348/35968)\n",
      "Epoch: 51 | Batch_idx: 290 |  Loss: (0.1320) | Acc: (95.47%) (35560/37248)\n",
      "Epoch: 51 | Batch_idx: 300 |  Loss: (0.1316) | Acc: (95.47%) (36783/38528)\n",
      "Epoch: 51 | Batch_idx: 310 |  Loss: (0.1314) | Acc: (95.49%) (38011/39808)\n",
      "Epoch: 51 | Batch_idx: 320 |  Loss: (0.1310) | Acc: (95.50%) (39238/41088)\n",
      "Epoch: 51 | Batch_idx: 330 |  Loss: (0.1311) | Acc: (95.50%) (40462/42368)\n",
      "Epoch: 51 | Batch_idx: 340 |  Loss: (0.1315) | Acc: (95.48%) (41673/43648)\n",
      "Epoch: 51 | Batch_idx: 350 |  Loss: (0.1320) | Acc: (95.45%) (42884/44928)\n",
      "Epoch: 51 | Batch_idx: 360 |  Loss: (0.1320) | Acc: (95.45%) (44107/46208)\n",
      "Epoch: 51 | Batch_idx: 370 |  Loss: (0.1323) | Acc: (95.43%) (45319/47488)\n",
      "Epoch: 51 | Batch_idx: 380 |  Loss: (0.1324) | Acc: (95.43%) (46540/48768)\n",
      "Epoch: 51 | Batch_idx: 390 |  Loss: (0.1326) | Acc: (95.42%) (47712/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6060) | Acc: (86.34%) (8634/10000)\n",
      "Epoch: 52 | Batch_idx: 0 |  Loss: (0.1552) | Acc: (95.31%) (122/128)\n",
      "Epoch: 52 | Batch_idx: 10 |  Loss: (0.1303) | Acc: (95.31%) (1342/1408)\n",
      "Epoch: 52 | Batch_idx: 20 |  Loss: (0.1265) | Acc: (95.61%) (2570/2688)\n",
      "Epoch: 52 | Batch_idx: 30 |  Loss: (0.1241) | Acc: (95.77%) (3800/3968)\n",
      "Epoch: 52 | Batch_idx: 40 |  Loss: (0.1199) | Acc: (95.94%) (5035/5248)\n",
      "Epoch: 52 | Batch_idx: 50 |  Loss: (0.1228) | Acc: (95.82%) (6255/6528)\n",
      "Epoch: 52 | Batch_idx: 60 |  Loss: (0.1228) | Acc: (95.88%) (7486/7808)\n",
      "Epoch: 52 | Batch_idx: 70 |  Loss: (0.1235) | Acc: (95.87%) (8713/9088)\n",
      "Epoch: 52 | Batch_idx: 80 |  Loss: (0.1227) | Acc: (95.95%) (9948/10368)\n",
      "Epoch: 52 | Batch_idx: 90 |  Loss: (0.1239) | Acc: (95.90%) (11170/11648)\n",
      "Epoch: 52 | Batch_idx: 100 |  Loss: (0.1237) | Acc: (95.89%) (12397/12928)\n",
      "Epoch: 52 | Batch_idx: 110 |  Loss: (0.1214) | Acc: (95.95%) (13632/14208)\n",
      "Epoch: 52 | Batch_idx: 120 |  Loss: (0.1223) | Acc: (95.89%) (14852/15488)\n",
      "Epoch: 52 | Batch_idx: 130 |  Loss: (0.1221) | Acc: (95.90%) (16080/16768)\n",
      "Epoch: 52 | Batch_idx: 140 |  Loss: (0.1218) | Acc: (95.87%) (17303/18048)\n",
      "Epoch: 52 | Batch_idx: 150 |  Loss: (0.1226) | Acc: (95.88%) (18532/19328)\n",
      "Epoch: 52 | Batch_idx: 160 |  Loss: (0.1223) | Acc: (95.87%) (19757/20608)\n",
      "Epoch: 52 | Batch_idx: 170 |  Loss: (0.1234) | Acc: (95.82%) (20974/21888)\n",
      "Epoch: 52 | Batch_idx: 180 |  Loss: (0.1226) | Acc: (95.85%) (22207/23168)\n",
      "Epoch: 52 | Batch_idx: 190 |  Loss: (0.1217) | Acc: (95.88%) (23441/24448)\n",
      "Epoch: 52 | Batch_idx: 200 |  Loss: (0.1217) | Acc: (95.90%) (24673/25728)\n",
      "Epoch: 52 | Batch_idx: 210 |  Loss: (0.1229) | Acc: (95.84%) (25884/27008)\n",
      "Epoch: 52 | Batch_idx: 220 |  Loss: (0.1229) | Acc: (95.83%) (27109/28288)\n",
      "Epoch: 52 | Batch_idx: 230 |  Loss: (0.1221) | Acc: (95.85%) (28342/29568)\n",
      "Epoch: 52 | Batch_idx: 240 |  Loss: (0.1224) | Acc: (95.84%) (29565/30848)\n",
      "Epoch: 52 | Batch_idx: 250 |  Loss: (0.1226) | Acc: (95.81%) (30783/32128)\n",
      "Epoch: 52 | Batch_idx: 260 |  Loss: (0.1229) | Acc: (95.82%) (32013/33408)\n",
      "Epoch: 52 | Batch_idx: 270 |  Loss: (0.1223) | Acc: (95.85%) (33247/34688)\n",
      "Epoch: 52 | Batch_idx: 280 |  Loss: (0.1224) | Acc: (95.85%) (34476/35968)\n",
      "Epoch: 52 | Batch_idx: 290 |  Loss: (0.1235) | Acc: (95.79%) (35680/37248)\n",
      "Epoch: 52 | Batch_idx: 300 |  Loss: (0.1244) | Acc: (95.77%) (36899/38528)\n",
      "Epoch: 52 | Batch_idx: 310 |  Loss: (0.1243) | Acc: (95.77%) (38124/39808)\n",
      "Epoch: 52 | Batch_idx: 320 |  Loss: (0.1245) | Acc: (95.76%) (39345/41088)\n",
      "Epoch: 52 | Batch_idx: 330 |  Loss: (0.1252) | Acc: (95.72%) (40554/42368)\n",
      "Epoch: 52 | Batch_idx: 340 |  Loss: (0.1256) | Acc: (95.70%) (41773/43648)\n",
      "Epoch: 52 | Batch_idx: 350 |  Loss: (0.1258) | Acc: (95.69%) (42990/44928)\n",
      "Epoch: 52 | Batch_idx: 360 |  Loss: (0.1259) | Acc: (95.68%) (44212/46208)\n",
      "Epoch: 52 | Batch_idx: 370 |  Loss: (0.1263) | Acc: (95.64%) (45419/47488)\n",
      "Epoch: 52 | Batch_idx: 380 |  Loss: (0.1257) | Acc: (95.67%) (46654/48768)\n",
      "Epoch: 52 | Batch_idx: 390 |  Loss: (0.1253) | Acc: (95.67%) (47835/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5406) | Acc: (87.94%) (8794/10000)\n",
      "Epoch: 53 | Batch_idx: 0 |  Loss: (0.0829) | Acc: (97.66%) (125/128)\n",
      "Epoch: 53 | Batch_idx: 10 |  Loss: (0.1217) | Acc: (96.02%) (1352/1408)\n",
      "Epoch: 53 | Batch_idx: 20 |  Loss: (0.1219) | Acc: (95.68%) (2572/2688)\n",
      "Epoch: 53 | Batch_idx: 30 |  Loss: (0.1173) | Acc: (95.87%) (3804/3968)\n",
      "Epoch: 53 | Batch_idx: 40 |  Loss: (0.1222) | Acc: (95.60%) (5017/5248)\n",
      "Epoch: 53 | Batch_idx: 50 |  Loss: (0.1238) | Acc: (95.62%) (6242/6528)\n",
      "Epoch: 53 | Batch_idx: 60 |  Loss: (0.1225) | Acc: (95.65%) (7468/7808)\n",
      "Epoch: 53 | Batch_idx: 70 |  Loss: (0.1224) | Acc: (95.69%) (8696/9088)\n",
      "Epoch: 53 | Batch_idx: 80 |  Loss: (0.1224) | Acc: (95.65%) (9917/10368)\n",
      "Epoch: 53 | Batch_idx: 90 |  Loss: (0.1230) | Acc: (95.69%) (11146/11648)\n",
      "Epoch: 53 | Batch_idx: 100 |  Loss: (0.1221) | Acc: (95.72%) (12375/12928)\n",
      "Epoch: 53 | Batch_idx: 110 |  Loss: (0.1201) | Acc: (95.81%) (13612/14208)\n",
      "Epoch: 53 | Batch_idx: 120 |  Loss: (0.1207) | Acc: (95.82%) (14840/15488)\n",
      "Epoch: 53 | Batch_idx: 130 |  Loss: (0.1215) | Acc: (95.80%) (16063/16768)\n",
      "Epoch: 53 | Batch_idx: 140 |  Loss: (0.1220) | Acc: (95.77%) (17284/18048)\n",
      "Epoch: 53 | Batch_idx: 150 |  Loss: (0.1223) | Acc: (95.76%) (18509/19328)\n",
      "Epoch: 53 | Batch_idx: 160 |  Loss: (0.1220) | Acc: (95.80%) (19743/20608)\n",
      "Epoch: 53 | Batch_idx: 170 |  Loss: (0.1213) | Acc: (95.83%) (20976/21888)\n",
      "Epoch: 53 | Batch_idx: 180 |  Loss: (0.1216) | Acc: (95.83%) (22203/23168)\n",
      "Epoch: 53 | Batch_idx: 190 |  Loss: (0.1218) | Acc: (95.84%) (23431/24448)\n",
      "Epoch: 53 | Batch_idx: 200 |  Loss: (0.1224) | Acc: (95.80%) (24648/25728)\n",
      "Epoch: 53 | Batch_idx: 210 |  Loss: (0.1232) | Acc: (95.77%) (25866/27008)\n",
      "Epoch: 53 | Batch_idx: 220 |  Loss: (0.1244) | Acc: (95.74%) (27083/28288)\n",
      "Epoch: 53 | Batch_idx: 230 |  Loss: (0.1258) | Acc: (95.66%) (28286/29568)\n",
      "Epoch: 53 | Batch_idx: 240 |  Loss: (0.1256) | Acc: (95.67%) (29511/30848)\n",
      "Epoch: 53 | Batch_idx: 250 |  Loss: (0.1262) | Acc: (95.64%) (30727/32128)\n",
      "Epoch: 53 | Batch_idx: 260 |  Loss: (0.1265) | Acc: (95.65%) (31954/33408)\n",
      "Epoch: 53 | Batch_idx: 270 |  Loss: (0.1264) | Acc: (95.64%) (33176/34688)\n",
      "Epoch: 53 | Batch_idx: 280 |  Loss: (0.1259) | Acc: (95.66%) (34406/35968)\n",
      "Epoch: 53 | Batch_idx: 290 |  Loss: (0.1258) | Acc: (95.66%) (35632/37248)\n",
      "Epoch: 53 | Batch_idx: 300 |  Loss: (0.1253) | Acc: (95.69%) (36867/38528)\n",
      "Epoch: 53 | Batch_idx: 310 |  Loss: (0.1254) | Acc: (95.70%) (38097/39808)\n",
      "Epoch: 53 | Batch_idx: 320 |  Loss: (0.1251) | Acc: (95.71%) (39326/41088)\n",
      "Epoch: 53 | Batch_idx: 330 |  Loss: (0.1247) | Acc: (95.72%) (40553/42368)\n",
      "Epoch: 53 | Batch_idx: 340 |  Loss: (0.1249) | Acc: (95.70%) (41772/43648)\n",
      "Epoch: 53 | Batch_idx: 350 |  Loss: (0.1243) | Acc: (95.72%) (43003/44928)\n",
      "Epoch: 53 | Batch_idx: 360 |  Loss: (0.1239) | Acc: (95.73%) (44235/46208)\n",
      "Epoch: 53 | Batch_idx: 370 |  Loss: (0.1238) | Acc: (95.73%) (45460/47488)\n",
      "Epoch: 53 | Batch_idx: 380 |  Loss: (0.1247) | Acc: (95.70%) (46671/48768)\n",
      "Epoch: 53 | Batch_idx: 390 |  Loss: (0.1247) | Acc: (95.69%) (47847/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6089) | Acc: (86.57%) (8657/10000)\n",
      "Epoch: 54 | Batch_idx: 0 |  Loss: (0.1991) | Acc: (93.75%) (120/128)\n",
      "Epoch: 54 | Batch_idx: 10 |  Loss: (0.1106) | Acc: (96.38%) (1357/1408)\n",
      "Epoch: 54 | Batch_idx: 20 |  Loss: (0.1047) | Acc: (96.47%) (2593/2688)\n",
      "Epoch: 54 | Batch_idx: 30 |  Loss: (0.1092) | Acc: (96.24%) (3819/3968)\n",
      "Epoch: 54 | Batch_idx: 40 |  Loss: (0.1061) | Acc: (96.30%) (5054/5248)\n",
      "Epoch: 54 | Batch_idx: 50 |  Loss: (0.1147) | Acc: (95.93%) (6262/6528)\n",
      "Epoch: 54 | Batch_idx: 60 |  Loss: (0.1153) | Acc: (95.86%) (7485/7808)\n",
      "Epoch: 54 | Batch_idx: 70 |  Loss: (0.1133) | Acc: (95.97%) (8722/9088)\n",
      "Epoch: 54 | Batch_idx: 80 |  Loss: (0.1123) | Acc: (96.00%) (9953/10368)\n",
      "Epoch: 54 | Batch_idx: 90 |  Loss: (0.1125) | Acc: (96.05%) (11188/11648)\n",
      "Epoch: 54 | Batch_idx: 100 |  Loss: (0.1114) | Acc: (96.12%) (12426/12928)\n",
      "Epoch: 54 | Batch_idx: 110 |  Loss: (0.1099) | Acc: (96.12%) (13657/14208)\n",
      "Epoch: 54 | Batch_idx: 120 |  Loss: (0.1088) | Acc: (96.15%) (14892/15488)\n",
      "Epoch: 54 | Batch_idx: 130 |  Loss: (0.1094) | Acc: (96.10%) (16114/16768)\n",
      "Epoch: 54 | Batch_idx: 140 |  Loss: (0.1107) | Acc: (96.08%) (17340/18048)\n",
      "Epoch: 54 | Batch_idx: 150 |  Loss: (0.1105) | Acc: (96.09%) (18573/19328)\n",
      "Epoch: 54 | Batch_idx: 160 |  Loss: (0.1101) | Acc: (96.12%) (19808/20608)\n",
      "Epoch: 54 | Batch_idx: 170 |  Loss: (0.1099) | Acc: (96.13%) (21040/21888)\n",
      "Epoch: 54 | Batch_idx: 180 |  Loss: (0.1096) | Acc: (96.15%) (22275/23168)\n",
      "Epoch: 54 | Batch_idx: 190 |  Loss: (0.1115) | Acc: (96.08%) (23490/24448)\n",
      "Epoch: 54 | Batch_idx: 200 |  Loss: (0.1109) | Acc: (96.10%) (24725/25728)\n",
      "Epoch: 54 | Batch_idx: 210 |  Loss: (0.1112) | Acc: (96.11%) (25957/27008)\n",
      "Epoch: 54 | Batch_idx: 220 |  Loss: (0.1111) | Acc: (96.13%) (27192/28288)\n",
      "Epoch: 54 | Batch_idx: 230 |  Loss: (0.1109) | Acc: (96.15%) (28431/29568)\n",
      "Epoch: 54 | Batch_idx: 240 |  Loss: (0.1107) | Acc: (96.15%) (29660/30848)\n",
      "Epoch: 54 | Batch_idx: 250 |  Loss: (0.1116) | Acc: (96.11%) (30878/32128)\n",
      "Epoch: 54 | Batch_idx: 260 |  Loss: (0.1116) | Acc: (96.12%) (32111/33408)\n",
      "Epoch: 54 | Batch_idx: 270 |  Loss: (0.1122) | Acc: (96.11%) (33337/34688)\n",
      "Epoch: 54 | Batch_idx: 280 |  Loss: (0.1127) | Acc: (96.07%) (34554/35968)\n",
      "Epoch: 54 | Batch_idx: 290 |  Loss: (0.1133) | Acc: (96.04%) (35774/37248)\n",
      "Epoch: 54 | Batch_idx: 300 |  Loss: (0.1134) | Acc: (96.04%) (37002/38528)\n",
      "Epoch: 54 | Batch_idx: 310 |  Loss: (0.1138) | Acc: (96.03%) (38229/39808)\n",
      "Epoch: 54 | Batch_idx: 320 |  Loss: (0.1147) | Acc: (96.01%) (39449/41088)\n",
      "Epoch: 54 | Batch_idx: 330 |  Loss: (0.1150) | Acc: (96.00%) (40675/42368)\n",
      "Epoch: 54 | Batch_idx: 340 |  Loss: (0.1153) | Acc: (96.00%) (41901/43648)\n",
      "Epoch: 54 | Batch_idx: 350 |  Loss: (0.1153) | Acc: (96.00%) (43132/44928)\n",
      "Epoch: 54 | Batch_idx: 360 |  Loss: (0.1151) | Acc: (96.01%) (44364/46208)\n",
      "Epoch: 54 | Batch_idx: 370 |  Loss: (0.1153) | Acc: (95.99%) (45586/47488)\n",
      "Epoch: 54 | Batch_idx: 380 |  Loss: (0.1154) | Acc: (95.99%) (46813/48768)\n",
      "Epoch: 54 | Batch_idx: 390 |  Loss: (0.1156) | Acc: (95.98%) (47990/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6149) | Acc: (86.20%) (8620/10000)\n",
      "Epoch: 55 | Batch_idx: 0 |  Loss: (0.0393) | Acc: (99.22%) (127/128)\n",
      "Epoch: 55 | Batch_idx: 10 |  Loss: (0.0808) | Acc: (97.44%) (1372/1408)\n",
      "Epoch: 55 | Batch_idx: 20 |  Loss: (0.1040) | Acc: (96.69%) (2599/2688)\n",
      "Epoch: 55 | Batch_idx: 30 |  Loss: (0.1078) | Acc: (96.42%) (3826/3968)\n",
      "Epoch: 55 | Batch_idx: 40 |  Loss: (0.1104) | Acc: (96.27%) (5052/5248)\n",
      "Epoch: 55 | Batch_idx: 50 |  Loss: (0.1114) | Acc: (96.12%) (6275/6528)\n",
      "Epoch: 55 | Batch_idx: 60 |  Loss: (0.1106) | Acc: (96.14%) (7507/7808)\n",
      "Epoch: 55 | Batch_idx: 70 |  Loss: (0.1095) | Acc: (96.17%) (8740/9088)\n",
      "Epoch: 55 | Batch_idx: 80 |  Loss: (0.1090) | Acc: (96.20%) (9974/10368)\n",
      "Epoch: 55 | Batch_idx: 90 |  Loss: (0.1069) | Acc: (96.33%) (11221/11648)\n",
      "Epoch: 55 | Batch_idx: 100 |  Loss: (0.1098) | Acc: (96.20%) (12437/12928)\n",
      "Epoch: 55 | Batch_idx: 110 |  Loss: (0.1109) | Acc: (96.10%) (13654/14208)\n",
      "Epoch: 55 | Batch_idx: 120 |  Loss: (0.1104) | Acc: (96.15%) (14891/15488)\n",
      "Epoch: 55 | Batch_idx: 130 |  Loss: (0.1110) | Acc: (96.13%) (16119/16768)\n",
      "Epoch: 55 | Batch_idx: 140 |  Loss: (0.1112) | Acc: (96.18%) (17358/18048)\n",
      "Epoch: 55 | Batch_idx: 150 |  Loss: (0.1113) | Acc: (96.20%) (18594/19328)\n",
      "Epoch: 55 | Batch_idx: 160 |  Loss: (0.1124) | Acc: (96.16%) (19816/20608)\n",
      "Epoch: 55 | Batch_idx: 170 |  Loss: (0.1122) | Acc: (96.17%) (21049/21888)\n",
      "Epoch: 55 | Batch_idx: 180 |  Loss: (0.1139) | Acc: (96.10%) (22265/23168)\n",
      "Epoch: 55 | Batch_idx: 190 |  Loss: (0.1138) | Acc: (96.09%) (23493/24448)\n",
      "Epoch: 55 | Batch_idx: 200 |  Loss: (0.1138) | Acc: (96.11%) (24726/25728)\n",
      "Epoch: 55 | Batch_idx: 210 |  Loss: (0.1130) | Acc: (96.12%) (25961/27008)\n",
      "Epoch: 55 | Batch_idx: 220 |  Loss: (0.1125) | Acc: (96.15%) (27198/28288)\n",
      "Epoch: 55 | Batch_idx: 230 |  Loss: (0.1126) | Acc: (96.15%) (28430/29568)\n",
      "Epoch: 55 | Batch_idx: 240 |  Loss: (0.1124) | Acc: (96.16%) (29663/30848)\n",
      "Epoch: 55 | Batch_idx: 250 |  Loss: (0.1122) | Acc: (96.16%) (30893/32128)\n",
      "Epoch: 55 | Batch_idx: 260 |  Loss: (0.1118) | Acc: (96.18%) (32131/33408)\n",
      "Epoch: 55 | Batch_idx: 270 |  Loss: (0.1120) | Acc: (96.16%) (33355/34688)\n",
      "Epoch: 55 | Batch_idx: 280 |  Loss: (0.1124) | Acc: (96.14%) (34579/35968)\n",
      "Epoch: 55 | Batch_idx: 290 |  Loss: (0.1133) | Acc: (96.11%) (35799/37248)\n",
      "Epoch: 55 | Batch_idx: 300 |  Loss: (0.1139) | Acc: (96.09%) (37020/38528)\n",
      "Epoch: 55 | Batch_idx: 310 |  Loss: (0.1138) | Acc: (96.10%) (38254/39808)\n",
      "Epoch: 55 | Batch_idx: 320 |  Loss: (0.1133) | Acc: (96.12%) (39495/41088)\n",
      "Epoch: 55 | Batch_idx: 330 |  Loss: (0.1132) | Acc: (96.13%) (40728/42368)\n",
      "Epoch: 55 | Batch_idx: 340 |  Loss: (0.1132) | Acc: (96.13%) (41959/43648)\n",
      "Epoch: 55 | Batch_idx: 350 |  Loss: (0.1129) | Acc: (96.15%) (43198/44928)\n",
      "Epoch: 55 | Batch_idx: 360 |  Loss: (0.1133) | Acc: (96.13%) (44418/46208)\n",
      "Epoch: 55 | Batch_idx: 370 |  Loss: (0.1142) | Acc: (96.09%) (45631/47488)\n",
      "Epoch: 55 | Batch_idx: 380 |  Loss: (0.1145) | Acc: (96.08%) (46856/48768)\n",
      "Epoch: 55 | Batch_idx: 390 |  Loss: (0.1146) | Acc: (96.08%) (48039/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6472) | Acc: (86.31%) (8631/10000)\n",
      "Epoch: 56 | Batch_idx: 0 |  Loss: (0.0618) | Acc: (98.44%) (126/128)\n",
      "Epoch: 56 | Batch_idx: 10 |  Loss: (0.0902) | Acc: (96.80%) (1363/1408)\n",
      "Epoch: 56 | Batch_idx: 20 |  Loss: (0.0967) | Acc: (96.43%) (2592/2688)\n",
      "Epoch: 56 | Batch_idx: 30 |  Loss: (0.1056) | Acc: (96.12%) (3814/3968)\n",
      "Epoch: 56 | Batch_idx: 40 |  Loss: (0.1076) | Acc: (96.09%) (5043/5248)\n",
      "Epoch: 56 | Batch_idx: 50 |  Loss: (0.1043) | Acc: (96.32%) (6288/6528)\n",
      "Epoch: 56 | Batch_idx: 60 |  Loss: (0.1066) | Acc: (96.25%) (7515/7808)\n",
      "Epoch: 56 | Batch_idx: 70 |  Loss: (0.1075) | Acc: (96.23%) (8745/9088)\n",
      "Epoch: 56 | Batch_idx: 80 |  Loss: (0.1067) | Acc: (96.28%) (9982/10368)\n",
      "Epoch: 56 | Batch_idx: 90 |  Loss: (0.1059) | Acc: (96.28%) (11215/11648)\n",
      "Epoch: 56 | Batch_idx: 100 |  Loss: (0.1052) | Acc: (96.33%) (12454/12928)\n",
      "Epoch: 56 | Batch_idx: 110 |  Loss: (0.1037) | Acc: (96.36%) (13691/14208)\n",
      "Epoch: 56 | Batch_idx: 120 |  Loss: (0.1033) | Acc: (96.42%) (14933/15488)\n",
      "Epoch: 56 | Batch_idx: 130 |  Loss: (0.1033) | Acc: (96.42%) (16167/16768)\n",
      "Epoch: 56 | Batch_idx: 140 |  Loss: (0.1029) | Acc: (96.40%) (17398/18048)\n",
      "Epoch: 56 | Batch_idx: 150 |  Loss: (0.1027) | Acc: (96.38%) (18628/19328)\n",
      "Epoch: 56 | Batch_idx: 160 |  Loss: (0.1051) | Acc: (96.30%) (19845/20608)\n",
      "Epoch: 56 | Batch_idx: 170 |  Loss: (0.1055) | Acc: (96.29%) (21076/21888)\n",
      "Epoch: 56 | Batch_idx: 180 |  Loss: (0.1053) | Acc: (96.30%) (22310/23168)\n",
      "Epoch: 56 | Batch_idx: 190 |  Loss: (0.1048) | Acc: (96.31%) (23547/24448)\n",
      "Epoch: 56 | Batch_idx: 200 |  Loss: (0.1046) | Acc: (96.33%) (24783/25728)\n",
      "Epoch: 56 | Batch_idx: 210 |  Loss: (0.1051) | Acc: (96.30%) (26008/27008)\n",
      "Epoch: 56 | Batch_idx: 220 |  Loss: (0.1062) | Acc: (96.25%) (27228/28288)\n",
      "Epoch: 56 | Batch_idx: 230 |  Loss: (0.1068) | Acc: (96.23%) (28453/29568)\n",
      "Epoch: 56 | Batch_idx: 240 |  Loss: (0.1064) | Acc: (96.24%) (29687/30848)\n",
      "Epoch: 56 | Batch_idx: 250 |  Loss: (0.1077) | Acc: (96.17%) (30897/32128)\n",
      "Epoch: 56 | Batch_idx: 260 |  Loss: (0.1085) | Acc: (96.15%) (32121/33408)\n",
      "Epoch: 56 | Batch_idx: 270 |  Loss: (0.1088) | Acc: (96.13%) (33344/34688)\n",
      "Epoch: 56 | Batch_idx: 280 |  Loss: (0.1093) | Acc: (96.09%) (34561/35968)\n",
      "Epoch: 56 | Batch_idx: 290 |  Loss: (0.1101) | Acc: (96.06%) (35782/37248)\n",
      "Epoch: 56 | Batch_idx: 300 |  Loss: (0.1096) | Acc: (96.08%) (37019/38528)\n",
      "Epoch: 56 | Batch_idx: 310 |  Loss: (0.1095) | Acc: (96.11%) (38259/39808)\n",
      "Epoch: 56 | Batch_idx: 320 |  Loss: (0.1098) | Acc: (96.11%) (39490/41088)\n",
      "Epoch: 56 | Batch_idx: 330 |  Loss: (0.1098) | Acc: (96.13%) (40729/42368)\n",
      "Epoch: 56 | Batch_idx: 340 |  Loss: (0.1099) | Acc: (96.13%) (41957/43648)\n",
      "Epoch: 56 | Batch_idx: 350 |  Loss: (0.1096) | Acc: (96.15%) (43200/44928)\n",
      "Epoch: 56 | Batch_idx: 360 |  Loss: (0.1098) | Acc: (96.14%) (44425/46208)\n",
      "Epoch: 56 | Batch_idx: 370 |  Loss: (0.1099) | Acc: (96.15%) (45660/47488)\n",
      "Epoch: 56 | Batch_idx: 380 |  Loss: (0.1100) | Acc: (96.15%) (46892/48768)\n",
      "Epoch: 56 | Batch_idx: 390 |  Loss: (0.1100) | Acc: (96.17%) (48083/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7603) | Acc: (84.63%) (8463/10000)\n",
      "Epoch: 57 | Batch_idx: 0 |  Loss: (0.0401) | Acc: (100.00%) (128/128)\n",
      "Epoch: 57 | Batch_idx: 10 |  Loss: (0.1001) | Acc: (96.24%) (1355/1408)\n",
      "Epoch: 57 | Batch_idx: 20 |  Loss: (0.1011) | Acc: (96.28%) (2588/2688)\n",
      "Epoch: 57 | Batch_idx: 30 |  Loss: (0.1001) | Acc: (96.37%) (3824/3968)\n",
      "Epoch: 57 | Batch_idx: 40 |  Loss: (0.1003) | Acc: (96.46%) (5062/5248)\n",
      "Epoch: 57 | Batch_idx: 50 |  Loss: (0.1052) | Acc: (96.28%) (6285/6528)\n",
      "Epoch: 57 | Batch_idx: 60 |  Loss: (0.1045) | Acc: (96.36%) (7524/7808)\n",
      "Epoch: 57 | Batch_idx: 70 |  Loss: (0.1053) | Acc: (96.28%) (8750/9088)\n",
      "Epoch: 57 | Batch_idx: 80 |  Loss: (0.1040) | Acc: (96.39%) (9994/10368)\n",
      "Epoch: 57 | Batch_idx: 90 |  Loss: (0.1055) | Acc: (96.35%) (11223/11648)\n",
      "Epoch: 57 | Batch_idx: 100 |  Loss: (0.1055) | Acc: (96.32%) (12452/12928)\n",
      "Epoch: 57 | Batch_idx: 110 |  Loss: (0.1057) | Acc: (96.30%) (13682/14208)\n",
      "Epoch: 57 | Batch_idx: 120 |  Loss: (0.1046) | Acc: (96.37%) (14926/15488)\n",
      "Epoch: 57 | Batch_idx: 130 |  Loss: (0.1055) | Acc: (96.34%) (16154/16768)\n",
      "Epoch: 57 | Batch_idx: 140 |  Loss: (0.1058) | Acc: (96.34%) (17387/18048)\n",
      "Epoch: 57 | Batch_idx: 150 |  Loss: (0.1056) | Acc: (96.35%) (18622/19328)\n",
      "Epoch: 57 | Batch_idx: 160 |  Loss: (0.1059) | Acc: (96.31%) (19847/20608)\n",
      "Epoch: 57 | Batch_idx: 170 |  Loss: (0.1070) | Acc: (96.24%) (21064/21888)\n",
      "Epoch: 57 | Batch_idx: 180 |  Loss: (0.1068) | Acc: (96.25%) (22300/23168)\n",
      "Epoch: 57 | Batch_idx: 190 |  Loss: (0.1077) | Acc: (96.21%) (23522/24448)\n",
      "Epoch: 57 | Batch_idx: 200 |  Loss: (0.1075) | Acc: (96.21%) (24754/25728)\n",
      "Epoch: 57 | Batch_idx: 210 |  Loss: (0.1077) | Acc: (96.20%) (25982/27008)\n",
      "Epoch: 57 | Batch_idx: 220 |  Loss: (0.1071) | Acc: (96.22%) (27218/28288)\n",
      "Epoch: 57 | Batch_idx: 230 |  Loss: (0.1074) | Acc: (96.22%) (28451/29568)\n",
      "Epoch: 57 | Batch_idx: 240 |  Loss: (0.1067) | Acc: (96.26%) (29694/30848)\n",
      "Epoch: 57 | Batch_idx: 250 |  Loss: (0.1064) | Acc: (96.27%) (30930/32128)\n",
      "Epoch: 57 | Batch_idx: 260 |  Loss: (0.1066) | Acc: (96.24%) (32153/33408)\n",
      "Epoch: 57 | Batch_idx: 270 |  Loss: (0.1064) | Acc: (96.26%) (33389/34688)\n",
      "Epoch: 57 | Batch_idx: 280 |  Loss: (0.1062) | Acc: (96.26%) (34624/35968)\n",
      "Epoch: 57 | Batch_idx: 290 |  Loss: (0.1067) | Acc: (96.26%) (35855/37248)\n",
      "Epoch: 57 | Batch_idx: 300 |  Loss: (0.1073) | Acc: (96.25%) (37084/38528)\n",
      "Epoch: 57 | Batch_idx: 310 |  Loss: (0.1065) | Acc: (96.28%) (38326/39808)\n",
      "Epoch: 57 | Batch_idx: 320 |  Loss: (0.1072) | Acc: (96.24%) (39543/41088)\n",
      "Epoch: 57 | Batch_idx: 330 |  Loss: (0.1079) | Acc: (96.23%) (40769/42368)\n",
      "Epoch: 57 | Batch_idx: 340 |  Loss: (0.1080) | Acc: (96.22%) (41999/43648)\n",
      "Epoch: 57 | Batch_idx: 350 |  Loss: (0.1077) | Acc: (96.26%) (43247/44928)\n",
      "Epoch: 57 | Batch_idx: 360 |  Loss: (0.1079) | Acc: (96.24%) (44471/46208)\n",
      "Epoch: 57 | Batch_idx: 370 |  Loss: (0.1083) | Acc: (96.23%) (45699/47488)\n",
      "Epoch: 57 | Batch_idx: 380 |  Loss: (0.1085) | Acc: (96.22%) (46923/48768)\n",
      "Epoch: 57 | Batch_idx: 390 |  Loss: (0.1087) | Acc: (96.22%) (48108/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5836) | Acc: (87.61%) (8761/10000)\n",
      "Epoch: 58 | Batch_idx: 0 |  Loss: (0.1783) | Acc: (94.53%) (121/128)\n",
      "Epoch: 58 | Batch_idx: 10 |  Loss: (0.1090) | Acc: (95.88%) (1350/1408)\n",
      "Epoch: 58 | Batch_idx: 20 |  Loss: (0.0995) | Acc: (96.39%) (2591/2688)\n",
      "Epoch: 58 | Batch_idx: 30 |  Loss: (0.0980) | Acc: (96.35%) (3823/3968)\n",
      "Epoch: 58 | Batch_idx: 40 |  Loss: (0.0963) | Acc: (96.47%) (5063/5248)\n",
      "Epoch: 58 | Batch_idx: 50 |  Loss: (0.0984) | Acc: (96.52%) (6301/6528)\n",
      "Epoch: 58 | Batch_idx: 60 |  Loss: (0.0996) | Acc: (96.43%) (7529/7808)\n",
      "Epoch: 58 | Batch_idx: 70 |  Loss: (0.1018) | Acc: (96.28%) (8750/9088)\n",
      "Epoch: 58 | Batch_idx: 80 |  Loss: (0.1016) | Acc: (96.25%) (9979/10368)\n",
      "Epoch: 58 | Batch_idx: 90 |  Loss: (0.1037) | Acc: (96.24%) (11210/11648)\n",
      "Epoch: 58 | Batch_idx: 100 |  Loss: (0.1050) | Acc: (96.23%) (12441/12928)\n",
      "Epoch: 58 | Batch_idx: 110 |  Loss: (0.1048) | Acc: (96.23%) (13672/14208)\n",
      "Epoch: 58 | Batch_idx: 120 |  Loss: (0.1037) | Acc: (96.26%) (14909/15488)\n",
      "Epoch: 58 | Batch_idx: 130 |  Loss: (0.1036) | Acc: (96.26%) (16141/16768)\n",
      "Epoch: 58 | Batch_idx: 140 |  Loss: (0.1031) | Acc: (96.29%) (17379/18048)\n",
      "Epoch: 58 | Batch_idx: 150 |  Loss: (0.1032) | Acc: (96.29%) (18611/19328)\n",
      "Epoch: 58 | Batch_idx: 160 |  Loss: (0.1029) | Acc: (96.30%) (19846/20608)\n",
      "Epoch: 58 | Batch_idx: 170 |  Loss: (0.1021) | Acc: (96.34%) (21086/21888)\n",
      "Epoch: 58 | Batch_idx: 180 |  Loss: (0.1012) | Acc: (96.37%) (22327/23168)\n",
      "Epoch: 58 | Batch_idx: 190 |  Loss: (0.1021) | Acc: (96.34%) (23553/24448)\n",
      "Epoch: 58 | Batch_idx: 200 |  Loss: (0.1009) | Acc: (96.39%) (24799/25728)\n",
      "Epoch: 58 | Batch_idx: 210 |  Loss: (0.1012) | Acc: (96.36%) (26026/27008)\n",
      "Epoch: 58 | Batch_idx: 220 |  Loss: (0.1013) | Acc: (96.38%) (27263/28288)\n",
      "Epoch: 58 | Batch_idx: 230 |  Loss: (0.1018) | Acc: (96.38%) (28499/29568)\n",
      "Epoch: 58 | Batch_idx: 240 |  Loss: (0.1016) | Acc: (96.40%) (29737/30848)\n",
      "Epoch: 58 | Batch_idx: 250 |  Loss: (0.1022) | Acc: (96.36%) (30960/32128)\n",
      "Epoch: 58 | Batch_idx: 260 |  Loss: (0.1026) | Acc: (96.38%) (32197/33408)\n",
      "Epoch: 58 | Batch_idx: 270 |  Loss: (0.1026) | Acc: (96.36%) (33424/34688)\n",
      "Epoch: 58 | Batch_idx: 280 |  Loss: (0.1030) | Acc: (96.35%) (34655/35968)\n",
      "Epoch: 58 | Batch_idx: 290 |  Loss: (0.1031) | Acc: (96.33%) (35881/37248)\n",
      "Epoch: 58 | Batch_idx: 300 |  Loss: (0.1032) | Acc: (96.33%) (37113/38528)\n",
      "Epoch: 58 | Batch_idx: 310 |  Loss: (0.1039) | Acc: (96.32%) (38343/39808)\n",
      "Epoch: 58 | Batch_idx: 320 |  Loss: (0.1042) | Acc: (96.32%) (39574/41088)\n",
      "Epoch: 58 | Batch_idx: 330 |  Loss: (0.1048) | Acc: (96.30%) (40800/42368)\n",
      "Epoch: 58 | Batch_idx: 340 |  Loss: (0.1048) | Acc: (96.31%) (42036/43648)\n",
      "Epoch: 58 | Batch_idx: 350 |  Loss: (0.1050) | Acc: (96.31%) (43270/44928)\n",
      "Epoch: 58 | Batch_idx: 360 |  Loss: (0.1053) | Acc: (96.30%) (44499/46208)\n",
      "Epoch: 58 | Batch_idx: 370 |  Loss: (0.1053) | Acc: (96.29%) (45727/47488)\n",
      "Epoch: 58 | Batch_idx: 380 |  Loss: (0.1049) | Acc: (96.31%) (46970/48768)\n",
      "Epoch: 58 | Batch_idx: 390 |  Loss: (0.1055) | Acc: (96.30%) (48148/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7704) | Acc: (84.44%) (8444/10000)\n",
      "Epoch: 59 | Batch_idx: 0 |  Loss: (0.0443) | Acc: (99.22%) (127/128)\n",
      "Epoch: 59 | Batch_idx: 10 |  Loss: (0.0842) | Acc: (97.30%) (1370/1408)\n",
      "Epoch: 59 | Batch_idx: 20 |  Loss: (0.0949) | Acc: (96.91%) (2605/2688)\n",
      "Epoch: 59 | Batch_idx: 30 |  Loss: (0.0935) | Acc: (97.00%) (3849/3968)\n",
      "Epoch: 59 | Batch_idx: 40 |  Loss: (0.0917) | Acc: (96.97%) (5089/5248)\n",
      "Epoch: 59 | Batch_idx: 50 |  Loss: (0.0923) | Acc: (96.81%) (6320/6528)\n",
      "Epoch: 59 | Batch_idx: 60 |  Loss: (0.0932) | Acc: (96.70%) (7550/7808)\n",
      "Epoch: 59 | Batch_idx: 70 |  Loss: (0.0923) | Acc: (96.71%) (8789/9088)\n",
      "Epoch: 59 | Batch_idx: 80 |  Loss: (0.0923) | Acc: (96.78%) (10034/10368)\n",
      "Epoch: 59 | Batch_idx: 90 |  Loss: (0.0930) | Acc: (96.70%) (11264/11648)\n",
      "Epoch: 59 | Batch_idx: 100 |  Loss: (0.0924) | Acc: (96.71%) (12503/12928)\n",
      "Epoch: 59 | Batch_idx: 110 |  Loss: (0.0927) | Acc: (96.69%) (13738/14208)\n",
      "Epoch: 59 | Batch_idx: 120 |  Loss: (0.0945) | Acc: (96.64%) (14968/15488)\n",
      "Epoch: 59 | Batch_idx: 130 |  Loss: (0.0951) | Acc: (96.63%) (16203/16768)\n",
      "Epoch: 59 | Batch_idx: 140 |  Loss: (0.0968) | Acc: (96.54%) (17423/18048)\n",
      "Epoch: 59 | Batch_idx: 150 |  Loss: (0.0971) | Acc: (96.54%) (18660/19328)\n",
      "Epoch: 59 | Batch_idx: 160 |  Loss: (0.0992) | Acc: (96.44%) (19875/20608)\n",
      "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1003) | Acc: (96.42%) (21104/21888)\n",
      "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1004) | Acc: (96.40%) (22334/23168)\n",
      "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1019) | Acc: (96.35%) (23556/24448)\n",
      "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1036) | Acc: (96.32%) (24780/25728)\n",
      "Epoch: 59 | Batch_idx: 210 |  Loss: (0.1031) | Acc: (96.30%) (26010/27008)\n",
      "Epoch: 59 | Batch_idx: 220 |  Loss: (0.1029) | Acc: (96.32%) (27247/28288)\n",
      "Epoch: 59 | Batch_idx: 230 |  Loss: (0.1033) | Acc: (96.30%) (28475/29568)\n",
      "Epoch: 59 | Batch_idx: 240 |  Loss: (0.1035) | Acc: (96.30%) (29706/30848)\n",
      "Epoch: 59 | Batch_idx: 250 |  Loss: (0.1044) | Acc: (96.28%) (30933/32128)\n",
      "Epoch: 59 | Batch_idx: 260 |  Loss: (0.1046) | Acc: (96.28%) (32166/33408)\n",
      "Epoch: 59 | Batch_idx: 270 |  Loss: (0.1042) | Acc: (96.30%) (33404/34688)\n",
      "Epoch: 59 | Batch_idx: 280 |  Loss: (0.1045) | Acc: (96.29%) (34633/35968)\n",
      "Epoch: 59 | Batch_idx: 290 |  Loss: (0.1054) | Acc: (96.26%) (35856/37248)\n",
      "Epoch: 59 | Batch_idx: 300 |  Loss: (0.1060) | Acc: (96.24%) (37081/38528)\n",
      "Epoch: 59 | Batch_idx: 310 |  Loss: (0.1061) | Acc: (96.25%) (38314/39808)\n",
      "Epoch: 59 | Batch_idx: 320 |  Loss: (0.1054) | Acc: (96.26%) (39553/41088)\n",
      "Epoch: 59 | Batch_idx: 330 |  Loss: (0.1051) | Acc: (96.28%) (40790/42368)\n",
      "Epoch: 59 | Batch_idx: 340 |  Loss: (0.1054) | Acc: (96.26%) (42016/43648)\n",
      "Epoch: 59 | Batch_idx: 350 |  Loss: (0.1054) | Acc: (96.28%) (43256/44928)\n",
      "Epoch: 59 | Batch_idx: 360 |  Loss: (0.1050) | Acc: (96.29%) (44494/46208)\n",
      "Epoch: 59 | Batch_idx: 370 |  Loss: (0.1048) | Acc: (96.31%) (45736/47488)\n",
      "Epoch: 59 | Batch_idx: 380 |  Loss: (0.1051) | Acc: (96.31%) (46967/48768)\n",
      "Epoch: 59 | Batch_idx: 390 |  Loss: (0.1058) | Acc: (96.28%) (48140/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6313) | Acc: (86.47%) (8647/10000)\n",
      "Epoch: 60 | Batch_idx: 0 |  Loss: (0.0854) | Acc: (96.88%) (124/128)\n",
      "Epoch: 60 | Batch_idx: 10 |  Loss: (0.0847) | Acc: (97.30%) (1370/1408)\n",
      "Epoch: 60 | Batch_idx: 20 |  Loss: (0.0872) | Acc: (97.06%) (2609/2688)\n",
      "Epoch: 60 | Batch_idx: 30 |  Loss: (0.0885) | Acc: (97.03%) (3850/3968)\n",
      "Epoch: 60 | Batch_idx: 40 |  Loss: (0.0864) | Acc: (97.14%) (5098/5248)\n",
      "Epoch: 60 | Batch_idx: 50 |  Loss: (0.0843) | Acc: (97.26%) (6349/6528)\n",
      "Epoch: 60 | Batch_idx: 60 |  Loss: (0.0874) | Acc: (97.05%) (7578/7808)\n",
      "Epoch: 60 | Batch_idx: 70 |  Loss: (0.0878) | Acc: (96.97%) (8813/9088)\n",
      "Epoch: 60 | Batch_idx: 80 |  Loss: (0.0881) | Acc: (96.98%) (10055/10368)\n",
      "Epoch: 60 | Batch_idx: 90 |  Loss: (0.0874) | Acc: (97.03%) (11302/11648)\n",
      "Epoch: 60 | Batch_idx: 100 |  Loss: (0.0893) | Acc: (96.98%) (12538/12928)\n",
      "Epoch: 60 | Batch_idx: 110 |  Loss: (0.0900) | Acc: (96.95%) (13774/14208)\n",
      "Epoch: 60 | Batch_idx: 120 |  Loss: (0.0906) | Acc: (96.92%) (15011/15488)\n",
      "Epoch: 60 | Batch_idx: 130 |  Loss: (0.0904) | Acc: (96.91%) (16250/16768)\n",
      "Epoch: 60 | Batch_idx: 140 |  Loss: (0.0902) | Acc: (96.92%) (17493/18048)\n",
      "Epoch: 60 | Batch_idx: 150 |  Loss: (0.0925) | Acc: (96.88%) (18724/19328)\n",
      "Epoch: 60 | Batch_idx: 160 |  Loss: (0.0934) | Acc: (96.85%) (19958/20608)\n",
      "Epoch: 60 | Batch_idx: 170 |  Loss: (0.0932) | Acc: (96.87%) (21202/21888)\n",
      "Epoch: 60 | Batch_idx: 180 |  Loss: (0.0918) | Acc: (96.93%) (22457/23168)\n",
      "Epoch: 60 | Batch_idx: 190 |  Loss: (0.0917) | Acc: (96.91%) (23693/24448)\n",
      "Epoch: 60 | Batch_idx: 200 |  Loss: (0.0912) | Acc: (96.91%) (24933/25728)\n",
      "Epoch: 60 | Batch_idx: 210 |  Loss: (0.0913) | Acc: (96.88%) (26164/27008)\n",
      "Epoch: 60 | Batch_idx: 220 |  Loss: (0.0919) | Acc: (96.86%) (27399/28288)\n",
      "Epoch: 60 | Batch_idx: 230 |  Loss: (0.0916) | Acc: (96.87%) (28642/29568)\n",
      "Epoch: 60 | Batch_idx: 240 |  Loss: (0.0917) | Acc: (96.89%) (29890/30848)\n",
      "Epoch: 60 | Batch_idx: 250 |  Loss: (0.0919) | Acc: (96.88%) (31124/32128)\n",
      "Epoch: 60 | Batch_idx: 260 |  Loss: (0.0921) | Acc: (96.87%) (32362/33408)\n",
      "Epoch: 60 | Batch_idx: 270 |  Loss: (0.0924) | Acc: (96.87%) (33601/34688)\n",
      "Epoch: 60 | Batch_idx: 280 |  Loss: (0.0922) | Acc: (96.86%) (34839/35968)\n",
      "Epoch: 60 | Batch_idx: 290 |  Loss: (0.0926) | Acc: (96.85%) (36073/37248)\n",
      "Epoch: 60 | Batch_idx: 300 |  Loss: (0.0937) | Acc: (96.80%) (37297/38528)\n",
      "Epoch: 60 | Batch_idx: 310 |  Loss: (0.0937) | Acc: (96.80%) (38533/39808)\n",
      "Epoch: 60 | Batch_idx: 320 |  Loss: (0.0938) | Acc: (96.79%) (39768/41088)\n",
      "Epoch: 60 | Batch_idx: 330 |  Loss: (0.0944) | Acc: (96.76%) (40996/42368)\n",
      "Epoch: 60 | Batch_idx: 340 |  Loss: (0.0943) | Acc: (96.76%) (42233/43648)\n",
      "Epoch: 60 | Batch_idx: 350 |  Loss: (0.0945) | Acc: (96.76%) (43472/44928)\n",
      "Epoch: 60 | Batch_idx: 360 |  Loss: (0.0948) | Acc: (96.74%) (44702/46208)\n",
      "Epoch: 60 | Batch_idx: 370 |  Loss: (0.0950) | Acc: (96.73%) (45936/47488)\n",
      "Epoch: 60 | Batch_idx: 380 |  Loss: (0.0951) | Acc: (96.73%) (47171/48768)\n",
      "Epoch: 60 | Batch_idx: 390 |  Loss: (0.0955) | Acc: (96.71%) (48354/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5727) | Acc: (87.45%) (8745/10000)\n",
      "Epoch: 61 | Batch_idx: 0 |  Loss: (0.0513) | Acc: (98.44%) (126/128)\n",
      "Epoch: 61 | Batch_idx: 10 |  Loss: (0.0900) | Acc: (96.88%) (1364/1408)\n",
      "Epoch: 61 | Batch_idx: 20 |  Loss: (0.0918) | Acc: (96.88%) (2604/2688)\n",
      "Epoch: 61 | Batch_idx: 30 |  Loss: (0.0914) | Acc: (96.80%) (3841/3968)\n",
      "Epoch: 61 | Batch_idx: 40 |  Loss: (0.0919) | Acc: (96.80%) (5080/5248)\n",
      "Epoch: 61 | Batch_idx: 50 |  Loss: (0.0943) | Acc: (96.74%) (6315/6528)\n",
      "Epoch: 61 | Batch_idx: 60 |  Loss: (0.0950) | Acc: (96.70%) (7550/7808)\n",
      "Epoch: 61 | Batch_idx: 70 |  Loss: (0.0930) | Acc: (96.75%) (8793/9088)\n",
      "Epoch: 61 | Batch_idx: 80 |  Loss: (0.0950) | Acc: (96.68%) (10024/10368)\n",
      "Epoch: 61 | Batch_idx: 90 |  Loss: (0.0954) | Acc: (96.71%) (11265/11648)\n",
      "Epoch: 61 | Batch_idx: 100 |  Loss: (0.0949) | Acc: (96.67%) (12497/12928)\n",
      "Epoch: 61 | Batch_idx: 110 |  Loss: (0.0952) | Acc: (96.69%) (13738/14208)\n",
      "Epoch: 61 | Batch_idx: 120 |  Loss: (0.0948) | Acc: (96.68%) (14974/15488)\n",
      "Epoch: 61 | Batch_idx: 130 |  Loss: (0.0945) | Acc: (96.66%) (16208/16768)\n",
      "Epoch: 61 | Batch_idx: 140 |  Loss: (0.0953) | Acc: (96.60%) (17435/18048)\n",
      "Epoch: 61 | Batch_idx: 150 |  Loss: (0.0961) | Acc: (96.58%) (18667/19328)\n",
      "Epoch: 61 | Batch_idx: 160 |  Loss: (0.0959) | Acc: (96.60%) (19908/20608)\n",
      "Epoch: 61 | Batch_idx: 170 |  Loss: (0.0953) | Acc: (96.66%) (21158/21888)\n",
      "Epoch: 61 | Batch_idx: 180 |  Loss: (0.0943) | Acc: (96.67%) (22396/23168)\n",
      "Epoch: 61 | Batch_idx: 190 |  Loss: (0.0942) | Acc: (96.68%) (23637/24448)\n",
      "Epoch: 61 | Batch_idx: 200 |  Loss: (0.0936) | Acc: (96.72%) (24885/25728)\n",
      "Epoch: 61 | Batch_idx: 210 |  Loss: (0.0935) | Acc: (96.72%) (26123/27008)\n",
      "Epoch: 61 | Batch_idx: 220 |  Loss: (0.0942) | Acc: (96.67%) (27346/28288)\n",
      "Epoch: 61 | Batch_idx: 230 |  Loss: (0.0942) | Acc: (96.69%) (28588/29568)\n",
      "Epoch: 61 | Batch_idx: 240 |  Loss: (0.0946) | Acc: (96.66%) (29819/30848)\n",
      "Epoch: 61 | Batch_idx: 250 |  Loss: (0.0947) | Acc: (96.66%) (31055/32128)\n",
      "Epoch: 61 | Batch_idx: 260 |  Loss: (0.0948) | Acc: (96.66%) (32293/33408)\n",
      "Epoch: 61 | Batch_idx: 270 |  Loss: (0.0950) | Acc: (96.66%) (33531/34688)\n",
      "Epoch: 61 | Batch_idx: 280 |  Loss: (0.0947) | Acc: (96.68%) (34773/35968)\n",
      "Epoch: 61 | Batch_idx: 290 |  Loss: (0.0946) | Acc: (96.67%) (36009/37248)\n",
      "Epoch: 61 | Batch_idx: 300 |  Loss: (0.0949) | Acc: (96.65%) (37236/38528)\n",
      "Epoch: 61 | Batch_idx: 310 |  Loss: (0.0944) | Acc: (96.67%) (38484/39808)\n",
      "Epoch: 61 | Batch_idx: 320 |  Loss: (0.0941) | Acc: (96.69%) (39727/41088)\n",
      "Epoch: 61 | Batch_idx: 330 |  Loss: (0.0938) | Acc: (96.69%) (40965/42368)\n",
      "Epoch: 61 | Batch_idx: 340 |  Loss: (0.0940) | Acc: (96.68%) (42200/43648)\n",
      "Epoch: 61 | Batch_idx: 350 |  Loss: (0.0943) | Acc: (96.66%) (43428/44928)\n",
      "Epoch: 61 | Batch_idx: 360 |  Loss: (0.0938) | Acc: (96.69%) (44678/46208)\n",
      "Epoch: 61 | Batch_idx: 370 |  Loss: (0.0933) | Acc: (96.71%) (45927/47488)\n",
      "Epoch: 61 | Batch_idx: 380 |  Loss: (0.0931) | Acc: (96.72%) (47170/48768)\n",
      "Epoch: 61 | Batch_idx: 390 |  Loss: (0.0932) | Acc: (96.72%) (48358/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6594) | Acc: (86.43%) (8643/10000)\n",
      "Epoch: 62 | Batch_idx: 0 |  Loss: (0.1401) | Acc: (95.31%) (122/128)\n",
      "Epoch: 62 | Batch_idx: 10 |  Loss: (0.0765) | Acc: (97.66%) (1375/1408)\n",
      "Epoch: 62 | Batch_idx: 20 |  Loss: (0.0794) | Acc: (97.43%) (2619/2688)\n",
      "Epoch: 62 | Batch_idx: 30 |  Loss: (0.0764) | Acc: (97.58%) (3872/3968)\n",
      "Epoch: 62 | Batch_idx: 40 |  Loss: (0.0796) | Acc: (97.48%) (5116/5248)\n",
      "Epoch: 62 | Batch_idx: 50 |  Loss: (0.0860) | Acc: (97.35%) (6355/6528)\n",
      "Epoch: 62 | Batch_idx: 60 |  Loss: (0.0891) | Acc: (97.18%) (7588/7808)\n",
      "Epoch: 62 | Batch_idx: 70 |  Loss: (0.0903) | Acc: (97.08%) (8823/9088)\n",
      "Epoch: 62 | Batch_idx: 80 |  Loss: (0.0895) | Acc: (97.09%) (10066/10368)\n",
      "Epoch: 62 | Batch_idx: 90 |  Loss: (0.0889) | Acc: (97.06%) (11305/11648)\n",
      "Epoch: 62 | Batch_idx: 100 |  Loss: (0.0898) | Acc: (96.99%) (12539/12928)\n",
      "Epoch: 62 | Batch_idx: 110 |  Loss: (0.0895) | Acc: (97.01%) (13783/14208)\n",
      "Epoch: 62 | Batch_idx: 120 |  Loss: (0.0892) | Acc: (97.06%) (15032/15488)\n",
      "Epoch: 62 | Batch_idx: 130 |  Loss: (0.0886) | Acc: (97.08%) (16279/16768)\n",
      "Epoch: 62 | Batch_idx: 140 |  Loss: (0.0882) | Acc: (97.09%) (17522/18048)\n",
      "Epoch: 62 | Batch_idx: 150 |  Loss: (0.0884) | Acc: (97.09%) (18766/19328)\n",
      "Epoch: 62 | Batch_idx: 160 |  Loss: (0.0887) | Acc: (97.09%) (20009/20608)\n",
      "Epoch: 62 | Batch_idx: 170 |  Loss: (0.0897) | Acc: (97.04%) (21241/21888)\n",
      "Epoch: 62 | Batch_idx: 180 |  Loss: (0.0903) | Acc: (97.00%) (22474/23168)\n",
      "Epoch: 62 | Batch_idx: 190 |  Loss: (0.0902) | Acc: (97.02%) (23719/24448)\n",
      "Epoch: 62 | Batch_idx: 200 |  Loss: (0.0910) | Acc: (96.98%) (24952/25728)\n",
      "Epoch: 62 | Batch_idx: 210 |  Loss: (0.0915) | Acc: (96.95%) (26184/27008)\n",
      "Epoch: 62 | Batch_idx: 220 |  Loss: (0.0916) | Acc: (96.93%) (27419/28288)\n",
      "Epoch: 62 | Batch_idx: 230 |  Loss: (0.0917) | Acc: (96.93%) (28661/29568)\n",
      "Epoch: 62 | Batch_idx: 240 |  Loss: (0.0914) | Acc: (96.93%) (29902/30848)\n",
      "Epoch: 62 | Batch_idx: 250 |  Loss: (0.0911) | Acc: (96.96%) (31152/32128)\n",
      "Epoch: 62 | Batch_idx: 260 |  Loss: (0.0915) | Acc: (96.93%) (32381/33408)\n",
      "Epoch: 62 | Batch_idx: 270 |  Loss: (0.0915) | Acc: (96.92%) (33619/34688)\n",
      "Epoch: 62 | Batch_idx: 280 |  Loss: (0.0911) | Acc: (96.93%) (34865/35968)\n",
      "Epoch: 62 | Batch_idx: 290 |  Loss: (0.0912) | Acc: (96.93%) (36103/37248)\n",
      "Epoch: 62 | Batch_idx: 300 |  Loss: (0.0923) | Acc: (96.89%) (37329/38528)\n",
      "Epoch: 62 | Batch_idx: 310 |  Loss: (0.0928) | Acc: (96.88%) (38564/39808)\n",
      "Epoch: 62 | Batch_idx: 320 |  Loss: (0.0932) | Acc: (96.88%) (39804/41088)\n",
      "Epoch: 62 | Batch_idx: 330 |  Loss: (0.0938) | Acc: (96.85%) (41034/42368)\n",
      "Epoch: 62 | Batch_idx: 340 |  Loss: (0.0939) | Acc: (96.85%) (42274/43648)\n",
      "Epoch: 62 | Batch_idx: 350 |  Loss: (0.0938) | Acc: (96.84%) (43510/44928)\n",
      "Epoch: 62 | Batch_idx: 360 |  Loss: (0.0937) | Acc: (96.84%) (44748/46208)\n",
      "Epoch: 62 | Batch_idx: 370 |  Loss: (0.0937) | Acc: (96.83%) (45985/47488)\n",
      "Epoch: 62 | Batch_idx: 380 |  Loss: (0.0940) | Acc: (96.81%) (47214/48768)\n",
      "Epoch: 62 | Batch_idx: 390 |  Loss: (0.0939) | Acc: (96.83%) (48414/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4937) | Acc: (89.16%) (8916/10000)\n",
      "Epoch: 63 | Batch_idx: 0 |  Loss: (0.0415) | Acc: (99.22%) (127/128)\n",
      "Epoch: 63 | Batch_idx: 10 |  Loss: (0.0885) | Acc: (96.80%) (1363/1408)\n",
      "Epoch: 63 | Batch_idx: 20 |  Loss: (0.0844) | Acc: (97.10%) (2610/2688)\n",
      "Epoch: 63 | Batch_idx: 30 |  Loss: (0.0805) | Acc: (97.38%) (3864/3968)\n",
      "Epoch: 63 | Batch_idx: 40 |  Loss: (0.0801) | Acc: (97.45%) (5114/5248)\n",
      "Epoch: 63 | Batch_idx: 50 |  Loss: (0.0824) | Acc: (97.29%) (6351/6528)\n",
      "Epoch: 63 | Batch_idx: 60 |  Loss: (0.0814) | Acc: (97.26%) (7594/7808)\n",
      "Epoch: 63 | Batch_idx: 70 |  Loss: (0.0824) | Acc: (97.16%) (8830/9088)\n",
      "Epoch: 63 | Batch_idx: 80 |  Loss: (0.0840) | Acc: (97.12%) (10069/10368)\n",
      "Epoch: 63 | Batch_idx: 90 |  Loss: (0.0842) | Acc: (97.08%) (11308/11648)\n",
      "Epoch: 63 | Batch_idx: 100 |  Loss: (0.0834) | Acc: (97.16%) (12561/12928)\n",
      "Epoch: 63 | Batch_idx: 110 |  Loss: (0.0834) | Acc: (97.18%) (13808/14208)\n",
      "Epoch: 63 | Batch_idx: 120 |  Loss: (0.0824) | Acc: (97.24%) (15061/15488)\n",
      "Epoch: 63 | Batch_idx: 130 |  Loss: (0.0834) | Acc: (97.19%) (16297/16768)\n",
      "Epoch: 63 | Batch_idx: 140 |  Loss: (0.0828) | Acc: (97.20%) (17543/18048)\n",
      "Epoch: 63 | Batch_idx: 150 |  Loss: (0.0841) | Acc: (97.16%) (18779/19328)\n",
      "Epoch: 63 | Batch_idx: 160 |  Loss: (0.0846) | Acc: (97.13%) (20017/20608)\n",
      "Epoch: 63 | Batch_idx: 170 |  Loss: (0.0853) | Acc: (97.08%) (21248/21888)\n",
      "Epoch: 63 | Batch_idx: 180 |  Loss: (0.0863) | Acc: (97.04%) (22483/23168)\n",
      "Epoch: 63 | Batch_idx: 190 |  Loss: (0.0862) | Acc: (97.03%) (23723/24448)\n",
      "Epoch: 63 | Batch_idx: 200 |  Loss: (0.0863) | Acc: (97.03%) (24964/25728)\n",
      "Epoch: 63 | Batch_idx: 210 |  Loss: (0.0865) | Acc: (97.03%) (26207/27008)\n",
      "Epoch: 63 | Batch_idx: 220 |  Loss: (0.0868) | Acc: (97.04%) (27451/28288)\n",
      "Epoch: 63 | Batch_idx: 230 |  Loss: (0.0872) | Acc: (97.00%) (28682/29568)\n",
      "Epoch: 63 | Batch_idx: 240 |  Loss: (0.0879) | Acc: (96.95%) (29908/30848)\n",
      "Epoch: 63 | Batch_idx: 250 |  Loss: (0.0881) | Acc: (96.97%) (31153/32128)\n",
      "Epoch: 63 | Batch_idx: 260 |  Loss: (0.0881) | Acc: (96.98%) (32398/33408)\n",
      "Epoch: 63 | Batch_idx: 270 |  Loss: (0.0881) | Acc: (96.98%) (33640/34688)\n",
      "Epoch: 63 | Batch_idx: 280 |  Loss: (0.0882) | Acc: (96.96%) (34874/35968)\n",
      "Epoch: 63 | Batch_idx: 290 |  Loss: (0.0883) | Acc: (96.96%) (36115/37248)\n",
      "Epoch: 63 | Batch_idx: 300 |  Loss: (0.0879) | Acc: (96.98%) (37363/38528)\n",
      "Epoch: 63 | Batch_idx: 310 |  Loss: (0.0880) | Acc: (96.98%) (38606/39808)\n",
      "Epoch: 63 | Batch_idx: 320 |  Loss: (0.0881) | Acc: (96.97%) (39843/41088)\n",
      "Epoch: 63 | Batch_idx: 330 |  Loss: (0.0879) | Acc: (96.97%) (41083/42368)\n",
      "Epoch: 63 | Batch_idx: 340 |  Loss: (0.0885) | Acc: (96.95%) (42317/43648)\n",
      "Epoch: 63 | Batch_idx: 350 |  Loss: (0.0892) | Acc: (96.92%) (43545/44928)\n",
      "Epoch: 63 | Batch_idx: 360 |  Loss: (0.0894) | Acc: (96.91%) (44779/46208)\n",
      "Epoch: 63 | Batch_idx: 370 |  Loss: (0.0896) | Acc: (96.89%) (46013/47488)\n",
      "Epoch: 63 | Batch_idx: 380 |  Loss: (0.0897) | Acc: (96.88%) (47245/48768)\n",
      "Epoch: 63 | Batch_idx: 390 |  Loss: (0.0901) | Acc: (96.85%) (48427/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5500) | Acc: (87.06%) (8706/10000)\n",
      "Epoch: 64 | Batch_idx: 0 |  Loss: (0.0941) | Acc: (96.88%) (124/128)\n",
      "Epoch: 64 | Batch_idx: 10 |  Loss: (0.0725) | Acc: (97.59%) (1374/1408)\n",
      "Epoch: 64 | Batch_idx: 20 |  Loss: (0.0701) | Acc: (97.66%) (2625/2688)\n",
      "Epoch: 64 | Batch_idx: 30 |  Loss: (0.0731) | Acc: (97.56%) (3871/3968)\n",
      "Epoch: 64 | Batch_idx: 40 |  Loss: (0.0761) | Acc: (97.47%) (5115/5248)\n",
      "Epoch: 64 | Batch_idx: 50 |  Loss: (0.0778) | Acc: (97.40%) (6358/6528)\n",
      "Epoch: 64 | Batch_idx: 60 |  Loss: (0.0789) | Acc: (97.31%) (7598/7808)\n",
      "Epoch: 64 | Batch_idx: 70 |  Loss: (0.0812) | Acc: (97.21%) (8834/9088)\n",
      "Epoch: 64 | Batch_idx: 80 |  Loss: (0.0832) | Acc: (97.16%) (10074/10368)\n",
      "Epoch: 64 | Batch_idx: 90 |  Loss: (0.0821) | Acc: (97.22%) (11324/11648)\n",
      "Epoch: 64 | Batch_idx: 100 |  Loss: (0.0811) | Acc: (97.26%) (12574/12928)\n",
      "Epoch: 64 | Batch_idx: 110 |  Loss: (0.0815) | Acc: (97.21%) (13811/14208)\n",
      "Epoch: 64 | Batch_idx: 120 |  Loss: (0.0816) | Acc: (97.24%) (15061/15488)\n",
      "Epoch: 64 | Batch_idx: 130 |  Loss: (0.0820) | Acc: (97.19%) (16297/16768)\n",
      "Epoch: 64 | Batch_idx: 140 |  Loss: (0.0818) | Acc: (97.21%) (17544/18048)\n",
      "Epoch: 64 | Batch_idx: 150 |  Loss: (0.0810) | Acc: (97.24%) (18794/19328)\n",
      "Epoch: 64 | Batch_idx: 160 |  Loss: (0.0806) | Acc: (97.24%) (20040/20608)\n",
      "Epoch: 64 | Batch_idx: 170 |  Loss: (0.0804) | Acc: (97.23%) (21282/21888)\n",
      "Epoch: 64 | Batch_idx: 180 |  Loss: (0.0813) | Acc: (97.19%) (22516/23168)\n",
      "Epoch: 64 | Batch_idx: 190 |  Loss: (0.0821) | Acc: (97.12%) (23744/24448)\n",
      "Epoch: 64 | Batch_idx: 200 |  Loss: (0.0824) | Acc: (97.13%) (24990/25728)\n",
      "Epoch: 64 | Batch_idx: 210 |  Loss: (0.0827) | Acc: (97.12%) (26229/27008)\n",
      "Epoch: 64 | Batch_idx: 220 |  Loss: (0.0835) | Acc: (97.08%) (27462/28288)\n",
      "Epoch: 64 | Batch_idx: 230 |  Loss: (0.0835) | Acc: (97.07%) (28703/29568)\n",
      "Epoch: 64 | Batch_idx: 240 |  Loss: (0.0842) | Acc: (97.05%) (29939/30848)\n",
      "Epoch: 64 | Batch_idx: 250 |  Loss: (0.0838) | Acc: (97.07%) (31187/32128)\n",
      "Epoch: 64 | Batch_idx: 260 |  Loss: (0.0845) | Acc: (97.06%) (32426/33408)\n",
      "Epoch: 64 | Batch_idx: 270 |  Loss: (0.0848) | Acc: (97.03%) (33657/34688)\n",
      "Epoch: 64 | Batch_idx: 280 |  Loss: (0.0856) | Acc: (96.98%) (34883/35968)\n",
      "Epoch: 64 | Batch_idx: 290 |  Loss: (0.0859) | Acc: (96.96%) (36116/37248)\n",
      "Epoch: 64 | Batch_idx: 300 |  Loss: (0.0862) | Acc: (96.97%) (37361/38528)\n",
      "Epoch: 64 | Batch_idx: 310 |  Loss: (0.0863) | Acc: (96.97%) (38601/39808)\n",
      "Epoch: 64 | Batch_idx: 320 |  Loss: (0.0860) | Acc: (96.97%) (39843/41088)\n",
      "Epoch: 64 | Batch_idx: 330 |  Loss: (0.0862) | Acc: (96.97%) (41083/42368)\n",
      "Epoch: 64 | Batch_idx: 340 |  Loss: (0.0864) | Acc: (96.96%) (42323/43648)\n",
      "Epoch: 64 | Batch_idx: 350 |  Loss: (0.0864) | Acc: (96.97%) (43568/44928)\n",
      "Epoch: 64 | Batch_idx: 360 |  Loss: (0.0869) | Acc: (96.96%) (44804/46208)\n",
      "Epoch: 64 | Batch_idx: 370 |  Loss: (0.0868) | Acc: (96.97%) (46049/47488)\n",
      "Epoch: 64 | Batch_idx: 380 |  Loss: (0.0874) | Acc: (96.93%) (47273/48768)\n",
      "Epoch: 64 | Batch_idx: 390 |  Loss: (0.0878) | Acc: (96.92%) (48462/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6698) | Acc: (86.71%) (8671/10000)\n",
      "Epoch: 65 | Batch_idx: 0 |  Loss: (0.0656) | Acc: (97.66%) (125/128)\n",
      "Epoch: 65 | Batch_idx: 10 |  Loss: (0.0788) | Acc: (97.16%) (1368/1408)\n",
      "Epoch: 65 | Batch_idx: 20 |  Loss: (0.0810) | Acc: (97.32%) (2616/2688)\n",
      "Epoch: 65 | Batch_idx: 30 |  Loss: (0.0830) | Acc: (97.18%) (3856/3968)\n",
      "Epoch: 65 | Batch_idx: 40 |  Loss: (0.0827) | Acc: (97.08%) (5095/5248)\n",
      "Epoch: 65 | Batch_idx: 50 |  Loss: (0.0869) | Acc: (96.95%) (6329/6528)\n",
      "Epoch: 65 | Batch_idx: 60 |  Loss: (0.0857) | Acc: (97.04%) (7577/7808)\n",
      "Epoch: 65 | Batch_idx: 70 |  Loss: (0.0868) | Acc: (97.08%) (8823/9088)\n",
      "Epoch: 65 | Batch_idx: 80 |  Loss: (0.0878) | Acc: (97.03%) (10060/10368)\n",
      "Epoch: 65 | Batch_idx: 90 |  Loss: (0.0859) | Acc: (97.07%) (11307/11648)\n",
      "Epoch: 65 | Batch_idx: 100 |  Loss: (0.0864) | Acc: (97.05%) (12547/12928)\n",
      "Epoch: 65 | Batch_idx: 110 |  Loss: (0.0856) | Acc: (97.07%) (13791/14208)\n",
      "Epoch: 65 | Batch_idx: 120 |  Loss: (0.0854) | Acc: (97.02%) (15027/15488)\n",
      "Epoch: 65 | Batch_idx: 130 |  Loss: (0.0842) | Acc: (97.05%) (16274/16768)\n",
      "Epoch: 65 | Batch_idx: 140 |  Loss: (0.0840) | Acc: (97.09%) (17522/18048)\n",
      "Epoch: 65 | Batch_idx: 150 |  Loss: (0.0836) | Acc: (97.10%) (18768/19328)\n",
      "Epoch: 65 | Batch_idx: 160 |  Loss: (0.0839) | Acc: (97.12%) (20014/20608)\n",
      "Epoch: 65 | Batch_idx: 170 |  Loss: (0.0847) | Acc: (97.04%) (21241/21888)\n",
      "Epoch: 65 | Batch_idx: 180 |  Loss: (0.0839) | Acc: (97.06%) (22488/23168)\n",
      "Epoch: 65 | Batch_idx: 190 |  Loss: (0.0834) | Acc: (97.06%) (23730/24448)\n",
      "Epoch: 65 | Batch_idx: 200 |  Loss: (0.0830) | Acc: (97.08%) (24976/25728)\n",
      "Epoch: 65 | Batch_idx: 210 |  Loss: (0.0827) | Acc: (97.10%) (26224/27008)\n",
      "Epoch: 65 | Batch_idx: 220 |  Loss: (0.0835) | Acc: (97.08%) (27461/28288)\n",
      "Epoch: 65 | Batch_idx: 230 |  Loss: (0.0837) | Acc: (97.08%) (28705/29568)\n",
      "Epoch: 65 | Batch_idx: 240 |  Loss: (0.0837) | Acc: (97.09%) (29950/30848)\n",
      "Epoch: 65 | Batch_idx: 250 |  Loss: (0.0828) | Acc: (97.13%) (31206/32128)\n",
      "Epoch: 65 | Batch_idx: 260 |  Loss: (0.0825) | Acc: (97.14%) (32453/33408)\n",
      "Epoch: 65 | Batch_idx: 270 |  Loss: (0.0831) | Acc: (97.13%) (33691/34688)\n",
      "Epoch: 65 | Batch_idx: 280 |  Loss: (0.0831) | Acc: (97.12%) (34933/35968)\n",
      "Epoch: 65 | Batch_idx: 290 |  Loss: (0.0834) | Acc: (97.11%) (36173/37248)\n",
      "Epoch: 65 | Batch_idx: 300 |  Loss: (0.0838) | Acc: (97.11%) (37416/38528)\n",
      "Epoch: 65 | Batch_idx: 310 |  Loss: (0.0841) | Acc: (97.10%) (38655/39808)\n",
      "Epoch: 65 | Batch_idx: 320 |  Loss: (0.0839) | Acc: (97.10%) (39896/41088)\n",
      "Epoch: 65 | Batch_idx: 330 |  Loss: (0.0839) | Acc: (97.09%) (41135/42368)\n",
      "Epoch: 65 | Batch_idx: 340 |  Loss: (0.0838) | Acc: (97.09%) (42377/43648)\n",
      "Epoch: 65 | Batch_idx: 350 |  Loss: (0.0835) | Acc: (97.11%) (43628/44928)\n",
      "Epoch: 65 | Batch_idx: 360 |  Loss: (0.0838) | Acc: (97.09%) (44864/46208)\n",
      "Epoch: 65 | Batch_idx: 370 |  Loss: (0.0837) | Acc: (97.10%) (46112/47488)\n",
      "Epoch: 65 | Batch_idx: 380 |  Loss: (0.0840) | Acc: (97.08%) (47346/48768)\n",
      "Epoch: 65 | Batch_idx: 390 |  Loss: (0.0840) | Acc: (97.10%) (48550/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5734) | Acc: (87.89%) (8789/10000)\n",
      "Epoch: 66 | Batch_idx: 0 |  Loss: (0.0962) | Acc: (97.66%) (125/128)\n",
      "Epoch: 66 | Batch_idx: 10 |  Loss: (0.0741) | Acc: (97.44%) (1372/1408)\n",
      "Epoch: 66 | Batch_idx: 20 |  Loss: (0.0681) | Acc: (97.77%) (2628/2688)\n",
      "Epoch: 66 | Batch_idx: 30 |  Loss: (0.0680) | Acc: (97.76%) (3879/3968)\n",
      "Epoch: 66 | Batch_idx: 40 |  Loss: (0.0706) | Acc: (97.71%) (5128/5248)\n",
      "Epoch: 66 | Batch_idx: 50 |  Loss: (0.0725) | Acc: (97.59%) (6371/6528)\n",
      "Epoch: 66 | Batch_idx: 60 |  Loss: (0.0725) | Acc: (97.57%) (7618/7808)\n",
      "Epoch: 66 | Batch_idx: 70 |  Loss: (0.0755) | Acc: (97.47%) (8858/9088)\n",
      "Epoch: 66 | Batch_idx: 80 |  Loss: (0.0756) | Acc: (97.45%) (10104/10368)\n",
      "Epoch: 66 | Batch_idx: 90 |  Loss: (0.0757) | Acc: (97.36%) (11341/11648)\n",
      "Epoch: 66 | Batch_idx: 100 |  Loss: (0.0760) | Acc: (97.32%) (12582/12928)\n",
      "Epoch: 66 | Batch_idx: 110 |  Loss: (0.0758) | Acc: (97.32%) (13827/14208)\n",
      "Epoch: 66 | Batch_idx: 120 |  Loss: (0.0762) | Acc: (97.29%) (15069/15488)\n",
      "Epoch: 66 | Batch_idx: 130 |  Loss: (0.0770) | Acc: (97.27%) (16310/16768)\n",
      "Epoch: 66 | Batch_idx: 140 |  Loss: (0.0760) | Acc: (97.33%) (17566/18048)\n",
      "Epoch: 66 | Batch_idx: 150 |  Loss: (0.0751) | Acc: (97.37%) (18819/19328)\n",
      "Epoch: 66 | Batch_idx: 160 |  Loss: (0.0756) | Acc: (97.37%) (20065/20608)\n",
      "Epoch: 66 | Batch_idx: 170 |  Loss: (0.0761) | Acc: (97.34%) (21306/21888)\n",
      "Epoch: 66 | Batch_idx: 180 |  Loss: (0.0757) | Acc: (97.37%) (22558/23168)\n",
      "Epoch: 66 | Batch_idx: 190 |  Loss: (0.0755) | Acc: (97.37%) (23805/24448)\n",
      "Epoch: 66 | Batch_idx: 200 |  Loss: (0.0751) | Acc: (97.38%) (25054/25728)\n",
      "Epoch: 66 | Batch_idx: 210 |  Loss: (0.0750) | Acc: (97.38%) (26301/27008)\n",
      "Epoch: 66 | Batch_idx: 220 |  Loss: (0.0749) | Acc: (97.40%) (27552/28288)\n",
      "Epoch: 66 | Batch_idx: 230 |  Loss: (0.0748) | Acc: (97.40%) (28800/29568)\n",
      "Epoch: 66 | Batch_idx: 240 |  Loss: (0.0751) | Acc: (97.40%) (30045/30848)\n",
      "Epoch: 66 | Batch_idx: 250 |  Loss: (0.0752) | Acc: (97.39%) (31289/32128)\n",
      "Epoch: 66 | Batch_idx: 260 |  Loss: (0.0769) | Acc: (97.34%) (32520/33408)\n",
      "Epoch: 66 | Batch_idx: 270 |  Loss: (0.0773) | Acc: (97.32%) (33760/34688)\n",
      "Epoch: 66 | Batch_idx: 280 |  Loss: (0.0773) | Acc: (97.31%) (35002/35968)\n",
      "Epoch: 66 | Batch_idx: 290 |  Loss: (0.0770) | Acc: (97.33%) (36255/37248)\n",
      "Epoch: 66 | Batch_idx: 300 |  Loss: (0.0777) | Acc: (97.31%) (37491/38528)\n",
      "Epoch: 66 | Batch_idx: 310 |  Loss: (0.0780) | Acc: (97.29%) (38731/39808)\n",
      "Epoch: 66 | Batch_idx: 320 |  Loss: (0.0784) | Acc: (97.29%) (39975/41088)\n",
      "Epoch: 66 | Batch_idx: 330 |  Loss: (0.0789) | Acc: (97.27%) (41212/42368)\n",
      "Epoch: 66 | Batch_idx: 340 |  Loss: (0.0789) | Acc: (97.27%) (42458/43648)\n",
      "Epoch: 66 | Batch_idx: 350 |  Loss: (0.0791) | Acc: (97.28%) (43704/44928)\n",
      "Epoch: 66 | Batch_idx: 360 |  Loss: (0.0795) | Acc: (97.26%) (44940/46208)\n",
      "Epoch: 66 | Batch_idx: 370 |  Loss: (0.0795) | Acc: (97.27%) (46190/47488)\n",
      "Epoch: 66 | Batch_idx: 380 |  Loss: (0.0793) | Acc: (97.27%) (47435/48768)\n",
      "Epoch: 66 | Batch_idx: 390 |  Loss: (0.0796) | Acc: (97.25%) (48624/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5546) | Acc: (88.28%) (8828/10000)\n",
      "Epoch: 67 | Batch_idx: 0 |  Loss: (0.0611) | Acc: (98.44%) (126/128)\n",
      "Epoch: 67 | Batch_idx: 10 |  Loss: (0.0869) | Acc: (97.44%) (1372/1408)\n",
      "Epoch: 67 | Batch_idx: 20 |  Loss: (0.0868) | Acc: (97.17%) (2612/2688)\n",
      "Epoch: 67 | Batch_idx: 30 |  Loss: (0.0820) | Acc: (97.18%) (3856/3968)\n",
      "Epoch: 67 | Batch_idx: 40 |  Loss: (0.0784) | Acc: (97.31%) (5107/5248)\n",
      "Epoch: 67 | Batch_idx: 50 |  Loss: (0.0761) | Acc: (97.37%) (6356/6528)\n",
      "Epoch: 67 | Batch_idx: 60 |  Loss: (0.0765) | Acc: (97.34%) (7600/7808)\n",
      "Epoch: 67 | Batch_idx: 70 |  Loss: (0.0737) | Acc: (97.41%) (8853/9088)\n",
      "Epoch: 67 | Batch_idx: 80 |  Loss: (0.0724) | Acc: (97.47%) (10106/10368)\n",
      "Epoch: 67 | Batch_idx: 90 |  Loss: (0.0730) | Acc: (97.47%) (11353/11648)\n",
      "Epoch: 67 | Batch_idx: 100 |  Loss: (0.0734) | Acc: (97.47%) (12601/12928)\n",
      "Epoch: 67 | Batch_idx: 110 |  Loss: (0.0739) | Acc: (97.45%) (13846/14208)\n",
      "Epoch: 67 | Batch_idx: 120 |  Loss: (0.0733) | Acc: (97.46%) (15095/15488)\n",
      "Epoch: 67 | Batch_idx: 130 |  Loss: (0.0741) | Acc: (97.39%) (16330/16768)\n",
      "Epoch: 67 | Batch_idx: 140 |  Loss: (0.0754) | Acc: (97.34%) (17568/18048)\n",
      "Epoch: 67 | Batch_idx: 150 |  Loss: (0.0749) | Acc: (97.36%) (18818/19328)\n",
      "Epoch: 67 | Batch_idx: 160 |  Loss: (0.0752) | Acc: (97.38%) (20069/20608)\n",
      "Epoch: 67 | Batch_idx: 170 |  Loss: (0.0743) | Acc: (97.43%) (21326/21888)\n",
      "Epoch: 67 | Batch_idx: 180 |  Loss: (0.0742) | Acc: (97.43%) (22572/23168)\n",
      "Epoch: 67 | Batch_idx: 190 |  Loss: (0.0744) | Acc: (97.43%) (23819/24448)\n",
      "Epoch: 67 | Batch_idx: 200 |  Loss: (0.0759) | Acc: (97.38%) (25054/25728)\n",
      "Epoch: 67 | Batch_idx: 210 |  Loss: (0.0763) | Acc: (97.39%) (26302/27008)\n",
      "Epoch: 67 | Batch_idx: 220 |  Loss: (0.0756) | Acc: (97.43%) (27560/28288)\n",
      "Epoch: 67 | Batch_idx: 230 |  Loss: (0.0755) | Acc: (97.40%) (28800/29568)\n",
      "Epoch: 67 | Batch_idx: 240 |  Loss: (0.0760) | Acc: (97.39%) (30042/30848)\n",
      "Epoch: 67 | Batch_idx: 250 |  Loss: (0.0759) | Acc: (97.38%) (31287/32128)\n",
      "Epoch: 67 | Batch_idx: 260 |  Loss: (0.0762) | Acc: (97.36%) (32527/33408)\n",
      "Epoch: 67 | Batch_idx: 270 |  Loss: (0.0762) | Acc: (97.36%) (33773/34688)\n",
      "Epoch: 67 | Batch_idx: 280 |  Loss: (0.0765) | Acc: (97.35%) (35015/35968)\n",
      "Epoch: 67 | Batch_idx: 290 |  Loss: (0.0767) | Acc: (97.34%) (36257/37248)\n",
      "Epoch: 67 | Batch_idx: 300 |  Loss: (0.0767) | Acc: (97.34%) (37503/38528)\n",
      "Epoch: 67 | Batch_idx: 310 |  Loss: (0.0772) | Acc: (97.32%) (38741/39808)\n",
      "Epoch: 67 | Batch_idx: 320 |  Loss: (0.0775) | Acc: (97.31%) (39982/41088)\n",
      "Epoch: 67 | Batch_idx: 330 |  Loss: (0.0780) | Acc: (97.30%) (41222/42368)\n",
      "Epoch: 67 | Batch_idx: 340 |  Loss: (0.0781) | Acc: (97.30%) (42469/43648)\n",
      "Epoch: 67 | Batch_idx: 350 |  Loss: (0.0784) | Acc: (97.29%) (43711/44928)\n",
      "Epoch: 67 | Batch_idx: 360 |  Loss: (0.0786) | Acc: (97.30%) (44959/46208)\n",
      "Epoch: 67 | Batch_idx: 370 |  Loss: (0.0794) | Acc: (97.27%) (46190/47488)\n",
      "Epoch: 67 | Batch_idx: 380 |  Loss: (0.0791) | Acc: (97.28%) (47440/48768)\n",
      "Epoch: 67 | Batch_idx: 390 |  Loss: (0.0794) | Acc: (97.27%) (48634/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6312) | Acc: (86.96%) (8696/10000)\n",
      "Epoch: 68 | Batch_idx: 0 |  Loss: (0.1406) | Acc: (96.09%) (123/128)\n",
      "Epoch: 68 | Batch_idx: 10 |  Loss: (0.0818) | Acc: (97.30%) (1370/1408)\n",
      "Epoch: 68 | Batch_idx: 20 |  Loss: (0.0708) | Acc: (97.73%) (2627/2688)\n",
      "Epoch: 68 | Batch_idx: 30 |  Loss: (0.0736) | Acc: (97.58%) (3872/3968)\n",
      "Epoch: 68 | Batch_idx: 40 |  Loss: (0.0708) | Acc: (97.75%) (5130/5248)\n",
      "Epoch: 68 | Batch_idx: 50 |  Loss: (0.0712) | Acc: (97.69%) (6377/6528)\n",
      "Epoch: 68 | Batch_idx: 60 |  Loss: (0.0700) | Acc: (97.72%) (7630/7808)\n",
      "Epoch: 68 | Batch_idx: 70 |  Loss: (0.0694) | Acc: (97.74%) (8883/9088)\n",
      "Epoch: 68 | Batch_idx: 80 |  Loss: (0.0688) | Acc: (97.71%) (10131/10368)\n",
      "Epoch: 68 | Batch_idx: 90 |  Loss: (0.0687) | Acc: (97.69%) (11379/11648)\n",
      "Epoch: 68 | Batch_idx: 100 |  Loss: (0.0696) | Acc: (97.64%) (12623/12928)\n",
      "Epoch: 68 | Batch_idx: 110 |  Loss: (0.0694) | Acc: (97.66%) (13876/14208)\n",
      "Epoch: 68 | Batch_idx: 120 |  Loss: (0.0697) | Acc: (97.66%) (15125/15488)\n",
      "Epoch: 68 | Batch_idx: 130 |  Loss: (0.0693) | Acc: (97.69%) (16380/16768)\n",
      "Epoch: 68 | Batch_idx: 140 |  Loss: (0.0695) | Acc: (97.68%) (17629/18048)\n",
      "Epoch: 68 | Batch_idx: 150 |  Loss: (0.0711) | Acc: (97.61%) (18866/19328)\n",
      "Epoch: 68 | Batch_idx: 160 |  Loss: (0.0718) | Acc: (97.58%) (20110/20608)\n",
      "Epoch: 68 | Batch_idx: 170 |  Loss: (0.0719) | Acc: (97.57%) (21356/21888)\n",
      "Epoch: 68 | Batch_idx: 180 |  Loss: (0.0720) | Acc: (97.58%) (22607/23168)\n",
      "Epoch: 68 | Batch_idx: 190 |  Loss: (0.0718) | Acc: (97.59%) (23859/24448)\n",
      "Epoch: 68 | Batch_idx: 200 |  Loss: (0.0721) | Acc: (97.57%) (25104/25728)\n",
      "Epoch: 68 | Batch_idx: 210 |  Loss: (0.0725) | Acc: (97.55%) (26346/27008)\n",
      "Epoch: 68 | Batch_idx: 220 |  Loss: (0.0731) | Acc: (97.51%) (27583/28288)\n",
      "Epoch: 68 | Batch_idx: 230 |  Loss: (0.0731) | Acc: (97.49%) (28827/29568)\n",
      "Epoch: 68 | Batch_idx: 240 |  Loss: (0.0743) | Acc: (97.44%) (30058/30848)\n",
      "Epoch: 68 | Batch_idx: 250 |  Loss: (0.0741) | Acc: (97.42%) (31300/32128)\n",
      "Epoch: 68 | Batch_idx: 260 |  Loss: (0.0747) | Acc: (97.40%) (32538/33408)\n",
      "Epoch: 68 | Batch_idx: 270 |  Loss: (0.0749) | Acc: (97.38%) (33779/34688)\n",
      "Epoch: 68 | Batch_idx: 280 |  Loss: (0.0747) | Acc: (97.41%) (35037/35968)\n",
      "Epoch: 68 | Batch_idx: 290 |  Loss: (0.0749) | Acc: (97.41%) (36285/37248)\n",
      "Epoch: 68 | Batch_idx: 300 |  Loss: (0.0752) | Acc: (97.39%) (37524/38528)\n",
      "Epoch: 68 | Batch_idx: 310 |  Loss: (0.0753) | Acc: (97.40%) (38773/39808)\n",
      "Epoch: 68 | Batch_idx: 320 |  Loss: (0.0753) | Acc: (97.40%) (40021/41088)\n",
      "Epoch: 68 | Batch_idx: 330 |  Loss: (0.0759) | Acc: (97.40%) (41268/42368)\n",
      "Epoch: 68 | Batch_idx: 340 |  Loss: (0.0763) | Acc: (97.38%) (42505/43648)\n",
      "Epoch: 68 | Batch_idx: 350 |  Loss: (0.0762) | Acc: (97.37%) (43748/44928)\n",
      "Epoch: 68 | Batch_idx: 360 |  Loss: (0.0762) | Acc: (97.37%) (44994/46208)\n",
      "Epoch: 68 | Batch_idx: 370 |  Loss: (0.0761) | Acc: (97.38%) (46243/47488)\n",
      "Epoch: 68 | Batch_idx: 380 |  Loss: (0.0766) | Acc: (97.36%) (47480/48768)\n",
      "Epoch: 68 | Batch_idx: 390 |  Loss: (0.0771) | Acc: (97.34%) (48668/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6238) | Acc: (86.89%) (8689/10000)\n",
      "Epoch: 69 | Batch_idx: 0 |  Loss: (0.0278) | Acc: (100.00%) (128/128)\n",
      "Epoch: 69 | Batch_idx: 10 |  Loss: (0.0767) | Acc: (97.73%) (1376/1408)\n",
      "Epoch: 69 | Batch_idx: 20 |  Loss: (0.0740) | Acc: (97.54%) (2622/2688)\n",
      "Epoch: 69 | Batch_idx: 30 |  Loss: (0.0688) | Acc: (97.76%) (3879/3968)\n",
      "Epoch: 69 | Batch_idx: 40 |  Loss: (0.0645) | Acc: (97.83%) (5134/5248)\n",
      "Epoch: 69 | Batch_idx: 50 |  Loss: (0.0664) | Acc: (97.67%) (6376/6528)\n",
      "Epoch: 69 | Batch_idx: 60 |  Loss: (0.0680) | Acc: (97.59%) (7620/7808)\n",
      "Epoch: 69 | Batch_idx: 70 |  Loss: (0.0696) | Acc: (97.55%) (8865/9088)\n",
      "Epoch: 69 | Batch_idx: 80 |  Loss: (0.0703) | Acc: (97.51%) (10110/10368)\n",
      "Epoch: 69 | Batch_idx: 90 |  Loss: (0.0699) | Acc: (97.55%) (11363/11648)\n",
      "Epoch: 69 | Batch_idx: 100 |  Loss: (0.0697) | Acc: (97.61%) (12619/12928)\n",
      "Epoch: 69 | Batch_idx: 110 |  Loss: (0.0703) | Acc: (97.61%) (13869/14208)\n",
      "Epoch: 69 | Batch_idx: 120 |  Loss: (0.0696) | Acc: (97.65%) (15124/15488)\n",
      "Epoch: 69 | Batch_idx: 130 |  Loss: (0.0701) | Acc: (97.60%) (16365/16768)\n",
      "Epoch: 69 | Batch_idx: 140 |  Loss: (0.0710) | Acc: (97.53%) (17603/18048)\n",
      "Epoch: 69 | Batch_idx: 150 |  Loss: (0.0714) | Acc: (97.52%) (18849/19328)\n",
      "Epoch: 69 | Batch_idx: 160 |  Loss: (0.0715) | Acc: (97.53%) (20100/20608)\n",
      "Epoch: 69 | Batch_idx: 170 |  Loss: (0.0718) | Acc: (97.52%) (21346/21888)\n",
      "Epoch: 69 | Batch_idx: 180 |  Loss: (0.0720) | Acc: (97.50%) (22588/23168)\n",
      "Epoch: 69 | Batch_idx: 190 |  Loss: (0.0726) | Acc: (97.50%) (23836/24448)\n",
      "Epoch: 69 | Batch_idx: 200 |  Loss: (0.0724) | Acc: (97.50%) (25085/25728)\n",
      "Epoch: 69 | Batch_idx: 210 |  Loss: (0.0726) | Acc: (97.49%) (26331/27008)\n",
      "Epoch: 69 | Batch_idx: 220 |  Loss: (0.0719) | Acc: (97.52%) (27586/28288)\n",
      "Epoch: 69 | Batch_idx: 230 |  Loss: (0.0718) | Acc: (97.51%) (28832/29568)\n",
      "Epoch: 69 | Batch_idx: 240 |  Loss: (0.0717) | Acc: (97.51%) (30080/30848)\n",
      "Epoch: 69 | Batch_idx: 250 |  Loss: (0.0720) | Acc: (97.50%) (31325/32128)\n",
      "Epoch: 69 | Batch_idx: 260 |  Loss: (0.0720) | Acc: (97.50%) (32573/33408)\n",
      "Epoch: 69 | Batch_idx: 270 |  Loss: (0.0722) | Acc: (97.48%) (33815/34688)\n",
      "Epoch: 69 | Batch_idx: 280 |  Loss: (0.0729) | Acc: (97.45%) (35051/35968)\n",
      "Epoch: 69 | Batch_idx: 290 |  Loss: (0.0726) | Acc: (97.46%) (36303/37248)\n",
      "Epoch: 69 | Batch_idx: 300 |  Loss: (0.0727) | Acc: (97.44%) (37541/38528)\n",
      "Epoch: 69 | Batch_idx: 310 |  Loss: (0.0727) | Acc: (97.44%) (38788/39808)\n",
      "Epoch: 69 | Batch_idx: 320 |  Loss: (0.0733) | Acc: (97.43%) (40033/41088)\n",
      "Epoch: 69 | Batch_idx: 330 |  Loss: (0.0739) | Acc: (97.42%) (41274/42368)\n",
      "Epoch: 69 | Batch_idx: 340 |  Loss: (0.0740) | Acc: (97.42%) (42522/43648)\n",
      "Epoch: 69 | Batch_idx: 350 |  Loss: (0.0744) | Acc: (97.40%) (43759/44928)\n",
      "Epoch: 69 | Batch_idx: 360 |  Loss: (0.0746) | Acc: (97.40%) (45008/46208)\n",
      "Epoch: 69 | Batch_idx: 370 |  Loss: (0.0749) | Acc: (97.39%) (46248/47488)\n",
      "Epoch: 69 | Batch_idx: 380 |  Loss: (0.0751) | Acc: (97.39%) (47493/48768)\n",
      "Epoch: 69 | Batch_idx: 390 |  Loss: (0.0753) | Acc: (97.38%) (48690/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5972) | Acc: (88.09%) (8809/10000)\n",
      "Epoch: 70 | Batch_idx: 0 |  Loss: (0.0993) | Acc: (96.88%) (124/128)\n",
      "Epoch: 70 | Batch_idx: 10 |  Loss: (0.0569) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 70 | Batch_idx: 20 |  Loss: (0.0646) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 70 | Batch_idx: 30 |  Loss: (0.0607) | Acc: (98.11%) (3893/3968)\n",
      "Epoch: 70 | Batch_idx: 40 |  Loss: (0.0649) | Acc: (97.96%) (5141/5248)\n",
      "Epoch: 70 | Batch_idx: 50 |  Loss: (0.0689) | Acc: (97.76%) (6382/6528)\n",
      "Epoch: 70 | Batch_idx: 60 |  Loss: (0.0719) | Acc: (97.68%) (7627/7808)\n",
      "Epoch: 70 | Batch_idx: 70 |  Loss: (0.0718) | Acc: (97.73%) (8882/9088)\n",
      "Epoch: 70 | Batch_idx: 80 |  Loss: (0.0731) | Acc: (97.69%) (10128/10368)\n",
      "Epoch: 70 | Batch_idx: 90 |  Loss: (0.0726) | Acc: (97.70%) (11380/11648)\n",
      "Epoch: 70 | Batch_idx: 100 |  Loss: (0.0720) | Acc: (97.73%) (12635/12928)\n",
      "Epoch: 70 | Batch_idx: 110 |  Loss: (0.0714) | Acc: (97.69%) (13880/14208)\n",
      "Epoch: 70 | Batch_idx: 120 |  Loss: (0.0710) | Acc: (97.69%) (15130/15488)\n",
      "Epoch: 70 | Batch_idx: 130 |  Loss: (0.0697) | Acc: (97.73%) (16387/16768)\n",
      "Epoch: 70 | Batch_idx: 140 |  Loss: (0.0702) | Acc: (97.69%) (17631/18048)\n",
      "Epoch: 70 | Batch_idx: 150 |  Loss: (0.0709) | Acc: (97.65%) (18873/19328)\n",
      "Epoch: 70 | Batch_idx: 160 |  Loss: (0.0699) | Acc: (97.68%) (20130/20608)\n",
      "Epoch: 70 | Batch_idx: 170 |  Loss: (0.0709) | Acc: (97.62%) (21366/21888)\n",
      "Epoch: 70 | Batch_idx: 180 |  Loss: (0.0711) | Acc: (97.61%) (22614/23168)\n",
      "Epoch: 70 | Batch_idx: 190 |  Loss: (0.0712) | Acc: (97.60%) (23862/24448)\n",
      "Epoch: 70 | Batch_idx: 200 |  Loss: (0.0712) | Acc: (97.58%) (25105/25728)\n",
      "Epoch: 70 | Batch_idx: 210 |  Loss: (0.0712) | Acc: (97.59%) (26356/27008)\n",
      "Epoch: 70 | Batch_idx: 220 |  Loss: (0.0710) | Acc: (97.58%) (27604/28288)\n",
      "Epoch: 70 | Batch_idx: 230 |  Loss: (0.0704) | Acc: (97.63%) (28867/29568)\n",
      "Epoch: 70 | Batch_idx: 240 |  Loss: (0.0713) | Acc: (97.58%) (30103/30848)\n",
      "Epoch: 70 | Batch_idx: 250 |  Loss: (0.0722) | Acc: (97.53%) (31335/32128)\n",
      "Epoch: 70 | Batch_idx: 260 |  Loss: (0.0719) | Acc: (97.54%) (32587/33408)\n",
      "Epoch: 70 | Batch_idx: 270 |  Loss: (0.0721) | Acc: (97.53%) (33832/34688)\n",
      "Epoch: 70 | Batch_idx: 280 |  Loss: (0.0723) | Acc: (97.53%) (35078/35968)\n",
      "Epoch: 70 | Batch_idx: 290 |  Loss: (0.0720) | Acc: (97.54%) (36333/37248)\n",
      "Epoch: 70 | Batch_idx: 300 |  Loss: (0.0726) | Acc: (97.52%) (37573/38528)\n",
      "Epoch: 70 | Batch_idx: 310 |  Loss: (0.0728) | Acc: (97.51%) (38817/39808)\n",
      "Epoch: 70 | Batch_idx: 320 |  Loss: (0.0729) | Acc: (97.51%) (40065/41088)\n",
      "Epoch: 70 | Batch_idx: 330 |  Loss: (0.0732) | Acc: (97.50%) (41308/42368)\n",
      "Epoch: 70 | Batch_idx: 340 |  Loss: (0.0728) | Acc: (97.51%) (42560/43648)\n",
      "Epoch: 70 | Batch_idx: 350 |  Loss: (0.0728) | Acc: (97.50%) (43804/44928)\n",
      "Epoch: 70 | Batch_idx: 360 |  Loss: (0.0725) | Acc: (97.51%) (45057/46208)\n",
      "Epoch: 70 | Batch_idx: 370 |  Loss: (0.0723) | Acc: (97.52%) (46308/47488)\n",
      "Epoch: 70 | Batch_idx: 380 |  Loss: (0.0728) | Acc: (97.50%) (47548/48768)\n",
      "Epoch: 70 | Batch_idx: 390 |  Loss: (0.0736) | Acc: (97.46%) (48729/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5802) | Acc: (88.29%) (8829/10000)\n",
      "Epoch: 71 | Batch_idx: 0 |  Loss: (0.1018) | Acc: (96.88%) (124/128)\n",
      "Epoch: 71 | Batch_idx: 10 |  Loss: (0.0872) | Acc: (97.02%) (1366/1408)\n",
      "Epoch: 71 | Batch_idx: 20 |  Loss: (0.0827) | Acc: (96.99%) (2607/2688)\n",
      "Epoch: 71 | Batch_idx: 30 |  Loss: (0.0773) | Acc: (97.33%) (3862/3968)\n",
      "Epoch: 71 | Batch_idx: 40 |  Loss: (0.0799) | Acc: (97.28%) (5105/5248)\n",
      "Epoch: 71 | Batch_idx: 50 |  Loss: (0.0801) | Acc: (97.32%) (6353/6528)\n",
      "Epoch: 71 | Batch_idx: 60 |  Loss: (0.0773) | Acc: (97.37%) (7603/7808)\n",
      "Epoch: 71 | Batch_idx: 70 |  Loss: (0.0761) | Acc: (97.39%) (8851/9088)\n",
      "Epoch: 71 | Batch_idx: 80 |  Loss: (0.0750) | Acc: (97.44%) (10103/10368)\n",
      "Epoch: 71 | Batch_idx: 90 |  Loss: (0.0750) | Acc: (97.50%) (11357/11648)\n",
      "Epoch: 71 | Batch_idx: 100 |  Loss: (0.0746) | Acc: (97.52%) (12607/12928)\n",
      "Epoch: 71 | Batch_idx: 110 |  Loss: (0.0730) | Acc: (97.56%) (13862/14208)\n",
      "Epoch: 71 | Batch_idx: 120 |  Loss: (0.0723) | Acc: (97.57%) (15112/15488)\n",
      "Epoch: 71 | Batch_idx: 130 |  Loss: (0.0725) | Acc: (97.57%) (16361/16768)\n",
      "Epoch: 71 | Batch_idx: 140 |  Loss: (0.0727) | Acc: (97.52%) (17600/18048)\n",
      "Epoch: 71 | Batch_idx: 150 |  Loss: (0.0741) | Acc: (97.44%) (18833/19328)\n",
      "Epoch: 71 | Batch_idx: 160 |  Loss: (0.0747) | Acc: (97.42%) (20077/20608)\n",
      "Epoch: 71 | Batch_idx: 170 |  Loss: (0.0758) | Acc: (97.38%) (21315/21888)\n",
      "Epoch: 71 | Batch_idx: 180 |  Loss: (0.0758) | Acc: (97.38%) (22560/23168)\n",
      "Epoch: 71 | Batch_idx: 190 |  Loss: (0.0757) | Acc: (97.36%) (23803/24448)\n",
      "Epoch: 71 | Batch_idx: 200 |  Loss: (0.0761) | Acc: (97.34%) (25044/25728)\n",
      "Epoch: 71 | Batch_idx: 210 |  Loss: (0.0762) | Acc: (97.33%) (26288/27008)\n",
      "Epoch: 71 | Batch_idx: 220 |  Loss: (0.0756) | Acc: (97.35%) (27538/28288)\n",
      "Epoch: 71 | Batch_idx: 230 |  Loss: (0.0748) | Acc: (97.39%) (28795/29568)\n",
      "Epoch: 71 | Batch_idx: 240 |  Loss: (0.0739) | Acc: (97.43%) (30054/30848)\n",
      "Epoch: 71 | Batch_idx: 250 |  Loss: (0.0737) | Acc: (97.44%) (31307/32128)\n",
      "Epoch: 71 | Batch_idx: 260 |  Loss: (0.0739) | Acc: (97.44%) (32552/33408)\n",
      "Epoch: 71 | Batch_idx: 270 |  Loss: (0.0738) | Acc: (97.45%) (33803/34688)\n",
      "Epoch: 71 | Batch_idx: 280 |  Loss: (0.0733) | Acc: (97.47%) (35059/35968)\n",
      "Epoch: 71 | Batch_idx: 290 |  Loss: (0.0732) | Acc: (97.48%) (36311/37248)\n",
      "Epoch: 71 | Batch_idx: 300 |  Loss: (0.0726) | Acc: (97.51%) (37569/38528)\n",
      "Epoch: 71 | Batch_idx: 310 |  Loss: (0.0728) | Acc: (97.49%) (38807/39808)\n",
      "Epoch: 71 | Batch_idx: 320 |  Loss: (0.0728) | Acc: (97.48%) (40052/41088)\n",
      "Epoch: 71 | Batch_idx: 330 |  Loss: (0.0729) | Acc: (97.46%) (41293/42368)\n",
      "Epoch: 71 | Batch_idx: 340 |  Loss: (0.0730) | Acc: (97.46%) (42540/43648)\n",
      "Epoch: 71 | Batch_idx: 350 |  Loss: (0.0729) | Acc: (97.47%) (43791/44928)\n",
      "Epoch: 71 | Batch_idx: 360 |  Loss: (0.0731) | Acc: (97.46%) (45035/46208)\n",
      "Epoch: 71 | Batch_idx: 370 |  Loss: (0.0733) | Acc: (97.45%) (46276/47488)\n",
      "Epoch: 71 | Batch_idx: 380 |  Loss: (0.0735) | Acc: (97.43%) (47517/48768)\n",
      "Epoch: 71 | Batch_idx: 390 |  Loss: (0.0738) | Acc: (97.43%) (48716/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7293) | Acc: (86.73%) (8673/10000)\n",
      "Epoch: 72 | Batch_idx: 0 |  Loss: (0.0531) | Acc: (97.66%) (125/128)\n",
      "Epoch: 72 | Batch_idx: 10 |  Loss: (0.0485) | Acc: (98.58%) (1388/1408)\n",
      "Epoch: 72 | Batch_idx: 20 |  Loss: (0.0603) | Acc: (98.07%) (2636/2688)\n",
      "Epoch: 72 | Batch_idx: 30 |  Loss: (0.0633) | Acc: (97.86%) (3883/3968)\n",
      "Epoch: 72 | Batch_idx: 40 |  Loss: (0.0633) | Acc: (97.90%) (5138/5248)\n",
      "Epoch: 72 | Batch_idx: 50 |  Loss: (0.0658) | Acc: (97.79%) (6384/6528)\n",
      "Epoch: 72 | Batch_idx: 60 |  Loss: (0.0664) | Acc: (97.78%) (7635/7808)\n",
      "Epoch: 72 | Batch_idx: 70 |  Loss: (0.0669) | Acc: (97.80%) (8888/9088)\n",
      "Epoch: 72 | Batch_idx: 80 |  Loss: (0.0672) | Acc: (97.71%) (10131/10368)\n",
      "Epoch: 72 | Batch_idx: 90 |  Loss: (0.0676) | Acc: (97.64%) (11373/11648)\n",
      "Epoch: 72 | Batch_idx: 100 |  Loss: (0.0681) | Acc: (97.59%) (12617/12928)\n",
      "Epoch: 72 | Batch_idx: 110 |  Loss: (0.0675) | Acc: (97.62%) (13870/14208)\n",
      "Epoch: 72 | Batch_idx: 120 |  Loss: (0.0685) | Acc: (97.57%) (15111/15488)\n",
      "Epoch: 72 | Batch_idx: 130 |  Loss: (0.0677) | Acc: (97.59%) (16364/16768)\n",
      "Epoch: 72 | Batch_idx: 140 |  Loss: (0.0676) | Acc: (97.60%) (17615/18048)\n",
      "Epoch: 72 | Batch_idx: 150 |  Loss: (0.0684) | Acc: (97.58%) (18861/19328)\n",
      "Epoch: 72 | Batch_idx: 160 |  Loss: (0.0682) | Acc: (97.60%) (20113/20608)\n",
      "Epoch: 72 | Batch_idx: 170 |  Loss: (0.0682) | Acc: (97.62%) (21367/21888)\n",
      "Epoch: 72 | Batch_idx: 180 |  Loss: (0.0689) | Acc: (97.59%) (22610/23168)\n",
      "Epoch: 72 | Batch_idx: 190 |  Loss: (0.0689) | Acc: (97.61%) (23864/24448)\n",
      "Epoch: 72 | Batch_idx: 200 |  Loss: (0.0682) | Acc: (97.64%) (25120/25728)\n",
      "Epoch: 72 | Batch_idx: 210 |  Loss: (0.0677) | Acc: (97.65%) (26373/27008)\n",
      "Epoch: 72 | Batch_idx: 220 |  Loss: (0.0677) | Acc: (97.67%) (27630/28288)\n",
      "Epoch: 72 | Batch_idx: 230 |  Loss: (0.0673) | Acc: (97.69%) (28884/29568)\n",
      "Epoch: 72 | Batch_idx: 240 |  Loss: (0.0672) | Acc: (97.69%) (30136/30848)\n",
      "Epoch: 72 | Batch_idx: 250 |  Loss: (0.0672) | Acc: (97.70%) (31389/32128)\n",
      "Epoch: 72 | Batch_idx: 260 |  Loss: (0.0674) | Acc: (97.69%) (32635/33408)\n",
      "Epoch: 72 | Batch_idx: 270 |  Loss: (0.0675) | Acc: (97.69%) (33885/34688)\n",
      "Epoch: 72 | Batch_idx: 280 |  Loss: (0.0674) | Acc: (97.67%) (35131/35968)\n",
      "Epoch: 72 | Batch_idx: 290 |  Loss: (0.0674) | Acc: (97.67%) (36381/37248)\n",
      "Epoch: 72 | Batch_idx: 300 |  Loss: (0.0673) | Acc: (97.69%) (37637/38528)\n",
      "Epoch: 72 | Batch_idx: 310 |  Loss: (0.0680) | Acc: (97.67%) (38879/39808)\n",
      "Epoch: 72 | Batch_idx: 320 |  Loss: (0.0674) | Acc: (97.70%) (40142/41088)\n",
      "Epoch: 72 | Batch_idx: 330 |  Loss: (0.0678) | Acc: (97.68%) (41385/42368)\n",
      "Epoch: 72 | Batch_idx: 340 |  Loss: (0.0682) | Acc: (97.66%) (42626/43648)\n",
      "Epoch: 72 | Batch_idx: 350 |  Loss: (0.0687) | Acc: (97.64%) (43867/44928)\n",
      "Epoch: 72 | Batch_idx: 360 |  Loss: (0.0688) | Acc: (97.64%) (45117/46208)\n",
      "Epoch: 72 | Batch_idx: 370 |  Loss: (0.0686) | Acc: (97.65%) (46371/47488)\n",
      "Epoch: 72 | Batch_idx: 380 |  Loss: (0.0688) | Acc: (97.64%) (47619/48768)\n",
      "Epoch: 72 | Batch_idx: 390 |  Loss: (0.0688) | Acc: (97.64%) (48820/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7126) | Acc: (87.13%) (8713/10000)\n",
      "Epoch: 73 | Batch_idx: 0 |  Loss: (0.0460) | Acc: (99.22%) (127/128)\n",
      "Epoch: 73 | Batch_idx: 10 |  Loss: (0.0717) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 73 | Batch_idx: 20 |  Loss: (0.0736) | Acc: (97.81%) (2629/2688)\n",
      "Epoch: 73 | Batch_idx: 30 |  Loss: (0.0709) | Acc: (97.83%) (3882/3968)\n",
      "Epoch: 73 | Batch_idx: 40 |  Loss: (0.0681) | Acc: (97.85%) (5135/5248)\n",
      "Epoch: 73 | Batch_idx: 50 |  Loss: (0.0686) | Acc: (97.78%) (6383/6528)\n",
      "Epoch: 73 | Batch_idx: 60 |  Loss: (0.0665) | Acc: (97.82%) (7638/7808)\n",
      "Epoch: 73 | Batch_idx: 70 |  Loss: (0.0655) | Acc: (97.87%) (8894/9088)\n",
      "Epoch: 73 | Batch_idx: 80 |  Loss: (0.0651) | Acc: (97.88%) (10148/10368)\n",
      "Epoch: 73 | Batch_idx: 90 |  Loss: (0.0658) | Acc: (97.79%) (11390/11648)\n",
      "Epoch: 73 | Batch_idx: 100 |  Loss: (0.0656) | Acc: (97.76%) (12639/12928)\n",
      "Epoch: 73 | Batch_idx: 110 |  Loss: (0.0654) | Acc: (97.78%) (13893/14208)\n",
      "Epoch: 73 | Batch_idx: 120 |  Loss: (0.0663) | Acc: (97.76%) (15141/15488)\n",
      "Epoch: 73 | Batch_idx: 130 |  Loss: (0.0656) | Acc: (97.78%) (16396/16768)\n",
      "Epoch: 73 | Batch_idx: 140 |  Loss: (0.0660) | Acc: (97.74%) (17641/18048)\n",
      "Epoch: 73 | Batch_idx: 150 |  Loss: (0.0664) | Acc: (97.72%) (18887/19328)\n",
      "Epoch: 73 | Batch_idx: 160 |  Loss: (0.0676) | Acc: (97.66%) (20126/20608)\n",
      "Epoch: 73 | Batch_idx: 170 |  Loss: (0.0671) | Acc: (97.67%) (21377/21888)\n",
      "Epoch: 73 | Batch_idx: 180 |  Loss: (0.0674) | Acc: (97.66%) (22627/23168)\n",
      "Epoch: 73 | Batch_idx: 190 |  Loss: (0.0668) | Acc: (97.69%) (23884/24448)\n",
      "Epoch: 73 | Batch_idx: 200 |  Loss: (0.0673) | Acc: (97.66%) (25125/25728)\n",
      "Epoch: 73 | Batch_idx: 210 |  Loss: (0.0663) | Acc: (97.71%) (26389/27008)\n",
      "Epoch: 73 | Batch_idx: 220 |  Loss: (0.0665) | Acc: (97.71%) (27639/28288)\n",
      "Epoch: 73 | Batch_idx: 230 |  Loss: (0.0660) | Acc: (97.72%) (28893/29568)\n",
      "Epoch: 73 | Batch_idx: 240 |  Loss: (0.0661) | Acc: (97.71%) (30142/30848)\n",
      "Epoch: 73 | Batch_idx: 250 |  Loss: (0.0664) | Acc: (97.72%) (31396/32128)\n",
      "Epoch: 73 | Batch_idx: 260 |  Loss: (0.0666) | Acc: (97.70%) (32641/33408)\n",
      "Epoch: 73 | Batch_idx: 270 |  Loss: (0.0669) | Acc: (97.70%) (33891/34688)\n",
      "Epoch: 73 | Batch_idx: 280 |  Loss: (0.0670) | Acc: (97.71%) (35144/35968)\n",
      "Epoch: 73 | Batch_idx: 290 |  Loss: (0.0669) | Acc: (97.72%) (36397/37248)\n",
      "Epoch: 73 | Batch_idx: 300 |  Loss: (0.0670) | Acc: (97.71%) (37646/38528)\n",
      "Epoch: 73 | Batch_idx: 310 |  Loss: (0.0670) | Acc: (97.72%) (38899/39808)\n",
      "Epoch: 73 | Batch_idx: 320 |  Loss: (0.0665) | Acc: (97.73%) (40156/41088)\n",
      "Epoch: 73 | Batch_idx: 330 |  Loss: (0.0668) | Acc: (97.72%) (41402/42368)\n",
      "Epoch: 73 | Batch_idx: 340 |  Loss: (0.0664) | Acc: (97.73%) (42659/43648)\n",
      "Epoch: 73 | Batch_idx: 350 |  Loss: (0.0662) | Acc: (97.74%) (43911/44928)\n",
      "Epoch: 73 | Batch_idx: 360 |  Loss: (0.0664) | Acc: (97.72%) (45154/46208)\n",
      "Epoch: 73 | Batch_idx: 370 |  Loss: (0.0667) | Acc: (97.70%) (46394/47488)\n",
      "Epoch: 73 | Batch_idx: 380 |  Loss: (0.0667) | Acc: (97.70%) (47646/48768)\n",
      "Epoch: 73 | Batch_idx: 390 |  Loss: (0.0667) | Acc: (97.70%) (48852/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6054) | Acc: (88.50%) (8850/10000)\n",
      "Epoch: 74 | Batch_idx: 0 |  Loss: (0.0552) | Acc: (97.66%) (125/128)\n",
      "Epoch: 74 | Batch_idx: 10 |  Loss: (0.0724) | Acc: (97.44%) (1372/1408)\n",
      "Epoch: 74 | Batch_idx: 20 |  Loss: (0.0682) | Acc: (97.54%) (2622/2688)\n",
      "Epoch: 74 | Batch_idx: 30 |  Loss: (0.0708) | Acc: (97.56%) (3871/3968)\n",
      "Epoch: 74 | Batch_idx: 40 |  Loss: (0.0702) | Acc: (97.56%) (5120/5248)\n",
      "Epoch: 74 | Batch_idx: 50 |  Loss: (0.0719) | Acc: (97.58%) (6370/6528)\n",
      "Epoch: 74 | Batch_idx: 60 |  Loss: (0.0711) | Acc: (97.59%) (7620/7808)\n",
      "Epoch: 74 | Batch_idx: 70 |  Loss: (0.0690) | Acc: (97.62%) (8872/9088)\n",
      "Epoch: 74 | Batch_idx: 80 |  Loss: (0.0668) | Acc: (97.71%) (10131/10368)\n",
      "Epoch: 74 | Batch_idx: 90 |  Loss: (0.0662) | Acc: (97.70%) (11380/11648)\n",
      "Epoch: 74 | Batch_idx: 100 |  Loss: (0.0656) | Acc: (97.68%) (12628/12928)\n",
      "Epoch: 74 | Batch_idx: 110 |  Loss: (0.0670) | Acc: (97.61%) (13869/14208)\n",
      "Epoch: 74 | Batch_idx: 120 |  Loss: (0.0658) | Acc: (97.67%) (15127/15488)\n",
      "Epoch: 74 | Batch_idx: 130 |  Loss: (0.0653) | Acc: (97.71%) (16384/16768)\n",
      "Epoch: 74 | Batch_idx: 140 |  Loss: (0.0648) | Acc: (97.73%) (17639/18048)\n",
      "Epoch: 74 | Batch_idx: 150 |  Loss: (0.0643) | Acc: (97.77%) (18897/19328)\n",
      "Epoch: 74 | Batch_idx: 160 |  Loss: (0.0644) | Acc: (97.76%) (20146/20608)\n",
      "Epoch: 74 | Batch_idx: 170 |  Loss: (0.0635) | Acc: (97.78%) (21401/21888)\n",
      "Epoch: 74 | Batch_idx: 180 |  Loss: (0.0634) | Acc: (97.79%) (22655/23168)\n",
      "Epoch: 74 | Batch_idx: 190 |  Loss: (0.0636) | Acc: (97.80%) (23911/24448)\n",
      "Epoch: 74 | Batch_idx: 200 |  Loss: (0.0630) | Acc: (97.82%) (25166/25728)\n",
      "Epoch: 74 | Batch_idx: 210 |  Loss: (0.0625) | Acc: (97.83%) (26423/27008)\n",
      "Epoch: 74 | Batch_idx: 220 |  Loss: (0.0633) | Acc: (97.81%) (27669/28288)\n",
      "Epoch: 74 | Batch_idx: 230 |  Loss: (0.0638) | Acc: (97.80%) (28918/29568)\n",
      "Epoch: 74 | Batch_idx: 240 |  Loss: (0.0641) | Acc: (97.79%) (30165/30848)\n",
      "Epoch: 74 | Batch_idx: 250 |  Loss: (0.0653) | Acc: (97.75%) (31405/32128)\n",
      "Epoch: 74 | Batch_idx: 260 |  Loss: (0.0658) | Acc: (97.73%) (32651/33408)\n",
      "Epoch: 74 | Batch_idx: 270 |  Loss: (0.0663) | Acc: (97.71%) (33893/34688)\n",
      "Epoch: 74 | Batch_idx: 280 |  Loss: (0.0667) | Acc: (97.69%) (35138/35968)\n",
      "Epoch: 74 | Batch_idx: 290 |  Loss: (0.0666) | Acc: (97.70%) (36390/37248)\n",
      "Epoch: 74 | Batch_idx: 300 |  Loss: (0.0666) | Acc: (97.70%) (37642/38528)\n",
      "Epoch: 74 | Batch_idx: 310 |  Loss: (0.0662) | Acc: (97.72%) (38899/39808)\n",
      "Epoch: 74 | Batch_idx: 320 |  Loss: (0.0665) | Acc: (97.70%) (40145/41088)\n",
      "Epoch: 74 | Batch_idx: 330 |  Loss: (0.0665) | Acc: (97.69%) (41391/42368)\n",
      "Epoch: 74 | Batch_idx: 340 |  Loss: (0.0666) | Acc: (97.69%) (42641/43648)\n",
      "Epoch: 74 | Batch_idx: 350 |  Loss: (0.0664) | Acc: (97.69%) (43891/44928)\n",
      "Epoch: 74 | Batch_idx: 360 |  Loss: (0.0661) | Acc: (97.71%) (45151/46208)\n",
      "Epoch: 74 | Batch_idx: 370 |  Loss: (0.0660) | Acc: (97.72%) (46406/47488)\n",
      "Epoch: 74 | Batch_idx: 380 |  Loss: (0.0658) | Acc: (97.73%) (47660/48768)\n",
      "Epoch: 74 | Batch_idx: 390 |  Loss: (0.0659) | Acc: (97.72%) (48862/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6225) | Acc: (88.58%) (8858/10000)\n",
      "Epoch: 75 | Batch_idx: 0 |  Loss: (0.0452) | Acc: (98.44%) (126/128)\n",
      "Epoch: 75 | Batch_idx: 10 |  Loss: (0.0635) | Acc: (97.87%) (1378/1408)\n",
      "Epoch: 75 | Batch_idx: 20 |  Loss: (0.0589) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 75 | Batch_idx: 30 |  Loss: (0.0654) | Acc: (97.78%) (3880/3968)\n",
      "Epoch: 75 | Batch_idx: 40 |  Loss: (0.0659) | Acc: (97.71%) (5128/5248)\n",
      "Epoch: 75 | Batch_idx: 50 |  Loss: (0.0604) | Acc: (97.92%) (6392/6528)\n",
      "Epoch: 75 | Batch_idx: 60 |  Loss: (0.0607) | Acc: (97.93%) (7646/7808)\n",
      "Epoch: 75 | Batch_idx: 70 |  Loss: (0.0606) | Acc: (97.95%) (8902/9088)\n",
      "Epoch: 75 | Batch_idx: 80 |  Loss: (0.0590) | Acc: (98.02%) (10163/10368)\n",
      "Epoch: 75 | Batch_idx: 90 |  Loss: (0.0581) | Acc: (98.06%) (11422/11648)\n",
      "Epoch: 75 | Batch_idx: 100 |  Loss: (0.0583) | Acc: (98.06%) (12677/12928)\n",
      "Epoch: 75 | Batch_idx: 110 |  Loss: (0.0585) | Acc: (98.05%) (13931/14208)\n",
      "Epoch: 75 | Batch_idx: 120 |  Loss: (0.0585) | Acc: (98.06%) (15188/15488)\n",
      "Epoch: 75 | Batch_idx: 130 |  Loss: (0.0579) | Acc: (98.06%) (16443/16768)\n",
      "Epoch: 75 | Batch_idx: 140 |  Loss: (0.0587) | Acc: (98.01%) (17689/18048)\n",
      "Epoch: 75 | Batch_idx: 150 |  Loss: (0.0589) | Acc: (98.03%) (18948/19328)\n",
      "Epoch: 75 | Batch_idx: 160 |  Loss: (0.0581) | Acc: (98.07%) (20210/20608)\n",
      "Epoch: 75 | Batch_idx: 170 |  Loss: (0.0583) | Acc: (98.04%) (21458/21888)\n",
      "Epoch: 75 | Batch_idx: 180 |  Loss: (0.0586) | Acc: (98.02%) (22710/23168)\n",
      "Epoch: 75 | Batch_idx: 190 |  Loss: (0.0593) | Acc: (97.99%) (23956/24448)\n",
      "Epoch: 75 | Batch_idx: 200 |  Loss: (0.0599) | Acc: (97.97%) (25205/25728)\n",
      "Epoch: 75 | Batch_idx: 210 |  Loss: (0.0601) | Acc: (97.95%) (26453/27008)\n",
      "Epoch: 75 | Batch_idx: 220 |  Loss: (0.0600) | Acc: (97.94%) (27706/28288)\n",
      "Epoch: 75 | Batch_idx: 230 |  Loss: (0.0598) | Acc: (97.98%) (28970/29568)\n",
      "Epoch: 75 | Batch_idx: 240 |  Loss: (0.0597) | Acc: (98.00%) (30230/30848)\n",
      "Epoch: 75 | Batch_idx: 250 |  Loss: (0.0594) | Acc: (98.01%) (31488/32128)\n",
      "Epoch: 75 | Batch_idx: 260 |  Loss: (0.0589) | Acc: (98.02%) (32747/33408)\n",
      "Epoch: 75 | Batch_idx: 270 |  Loss: (0.0592) | Acc: (98.01%) (33997/34688)\n",
      "Epoch: 75 | Batch_idx: 280 |  Loss: (0.0591) | Acc: (98.01%) (35254/35968)\n",
      "Epoch: 75 | Batch_idx: 290 |  Loss: (0.0595) | Acc: (98.01%) (36505/37248)\n",
      "Epoch: 75 | Batch_idx: 300 |  Loss: (0.0594) | Acc: (98.01%) (37761/38528)\n",
      "Epoch: 75 | Batch_idx: 310 |  Loss: (0.0591) | Acc: (98.04%) (39027/39808)\n",
      "Epoch: 75 | Batch_idx: 320 |  Loss: (0.0592) | Acc: (98.02%) (40275/41088)\n",
      "Epoch: 75 | Batch_idx: 330 |  Loss: (0.0592) | Acc: (98.02%) (41531/42368)\n",
      "Epoch: 75 | Batch_idx: 340 |  Loss: (0.0596) | Acc: (98.00%) (42777/43648)\n",
      "Epoch: 75 | Batch_idx: 350 |  Loss: (0.0595) | Acc: (98.00%) (44030/44928)\n",
      "Epoch: 75 | Batch_idx: 360 |  Loss: (0.0593) | Acc: (98.01%) (45288/46208)\n",
      "Epoch: 75 | Batch_idx: 370 |  Loss: (0.0597) | Acc: (97.99%) (46534/47488)\n",
      "Epoch: 75 | Batch_idx: 380 |  Loss: (0.0603) | Acc: (97.97%) (47779/48768)\n",
      "Epoch: 75 | Batch_idx: 390 |  Loss: (0.0608) | Acc: (97.94%) (48972/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6345) | Acc: (88.57%) (8857/10000)\n",
      "Epoch: 76 | Batch_idx: 0 |  Loss: (0.0865) | Acc: (96.88%) (124/128)\n",
      "Epoch: 76 | Batch_idx: 10 |  Loss: (0.0701) | Acc: (97.51%) (1373/1408)\n",
      "Epoch: 76 | Batch_idx: 20 |  Loss: (0.0671) | Acc: (97.84%) (2630/2688)\n",
      "Epoch: 76 | Batch_idx: 30 |  Loss: (0.0627) | Acc: (97.96%) (3887/3968)\n",
      "Epoch: 76 | Batch_idx: 40 |  Loss: (0.0608) | Acc: (98.00%) (5143/5248)\n",
      "Epoch: 76 | Batch_idx: 50 |  Loss: (0.0599) | Acc: (97.98%) (6396/6528)\n",
      "Epoch: 76 | Batch_idx: 60 |  Loss: (0.0620) | Acc: (97.96%) (7649/7808)\n",
      "Epoch: 76 | Batch_idx: 70 |  Loss: (0.0644) | Acc: (97.85%) (8893/9088)\n",
      "Epoch: 76 | Batch_idx: 80 |  Loss: (0.0639) | Acc: (97.90%) (10150/10368)\n",
      "Epoch: 76 | Batch_idx: 90 |  Loss: (0.0630) | Acc: (97.93%) (11407/11648)\n",
      "Epoch: 76 | Batch_idx: 100 |  Loss: (0.0618) | Acc: (97.95%) (12663/12928)\n",
      "Epoch: 76 | Batch_idx: 110 |  Loss: (0.0622) | Acc: (97.92%) (13913/14208)\n",
      "Epoch: 76 | Batch_idx: 120 |  Loss: (0.0628) | Acc: (97.91%) (15165/15488)\n",
      "Epoch: 76 | Batch_idx: 130 |  Loss: (0.0617) | Acc: (97.95%) (16424/16768)\n",
      "Epoch: 76 | Batch_idx: 140 |  Loss: (0.0616) | Acc: (97.99%) (17686/18048)\n",
      "Epoch: 76 | Batch_idx: 150 |  Loss: (0.0606) | Acc: (98.03%) (18948/19328)\n",
      "Epoch: 76 | Batch_idx: 160 |  Loss: (0.0605) | Acc: (98.06%) (20208/20608)\n",
      "Epoch: 76 | Batch_idx: 170 |  Loss: (0.0611) | Acc: (98.04%) (21458/21888)\n",
      "Epoch: 76 | Batch_idx: 180 |  Loss: (0.0611) | Acc: (98.02%) (22709/23168)\n",
      "Epoch: 76 | Batch_idx: 190 |  Loss: (0.0610) | Acc: (98.03%) (23966/24448)\n",
      "Epoch: 76 | Batch_idx: 200 |  Loss: (0.0609) | Acc: (98.02%) (25219/25728)\n",
      "Epoch: 76 | Batch_idx: 210 |  Loss: (0.0607) | Acc: (98.04%) (26478/27008)\n",
      "Epoch: 76 | Batch_idx: 220 |  Loss: (0.0605) | Acc: (98.03%) (27731/28288)\n",
      "Epoch: 76 | Batch_idx: 230 |  Loss: (0.0609) | Acc: (98.00%) (28976/29568)\n",
      "Epoch: 76 | Batch_idx: 240 |  Loss: (0.0611) | Acc: (98.00%) (30230/30848)\n",
      "Epoch: 76 | Batch_idx: 250 |  Loss: (0.0610) | Acc: (98.00%) (31487/32128)\n",
      "Epoch: 76 | Batch_idx: 260 |  Loss: (0.0607) | Acc: (98.01%) (32742/33408)\n",
      "Epoch: 76 | Batch_idx: 270 |  Loss: (0.0609) | Acc: (98.00%) (33994/34688)\n",
      "Epoch: 76 | Batch_idx: 280 |  Loss: (0.0609) | Acc: (98.00%) (35250/35968)\n",
      "Epoch: 76 | Batch_idx: 290 |  Loss: (0.0609) | Acc: (98.00%) (36504/37248)\n",
      "Epoch: 76 | Batch_idx: 300 |  Loss: (0.0612) | Acc: (97.98%) (37751/38528)\n",
      "Epoch: 76 | Batch_idx: 310 |  Loss: (0.0610) | Acc: (97.98%) (39003/39808)\n",
      "Epoch: 76 | Batch_idx: 320 |  Loss: (0.0608) | Acc: (97.98%) (40257/41088)\n",
      "Epoch: 76 | Batch_idx: 330 |  Loss: (0.0612) | Acc: (97.97%) (41508/42368)\n",
      "Epoch: 76 | Batch_idx: 340 |  Loss: (0.0618) | Acc: (97.96%) (42757/43648)\n",
      "Epoch: 76 | Batch_idx: 350 |  Loss: (0.0617) | Acc: (97.96%) (44012/44928)\n",
      "Epoch: 76 | Batch_idx: 360 |  Loss: (0.0614) | Acc: (97.96%) (45267/46208)\n",
      "Epoch: 76 | Batch_idx: 370 |  Loss: (0.0616) | Acc: (97.96%) (46519/47488)\n",
      "Epoch: 76 | Batch_idx: 380 |  Loss: (0.0613) | Acc: (97.97%) (47779/48768)\n",
      "Epoch: 76 | Batch_idx: 390 |  Loss: (0.0612) | Acc: (97.98%) (48988/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6831) | Acc: (87.11%) (8711/10000)\n",
      "Epoch: 77 | Batch_idx: 0 |  Loss: (0.0413) | Acc: (98.44%) (126/128)\n",
      "Epoch: 77 | Batch_idx: 10 |  Loss: (0.0552) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 77 | Batch_idx: 20 |  Loss: (0.0590) | Acc: (98.03%) (2635/2688)\n",
      "Epoch: 77 | Batch_idx: 30 |  Loss: (0.0592) | Acc: (98.03%) (3890/3968)\n",
      "Epoch: 77 | Batch_idx: 40 |  Loss: (0.0599) | Acc: (97.88%) (5137/5248)\n",
      "Epoch: 77 | Batch_idx: 50 |  Loss: (0.0600) | Acc: (97.87%) (6389/6528)\n",
      "Epoch: 77 | Batch_idx: 60 |  Loss: (0.0608) | Acc: (97.89%) (7643/7808)\n",
      "Epoch: 77 | Batch_idx: 70 |  Loss: (0.0586) | Acc: (97.98%) (8904/9088)\n",
      "Epoch: 77 | Batch_idx: 80 |  Loss: (0.0574) | Acc: (97.99%) (10160/10368)\n",
      "Epoch: 77 | Batch_idx: 90 |  Loss: (0.0574) | Acc: (98.00%) (11415/11648)\n",
      "Epoch: 77 | Batch_idx: 100 |  Loss: (0.0574) | Acc: (98.00%) (12669/12928)\n",
      "Epoch: 77 | Batch_idx: 110 |  Loss: (0.0574) | Acc: (98.00%) (13924/14208)\n",
      "Epoch: 77 | Batch_idx: 120 |  Loss: (0.0579) | Acc: (97.99%) (15177/15488)\n",
      "Epoch: 77 | Batch_idx: 130 |  Loss: (0.0576) | Acc: (98.02%) (16436/16768)\n",
      "Epoch: 77 | Batch_idx: 140 |  Loss: (0.0575) | Acc: (98.03%) (17692/18048)\n",
      "Epoch: 77 | Batch_idx: 150 |  Loss: (0.0572) | Acc: (98.04%) (18949/19328)\n",
      "Epoch: 77 | Batch_idx: 160 |  Loss: (0.0570) | Acc: (98.05%) (20206/20608)\n",
      "Epoch: 77 | Batch_idx: 170 |  Loss: (0.0564) | Acc: (98.07%) (21466/21888)\n",
      "Epoch: 77 | Batch_idx: 180 |  Loss: (0.0559) | Acc: (98.11%) (22731/23168)\n",
      "Epoch: 77 | Batch_idx: 190 |  Loss: (0.0553) | Acc: (98.13%) (23992/24448)\n",
      "Epoch: 77 | Batch_idx: 200 |  Loss: (0.0554) | Acc: (98.13%) (25246/25728)\n",
      "Epoch: 77 | Batch_idx: 210 |  Loss: (0.0556) | Acc: (98.12%) (26499/27008)\n",
      "Epoch: 77 | Batch_idx: 220 |  Loss: (0.0563) | Acc: (98.07%) (27741/28288)\n",
      "Epoch: 77 | Batch_idx: 230 |  Loss: (0.0565) | Acc: (98.06%) (28993/29568)\n",
      "Epoch: 77 | Batch_idx: 240 |  Loss: (0.0566) | Acc: (98.05%) (30248/30848)\n",
      "Epoch: 77 | Batch_idx: 250 |  Loss: (0.0565) | Acc: (98.05%) (31501/32128)\n",
      "Epoch: 77 | Batch_idx: 260 |  Loss: (0.0570) | Acc: (98.02%) (32747/33408)\n",
      "Epoch: 77 | Batch_idx: 270 |  Loss: (0.0572) | Acc: (98.03%) (34003/34688)\n",
      "Epoch: 77 | Batch_idx: 280 |  Loss: (0.0567) | Acc: (98.06%) (35272/35968)\n",
      "Epoch: 77 | Batch_idx: 290 |  Loss: (0.0567) | Acc: (98.06%) (36526/37248)\n",
      "Epoch: 77 | Batch_idx: 300 |  Loss: (0.0569) | Acc: (98.05%) (37776/38528)\n",
      "Epoch: 77 | Batch_idx: 310 |  Loss: (0.0573) | Acc: (98.03%) (39025/39808)\n",
      "Epoch: 77 | Batch_idx: 320 |  Loss: (0.0574) | Acc: (98.05%) (40285/41088)\n",
      "Epoch: 77 | Batch_idx: 330 |  Loss: (0.0579) | Acc: (98.04%) (41536/42368)\n",
      "Epoch: 77 | Batch_idx: 340 |  Loss: (0.0580) | Acc: (98.03%) (42788/43648)\n",
      "Epoch: 77 | Batch_idx: 350 |  Loss: (0.0581) | Acc: (98.03%) (44044/44928)\n",
      "Epoch: 77 | Batch_idx: 360 |  Loss: (0.0580) | Acc: (98.03%) (45297/46208)\n",
      "Epoch: 77 | Batch_idx: 370 |  Loss: (0.0580) | Acc: (98.04%) (46557/47488)\n",
      "Epoch: 77 | Batch_idx: 380 |  Loss: (0.0579) | Acc: (98.05%) (47819/48768)\n",
      "Epoch: 77 | Batch_idx: 390 |  Loss: (0.0576) | Acc: (98.07%) (49033/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6863) | Acc: (88.09%) (8809/10000)\n",
      "Epoch: 78 | Batch_idx: 0 |  Loss: (0.0397) | Acc: (98.44%) (126/128)\n",
      "Epoch: 78 | Batch_idx: 10 |  Loss: (0.0397) | Acc: (98.58%) (1388/1408)\n",
      "Epoch: 78 | Batch_idx: 20 |  Loss: (0.0433) | Acc: (98.55%) (2649/2688)\n",
      "Epoch: 78 | Batch_idx: 30 |  Loss: (0.0458) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 78 | Batch_idx: 40 |  Loss: (0.0471) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 78 | Batch_idx: 50 |  Loss: (0.0480) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 78 | Batch_idx: 60 |  Loss: (0.0499) | Acc: (98.40%) (7683/7808)\n",
      "Epoch: 78 | Batch_idx: 70 |  Loss: (0.0488) | Acc: (98.42%) (8944/9088)\n",
      "Epoch: 78 | Batch_idx: 80 |  Loss: (0.0489) | Acc: (98.39%) (10201/10368)\n",
      "Epoch: 78 | Batch_idx: 90 |  Loss: (0.0504) | Acc: (98.34%) (11455/11648)\n",
      "Epoch: 78 | Batch_idx: 100 |  Loss: (0.0508) | Acc: (98.32%) (12711/12928)\n",
      "Epoch: 78 | Batch_idx: 110 |  Loss: (0.0521) | Acc: (98.30%) (13966/14208)\n",
      "Epoch: 78 | Batch_idx: 120 |  Loss: (0.0539) | Acc: (98.24%) (15216/15488)\n",
      "Epoch: 78 | Batch_idx: 130 |  Loss: (0.0542) | Acc: (98.25%) (16474/16768)\n",
      "Epoch: 78 | Batch_idx: 140 |  Loss: (0.0556) | Acc: (98.20%) (17723/18048)\n",
      "Epoch: 78 | Batch_idx: 150 |  Loss: (0.0566) | Acc: (98.18%) (18976/19328)\n",
      "Epoch: 78 | Batch_idx: 160 |  Loss: (0.0571) | Acc: (98.14%) (20225/20608)\n",
      "Epoch: 78 | Batch_idx: 170 |  Loss: (0.0572) | Acc: (98.12%) (21477/21888)\n",
      "Epoch: 78 | Batch_idx: 180 |  Loss: (0.0582) | Acc: (98.07%) (22720/23168)\n",
      "Epoch: 78 | Batch_idx: 190 |  Loss: (0.0582) | Acc: (98.06%) (23973/24448)\n",
      "Epoch: 78 | Batch_idx: 200 |  Loss: (0.0590) | Acc: (98.05%) (25227/25728)\n",
      "Epoch: 78 | Batch_idx: 210 |  Loss: (0.0588) | Acc: (98.04%) (26479/27008)\n",
      "Epoch: 78 | Batch_idx: 220 |  Loss: (0.0587) | Acc: (98.02%) (27728/28288)\n",
      "Epoch: 78 | Batch_idx: 230 |  Loss: (0.0586) | Acc: (98.01%) (28980/29568)\n",
      "Epoch: 78 | Batch_idx: 240 |  Loss: (0.0587) | Acc: (98.01%) (30235/30848)\n",
      "Epoch: 78 | Batch_idx: 250 |  Loss: (0.0587) | Acc: (98.00%) (31487/32128)\n",
      "Epoch: 78 | Batch_idx: 260 |  Loss: (0.0583) | Acc: (98.02%) (32747/33408)\n",
      "Epoch: 78 | Batch_idx: 270 |  Loss: (0.0586) | Acc: (98.02%) (34002/34688)\n",
      "Epoch: 78 | Batch_idx: 280 |  Loss: (0.0585) | Acc: (98.01%) (35252/35968)\n",
      "Epoch: 78 | Batch_idx: 290 |  Loss: (0.0588) | Acc: (98.00%) (36504/37248)\n",
      "Epoch: 78 | Batch_idx: 300 |  Loss: (0.0590) | Acc: (97.99%) (37755/38528)\n",
      "Epoch: 78 | Batch_idx: 310 |  Loss: (0.0598) | Acc: (97.97%) (39001/39808)\n",
      "Epoch: 78 | Batch_idx: 320 |  Loss: (0.0601) | Acc: (97.96%) (40251/41088)\n",
      "Epoch: 78 | Batch_idx: 330 |  Loss: (0.0602) | Acc: (97.97%) (41506/42368)\n",
      "Epoch: 78 | Batch_idx: 340 |  Loss: (0.0605) | Acc: (97.95%) (42755/43648)\n",
      "Epoch: 78 | Batch_idx: 350 |  Loss: (0.0603) | Acc: (97.95%) (44008/44928)\n",
      "Epoch: 78 | Batch_idx: 360 |  Loss: (0.0604) | Acc: (97.96%) (45265/46208)\n",
      "Epoch: 78 | Batch_idx: 370 |  Loss: (0.0602) | Acc: (97.97%) (46526/47488)\n",
      "Epoch: 78 | Batch_idx: 380 |  Loss: (0.0599) | Acc: (97.98%) (47781/48768)\n",
      "Epoch: 78 | Batch_idx: 390 |  Loss: (0.0601) | Acc: (97.98%) (48991/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6531) | Acc: (88.52%) (8852/10000)\n",
      "Epoch: 79 | Batch_idx: 0 |  Loss: (0.0665) | Acc: (98.44%) (126/128)\n",
      "Epoch: 79 | Batch_idx: 10 |  Loss: (0.0574) | Acc: (97.80%) (1377/1408)\n",
      "Epoch: 79 | Batch_idx: 20 |  Loss: (0.0516) | Acc: (98.21%) (2640/2688)\n",
      "Epoch: 79 | Batch_idx: 30 |  Loss: (0.0496) | Acc: (98.36%) (3903/3968)\n",
      "Epoch: 79 | Batch_idx: 40 |  Loss: (0.0472) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 79 | Batch_idx: 50 |  Loss: (0.0478) | Acc: (98.41%) (6424/6528)\n",
      "Epoch: 79 | Batch_idx: 60 |  Loss: (0.0492) | Acc: (98.34%) (7678/7808)\n",
      "Epoch: 79 | Batch_idx: 70 |  Loss: (0.0495) | Acc: (98.36%) (8939/9088)\n",
      "Epoch: 79 | Batch_idx: 80 |  Loss: (0.0522) | Acc: (98.21%) (10182/10368)\n",
      "Epoch: 79 | Batch_idx: 90 |  Loss: (0.0526) | Acc: (98.18%) (11436/11648)\n",
      "Epoch: 79 | Batch_idx: 100 |  Loss: (0.0532) | Acc: (98.18%) (12693/12928)\n",
      "Epoch: 79 | Batch_idx: 110 |  Loss: (0.0526) | Acc: (98.22%) (13955/14208)\n",
      "Epoch: 79 | Batch_idx: 120 |  Loss: (0.0523) | Acc: (98.24%) (15215/15488)\n",
      "Epoch: 79 | Batch_idx: 130 |  Loss: (0.0538) | Acc: (98.20%) (16467/16768)\n",
      "Epoch: 79 | Batch_idx: 140 |  Loss: (0.0543) | Acc: (98.19%) (17722/18048)\n",
      "Epoch: 79 | Batch_idx: 150 |  Loss: (0.0546) | Acc: (98.18%) (18977/19328)\n",
      "Epoch: 79 | Batch_idx: 160 |  Loss: (0.0551) | Acc: (98.15%) (20227/20608)\n",
      "Epoch: 79 | Batch_idx: 170 |  Loss: (0.0560) | Acc: (98.14%) (21481/21888)\n",
      "Epoch: 79 | Batch_idx: 180 |  Loss: (0.0558) | Acc: (98.14%) (22736/23168)\n",
      "Epoch: 79 | Batch_idx: 190 |  Loss: (0.0551) | Acc: (98.17%) (24000/24448)\n",
      "Epoch: 79 | Batch_idx: 200 |  Loss: (0.0557) | Acc: (98.13%) (25247/25728)\n",
      "Epoch: 79 | Batch_idx: 210 |  Loss: (0.0554) | Acc: (98.13%) (26504/27008)\n",
      "Epoch: 79 | Batch_idx: 220 |  Loss: (0.0557) | Acc: (98.13%) (27758/28288)\n",
      "Epoch: 79 | Batch_idx: 230 |  Loss: (0.0553) | Acc: (98.15%) (29021/29568)\n",
      "Epoch: 79 | Batch_idx: 240 |  Loss: (0.0555) | Acc: (98.13%) (30271/30848)\n",
      "Epoch: 79 | Batch_idx: 250 |  Loss: (0.0555) | Acc: (98.13%) (31526/32128)\n",
      "Epoch: 79 | Batch_idx: 260 |  Loss: (0.0554) | Acc: (98.13%) (32783/33408)\n",
      "Epoch: 79 | Batch_idx: 270 |  Loss: (0.0553) | Acc: (98.13%) (34040/34688)\n",
      "Epoch: 79 | Batch_idx: 280 |  Loss: (0.0555) | Acc: (98.13%) (35294/35968)\n",
      "Epoch: 79 | Batch_idx: 290 |  Loss: (0.0559) | Acc: (98.10%) (36542/37248)\n",
      "Epoch: 79 | Batch_idx: 300 |  Loss: (0.0560) | Acc: (98.11%) (37800/38528)\n",
      "Epoch: 79 | Batch_idx: 310 |  Loss: (0.0560) | Acc: (98.11%) (39055/39808)\n",
      "Epoch: 79 | Batch_idx: 320 |  Loss: (0.0558) | Acc: (98.11%) (40313/41088)\n",
      "Epoch: 79 | Batch_idx: 330 |  Loss: (0.0557) | Acc: (98.12%) (41573/42368)\n",
      "Epoch: 79 | Batch_idx: 340 |  Loss: (0.0562) | Acc: (98.10%) (42819/43648)\n",
      "Epoch: 79 | Batch_idx: 350 |  Loss: (0.0563) | Acc: (98.09%) (44069/44928)\n",
      "Epoch: 79 | Batch_idx: 360 |  Loss: (0.0558) | Acc: (98.11%) (45336/46208)\n",
      "Epoch: 79 | Batch_idx: 370 |  Loss: (0.0557) | Acc: (98.12%) (46593/47488)\n",
      "Epoch: 79 | Batch_idx: 380 |  Loss: (0.0563) | Acc: (98.09%) (47836/48768)\n",
      "Epoch: 79 | Batch_idx: 390 |  Loss: (0.0563) | Acc: (98.09%) (49043/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6622) | Acc: (88.53%) (8853/10000)\n",
      "Epoch: 80 | Batch_idx: 0 |  Loss: (0.0709) | Acc: (98.44%) (126/128)\n",
      "Epoch: 80 | Batch_idx: 10 |  Loss: (0.0628) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 80 | Batch_idx: 20 |  Loss: (0.0587) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 80 | Batch_idx: 30 |  Loss: (0.0544) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 80 | Batch_idx: 40 |  Loss: (0.0555) | Acc: (98.34%) (5161/5248)\n",
      "Epoch: 80 | Batch_idx: 50 |  Loss: (0.0528) | Acc: (98.39%) (6423/6528)\n",
      "Epoch: 80 | Batch_idx: 60 |  Loss: (0.0502) | Acc: (98.46%) (7688/7808)\n",
      "Epoch: 80 | Batch_idx: 70 |  Loss: (0.0487) | Acc: (98.51%) (8953/9088)\n",
      "Epoch: 80 | Batch_idx: 80 |  Loss: (0.0466) | Acc: (98.56%) (10219/10368)\n",
      "Epoch: 80 | Batch_idx: 90 |  Loss: (0.0458) | Acc: (98.58%) (11483/11648)\n",
      "Epoch: 80 | Batch_idx: 100 |  Loss: (0.0449) | Acc: (98.59%) (12746/12928)\n",
      "Epoch: 80 | Batch_idx: 110 |  Loss: (0.0436) | Acc: (98.63%) (14014/14208)\n",
      "Epoch: 80 | Batch_idx: 120 |  Loss: (0.0430) | Acc: (98.66%) (15280/15488)\n",
      "Epoch: 80 | Batch_idx: 130 |  Loss: (0.0429) | Acc: (98.65%) (16542/16768)\n",
      "Epoch: 80 | Batch_idx: 140 |  Loss: (0.0419) | Acc: (98.69%) (17811/18048)\n",
      "Epoch: 80 | Batch_idx: 150 |  Loss: (0.0414) | Acc: (98.69%) (19075/19328)\n",
      "Epoch: 80 | Batch_idx: 160 |  Loss: (0.0411) | Acc: (98.71%) (20343/20608)\n",
      "Epoch: 80 | Batch_idx: 170 |  Loss: (0.0404) | Acc: (98.75%) (21614/21888)\n",
      "Epoch: 80 | Batch_idx: 180 |  Loss: (0.0401) | Acc: (98.75%) (22879/23168)\n",
      "Epoch: 80 | Batch_idx: 190 |  Loss: (0.0397) | Acc: (98.77%) (24148/24448)\n",
      "Epoch: 80 | Batch_idx: 200 |  Loss: (0.0396) | Acc: (98.77%) (25411/25728)\n",
      "Epoch: 80 | Batch_idx: 210 |  Loss: (0.0390) | Acc: (98.78%) (26678/27008)\n",
      "Epoch: 80 | Batch_idx: 220 |  Loss: (0.0388) | Acc: (98.80%) (27948/28288)\n",
      "Epoch: 80 | Batch_idx: 230 |  Loss: (0.0381) | Acc: (98.83%) (29222/29568)\n",
      "Epoch: 80 | Batch_idx: 240 |  Loss: (0.0377) | Acc: (98.84%) (30490/30848)\n",
      "Epoch: 80 | Batch_idx: 250 |  Loss: (0.0374) | Acc: (98.85%) (31759/32128)\n",
      "Epoch: 80 | Batch_idx: 260 |  Loss: (0.0378) | Acc: (98.83%) (33016/33408)\n",
      "Epoch: 80 | Batch_idx: 270 |  Loss: (0.0377) | Acc: (98.83%) (34281/34688)\n",
      "Epoch: 80 | Batch_idx: 280 |  Loss: (0.0374) | Acc: (98.84%) (35552/35968)\n",
      "Epoch: 80 | Batch_idx: 290 |  Loss: (0.0372) | Acc: (98.85%) (36818/37248)\n",
      "Epoch: 80 | Batch_idx: 300 |  Loss: (0.0372) | Acc: (98.85%) (38084/38528)\n",
      "Epoch: 80 | Batch_idx: 310 |  Loss: (0.0372) | Acc: (98.85%) (39349/39808)\n",
      "Epoch: 80 | Batch_idx: 320 |  Loss: (0.0368) | Acc: (98.86%) (40620/41088)\n",
      "Epoch: 80 | Batch_idx: 330 |  Loss: (0.0365) | Acc: (98.88%) (41895/42368)\n",
      "Epoch: 80 | Batch_idx: 340 |  Loss: (0.0364) | Acc: (98.88%) (43159/43648)\n",
      "Epoch: 80 | Batch_idx: 350 |  Loss: (0.0366) | Acc: (98.86%) (44417/44928)\n",
      "Epoch: 80 | Batch_idx: 360 |  Loss: (0.0366) | Acc: (98.86%) (45680/46208)\n",
      "Epoch: 80 | Batch_idx: 370 |  Loss: (0.0364) | Acc: (98.87%) (46952/47488)\n",
      "Epoch: 80 | Batch_idx: 380 |  Loss: (0.0363) | Acc: (98.88%) (48224/48768)\n",
      "Epoch: 80 | Batch_idx: 390 |  Loss: (0.0360) | Acc: (98.89%) (49447/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5615) | Acc: (89.78%) (8978/10000)\n",
      "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0248) | Acc: (99.22%) (127/128)\n",
      "Epoch: 81 | Batch_idx: 10 |  Loss: (0.0323) | Acc: (98.93%) (1393/1408)\n",
      "Epoch: 81 | Batch_idx: 20 |  Loss: (0.0330) | Acc: (99.03%) (2662/2688)\n",
      "Epoch: 81 | Batch_idx: 30 |  Loss: (0.0299) | Acc: (99.19%) (3936/3968)\n",
      "Epoch: 81 | Batch_idx: 40 |  Loss: (0.0308) | Acc: (99.12%) (5202/5248)\n",
      "Epoch: 81 | Batch_idx: 50 |  Loss: (0.0319) | Acc: (99.14%) (6472/6528)\n",
      "Epoch: 81 | Batch_idx: 60 |  Loss: (0.0322) | Acc: (99.05%) (7734/7808)\n",
      "Epoch: 81 | Batch_idx: 70 |  Loss: (0.0314) | Acc: (99.09%) (9005/9088)\n",
      "Epoch: 81 | Batch_idx: 80 |  Loss: (0.0317) | Acc: (99.05%) (10270/10368)\n",
      "Epoch: 81 | Batch_idx: 90 |  Loss: (0.0321) | Acc: (99.01%) (11533/11648)\n",
      "Epoch: 81 | Batch_idx: 100 |  Loss: (0.0314) | Acc: (99.06%) (12806/12928)\n",
      "Epoch: 81 | Batch_idx: 110 |  Loss: (0.0306) | Acc: (99.09%) (14078/14208)\n",
      "Epoch: 81 | Batch_idx: 120 |  Loss: (0.0296) | Acc: (99.15%) (15357/15488)\n",
      "Epoch: 81 | Batch_idx: 130 |  Loss: (0.0300) | Acc: (99.14%) (16624/16768)\n",
      "Epoch: 81 | Batch_idx: 140 |  Loss: (0.0303) | Acc: (99.12%) (17889/18048)\n",
      "Epoch: 81 | Batch_idx: 150 |  Loss: (0.0301) | Acc: (99.14%) (19162/19328)\n",
      "Epoch: 81 | Batch_idx: 160 |  Loss: (0.0297) | Acc: (99.15%) (20432/20608)\n",
      "Epoch: 81 | Batch_idx: 170 |  Loss: (0.0299) | Acc: (99.14%) (21699/21888)\n",
      "Epoch: 81 | Batch_idx: 180 |  Loss: (0.0295) | Acc: (99.16%) (22973/23168)\n",
      "Epoch: 81 | Batch_idx: 190 |  Loss: (0.0296) | Acc: (99.15%) (24239/24448)\n",
      "Epoch: 81 | Batch_idx: 200 |  Loss: (0.0291) | Acc: (99.16%) (25513/25728)\n",
      "Epoch: 81 | Batch_idx: 210 |  Loss: (0.0292) | Acc: (99.15%) (26778/27008)\n",
      "Epoch: 81 | Batch_idx: 220 |  Loss: (0.0293) | Acc: (99.14%) (28044/28288)\n",
      "Epoch: 81 | Batch_idx: 230 |  Loss: (0.0291) | Acc: (99.15%) (29316/29568)\n",
      "Epoch: 81 | Batch_idx: 240 |  Loss: (0.0289) | Acc: (99.16%) (30588/30848)\n",
      "Epoch: 81 | Batch_idx: 250 |  Loss: (0.0288) | Acc: (99.16%) (31857/32128)\n",
      "Epoch: 81 | Batch_idx: 260 |  Loss: (0.0286) | Acc: (99.16%) (33127/33408)\n",
      "Epoch: 81 | Batch_idx: 270 |  Loss: (0.0289) | Acc: (99.16%) (34395/34688)\n",
      "Epoch: 81 | Batch_idx: 280 |  Loss: (0.0293) | Acc: (99.13%) (35655/35968)\n",
      "Epoch: 81 | Batch_idx: 290 |  Loss: (0.0291) | Acc: (99.14%) (36927/37248)\n",
      "Epoch: 81 | Batch_idx: 300 |  Loss: (0.0291) | Acc: (99.14%) (38196/38528)\n",
      "Epoch: 81 | Batch_idx: 310 |  Loss: (0.0289) | Acc: (99.14%) (39466/39808)\n",
      "Epoch: 81 | Batch_idx: 320 |  Loss: (0.0289) | Acc: (99.14%) (40733/41088)\n",
      "Epoch: 81 | Batch_idx: 330 |  Loss: (0.0290) | Acc: (99.14%) (42002/42368)\n",
      "Epoch: 81 | Batch_idx: 340 |  Loss: (0.0289) | Acc: (99.14%) (43273/43648)\n",
      "Epoch: 81 | Batch_idx: 350 |  Loss: (0.0289) | Acc: (99.14%) (44541/44928)\n",
      "Epoch: 81 | Batch_idx: 360 |  Loss: (0.0286) | Acc: (99.15%) (45815/46208)\n",
      "Epoch: 81 | Batch_idx: 370 |  Loss: (0.0285) | Acc: (99.15%) (47086/47488)\n",
      "Epoch: 81 | Batch_idx: 380 |  Loss: (0.0283) | Acc: (99.16%) (48358/48768)\n",
      "Epoch: 81 | Batch_idx: 390 |  Loss: (0.0283) | Acc: (99.16%) (49579/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5947) | Acc: (89.36%) (8936/10000)\n",
      "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0302) | Acc: (99.22%) (127/128)\n",
      "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0235) | Acc: (99.22%) (1397/1408)\n",
      "Epoch: 82 | Batch_idx: 20 |  Loss: (0.0268) | Acc: (99.22%) (2667/2688)\n",
      "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0268) | Acc: (99.19%) (3936/3968)\n",
      "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0261) | Acc: (99.24%) (5208/5248)\n",
      "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0262) | Acc: (99.22%) (6477/6528)\n",
      "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0271) | Acc: (99.17%) (7743/7808)\n",
      "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0266) | Acc: (99.20%) (9015/9088)\n",
      "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0265) | Acc: (99.18%) (10283/10368)\n",
      "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0266) | Acc: (99.21%) (11556/11648)\n",
      "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0273) | Acc: (99.18%) (12822/12928)\n",
      "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0275) | Acc: (99.18%) (14092/14208)\n",
      "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0271) | Acc: (99.21%) (15366/15488)\n",
      "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0274) | Acc: (99.22%) (16637/16768)\n",
      "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0283) | Acc: (99.17%) (26785/27008)\n",
      "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0283) | Acc: (99.17%) (28053/28288)\n",
      "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0282) | Acc: (99.17%) (29323/29568)\n",
      "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0282) | Acc: (99.18%) (30596/30848)\n",
      "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0281) | Acc: (99.18%) (31865/32128)\n",
      "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0279) | Acc: (99.19%) (33139/33408)\n",
      "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0278) | Acc: (99.20%) (34409/34688)\n",
      "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0278) | Acc: (99.19%) (35678/35968)\n",
      "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0276) | Acc: (99.20%) (36950/37248)\n",
      "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0279) | Acc: (99.19%) (38217/38528)\n",
      "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0277) | Acc: (99.20%) (39490/39808)\n",
      "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0276) | Acc: (99.20%) (40759/41088)\n",
      "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0273) | Acc: (99.21%) (42035/42368)\n",
      "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0272) | Acc: (99.22%) (43306/43648)\n",
      "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0271) | Acc: (99.22%) (44577/44928)\n",
      "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0270) | Acc: (99.22%) (45847/46208)\n",
      "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0270) | Acc: (99.22%) (47117/47488)\n",
      "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0270) | Acc: (99.22%) (48387/48768)\n",
      "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0270) | Acc: (99.22%) (49609/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6028) | Acc: (89.47%) (8947/10000)\n",
      "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0407) | Acc: (99.22%) (127/128)\n",
      "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0301) | Acc: (99.22%) (1397/1408)\n",
      "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0287) | Acc: (99.22%) (2667/2688)\n",
      "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0262) | Acc: (99.32%) (3941/3968)\n",
      "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0249) | Acc: (99.33%) (5213/5248)\n",
      "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0249) | Acc: (99.28%) (6481/6528)\n",
      "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0252) | Acc: (99.27%) (7751/7808)\n",
      "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0250) | Acc: (99.28%) (9023/9088)\n",
      "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0258) | Acc: (99.23%) (10288/10368)\n",
      "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0257) | Acc: (99.24%) (11560/11648)\n",
      "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0263) | Acc: (99.22%) (12827/12928)\n",
      "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0257) | Acc: (99.25%) (14102/14208)\n",
      "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0265) | Acc: (99.23%) (15368/15488)\n",
      "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0269) | Acc: (99.21%) (16635/16768)\n",
      "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0268) | Acc: (99.21%) (17906/18048)\n",
      "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0269) | Acc: (99.21%) (19175/19328)\n",
      "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0271) | Acc: (99.19%) (20441/20608)\n",
      "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0266) | Acc: (99.21%) (21716/21888)\n",
      "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0262) | Acc: (99.24%) (22991/23168)\n",
      "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0261) | Acc: (99.24%) (24262/24448)\n",
      "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0260) | Acc: (99.25%) (25534/25728)\n",
      "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0261) | Acc: (99.25%) (26806/27008)\n",
      "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0265) | Acc: (99.25%) (28075/28288)\n",
      "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0261) | Acc: (99.27%) (29351/29568)\n",
      "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0258) | Acc: (99.28%) (30626/30848)\n",
      "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0260) | Acc: (99.27%) (31894/32128)\n",
      "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0260) | Acc: (99.27%) (33164/33408)\n",
      "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0258) | Acc: (99.28%) (34438/34688)\n",
      "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0258) | Acc: (99.29%) (35711/35968)\n",
      "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0257) | Acc: (99.29%) (36984/37248)\n",
      "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0258) | Acc: (99.30%) (38257/38528)\n",
      "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0256) | Acc: (99.31%) (39533/39808)\n",
      "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0253) | Acc: (99.32%) (40810/41088)\n",
      "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0253) | Acc: (99.32%) (42081/42368)\n",
      "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0252) | Acc: (99.33%) (43354/43648)\n",
      "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0253) | Acc: (99.32%) (44622/44928)\n",
      "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0254) | Acc: (99.31%) (45891/46208)\n",
      "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0252) | Acc: (99.32%) (47166/47488)\n",
      "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0251) | Acc: (99.33%) (48439/48768)\n",
      "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0250) | Acc: (99.33%) (49664/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5989) | Acc: (89.22%) (8922/10000)\n",
      "Epoch: 84 | Batch_idx: 0 |  Loss: (0.0216) | Acc: (99.22%) (127/128)\n",
      "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0325) | Acc: (99.15%) (1396/1408)\n",
      "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0289) | Acc: (99.26%) (2668/2688)\n",
      "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0288) | Acc: (99.19%) (3936/3968)\n",
      "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0291) | Acc: (99.14%) (5203/5248)\n",
      "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0280) | Acc: (99.14%) (6472/6528)\n",
      "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0273) | Acc: (99.17%) (7743/7808)\n",
      "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0276) | Acc: (99.14%) (9010/9088)\n",
      "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0270) | Acc: (99.17%) (10282/10368)\n",
      "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0266) | Acc: (99.20%) (11555/11648)\n",
      "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0262) | Acc: (99.22%) (12827/12928)\n",
      "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0263) | Acc: (99.20%) (14094/14208)\n",
      "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0260) | Acc: (99.23%) (15369/15488)\n",
      "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0260) | Acc: (99.24%) (16641/16768)\n",
      "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0261) | Acc: (99.23%) (17909/18048)\n",
      "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0263) | Acc: (99.24%) (19182/19328)\n",
      "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0258) | Acc: (99.25%) (20454/20608)\n",
      "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0254) | Acc: (99.28%) (21730/21888)\n",
      "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0257) | Acc: (99.28%) (23001/23168)\n",
      "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0260) | Acc: (99.27%) (24269/24448)\n",
      "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0260) | Acc: (99.26%) (25538/25728)\n",
      "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0257) | Acc: (99.28%) (26813/27008)\n",
      "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0258) | Acc: (99.28%) (28083/28288)\n",
      "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0256) | Acc: (99.28%) (29355/29568)\n",
      "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0255) | Acc: (99.28%) (30625/30848)\n",
      "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0252) | Acc: (99.29%) (31899/32128)\n",
      "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0251) | Acc: (99.29%) (33172/33408)\n",
      "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0249) | Acc: (99.30%) (34446/34688)\n",
      "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0248) | Acc: (99.30%) (35718/35968)\n",
      "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0249) | Acc: (99.30%) (36989/37248)\n",
      "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0247) | Acc: (99.32%) (38267/38528)\n",
      "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0247) | Acc: (99.32%) (39536/39808)\n",
      "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0246) | Acc: (99.32%) (40809/41088)\n",
      "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0245) | Acc: (99.33%) (42083/42368)\n",
      "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0248) | Acc: (99.32%) (43351/43648)\n",
      "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0248) | Acc: (99.32%) (44622/44928)\n",
      "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0250) | Acc: (99.31%) (45888/46208)\n",
      "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0250) | Acc: (99.31%) (47160/47488)\n",
      "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0250) | Acc: (99.31%) (48430/48768)\n",
      "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0249) | Acc: (99.31%) (49654/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5912) | Acc: (89.58%) (8958/10000)\n",
      "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0228) | Acc: (99.22%) (127/128)\n",
      "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0178) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0206) | Acc: (99.48%) (2674/2688)\n",
      "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0190) | Acc: (99.55%) (3950/3968)\n",
      "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0206) | Acc: (99.47%) (5220/5248)\n",
      "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0220) | Acc: (99.42%) (6490/6528)\n",
      "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0234) | Acc: (99.37%) (7759/7808)\n",
      "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0246) | Acc: (99.32%) (9026/9088)\n",
      "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0236) | Acc: (99.35%) (10301/10368)\n",
      "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0248) | Acc: (99.30%) (11566/11648)\n",
      "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0250) | Acc: (99.29%) (12836/12928)\n",
      "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0253) | Acc: (99.26%) (14103/14208)\n",
      "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0247) | Acc: (99.29%) (15378/15488)\n",
      "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0254) | Acc: (99.26%) (16644/16768)\n",
      "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0253) | Acc: (99.26%) (17914/18048)\n",
      "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0252) | Acc: (99.27%) (19187/19328)\n",
      "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0248) | Acc: (99.29%) (20461/20608)\n",
      "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0245) | Acc: (99.31%) (21737/21888)\n",
      "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0248) | Acc: (99.30%) (23005/23168)\n",
      "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0252) | Acc: (99.27%) (24270/24448)\n",
      "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0252) | Acc: (99.28%) (25542/25728)\n",
      "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0253) | Acc: (99.27%) (26811/27008)\n",
      "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0251) | Acc: (99.27%) (28082/28288)\n",
      "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0249) | Acc: (99.29%) (29357/29568)\n",
      "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0248) | Acc: (99.29%) (30630/30848)\n",
      "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0248) | Acc: (99.30%) (31902/32128)\n",
      "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0250) | Acc: (99.29%) (33171/33408)\n",
      "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0249) | Acc: (99.29%) (34443/34688)\n",
      "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0248) | Acc: (99.30%) (35718/35968)\n",
      "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0247) | Acc: (99.32%) (36993/37248)\n",
      "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0245) | Acc: (99.33%) (38268/38528)\n",
      "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0243) | Acc: (99.33%) (39541/39808)\n",
      "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0244) | Acc: (99.32%) (40810/41088)\n",
      "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0243) | Acc: (99.33%) (42083/42368)\n",
      "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0243) | Acc: (99.33%) (43354/43648)\n",
      "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0245) | Acc: (99.32%) (44623/44928)\n",
      "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0244) | Acc: (99.33%) (45897/46208)\n",
      "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0243) | Acc: (99.33%) (47170/47488)\n",
      "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0244) | Acc: (99.32%) (48437/48768)\n",
      "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0242) | Acc: (99.33%) (49663/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5930) | Acc: (89.58%) (8958/10000)\n",
      "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0094) | Acc: (100.00%) (128/128)\n",
      "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0183) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0227) | Acc: (99.29%) (2669/2688)\n",
      "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0224) | Acc: (99.40%) (3944/3968)\n",
      "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0221) | Acc: (99.43%) (5218/5248)\n",
      "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0225) | Acc: (99.40%) (6489/6528)\n",
      "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0223) | Acc: (99.40%) (7761/7808)\n",
      "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0216) | Acc: (99.44%) (9037/9088)\n",
      "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0215) | Acc: (99.45%) (10311/10368)\n",
      "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0213) | Acc: (99.48%) (11587/11648)\n",
      "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0225) | Acc: (99.44%) (12855/12928)\n",
      "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0230) | Acc: (99.40%) (14123/14208)\n",
      "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0225) | Acc: (99.42%) (15398/15488)\n",
      "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0227) | Acc: (99.42%) (16670/16768)\n",
      "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0226) | Acc: (99.42%) (17943/18048)\n",
      "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0228) | Acc: (99.40%) (19212/19328)\n",
      "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0229) | Acc: (99.39%) (20483/20608)\n",
      "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0230) | Acc: (99.39%) (21754/21888)\n",
      "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0227) | Acc: (99.39%) (23027/23168)\n",
      "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0227) | Acc: (99.39%) (24300/24448)\n",
      "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0227) | Acc: (99.38%) (25569/25728)\n",
      "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0228) | Acc: (99.37%) (26839/27008)\n",
      "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0227) | Acc: (99.37%) (28111/28288)\n",
      "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0227) | Acc: (99.38%) (29386/29568)\n",
      "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0228) | Acc: (99.37%) (30653/30848)\n",
      "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0224) | Acc: (99.38%) (31928/32128)\n",
      "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0228) | Acc: (99.36%) (33193/33408)\n",
      "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0228) | Acc: (99.36%) (34465/34688)\n",
      "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0226) | Acc: (99.37%) (35741/35968)\n",
      "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0226) | Acc: (99.38%) (37016/37248)\n",
      "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0224) | Acc: (99.38%) (38291/38528)\n",
      "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0223) | Acc: (99.38%) (39562/39808)\n",
      "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0224) | Acc: (99.38%) (40834/41088)\n",
      "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0225) | Acc: (99.38%) (42105/42368)\n",
      "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0227) | Acc: (99.38%) (43377/43648)\n",
      "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0228) | Acc: (99.37%) (44646/44928)\n",
      "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0228) | Acc: (99.37%) (45918/46208)\n",
      "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0228) | Acc: (99.37%) (47190/47488)\n",
      "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0227) | Acc: (99.38%) (48466/48768)\n",
      "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0225) | Acc: (99.38%) (49692/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5646) | Acc: (89.81%) (8981/10000)\n",
      "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
      "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0193) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0199) | Acc: (99.44%) (2673/2688)\n",
      "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0209) | Acc: (99.47%) (3947/3968)\n",
      "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0205) | Acc: (99.50%) (5222/5248)\n",
      "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0205) | Acc: (99.46%) (6493/6528)\n",
      "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0214) | Acc: (99.40%) (7761/7808)\n",
      "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0212) | Acc: (99.39%) (9033/9088)\n",
      "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0210) | Acc: (99.42%) (10308/10368)\n",
      "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0204) | Acc: (99.45%) (11584/11648)\n",
      "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0205) | Acc: (99.44%) (12856/12928)\n",
      "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0209) | Acc: (99.43%) (14127/14208)\n",
      "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0207) | Acc: (99.45%) (15403/15488)\n",
      "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0208) | Acc: (99.43%) (16672/16768)\n",
      "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0209) | Acc: (99.41%) (17942/18048)\n",
      "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0209) | Acc: (99.42%) (19215/19328)\n",
      "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0213) | Acc: (99.38%) (20481/20608)\n",
      "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0213) | Acc: (99.38%) (21753/21888)\n",
      "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0213) | Acc: (99.39%) (23026/23168)\n",
      "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0218) | Acc: (99.38%) (24296/24448)\n",
      "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0220) | Acc: (99.37%) (25567/25728)\n",
      "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0220) | Acc: (99.38%) (26841/27008)\n",
      "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0219) | Acc: (99.39%) (28115/28288)\n",
      "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0220) | Acc: (99.38%) (29385/29568)\n",
      "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0222) | Acc: (99.37%) (30654/30848)\n",
      "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0219) | Acc: (99.38%) (31929/32128)\n",
      "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0220) | Acc: (99.39%) (33203/33408)\n",
      "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0217) | Acc: (99.40%) (34481/34688)\n",
      "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0220) | Acc: (99.39%) (35748/35968)\n",
      "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0221) | Acc: (99.39%) (37021/37248)\n",
      "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0222) | Acc: (99.39%) (38292/38528)\n",
      "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0223) | Acc: (99.39%) (39564/39808)\n",
      "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0223) | Acc: (99.39%) (40837/41088)\n",
      "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0225) | Acc: (99.39%) (42108/42368)\n",
      "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0223) | Acc: (99.40%) (43386/43648)\n",
      "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0224) | Acc: (99.39%) (44654/44928)\n",
      "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0224) | Acc: (99.39%) (45926/46208)\n",
      "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0223) | Acc: (99.40%) (47201/47488)\n",
      "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0223) | Acc: (99.40%) (48474/48768)\n",
      "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0222) | Acc: (99.40%) (49700/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5799) | Acc: (89.85%) (8985/10000)\n",
      "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0143) | Acc: (100.00%) (128/128)\n",
      "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0187) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0208) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0234) | Acc: (99.42%) (3945/3968)\n",
      "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0230) | Acc: (99.41%) (5217/5248)\n",
      "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0230) | Acc: (99.40%) (6489/6528)\n",
      "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0221) | Acc: (99.46%) (7766/7808)\n",
      "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0213) | Acc: (99.49%) (9042/9088)\n",
      "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0211) | Acc: (99.49%) (10315/10368)\n",
      "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0214) | Acc: (99.47%) (11586/11648)\n",
      "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0215) | Acc: (99.47%) (12860/12928)\n",
      "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0214) | Acc: (99.48%) (14134/14208)\n",
      "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0219) | Acc: (99.45%) (15403/15488)\n",
      "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0217) | Acc: (99.46%) (16677/16768)\n",
      "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0215) | Acc: (99.47%) (17952/18048)\n",
      "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0214) | Acc: (99.48%) (19227/19328)\n",
      "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0222) | Acc: (99.44%) (20493/20608)\n",
      "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0220) | Acc: (99.44%) (21766/21888)\n",
      "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0219) | Acc: (99.45%) (23040/23168)\n",
      "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0218) | Acc: (99.45%) (24314/24448)\n",
      "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0220) | Acc: (99.44%) (25584/25728)\n",
      "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0223) | Acc: (99.42%) (26852/27008)\n",
      "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0223) | Acc: (99.43%) (28126/28288)\n",
      "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0223) | Acc: (99.42%) (29396/29568)\n",
      "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0223) | Acc: (99.42%) (30668/30848)\n",
      "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0223) | Acc: (99.41%) (31940/32128)\n",
      "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0222) | Acc: (99.42%) (33213/33408)\n",
      "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0221) | Acc: (99.42%) (34488/34688)\n",
      "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0219) | Acc: (99.43%) (35763/35968)\n",
      "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0219) | Acc: (99.44%) (37038/37248)\n",
      "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0218) | Acc: (99.44%) (38311/38528)\n",
      "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0217) | Acc: (99.44%) (39584/39808)\n",
      "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0219) | Acc: (99.43%) (40853/41088)\n",
      "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0219) | Acc: (99.42%) (42121/42368)\n",
      "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0219) | Acc: (99.42%) (43395/43648)\n",
      "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0218) | Acc: (99.42%) (44668/44928)\n",
      "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0220) | Acc: (99.41%) (45935/46208)\n",
      "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0220) | Acc: (99.40%) (47205/47488)\n",
      "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0220) | Acc: (99.41%) (48480/48768)\n",
      "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0220) | Acc: (99.41%) (49703/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5976) | Acc: (89.45%) (8945/10000)\n",
      "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0154) | Acc: (99.22%) (127/128)\n",
      "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0162) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0189) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0203) | Acc: (99.55%) (3950/3968)\n",
      "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.49%) (5221/5248)\n",
      "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0197) | Acc: (99.56%) (6499/6528)\n",
      "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0212) | Acc: (99.44%) (7764/7808)\n",
      "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0210) | Acc: (99.44%) (9037/9088)\n",
      "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0207) | Acc: (99.45%) (10311/10368)\n",
      "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0212) | Acc: (99.45%) (11584/11648)\n",
      "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0214) | Acc: (99.46%) (12858/12928)\n",
      "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0209) | Acc: (99.49%) (14136/14208)\n",
      "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0210) | Acc: (99.48%) (15407/15488)\n",
      "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0208) | Acc: (99.49%) (16682/16768)\n",
      "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0206) | Acc: (99.49%) (17956/18048)\n",
      "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0203) | Acc: (99.51%) (19233/19328)\n",
      "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0203) | Acc: (99.51%) (20508/20608)\n",
      "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0204) | Acc: (99.51%) (21780/21888)\n",
      "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0202) | Acc: (99.51%) (23054/23168)\n",
      "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0203) | Acc: (99.50%) (24325/24448)\n",
      "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0203) | Acc: (99.49%) (25598/25728)\n",
      "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0200) | Acc: (99.50%) (26874/27008)\n",
      "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0199) | Acc: (99.52%) (28151/28288)\n",
      "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0205) | Acc: (99.49%) (33237/33408)\n",
      "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0204) | Acc: (99.50%) (34514/34688)\n",
      "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0205) | Acc: (99.50%) (35788/35968)\n",
      "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0204) | Acc: (99.50%) (37063/37248)\n",
      "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0204) | Acc: (99.50%) (38336/38528)\n",
      "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0205) | Acc: (99.49%) (39606/39808)\n",
      "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0203) | Acc: (99.50%) (40883/41088)\n",
      "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0204) | Acc: (99.49%) (42154/42368)\n",
      "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0205) | Acc: (99.49%) (43426/43648)\n",
      "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0205) | Acc: (99.49%) (44701/44928)\n",
      "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0204) | Acc: (99.50%) (45976/46208)\n",
      "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0205) | Acc: (99.49%) (47245/47488)\n",
      "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0206) | Acc: (99.49%) (48518/48768)\n",
      "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0210) | Acc: (99.47%) (49735/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5835) | Acc: (89.87%) (8987/10000)\n",
      "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0123) | Acc: (100.00%) (128/128)\n",
      "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0192) | Acc: (99.36%) (1399/1408)\n",
      "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0250) | Acc: (99.22%) (2667/2688)\n",
      "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0226) | Acc: (99.34%) (3942/3968)\n",
      "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0207) | Acc: (99.45%) (5219/5248)\n",
      "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0206) | Acc: (99.46%) (6493/6528)\n",
      "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0201) | Acc: (99.49%) (7768/7808)\n",
      "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0203) | Acc: (99.48%) (9041/9088)\n",
      "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0202) | Acc: (99.48%) (10314/10368)\n",
      "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0205) | Acc: (99.46%) (11585/11648)\n",
      "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0202) | Acc: (99.47%) (12860/12928)\n",
      "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0201) | Acc: (99.47%) (14133/14208)\n",
      "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0207) | Acc: (99.43%) (15400/15488)\n",
      "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0209) | Acc: (99.43%) (16673/16768)\n",
      "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0206) | Acc: (99.44%) (17947/18048)\n",
      "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0208) | Acc: (99.42%) (19215/19328)\n",
      "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0209) | Acc: (99.42%) (20488/20608)\n",
      "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0206) | Acc: (99.43%) (21764/21888)\n",
      "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0204) | Acc: (99.45%) (23040/23168)\n",
      "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0206) | Acc: (99.44%) (24311/24448)\n",
      "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0204) | Acc: (99.45%) (25586/25728)\n",
      "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0204) | Acc: (99.44%) (26858/27008)\n",
      "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0203) | Acc: (99.45%) (28133/28288)\n",
      "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0203) | Acc: (99.45%) (29405/29568)\n",
      "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0203) | Acc: (99.45%) (30678/30848)\n",
      "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0202) | Acc: (99.45%) (31950/32128)\n",
      "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0202) | Acc: (99.44%) (33221/33408)\n",
      "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0200) | Acc: (99.45%) (34498/34688)\n",
      "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0202) | Acc: (99.44%) (35766/35968)\n",
      "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0205) | Acc: (99.43%) (37036/37248)\n",
      "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0207) | Acc: (99.43%) (38308/38528)\n",
      "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0206) | Acc: (99.44%) (39585/39808)\n",
      "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0205) | Acc: (99.45%) (40862/41088)\n",
      "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0204) | Acc: (99.45%) (42137/42368)\n",
      "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0205) | Acc: (99.45%) (43407/43648)\n",
      "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0204) | Acc: (99.45%) (44683/44928)\n",
      "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0204) | Acc: (99.46%) (45958/46208)\n",
      "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0204) | Acc: (99.46%) (47231/47488)\n",
      "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0205) | Acc: (99.45%) (48501/48768)\n",
      "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0204) | Acc: (99.46%) (49730/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5838) | Acc: (89.69%) (8969/10000)\n",
      "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0200) | Acc: (99.22%) (127/128)\n",
      "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0207) | Acc: (99.36%) (1399/1408)\n",
      "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0212) | Acc: (99.33%) (2670/2688)\n",
      "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0218) | Acc: (99.29%) (3940/3968)\n",
      "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0220) | Acc: (99.28%) (5210/5248)\n",
      "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0213) | Acc: (99.36%) (6486/6528)\n",
      "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0213) | Acc: (99.33%) (7756/7808)\n",
      "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0212) | Acc: (99.34%) (9028/9088)\n",
      "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0213) | Acc: (99.35%) (10301/10368)\n",
      "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0210) | Acc: (99.38%) (11576/11648)\n",
      "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0206) | Acc: (99.40%) (12850/12928)\n",
      "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0205) | Acc: (99.42%) (14125/14208)\n",
      "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0199) | Acc: (99.44%) (15402/15488)\n",
      "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0202) | Acc: (99.44%) (16674/16768)\n",
      "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0200) | Acc: (99.46%) (17951/18048)\n",
      "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0202) | Acc: (99.45%) (19222/19328)\n",
      "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0205) | Acc: (99.44%) (20492/20608)\n",
      "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0208) | Acc: (99.44%) (21766/21888)\n",
      "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0208) | Acc: (99.45%) (23041/23168)\n",
      "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0208) | Acc: (99.45%) (24314/24448)\n",
      "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0209) | Acc: (99.44%) (25585/25728)\n",
      "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0208) | Acc: (99.44%) (26858/27008)\n",
      "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0207) | Acc: (99.45%) (28132/28288)\n",
      "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0207) | Acc: (99.45%) (29404/29568)\n",
      "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0208) | Acc: (99.45%) (30677/30848)\n",
      "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0210) | Acc: (99.45%) (31950/32128)\n",
      "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0211) | Acc: (99.44%) (33220/33408)\n",
      "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0210) | Acc: (99.45%) (34496/34688)\n",
      "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0210) | Acc: (99.44%) (35768/35968)\n",
      "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0210) | Acc: (99.45%) (37043/37248)\n",
      "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0210) | Acc: (99.45%) (38317/38528)\n",
      "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0210) | Acc: (99.45%) (39591/39808)\n",
      "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0210) | Acc: (99.45%) (40864/41088)\n",
      "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0208) | Acc: (99.46%) (42140/42368)\n",
      "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0208) | Acc: (99.47%) (43415/43648)\n",
      "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0208) | Acc: (99.47%) (44688/44928)\n",
      "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0209) | Acc: (99.46%) (45958/46208)\n",
      "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0209) | Acc: (99.46%) (47231/47488)\n",
      "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0209) | Acc: (99.46%) (48506/48768)\n",
      "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0209) | Acc: (99.46%) (49728/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5991) | Acc: (89.67%) (8967/10000)\n",
      "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0286) | Acc: (99.22%) (127/128)\n",
      "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0173) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0226) | Acc: (99.29%) (2669/2688)\n",
      "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0206) | Acc: (99.42%) (3945/3968)\n",
      "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0203) | Acc: (99.47%) (5220/5248)\n",
      "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0189) | Acc: (99.53%) (6497/6528)\n",
      "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0190) | Acc: (99.50%) (7769/7808)\n",
      "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0194) | Acc: (99.45%) (9038/9088)\n",
      "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0200) | Acc: (99.44%) (10310/10368)\n",
      "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0207) | Acc: (99.39%) (11577/11648)\n",
      "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0203) | Acc: (99.40%) (12850/12928)\n",
      "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0207) | Acc: (99.37%) (14119/14208)\n",
      "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0209) | Acc: (99.39%) (15393/15488)\n",
      "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0208) | Acc: (99.39%) (16666/16768)\n",
      "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0204) | Acc: (99.41%) (17942/18048)\n",
      "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0201) | Acc: (99.43%) (19218/19328)\n",
      "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0199) | Acc: (99.45%) (20495/20608)\n",
      "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0201) | Acc: (99.44%) (21765/21888)\n",
      "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0201) | Acc: (99.45%) (23040/23168)\n",
      "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0200) | Acc: (99.46%) (24316/24448)\n",
      "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0201) | Acc: (99.46%) (25590/25728)\n",
      "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0200) | Acc: (99.47%) (26864/27008)\n",
      "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0198) | Acc: (99.47%) (28139/28288)\n",
      "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0198) | Acc: (99.48%) (29413/29568)\n",
      "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0197) | Acc: (99.48%) (30689/30848)\n",
      "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0198) | Acc: (99.49%) (31964/32128)\n",
      "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0198) | Acc: (99.48%) (33235/33408)\n",
      "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0197) | Acc: (99.48%) (34509/34688)\n",
      "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0195) | Acc: (99.49%) (35786/35968)\n",
      "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0196) | Acc: (99.49%) (37059/37248)\n",
      "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0196) | Acc: (99.49%) (38332/38528)\n",
      "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0194) | Acc: (99.49%) (39606/39808)\n",
      "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0195) | Acc: (99.49%) (40879/41088)\n",
      "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0198) | Acc: (99.48%) (42149/42368)\n",
      "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0198) | Acc: (99.48%) (43421/43648)\n",
      "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0197) | Acc: (99.48%) (44696/44928)\n",
      "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0197) | Acc: (99.48%) (45969/46208)\n",
      "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0197) | Acc: (99.48%) (47239/47488)\n",
      "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0195) | Acc: (99.49%) (48518/48768)\n",
      "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0195) | Acc: (99.48%) (49742/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5942) | Acc: (89.62%) (8962/10000)\n",
      "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0236) | Acc: (99.22%) (127/128)\n",
      "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0196) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0186) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0195) | Acc: (99.45%) (3946/3968)\n",
      "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0205) | Acc: (99.37%) (5215/5248)\n",
      "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0213) | Acc: (99.36%) (6486/6528)\n",
      "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0217) | Acc: (99.36%) (7758/7808)\n",
      "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0209) | Acc: (99.37%) (9031/9088)\n",
      "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0206) | Acc: (99.38%) (10304/10368)\n",
      "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0207) | Acc: (99.39%) (11577/11648)\n",
      "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0205) | Acc: (99.41%) (12852/12928)\n",
      "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0211) | Acc: (99.40%) (14123/14208)\n",
      "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0206) | Acc: (99.43%) (15399/15488)\n",
      "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0212) | Acc: (99.40%) (16667/16768)\n",
      "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0216) | Acc: (99.38%) (17937/18048)\n",
      "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0215) | Acc: (99.39%) (25571/25728)\n",
      "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.39%) (26843/27008)\n",
      "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0215) | Acc: (99.39%) (28115/28288)\n",
      "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0214) | Acc: (99.40%) (29390/29568)\n",
      "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0213) | Acc: (99.41%) (30665/30848)\n",
      "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0213) | Acc: (99.41%) (31937/32128)\n",
      "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.40%) (33209/33408)\n",
      "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0212) | Acc: (99.41%) (34484/34688)\n",
      "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0214) | Acc: (99.41%) (35754/35968)\n",
      "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0211) | Acc: (99.42%) (37032/37248)\n",
      "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0212) | Acc: (99.42%) (38306/38528)\n",
      "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0211) | Acc: (99.43%) (39583/39808)\n",
      "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0212) | Acc: (99.43%) (40855/41088)\n",
      "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0213) | Acc: (99.43%) (42127/42368)\n",
      "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0211) | Acc: (99.44%) (43403/43648)\n",
      "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0212) | Acc: (99.43%) (44674/44928)\n",
      "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0211) | Acc: (99.44%) (45947/46208)\n",
      "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0209) | Acc: (99.44%) (47224/47488)\n",
      "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0208) | Acc: (99.45%) (48501/48768)\n",
      "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0208) | Acc: (99.45%) (49724/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5560) | Acc: (90.02%) (9002/10000)\n",
      "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0051) | Acc: (100.00%) (128/128)\n",
      "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0177) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0155) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0150) | Acc: (99.65%) (3954/3968)\n",
      "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0150) | Acc: (99.66%) (5230/5248)\n",
      "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0153) | Acc: (99.62%) (6503/6528)\n",
      "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0157) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0161) | Acc: (99.58%) (9050/9088)\n",
      "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0172) | Acc: (99.54%) (10320/10368)\n",
      "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0184) | Acc: (99.48%) (11588/11648)\n",
      "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0182) | Acc: (99.48%) (12861/12928)\n",
      "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0182) | Acc: (99.49%) (14136/14208)\n",
      "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0181) | Acc: (99.51%) (15412/15488)\n",
      "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0180) | Acc: (99.52%) (16687/16768)\n",
      "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0179) | Acc: (99.51%) (17960/18048)\n",
      "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0181) | Acc: (99.50%) (19232/19328)\n",
      "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0181) | Acc: (99.51%) (20508/20608)\n",
      "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0178) | Acc: (99.53%) (21786/21888)\n",
      "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0177) | Acc: (99.54%) (23061/23168)\n",
      "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0177) | Acc: (99.53%) (24334/24448)\n",
      "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0177) | Acc: (99.53%) (25608/25728)\n",
      "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0178) | Acc: (99.53%) (26881/27008)\n",
      "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0176) | Acc: (99.54%) (28157/28288)\n",
      "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0176) | Acc: (99.54%) (29432/29568)\n",
      "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0178) | Acc: (99.53%) (30703/30848)\n",
      "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0177) | Acc: (99.53%) (31976/32128)\n",
      "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0178) | Acc: (99.54%) (33253/33408)\n",
      "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0178) | Acc: (99.54%) (34528/34688)\n",
      "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0179) | Acc: (99.53%) (35800/35968)\n",
      "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0181) | Acc: (99.53%) (37073/37248)\n",
      "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0181) | Acc: (99.53%) (38346/38528)\n",
      "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0181) | Acc: (99.53%) (39621/39808)\n",
      "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0180) | Acc: (99.54%) (40897/41088)\n",
      "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0178) | Acc: (99.54%) (42173/42368)\n",
      "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0179) | Acc: (99.54%) (43446/43648)\n",
      "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0179) | Acc: (99.53%) (44719/44928)\n",
      "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0180) | Acc: (99.53%) (45993/46208)\n",
      "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0182) | Acc: (99.52%) (47260/47488)\n",
      "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0184) | Acc: (99.51%) (48531/48768)\n",
      "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0187) | Acc: (99.50%) (49751/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5778) | Acc: (89.78%) (8978/10000)\n",
      "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0077) | Acc: (100.00%) (128/128)\n",
      "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0203) | Acc: (99.36%) (1399/1408)\n",
      "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0205) | Acc: (99.33%) (2670/2688)\n",
      "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0184) | Acc: (99.47%) (3947/3968)\n",
      "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0175) | Acc: (99.50%) (5222/5248)\n",
      "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0175) | Acc: (99.51%) (6496/6528)\n",
      "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0180) | Acc: (99.49%) (7768/7808)\n",
      "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0175) | Acc: (99.52%) (9044/9088)\n",
      "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0177) | Acc: (99.50%) (10316/10368)\n",
      "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0180) | Acc: (99.50%) (11590/11648)\n",
      "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0183) | Acc: (99.49%) (12862/12928)\n",
      "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0183) | Acc: (99.51%) (14138/14208)\n",
      "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0185) | Acc: (99.51%) (15412/15488)\n",
      "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0185) | Acc: (99.51%) (16685/16768)\n",
      "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0187) | Acc: (99.50%) (17958/18048)\n",
      "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0187) | Acc: (99.51%) (19234/19328)\n",
      "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0192) | Acc: (99.49%) (20502/20608)\n",
      "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0198) | Acc: (99.46%) (21770/21888)\n",
      "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0195) | Acc: (99.47%) (23046/23168)\n",
      "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0197) | Acc: (99.48%) (24320/24448)\n",
      "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0198) | Acc: (99.47%) (25591/25728)\n",
      "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0194) | Acc: (99.49%) (26869/27008)\n",
      "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0193) | Acc: (99.49%) (28144/28288)\n",
      "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0192) | Acc: (99.49%) (29418/29568)\n",
      "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0192) | Acc: (99.49%) (30690/30848)\n",
      "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0192) | Acc: (99.49%) (31963/32128)\n",
      "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0193) | Acc: (99.49%) (33236/33408)\n",
      "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0193) | Acc: (99.48%) (34507/34688)\n",
      "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0191) | Acc: (99.49%) (35784/35968)\n",
      "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0192) | Acc: (99.48%) (37055/37248)\n",
      "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0190) | Acc: (99.49%) (38331/38528)\n",
      "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0192) | Acc: (99.48%) (39602/39808)\n",
      "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0192) | Acc: (99.48%) (40875/41088)\n",
      "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0194) | Acc: (99.48%) (42147/42368)\n",
      "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0194) | Acc: (99.48%) (43421/43648)\n",
      "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0193) | Acc: (99.48%) (44696/44928)\n",
      "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0193) | Acc: (99.48%) (45968/46208)\n",
      "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0192) | Acc: (99.48%) (47243/47488)\n",
      "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0192) | Acc: (99.48%) (48515/48768)\n",
      "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0193) | Acc: (99.48%) (49741/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5708) | Acc: (89.87%) (8987/10000)\n",
      "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0427) | Acc: (98.44%) (126/128)\n",
      "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0213) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0193) | Acc: (99.59%) (2677/2688)\n",
      "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0200) | Acc: (99.47%) (3947/3968)\n",
      "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0192) | Acc: (99.50%) (5222/5248)\n",
      "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0189) | Acc: (99.49%) (6495/6528)\n",
      "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0189) | Acc: (99.47%) (7767/7808)\n",
      "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0179) | Acc: (99.50%) (9043/9088)\n",
      "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0182) | Acc: (99.51%) (10317/10368)\n",
      "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0179) | Acc: (99.51%) (11591/11648)\n",
      "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0184) | Acc: (99.50%) (12864/12928)\n",
      "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0184) | Acc: (99.50%) (14137/14208)\n",
      "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0188) | Acc: (99.48%) (15407/15488)\n",
      "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0187) | Acc: (99.48%) (16681/16768)\n",
      "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0191) | Acc: (99.46%) (17950/18048)\n",
      "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0197) | Acc: (99.44%) (19219/19328)\n",
      "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0196) | Acc: (99.45%) (20494/20608)\n",
      "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0196) | Acc: (99.44%) (21766/21888)\n",
      "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0194) | Acc: (99.46%) (23042/23168)\n",
      "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0194) | Acc: (99.47%) (24318/24448)\n",
      "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0197) | Acc: (99.46%) (25589/25728)\n",
      "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0197) | Acc: (99.46%) (26861/27008)\n",
      "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0199) | Acc: (99.46%) (28134/28288)\n",
      "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0200) | Acc: (99.45%) (29404/29568)\n",
      "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0200) | Acc: (99.44%) (30674/30848)\n",
      "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0200) | Acc: (99.43%) (31944/32128)\n",
      "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0201) | Acc: (99.42%) (33213/33408)\n",
      "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0200) | Acc: (99.42%) (34488/34688)\n",
      "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0199) | Acc: (99.44%) (35766/35968)\n",
      "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0198) | Acc: (99.44%) (37041/37248)\n",
      "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0199) | Acc: (99.45%) (38316/38528)\n",
      "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0198) | Acc: (99.45%) (39589/39808)\n",
      "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0198) | Acc: (99.45%) (40862/41088)\n",
      "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0197) | Acc: (99.46%) (42139/42368)\n",
      "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0196) | Acc: (99.46%) (43412/43648)\n",
      "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0195) | Acc: (99.46%) (44684/44928)\n",
      "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0196) | Acc: (99.45%) (45956/46208)\n",
      "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0196) | Acc: (99.45%) (47227/47488)\n",
      "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0196) | Acc: (99.45%) (48500/48768)\n",
      "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0196) | Acc: (99.45%) (49725/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6238) | Acc: (89.04%) (8904/10000)\n",
      "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0184) | Acc: (100.00%) (128/128)\n",
      "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0170) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0153) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0182) | Acc: (99.57%) (3951/3968)\n",
      "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0179) | Acc: (99.52%) (5223/5248)\n",
      "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.54%) (6498/6528)\n",
      "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0182) | Acc: (99.51%) (7770/7808)\n",
      "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0182) | Acc: (99.53%) (9045/9088)\n",
      "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0177) | Acc: (99.57%) (10323/10368)\n",
      "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0179) | Acc: (99.54%) (11594/11648)\n",
      "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0172) | Acc: (99.57%) (12872/12928)\n",
      "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0172) | Acc: (99.58%) (14148/14208)\n",
      "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0171) | Acc: (99.60%) (15426/15488)\n",
      "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0169) | Acc: (99.61%) (16702/16768)\n",
      "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0165) | Acc: (99.62%) (17979/18048)\n",
      "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0167) | Acc: (99.61%) (19252/19328)\n",
      "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0169) | Acc: (99.61%) (20527/20608)\n",
      "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0169) | Acc: (99.61%) (21802/21888)\n",
      "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0168) | Acc: (99.60%) (23076/23168)\n",
      "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0168) | Acc: (99.60%) (24350/24448)\n",
      "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0169) | Acc: (99.60%) (25625/25728)\n",
      "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0168) | Acc: (99.60%) (26900/27008)\n",
      "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0171) | Acc: (99.59%) (28172/28288)\n",
      "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0174) | Acc: (99.58%) (29445/29568)\n",
      "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0175) | Acc: (99.59%) (30720/30848)\n",
      "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0176) | Acc: (99.58%) (31994/32128)\n",
      "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0179) | Acc: (99.57%) (33264/33408)\n",
      "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0179) | Acc: (99.56%) (34536/34688)\n",
      "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0179) | Acc: (99.56%) (35810/35968)\n",
      "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0179) | Acc: (99.56%) (37083/37248)\n",
      "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0178) | Acc: (99.56%) (38358/38528)\n",
      "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0178) | Acc: (99.57%) (39635/39808)\n",
      "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0180) | Acc: (99.56%) (40906/41088)\n",
      "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0179) | Acc: (99.55%) (42178/42368)\n",
      "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0179) | Acc: (99.55%) (43452/43648)\n",
      "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0180) | Acc: (99.54%) (44722/44928)\n",
      "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0179) | Acc: (99.54%) (45997/46208)\n",
      "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0181) | Acc: (99.54%) (47268/47488)\n",
      "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.53%) (48538/48768)\n",
      "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0184) | Acc: (99.52%) (49760/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5935) | Acc: (89.75%) (8975/10000)\n",
      "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0156) | Acc: (100.00%) (128/128)\n",
      "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0233) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0226) | Acc: (99.44%) (2673/2688)\n",
      "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0241) | Acc: (99.37%) (3943/3968)\n",
      "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0233) | Acc: (99.35%) (5214/5248)\n",
      "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0230) | Acc: (99.36%) (6486/6528)\n",
      "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0218) | Acc: (99.40%) (7761/7808)\n",
      "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0214) | Acc: (99.42%) (9035/9088)\n",
      "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0214) | Acc: (99.40%) (10306/10368)\n",
      "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0204) | Acc: (99.44%) (11583/11648)\n",
      "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0202) | Acc: (99.44%) (12855/12928)\n",
      "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0199) | Acc: (99.46%) (14131/14208)\n",
      "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0203) | Acc: (99.45%) (15403/15488)\n",
      "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0207) | Acc: (99.43%) (16673/16768)\n",
      "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0205) | Acc: (99.42%) (17944/18048)\n",
      "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0206) | Acc: (99.44%) (19219/19328)\n",
      "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0201) | Acc: (99.45%) (20494/20608)\n",
      "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0199) | Acc: (99.46%) (21769/21888)\n",
      "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0195) | Acc: (99.47%) (23045/23168)\n",
      "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0195) | Acc: (99.48%) (24321/24448)\n",
      "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0195) | Acc: (99.48%) (25593/25728)\n",
      "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0194) | Acc: (99.48%) (26867/27008)\n",
      "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0197) | Acc: (99.47%) (28138/28288)\n",
      "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0195) | Acc: (99.48%) (29413/29568)\n",
      "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0193) | Acc: (99.47%) (30686/30848)\n",
      "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0195) | Acc: (99.47%) (31959/32128)\n",
      "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0192) | Acc: (99.49%) (33236/33408)\n",
      "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0192) | Acc: (99.49%) (34511/34688)\n",
      "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0191) | Acc: (99.48%) (35782/35968)\n",
      "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0194) | Acc: (99.47%) (37050/37248)\n",
      "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0193) | Acc: (99.47%) (38324/38528)\n",
      "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0194) | Acc: (99.47%) (39596/39808)\n",
      "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0193) | Acc: (99.48%) (40873/41088)\n",
      "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0193) | Acc: (99.47%) (42145/42368)\n",
      "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0194) | Acc: (99.47%) (43416/43648)\n",
      "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0192) | Acc: (99.47%) (44692/44928)\n",
      "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0191) | Acc: (99.48%) (45969/46208)\n",
      "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0190) | Acc: (99.49%) (47245/47488)\n",
      "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0189) | Acc: (99.50%) (48523/48768)\n",
      "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0189) | Acc: (99.50%) (49752/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6078) | Acc: (89.90%) (8990/10000)\n",
      "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0116) | Acc: (100.00%) (128/128)\n",
      "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0187) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0197) | Acc: (99.59%) (2677/2688)\n",
      "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0201) | Acc: (99.52%) (3949/3968)\n",
      "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0194) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0188) | Acc: (99.59%) (6501/6528)\n",
      "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0178) | Acc: (99.63%) (7779/7808)\n",
      "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0178) | Acc: (99.64%) (9055/9088)\n",
      "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0182) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0182) | Acc: (99.60%) (11601/11648)\n",
      "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0179) | Acc: (99.61%) (12877/12928)\n",
      "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0176) | Acc: (99.61%) (14153/14208)\n",
      "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0180) | Acc: (99.59%) (15425/15488)\n",
      "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0177) | Acc: (99.61%) (16703/16768)\n",
      "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0176) | Acc: (99.61%) (17978/18048)\n",
      "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0175) | Acc: (99.61%) (19252/19328)\n",
      "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0174) | Acc: (99.61%) (20527/20608)\n",
      "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0176) | Acc: (99.58%) (21797/21888)\n",
      "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0177) | Acc: (99.58%) (23070/23168)\n",
      "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0176) | Acc: (99.58%) (24345/24448)\n",
      "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0175) | Acc: (99.58%) (25621/25728)\n",
      "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0176) | Acc: (99.58%) (26894/27008)\n",
      "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0176) | Acc: (99.58%) (28169/28288)\n",
      "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0175) | Acc: (99.58%) (29443/29568)\n",
      "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.57%) (30715/30848)\n",
      "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0175) | Acc: (99.58%) (31992/32128)\n",
      "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0174) | Acc: (99.59%) (33271/33408)\n",
      "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0174) | Acc: (99.59%) (34546/34688)\n",
      "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0174) | Acc: (99.59%) (35820/35968)\n",
      "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0175) | Acc: (99.58%) (37090/37248)\n",
      "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0174) | Acc: (99.58%) (38366/38528)\n",
      "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0173) | Acc: (99.59%) (39643/39808)\n",
      "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0174) | Acc: (99.58%) (40915/41088)\n",
      "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0175) | Acc: (99.58%) (42190/42368)\n",
      "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0176) | Acc: (99.57%) (43461/43648)\n",
      "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0174) | Acc: (99.58%) (44740/44928)\n",
      "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.58%) (46016/46208)\n",
      "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0175) | Acc: (99.58%) (47287/47488)\n",
      "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0177) | Acc: (99.57%) (48557/48768)\n",
      "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0176) | Acc: (99.57%) (49784/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6037) | Acc: (89.81%) (8981/10000)\n",
      "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0126) | Acc: (100.00%) (128/128)\n",
      "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0207) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0191) | Acc: (99.40%) (2672/2688)\n",
      "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0185) | Acc: (99.50%) (3948/3968)\n",
      "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0191) | Acc: (99.49%) (5221/5248)\n",
      "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0189) | Acc: (99.48%) (6494/6528)\n",
      "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0175) | Acc: (99.54%) (7772/7808)\n",
      "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0180) | Acc: (99.53%) (9045/9088)\n",
      "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0178) | Acc: (99.53%) (10319/10368)\n",
      "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0180) | Acc: (99.53%) (11593/11648)\n",
      "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0175) | Acc: (99.56%) (12871/12928)\n",
      "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0175) | Acc: (99.58%) (14149/14208)\n",
      "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.60%) (15426/15488)\n",
      "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0174) | Acc: (99.58%) (16697/16768)\n",
      "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0174) | Acc: (99.58%) (17973/18048)\n",
      "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0175) | Acc: (99.59%) (19248/19328)\n",
      "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0175) | Acc: (99.58%) (20522/20608)\n",
      "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0178) | Acc: (99.58%) (21795/21888)\n",
      "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0177) | Acc: (99.58%) (23070/23168)\n",
      "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0174) | Acc: (99.59%) (24347/24448)\n",
      "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0173) | Acc: (99.59%) (25623/25728)\n",
      "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0172) | Acc: (99.60%) (26900/27008)\n",
      "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0173) | Acc: (99.60%) (28176/28288)\n",
      "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0172) | Acc: (99.60%) (29451/29568)\n",
      "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0173) | Acc: (99.60%) (30724/30848)\n",
      "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0172) | Acc: (99.60%) (32001/32128)\n",
      "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0170) | Acc: (99.61%) (33278/33408)\n",
      "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0173) | Acc: (99.60%) (34550/34688)\n",
      "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0173) | Acc: (99.60%) (35823/35968)\n",
      "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0175) | Acc: (99.58%) (37093/37248)\n",
      "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0174) | Acc: (99.58%) (38368/38528)\n",
      "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0173) | Acc: (99.59%) (39644/39808)\n",
      "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0176) | Acc: (99.58%) (40914/41088)\n",
      "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0178) | Acc: (99.56%) (42183/42368)\n",
      "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0179) | Acc: (99.56%) (43455/43648)\n",
      "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0178) | Acc: (99.56%) (44731/44928)\n",
      "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0178) | Acc: (99.57%) (46007/46208)\n",
      "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0177) | Acc: (99.57%) (47282/47488)\n",
      "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0178) | Acc: (99.57%) (48556/48768)\n",
      "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0178) | Acc: (99.57%) (49784/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5865) | Acc: (89.81%) (8981/10000)\n",
      "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0377) | Acc: (99.22%) (127/128)\n",
      "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0186) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0167) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0185) | Acc: (99.52%) (3949/3968)\n",
      "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0186) | Acc: (99.52%) (5223/5248)\n",
      "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0194) | Acc: (99.43%) (6491/6528)\n",
      "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0192) | Acc: (99.46%) (7766/7808)\n",
      "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0190) | Acc: (99.46%) (9039/9088)\n",
      "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0189) | Acc: (99.47%) (10313/10368)\n",
      "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0189) | Acc: (99.46%) (11585/11648)\n",
      "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0188) | Acc: (99.47%) (12859/12928)\n",
      "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0196) | Acc: (99.44%) (14129/14208)\n",
      "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0194) | Acc: (99.46%) (15405/15488)\n",
      "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0198) | Acc: (99.45%) (16675/16768)\n",
      "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0202) | Acc: (99.43%) (17946/18048)\n",
      "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0199) | Acc: (99.45%) (19221/19328)\n",
      "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0196) | Acc: (99.46%) (20497/20608)\n",
      "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0194) | Acc: (99.46%) (21770/21888)\n",
      "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0193) | Acc: (99.46%) (23043/23168)\n",
      "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0192) | Acc: (99.46%) (24316/24448)\n",
      "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0191) | Acc: (99.47%) (25591/25728)\n",
      "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0188) | Acc: (99.48%) (26868/27008)\n",
      "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0187) | Acc: (99.49%) (28144/28288)\n",
      "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0187) | Acc: (99.49%) (29418/29568)\n",
      "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0185) | Acc: (99.50%) (30693/30848)\n",
      "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0183) | Acc: (99.51%) (31970/32128)\n",
      "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0185) | Acc: (99.51%) (33243/33408)\n",
      "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0184) | Acc: (99.51%) (34517/34688)\n",
      "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0183) | Acc: (99.51%) (35793/35968)\n",
      "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0182) | Acc: (99.52%) (37068/37248)\n",
      "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0182) | Acc: (99.52%) (38344/38528)\n",
      "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0183) | Acc: (99.52%) (39615/39808)\n",
      "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0183) | Acc: (99.51%) (40887/41088)\n",
      "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0181) | Acc: (99.52%) (42164/42368)\n",
      "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0184) | Acc: (99.51%) (43432/43648)\n",
      "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0183) | Acc: (99.50%) (44705/44928)\n",
      "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0182) | Acc: (99.50%) (45979/46208)\n",
      "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0182) | Acc: (99.50%) (47251/47488)\n",
      "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.51%) (48527/48768)\n",
      "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.51%) (49754/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5965) | Acc: (89.84%) (8984/10000)\n",
      "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0140) | Acc: (100.00%) (128/128)\n",
      "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0159) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0168) | Acc: (99.57%) (3951/3968)\n",
      "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0156) | Acc: (99.64%) (5229/5248)\n",
      "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0153) | Acc: (99.68%) (6507/6528)\n",
      "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.62%) (7778/7808)\n",
      "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0166) | Acc: (99.61%) (9053/9088)\n",
      "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0167) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0161) | Acc: (99.64%) (11606/11648)\n",
      "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0160) | Acc: (99.64%) (12881/12928)\n",
      "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0158) | Acc: (99.66%) (14159/14208)\n",
      "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0158) | Acc: (99.66%) (15435/15488)\n",
      "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0159) | Acc: (99.64%) (16708/16768)\n",
      "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0159) | Acc: (99.65%) (17984/18048)\n",
      "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0157) | Acc: (99.65%) (19261/19328)\n",
      "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0157) | Acc: (99.66%) (20538/20608)\n",
      "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0159) | Acc: (99.64%) (21809/21888)\n",
      "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0160) | Acc: (99.64%) (23084/23168)\n",
      "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0158) | Acc: (99.64%) (24360/24448)\n",
      "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0157) | Acc: (99.64%) (25636/25728)\n",
      "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0160) | Acc: (99.63%) (26908/27008)\n",
      "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0161) | Acc: (99.63%) (28183/28288)\n",
      "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0161) | Acc: (99.63%) (29459/29568)\n",
      "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0162) | Acc: (99.63%) (30734/30848)\n",
      "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0164) | Acc: (99.62%) (32006/32128)\n",
      "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0165) | Acc: (99.61%) (33279/33408)\n",
      "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0164) | Acc: (99.62%) (34556/34688)\n",
      "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0165) | Acc: (99.61%) (35828/35968)\n",
      "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0166) | Acc: (99.61%) (37101/37248)\n",
      "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0167) | Acc: (99.59%) (38371/38528)\n",
      "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0170) | Acc: (99.58%) (39642/39808)\n",
      "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0170) | Acc: (99.58%) (40916/41088)\n",
      "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0169) | Acc: (99.58%) (42189/42368)\n",
      "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0170) | Acc: (99.58%) (43463/43648)\n",
      "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0169) | Acc: (99.58%) (44741/44928)\n",
      "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0169) | Acc: (99.59%) (46017/46208)\n",
      "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0169) | Acc: (99.59%) (47292/47488)\n",
      "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0171) | Acc: (99.58%) (48561/48768)\n",
      "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0171) | Acc: (99.57%) (49786/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5641) | Acc: (90.16%) (9016/10000)\n",
      "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0195) | Acc: (99.22%) (127/128)\n",
      "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0200) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0175) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0164) | Acc: (99.70%) (3956/3968)\n",
      "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0170) | Acc: (99.62%) (5228/5248)\n",
      "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0164) | Acc: (99.62%) (6503/6528)\n",
      "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0169) | Acc: (99.59%) (7776/7808)\n",
      "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0170) | Acc: (99.58%) (9050/9088)\n",
      "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0170) | Acc: (99.59%) (10325/10368)\n",
      "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0171) | Acc: (99.58%) (11599/11648)\n",
      "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0176) | Acc: (99.57%) (12872/12928)\n",
      "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0171) | Acc: (99.58%) (14148/14208)\n",
      "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0167) | Acc: (99.59%) (15424/15488)\n",
      "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0165) | Acc: (99.60%) (16701/16768)\n",
      "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0162) | Acc: (99.61%) (17978/18048)\n",
      "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0160) | Acc: (99.62%) (19255/19328)\n",
      "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0159) | Acc: (99.64%) (20534/20608)\n",
      "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.62%) (21805/21888)\n",
      "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.60%) (23076/23168)\n",
      "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0161) | Acc: (99.61%) (24352/24448)\n",
      "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0160) | Acc: (99.60%) (25626/25728)\n",
      "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0162) | Acc: (99.60%) (26899/27008)\n",
      "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0164) | Acc: (99.59%) (28172/28288)\n",
      "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0163) | Acc: (99.60%) (29449/29568)\n",
      "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.60%) (30724/30848)\n",
      "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0165) | Acc: (99.59%) (31995/32128)\n",
      "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0164) | Acc: (99.60%) (33273/33408)\n",
      "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0164) | Acc: (99.60%) (34548/34688)\n",
      "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0166) | Acc: (99.59%) (35821/35968)\n",
      "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0164) | Acc: (99.60%) (37099/37248)\n",
      "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0165) | Acc: (99.60%) (38372/38528)\n",
      "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0166) | Acc: (99.59%) (39645/39808)\n",
      "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0165) | Acc: (99.60%) (40922/41088)\n",
      "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0165) | Acc: (99.59%) (42194/42368)\n",
      "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0166) | Acc: (99.59%) (43469/43648)\n",
      "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0164) | Acc: (99.59%) (44745/44928)\n",
      "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0167) | Acc: (99.58%) (46015/46208)\n",
      "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0166) | Acc: (99.58%) (47288/47488)\n",
      "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0167) | Acc: (99.58%) (48563/48768)\n",
      "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0169) | Acc: (99.57%) (49784/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5765) | Acc: (89.86%) (8986/10000)\n",
      "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0094) | Acc: (100.00%) (128/128)\n",
      "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0124) | Acc: (99.86%) (1406/1408)\n",
      "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0139) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0152) | Acc: (99.67%) (3955/3968)\n",
      "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0159) | Acc: (99.64%) (5229/5248)\n",
      "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0161) | Acc: (99.62%) (6503/6528)\n",
      "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0158) | Acc: (99.64%) (7780/7808)\n",
      "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.66%) (9057/9088)\n",
      "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0159) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0169) | Acc: (99.59%) (11600/11648)\n",
      "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0167) | Acc: (99.59%) (12875/12928)\n",
      "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0169) | Acc: (99.57%) (14147/14208)\n",
      "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0172) | Acc: (99.57%) (15421/15488)\n",
      "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0173) | Acc: (99.55%) (16692/16768)\n",
      "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0171) | Acc: (99.56%) (17968/18048)\n",
      "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0175) | Acc: (99.54%) (19239/19328)\n",
      "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0175) | Acc: (99.55%) (20516/20608)\n",
      "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0173) | Acc: (99.57%) (21794/21888)\n",
      "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0173) | Acc: (99.57%) (23068/23168)\n",
      "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0171) | Acc: (99.58%) (24345/24448)\n",
      "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0174) | Acc: (99.57%) (25617/25728)\n",
      "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0173) | Acc: (99.57%) (26891/27008)\n",
      "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0154) | Acc: (99.60%) (9052/9088)\n",
      "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.60%) (10327/10368)\n",
      "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0158) | Acc: (99.59%) (11600/11648)\n",
      "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.58%) (12874/12928)\n",
      "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.58%) (14149/14208)\n",
      "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0162) | Acc: (99.58%) (17973/18048)\n",
      "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0164) | Acc: (99.58%) (19246/19328)\n",
      "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0162) | Acc: (99.58%) (20522/20608)\n",
      "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0165) | Acc: (99.57%) (21793/21888)\n",
      "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.58%) (23071/23168)\n",
      "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0164) | Acc: (99.59%) (24347/24448)\n",
      "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0164) | Acc: (99.60%) (25624/25728)\n",
      "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0165) | Acc: (99.60%) (26900/27008)\n",
      "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0165) | Acc: (99.60%) (28175/28288)\n",
      "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0165) | Acc: (99.59%) (29447/29568)\n",
      "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0165) | Acc: (99.59%) (30723/30848)\n",
      "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0166) | Acc: (99.59%) (31995/32128)\n",
      "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0165) | Acc: (99.60%) (33273/33408)\n",
      "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0165) | Acc: (99.60%) (34548/34688)\n",
      "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0166) | Acc: (99.59%) (35822/35968)\n",
      "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0168) | Acc: (99.58%) (37093/37248)\n",
      "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0168) | Acc: (99.58%) (38365/38528)\n",
      "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0169) | Acc: (99.57%) (39638/39808)\n",
      "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0170) | Acc: (99.57%) (40911/41088)\n",
      "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0169) | Acc: (99.57%) (42185/42368)\n",
      "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0168) | Acc: (99.57%) (43461/43648)\n",
      "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0168) | Acc: (99.57%) (44735/44928)\n",
      "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0169) | Acc: (99.56%) (46006/46208)\n",
      "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0169) | Acc: (99.57%) (47282/47488)\n",
      "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0170) | Acc: (99.56%) (48554/48768)\n",
      "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0170) | Acc: (99.56%) (49779/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5942) | Acc: (89.85%) (8985/10000)\n",
      "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0141) | Acc: (100.00%) (128/128)\n",
      "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0216) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0207) | Acc: (99.37%) (2671/2688)\n",
      "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0198) | Acc: (99.40%) (3944/3968)\n",
      "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0181) | Acc: (99.43%) (5218/5248)\n",
      "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0179) | Acc: (99.49%) (6495/6528)\n",
      "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0173) | Acc: (99.55%) (7773/7808)\n",
      "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0172) | Acc: (99.55%) (9047/9088)\n",
      "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0169) | Acc: (99.58%) (10324/10368)\n",
      "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0166) | Acc: (99.59%) (11600/11648)\n",
      "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0176) | Acc: (99.55%) (12870/12928)\n",
      "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0174) | Acc: (99.56%) (14146/14208)\n",
      "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0171) | Acc: (99.58%) (15423/15488)\n",
      "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0166) | Acc: (99.61%) (16702/16768)\n",
      "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0164) | Acc: (99.61%) (17978/18048)\n",
      "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0164) | Acc: (99.61%) (19253/19328)\n",
      "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0162) | Acc: (99.63%) (20531/20608)\n",
      "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0164) | Acc: (99.61%) (21803/21888)\n",
      "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.62%) (23079/23168)\n",
      "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0163) | Acc: (99.61%) (24352/24448)\n",
      "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0160) | Acc: (99.62%) (25630/25728)\n",
      "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0159) | Acc: (99.61%) (26903/27008)\n",
      "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0159) | Acc: (99.61%) (28178/28288)\n",
      "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0159) | Acc: (99.60%) (29451/29568)\n",
      "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0158) | Acc: (99.61%) (30727/30848)\n",
      "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0160) | Acc: (99.61%) (32002/32128)\n",
      "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0161) | Acc: (99.60%) (33275/33408)\n",
      "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0159) | Acc: (99.61%) (34552/34688)\n",
      "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0161) | Acc: (99.59%) (35821/35968)\n",
      "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0163) | Acc: (99.58%) (37091/37248)\n",
      "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0162) | Acc: (99.58%) (38366/38528)\n",
      "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0162) | Acc: (99.58%) (39641/39808)\n",
      "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0163) | Acc: (99.58%) (40915/41088)\n",
      "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0162) | Acc: (99.58%) (42192/42368)\n",
      "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0163) | Acc: (99.58%) (43466/43648)\n",
      "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0163) | Acc: (99.58%) (44741/44928)\n",
      "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0162) | Acc: (99.58%) (46016/46208)\n",
      "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0162) | Acc: (99.59%) (47291/47488)\n",
      "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0162) | Acc: (99.59%) (48568/48768)\n",
      "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0162) | Acc: (99.59%) (49793/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6011) | Acc: (89.63%) (8963/10000)\n",
      "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0226) | Acc: (99.22%) (127/128)\n",
      "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0136) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0159) | Acc: (99.67%) (2679/2688)\n",
      "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.70%) (3956/3968)\n",
      "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0139) | Acc: (99.68%) (5231/5248)\n",
      "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0135) | Acc: (99.68%) (6507/6528)\n",
      "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0143) | Acc: (99.62%) (7778/7808)\n",
      "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0141) | Acc: (99.65%) (9056/9088)\n",
      "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.64%) (10331/10368)\n",
      "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0137) | Acc: (99.66%) (11608/11648)\n",
      "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0143) | Acc: (99.64%) (12882/12928)\n",
      "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0140) | Acc: (99.67%) (14161/14208)\n",
      "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0146) | Acc: (99.64%) (15432/15488)\n",
      "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0145) | Acc: (99.64%) (16707/16768)\n",
      "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0148) | Acc: (99.62%) (17980/18048)\n",
      "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0150) | Acc: (99.62%) (19254/19328)\n",
      "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0151) | Acc: (99.61%) (20528/20608)\n",
      "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.61%) (21802/21888)\n",
      "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0167) | Acc: (99.54%) (43448/43648)\n",
      "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.55%) (44725/44928)\n",
      "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0166) | Acc: (99.54%) (45996/46208)\n",
      "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0167) | Acc: (99.54%) (47268/47488)\n",
      "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0170) | Acc: (99.53%) (48540/48768)\n",
      "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0170) | Acc: (99.53%) (49766/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5413) | Acc: (90.28%) (9028/10000)\n",
      "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0082) | Acc: (100.00%) (128/128)\n",
      "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0149) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0167) | Acc: (99.48%) (2674/2688)\n",
      "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0168) | Acc: (99.47%) (3947/3968)\n",
      "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0167) | Acc: (99.52%) (5223/5248)\n",
      "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0163) | Acc: (99.57%) (6500/6528)\n",
      "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0159) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0153) | Acc: (99.65%) (9056/9088)\n",
      "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0146) | Acc: (99.68%) (10335/10368)\n",
      "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0143) | Acc: (99.69%) (11612/11648)\n",
      "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0140) | Acc: (99.71%) (12890/12928)\n",
      "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0139) | Acc: (99.70%) (14166/14208)\n",
      "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0138) | Acc: (99.72%) (15445/15488)\n",
      "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0138) | Acc: (99.70%) (16718/16768)\n",
      "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0142) | Acc: (99.68%) (17991/18048)\n",
      "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0141) | Acc: (99.69%) (19268/19328)\n",
      "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0143) | Acc: (99.68%) (20542/20608)\n",
      "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0142) | Acc: (99.69%) (21820/21888)\n",
      "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0145) | Acc: (99.68%) (23095/23168)\n",
      "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.68%) (24369/24448)\n",
      "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0148) | Acc: (99.67%) (25643/25728)\n",
      "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0146) | Acc: (99.67%) (26920/27008)\n",
      "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0149) | Acc: (99.66%) (28192/28288)\n",
      "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0148) | Acc: (99.67%) (29471/29568)\n",
      "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0148) | Acc: (99.66%) (30744/30848)\n",
      "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0147) | Acc: (99.66%) (32020/32128)\n",
      "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.65%) (33291/33408)\n",
      "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0152) | Acc: (99.65%) (34566/34688)\n",
      "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0155) | Acc: (99.63%) (35836/35968)\n",
      "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0156) | Acc: (99.63%) (37110/37248)\n",
      "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0156) | Acc: (99.63%) (38385/38528)\n",
      "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0155) | Acc: (99.63%) (39660/39808)\n",
      "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0154) | Acc: (99.63%) (40937/41088)\n",
      "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0154) | Acc: (99.63%) (42211/42368)\n",
      "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0153) | Acc: (99.63%) (43487/43648)\n",
      "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0153) | Acc: (99.63%) (44760/44928)\n",
      "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0152) | Acc: (99.63%) (46039/46208)\n",
      "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0151) | Acc: (99.64%) (47315/47488)\n",
      "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0152) | Acc: (99.64%) (48591/48768)\n",
      "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0150) | Acc: (99.64%) (49822/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5757) | Acc: (90.03%) (9003/10000)\n",
      "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0101) | Acc: (100.00%) (128/128)\n",
      "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0130) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0150) | Acc: (99.67%) (2679/2688)\n",
      "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0146) | Acc: (99.70%) (3956/3968)\n",
      "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0151) | Acc: (99.70%) (5232/5248)\n",
      "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0142) | Acc: (99.75%) (6512/6528)\n",
      "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0147) | Acc: (99.71%) (7785/7808)\n",
      "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0144) | Acc: (99.69%) (9060/9088)\n",
      "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0150) | Acc: (99.63%) (10330/10368)\n",
      "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0148) | Acc: (99.63%) (11605/11648)\n",
      "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0149) | Acc: (99.63%) (12880/12928)\n",
      "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0150) | Acc: (99.61%) (14152/14208)\n",
      "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0153) | Acc: (99.59%) (15424/15488)\n",
      "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0153) | Acc: (99.58%) (16697/16768)\n",
      "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.58%) (17973/18048)\n",
      "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.59%) (19249/19328)\n",
      "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0151) | Acc: (99.60%) (20525/20608)\n",
      "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0152) | Acc: (99.59%) (21798/21888)\n",
      "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0150) | Acc: (99.61%) (23077/23168)\n",
      "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0151) | Acc: (99.61%) (24352/24448)\n",
      "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0151) | Acc: (99.61%) (25627/25728)\n",
      "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0150) | Acc: (99.61%) (26904/27008)\n",
      "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0150) | Acc: (99.62%) (28180/28288)\n",
      "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0153) | Acc: (99.61%) (29453/29568)\n",
      "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0154) | Acc: (99.60%) (30726/30848)\n",
      "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0155) | Acc: (99.60%) (32000/32128)\n",
      "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0154) | Acc: (99.61%) (33277/33408)\n",
      "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0153) | Acc: (99.62%) (34555/34688)\n",
      "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0152) | Acc: (99.62%) (35832/35968)\n",
      "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0151) | Acc: (99.63%) (37109/37248)\n",
      "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0149) | Acc: (99.63%) (38387/38528)\n",
      "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0150) | Acc: (99.64%) (39663/39808)\n",
      "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0149) | Acc: (99.64%) (40939/41088)\n",
      "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0149) | Acc: (99.64%) (42216/42368)\n",
      "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0149) | Acc: (99.64%) (43492/43648)\n",
      "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0151) | Acc: (99.64%) (44767/44928)\n",
      "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0151) | Acc: (99.64%) (46042/46208)\n",
      "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0152) | Acc: (99.64%) (47316/47488)\n",
      "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0151) | Acc: (99.64%) (48594/48768)\n",
      "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0152) | Acc: (99.64%) (49818/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5872) | Acc: (89.97%) (8997/10000)\n",
      "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0315) | Acc: (99.22%) (127/128)\n",
      "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0196) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0176) | Acc: (99.52%) (2675/2688)\n",
      "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0163) | Acc: (99.55%) (3950/3968)\n",
      "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0158) | Acc: (99.58%) (5226/5248)\n",
      "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0167) | Acc: (99.56%) (6499/6528)\n",
      "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0154) | Acc: (99.62%) (7778/7808)\n",
      "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0149) | Acc: (99.64%) (9055/9088)\n",
      "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0146) | Acc: (99.65%) (10332/10368)\n",
      "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.61%) (11603/11648)\n",
      "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.59%) (12875/12928)\n",
      "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.58%) (14149/14208)\n",
      "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0165) | Acc: (99.54%) (15417/15488)\n",
      "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0165) | Acc: (99.55%) (16693/16768)\n",
      "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0165) | Acc: (99.56%) (17968/18048)\n",
      "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0162) | Acc: (99.57%) (19244/19328)\n",
      "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0160) | Acc: (99.58%) (20521/20608)\n",
      "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.57%) (21793/21888)\n",
      "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0161) | Acc: (99.56%) (23067/23168)\n",
      "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0162) | Acc: (99.55%) (24338/24448)\n",
      "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0163) | Acc: (99.55%) (25613/25728)\n",
      "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0165) | Acc: (99.53%) (26882/27008)\n",
      "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0164) | Acc: (99.53%) (28155/28288)\n",
      "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0163) | Acc: (99.53%) (29428/29568)\n",
      "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0165) | Acc: (99.52%) (30701/30848)\n",
      "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0165) | Acc: (99.53%) (31976/32128)\n",
      "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0165) | Acc: (99.53%) (33250/33408)\n",
      "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0165) | Acc: (99.53%) (34526/34688)\n",
      "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0170) | Acc: (99.52%) (35794/35968)\n",
      "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0170) | Acc: (99.51%) (37067/37248)\n",
      "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0171) | Acc: (99.50%) (38336/38528)\n",
      "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0170) | Acc: (99.51%) (39612/39808)\n",
      "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0169) | Acc: (99.51%) (40886/41088)\n",
      "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0167) | Acc: (99.52%) (42164/42368)\n",
      "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0168) | Acc: (99.51%) (43433/43648)\n",
      "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.51%) (44709/44928)\n",
      "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0166) | Acc: (99.52%) (45984/46208)\n",
      "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0165) | Acc: (99.53%) (47263/47488)\n",
      "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0165) | Acc: (99.52%) (48536/48768)\n",
      "# TEST : Loss: (0.5946) | Acc: (89.81%) (8981/10000)\n",
      "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0097) | Acc: (100.00%) (128/128)\n",
      "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0134) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0135) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0135) | Acc: (99.22%) (127/128)\n",
      "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0158) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0174) | Acc: (99.50%) (3948/3968)\n",
      "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0166) | Acc: (99.52%) (5223/5248)\n",
      "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0159) | Acc: (99.54%) (6498/6528)\n",
      "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0164) | Acc: (99.51%) (7770/7808)\n",
      "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0156) | Acc: (99.54%) (9046/9088)\n",
      "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0157) | Acc: (99.54%) (10320/10368)\n",
      "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0159) | Acc: (99.54%) (11594/11648)\n",
      "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0159) | Acc: (99.54%) (12869/12928)\n",
      "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.56%) (14146/14208)\n",
      "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0159) | Acc: (99.57%) (15421/15488)\n",
      "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0159) | Acc: (99.56%) (16695/16768)\n",
      "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0159) | Acc: (99.56%) (17969/18048)\n",
      "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0157) | Acc: (99.57%) (19245/19328)\n",
      "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0159) | Acc: (99.56%) (20518/20608)\n",
      "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0156) | Acc: (99.58%) (21796/21888)\n",
      "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0155) | Acc: (99.58%) (23071/23168)\n",
      "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0144) | Acc: (99.63%) (40937/41088)\n",
      "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0143) | Acc: (99.63%) (42212/42368)\n",
      "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0144) | Acc: (99.63%) (43486/43648)\n",
      "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0143) | Acc: (99.63%) (44761/44928)\n",
      "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0143) | Acc: (99.63%) (46039/46208)\n",
      "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0142) | Acc: (99.64%) (47317/47488)\n",
      "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0142) | Acc: (99.65%) (48595/48768)\n",
      "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0142) | Acc: (99.64%) (49822/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5821) | Acc: (90.05%) (9005/10000)\n",
      "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0036) | Acc: (100.00%) (128/128)\n",
      "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0123) | Acc: (99.86%) (1406/1408)\n",
      "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0120) | Acc: (99.89%) (2685/2688)\n",
      "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.87%) (3963/3968)\n",
      "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0127) | Acc: (99.87%) (5241/5248)\n",
      "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0126) | Acc: (99.86%) (6519/6528)\n",
      "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0129) | Acc: (99.82%) (7794/7808)\n",
      "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0132) | Acc: (99.80%) (9070/9088)\n",
      "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0132) | Acc: (99.79%) (10346/10368)\n",
      "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0131) | Acc: (99.76%) (11620/11648)\n",
      "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0133) | Acc: (99.72%) (12892/12928)\n",
      "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.72%) (14168/14208)\n",
      "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0137) | Acc: (99.72%) (15445/15488)\n",
      "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0137) | Acc: (99.71%) (16720/16768)\n",
      "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0134) | Acc: (99.73%) (18000/18048)\n",
      "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0135) | Acc: (99.73%) (19276/19328)\n",
      "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0137) | Acc: (99.72%) (20551/20608)\n",
      "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.73%) (21828/21888)\n",
      "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0136) | Acc: (99.71%) (23101/23168)\n",
      "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0136) | Acc: (99.72%) (24379/24448)\n",
      "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0135) | Acc: (99.72%) (25657/25728)\n",
      "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0134) | Acc: (99.72%) (26933/27008)\n",
      "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0137) | Acc: (99.71%) (28206/28288)\n",
      "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0138) | Acc: (99.71%) (29482/29568)\n",
      "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0139) | Acc: (99.70%) (30756/30848)\n",
      "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.69%) (32030/32128)\n",
      "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0139) | Acc: (99.70%) (33307/33408)\n",
      "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0139) | Acc: (99.71%) (34586/34688)\n",
      "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0139) | Acc: (99.71%) (35862/35968)\n",
      "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0138) | Acc: (99.71%) (37139/37248)\n",
      "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.70%) (38414/38528)\n",
      "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0138) | Acc: (99.70%) (39690/39808)\n",
      "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0138) | Acc: (99.71%) (40967/41088)\n",
      "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.69%) (42238/42368)\n",
      "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0141) | Acc: (99.70%) (43515/43648)\n",
      "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0164) | Acc: (99.52%) (16688/16768)\n",
      "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0171) | Acc: (99.49%) (17956/18048)\n",
      "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0168) | Acc: (99.50%) (19232/19328)\n",
      "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0169) | Acc: (99.50%) (20505/20608)\n",
      "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0169) | Acc: (99.50%) (21779/21888)\n",
      "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0166) | Acc: (99.52%) (23057/23168)\n",
      "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0164) | Acc: (99.53%) (24332/24448)\n",
      "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.54%) (25610/25728)\n",
      "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0161) | Acc: (99.55%) (26887/27008)\n",
      "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0159) | Acc: (99.57%) (28166/28288)\n",
      "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0158) | Acc: (99.57%) (29441/29568)\n",
      "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0159) | Acc: (99.57%) (30714/30848)\n",
      "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0158) | Acc: (99.58%) (31992/32128)\n",
      "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0156) | Acc: (99.58%) (33269/33408)\n",
      "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.59%) (34546/34688)\n",
      "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0153) | Acc: (99.60%) (35824/35968)\n",
      "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0154) | Acc: (99.59%) (37097/37248)\n",
      "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0155) | Acc: (99.59%) (38371/38528)\n",
      "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0155) | Acc: (99.59%) (39645/39808)\n",
      "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0155) | Acc: (99.59%) (40921/41088)\n",
      "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0154) | Acc: (99.60%) (42197/42368)\n",
      "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0154) | Acc: (99.59%) (43470/43648)\n",
      "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0154) | Acc: (99.59%) (44746/44928)\n",
      "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0153) | Acc: (99.60%) (46022/46208)\n",
      "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0151) | Acc: (99.61%) (47301/47488)\n",
      "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0151) | Acc: (99.60%) (48574/48768)\n",
      "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0152) | Acc: (99.60%) (49798/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5856) | Acc: (89.86%) (8986/10000)\n",
      "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0040) | Acc: (100.00%) (128/128)\n",
      "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0102) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0121) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0114) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0116) | Acc: (99.75%) (5235/5248)\n",
      "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0116) | Acc: (99.79%) (6514/6528)\n",
      "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0117) | Acc: (99.77%) (7790/7808)\n",
      "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0116) | Acc: (99.78%) (9068/9088)\n",
      "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0113) | Acc: (99.79%) (10346/10368)\n",
      "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0115) | Acc: (99.79%) (11623/11648)\n",
      "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0115) | Acc: (99.78%) (12899/12928)\n",
      "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0117) | Acc: (99.76%) (14174/14208)\n",
      "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0119) | Acc: (99.75%) (15450/15488)\n",
      "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0119) | Acc: (99.76%) (16727/16768)\n",
      "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0118) | Acc: (99.76%) (18004/18048)\n",
      "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0120) | Acc: (99.74%) (19278/19328)\n",
      "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0124) | Acc: (99.72%) (20550/20608)\n",
      "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.70%) (21822/21888)\n",
      "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0129) | Acc: (99.69%) (23097/23168)\n",
      "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0127) | Acc: (99.69%) (24373/24448)\n",
      "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0127) | Acc: (99.70%) (25651/25728)\n",
      "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0126) | Acc: (99.71%) (26929/27008)\n",
      "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0126) | Acc: (99.70%) (28202/28288)\n",
      "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0128) | Acc: (99.68%) (29472/29568)\n",
      "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0128) | Acc: (99.67%) (30746/30848)\n",
      "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.67%) (32022/32128)\n",
      "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.67%) (33299/33408)\n",
      "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0130) | Acc: (99.67%) (34575/34688)\n",
      "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.68%) (35852/35968)\n",
      "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0132) | Acc: (99.67%) (37126/37248)\n",
      "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.67%) (38402/38528)\n",
      "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.68%) (39680/39808)\n",
      "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.67%) (40954/41088)\n",
      "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0133) | Acc: (99.68%) (42231/42368)\n",
      "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.67%) (43506/43648)\n",
      "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.68%) (44784/44928)\n",
      "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0135) | Acc: (99.67%) (46054/46208)\n",
      "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0135) | Acc: (99.67%) (47330/47488)\n",
      "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0135) | Acc: (99.67%) (48606/48768)\n",
      "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0135) | Acc: (99.67%) (49834/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5795) | Acc: (90.05%) (9005/10000)\n",
      "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0247) | Acc: (99.22%) (127/128)\n",
      "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0149) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0142) | Acc: (99.59%) (2677/2688)\n",
      "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0153) | Acc: (99.57%) (3951/3968)\n",
      "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0153) | Acc: (99.60%) (5227/5248)\n",
      "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0154) | Acc: (99.59%) (6501/6528)\n",
      "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0153) | Acc: (99.59%) (7776/7808)\n",
      "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0150) | Acc: (99.63%) (9054/9088)\n",
      "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0148) | Acc: (99.62%) (10329/10368)\n",
      "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0152) | Acc: (99.61%) (11603/11648)\n",
      "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.59%) (12875/12928)\n",
      "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0157) | Acc: (99.58%) (14149/14208)\n",
      "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0158) | Acc: (99.59%) (15425/15488)\n",
      "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0157) | Acc: (99.61%) (16702/16768)\n",
      "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0157) | Acc: (99.61%) (17978/18048)\n",
      "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0156) | Acc: (99.61%) (19253/19328)\n",
      "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0155) | Acc: (99.62%) (20529/20608)\n",
      "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0155) | Acc: (99.61%) (21803/21888)\n",
      "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0152) | Acc: (99.63%) (23082/23168)\n",
      "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0152) | Acc: (99.62%) (24356/24448)\n",
      "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0148) | Acc: (99.62%) (30731/30848)\n",
      "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0149) | Acc: (99.61%) (32003/32128)\n",
      "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0147) | Acc: (99.62%) (33280/33408)\n",
      "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0146) | Acc: (99.62%) (34556/34688)\n",
      "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0145) | Acc: (99.62%) (35830/35968)\n",
      "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0145) | Acc: (99.62%) (37107/37248)\n",
      "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.63%) (38386/38528)\n",
      "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0144) | Acc: (99.63%) (39662/39808)\n",
      "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.64%) (40941/41088)\n",
      "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.64%) (42216/42368)\n",
      "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0143) | Acc: (99.64%) (43491/43648)\n",
      "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.64%) (44768/44928)\n",
      "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.65%) (46044/46208)\n",
      "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0140) | Acc: (99.65%) (47323/47488)\n",
      "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0141) | Acc: (99.65%) (48597/48768)\n",
      "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.65%) (49824/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5884) | Acc: (90.00%) (9000/10000)\n",
      "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0306) | Acc: (99.22%) (127/128)\n",
      "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0177) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0175) | Acc: (99.52%) (2675/2688)\n",
      "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0146) | Acc: (99.62%) (3953/3968)\n",
      "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0143) | Acc: (99.64%) (5229/5248)\n",
      "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0143) | Acc: (99.63%) (6504/6528)\n",
      "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0139) | Acc: (99.65%) (7781/7808)\n",
      "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0141) | Acc: (99.67%) (9058/9088)\n",
      "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0139) | Acc: (99.66%) (10333/10368)\n",
      "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0139) | Acc: (99.65%) (11607/11648)\n",
      "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0138) | Acc: (99.66%) (12884/12928)\n",
      "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.66%) (14159/14208)\n",
      "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0137) | Acc: (99.67%) (15437/15488)\n",
      "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0140) | Acc: (99.67%) (16713/16768)\n",
      "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0137) | Acc: (99.68%) (17991/18048)\n",
      "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0133) | Acc: (99.70%) (19270/19328)\n",
      "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0134) | Acc: (99.69%) (20544/20608)\n",
      "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0133) | Acc: (99.70%) (21822/21888)\n",
      "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0132) | Acc: (99.69%) (23097/23168)\n",
      "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.68%) (24370/24448)\n",
      "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0134) | Acc: (99.67%) (25644/25728)\n",
      "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0134) | Acc: (99.67%) (26920/27008)\n",
      "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0135) | Acc: (99.68%) (28197/28288)\n",
      "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.68%) (29472/29568)\n",
      "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.68%) (30750/30848)\n",
      "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0132) | Acc: (99.69%) (32029/32128)\n",
      "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.69%) (33305/33408)\n",
      "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.69%) (34579/34688)\n",
      "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0132) | Acc: (99.69%) (35855/35968)\n",
      "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0133) | Acc: (99.69%) (37131/37248)\n",
      "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.68%) (38406/38528)\n",
      "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0131) | Acc: (99.69%) (39685/39808)\n",
      "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.70%) (40963/41088)\n",
      "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.70%) (42241/42368)\n",
      "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.69%) (43514/43648)\n",
      "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0131) | Acc: (99.69%) (44790/44928)\n",
      "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.69%) (46063/46208)\n",
      "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0131) | Acc: (99.69%) (47342/47488)\n",
      "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.69%) (48618/48768)\n",
      "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.68%) (49841/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6230) | Acc: (89.69%) (8969/10000)\n",
      "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0070) | Acc: (100.00%) (128/128)\n",
      "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.86%) (1406/1408)\n",
      "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0105) | Acc: (99.78%) (2682/2688)\n",
      "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0121) | Acc: (99.72%) (3957/3968)\n",
      "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0123) | Acc: (99.73%) (5234/5248)\n",
      "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0125) | Acc: (99.74%) (6511/6528)\n",
      "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0126) | Acc: (99.77%) (7790/7808)\n",
      "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.77%) (9067/9088)\n",
      "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0132) | Acc: (99.75%) (10342/10368)\n",
      "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0132) | Acc: (99.73%) (11617/11648)\n",
      "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.70%) (12889/12928)\n",
      "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0143) | Acc: (99.70%) (14165/14208)\n",
      "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0141) | Acc: (99.71%) (15443/15488)\n",
      "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0139) | Acc: (99.71%) (16720/16768)\n",
      "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0141) | Acc: (99.70%) (17993/18048)\n",
      "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0143) | Acc: (99.69%) (19268/19328)\n",
      "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0142) | Acc: (99.70%) (20546/20608)\n",
      "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0138) | Acc: (99.72%) (21826/21888)\n",
      "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0142) | Acc: (99.69%) (23097/23168)\n",
      "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0141) | Acc: (99.70%) (24374/24448)\n",
      "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0139) | Acc: (99.70%) (25652/25728)\n",
      "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0138) | Acc: (99.70%) (26927/27008)\n",
      "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0138) | Acc: (99.70%) (28202/28288)\n",
      "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0137) | Acc: (99.70%) (29478/29568)\n",
      "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.70%) (30754/30848)\n",
      "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0138) | Acc: (99.69%) (32029/32128)\n",
      "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.69%) (33306/33408)\n",
      "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0136) | Acc: (99.70%) (34583/34688)\n",
      "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.70%) (35860/35968)\n",
      "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0135) | Acc: (99.70%) (37135/37248)\n",
      "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0135) | Acc: (99.69%) (38410/38528)\n",
      "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.69%) (39686/39808)\n",
      "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0135) | Acc: (99.69%) (40962/41088)\n",
      "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.69%) (42236/42368)\n",
      "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.69%) (43512/43648)\n",
      "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.69%) (44787/44928)\n",
      "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.68%) (46061/46208)\n",
      "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.68%) (47338/47488)\n",
      "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.68%) (48612/48768)\n",
      "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.68%) (49842/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5854) | Acc: (89.86%) (8986/10000)\n",
      "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0043) | Acc: (100.00%) (128/128)\n",
      "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0157) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0142) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0164) | Acc: (99.62%) (3953/3968)\n",
      "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0150) | Acc: (99.62%) (5228/5248)\n",
      "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0141) | Acc: (99.63%) (6504/6528)\n",
      "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0143) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0142) | Acc: (99.60%) (9052/9088)\n",
      "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0142) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0139) | Acc: (99.64%) (11606/11648)\n",
      "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0134) | Acc: (99.67%) (12885/12928)\n",
      "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.66%) (14160/14208)\n",
      "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0138) | Acc: (99.66%) (15435/15488)\n",
      "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0140) | Acc: (99.64%) (16708/16768)\n",
      "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0137) | Acc: (99.66%) (17986/18048)\n",
      "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0138) | Acc: (99.65%) (19260/19328)\n",
      "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0137) | Acc: (99.66%) (20538/20608)\n",
      "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0139) | Acc: (99.65%) (21811/21888)\n",
      "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0139) | Acc: (99.65%) (23086/23168)\n",
      "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0138) | Acc: (99.65%) (24363/24448)\n",
      "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0139) | Acc: (99.66%) (25641/25728)\n",
      "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0138) | Acc: (99.67%) (26918/27008)\n",
      "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0138) | Acc: (99.66%) (28191/28288)\n",
      "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0140) | Acc: (99.65%) (29464/29568)\n",
      "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0141) | Acc: (99.64%) (30737/30848)\n",
      "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.65%) (32015/32128)\n",
      "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0141) | Acc: (99.65%) (33292/33408)\n",
      "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0141) | Acc: (99.65%) (34568/34688)\n",
      "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.64%) (35839/35968)\n",
      "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0142) | Acc: (99.64%) (37115/37248)\n",
      "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.63%) (38387/38528)\n",
      "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0144) | Acc: (99.64%) (39664/39808)\n",
      "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0144) | Acc: (99.64%) (40939/41088)\n",
      "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0145) | Acc: (99.63%) (42210/42368)\n",
      "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0147) | Acc: (99.62%) (43484/43648)\n",
      "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0147) | Acc: (99.63%) (44760/44928)\n",
      "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.62%) (46034/46208)\n",
      "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0146) | Acc: (99.63%) (47310/47488)\n",
      "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0145) | Acc: (99.64%) (48590/48768)\n",
      "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0144) | Acc: (99.64%) (49821/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5639) | Acc: (90.18%) (9018/10000)\n",
      "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0022) | Acc: (100.00%) (128/128)\n",
      "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0146) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0124) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0135) | Acc: (99.62%) (3953/3968)\n",
      "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0141) | Acc: (99.60%) (5227/5248)\n",
      "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0144) | Acc: (99.62%) (6503/6528)\n",
      "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0144) | Acc: (99.63%) (7779/7808)\n",
      "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0139) | Acc: (99.65%) (9056/9088)\n",
      "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0135) | Acc: (99.67%) (10334/10368)\n",
      "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0131) | Acc: (99.70%) (11613/11648)\n",
      "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0128) | Acc: (99.71%) (12890/12928)\n",
      "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0129) | Acc: (99.70%) (14165/14208)\n",
      "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0131) | Acc: (99.70%) (15441/15488)\n",
      "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0132) | Acc: (99.69%) (16716/16768)\n",
      "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0132) | Acc: (99.70%) (17993/18048)\n",
      "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0134) | Acc: (99.68%) (19267/19328)\n",
      "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0140) | Acc: (99.66%) (20538/20608)\n",
      "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0140) | Acc: (99.67%) (21815/21888)\n",
      "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0137) | Acc: (99.68%) (23094/23168)\n",
      "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0138) | Acc: (99.68%) (24369/24448)\n",
      "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0138) | Acc: (99.67%) (25643/25728)\n",
      "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0139) | Acc: (99.67%) (26920/27008)\n",
      "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0139) | Acc: (99.68%) (28197/28288)\n",
      "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0140) | Acc: (99.67%) (29470/29568)\n",
      "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0141) | Acc: (99.66%) (30744/30848)\n",
      "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.67%) (32023/32128)\n",
      "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0140) | Acc: (99.67%) (33298/33408)\n",
      "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0140) | Acc: (99.67%) (34575/34688)\n",
      "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0139) | Acc: (99.67%) (35851/35968)\n",
      "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0139) | Acc: (99.67%) (37125/37248)\n",
      "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0140) | Acc: (99.65%) (38395/38528)\n",
      "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0139) | Acc: (99.66%) (39672/39808)\n",
      "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0140) | Acc: (99.65%) (40945/41088)\n",
      "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.65%) (42220/42368)\n",
      "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0141) | Acc: (99.66%) (43498/43648)\n",
      "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.66%) (44775/44928)\n",
      "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0140) | Acc: (99.65%) (46048/46208)\n",
      "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0140) | Acc: (99.66%) (47326/47488)\n",
      "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.67%) (48605/48768)\n",
      "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.66%) (49831/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5800) | Acc: (89.91%) (8991/10000)\n",
      "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0072) | Acc: (100.00%) (128/128)\n",
      "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0136) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0134) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0121) | Acc: (99.72%) (3957/3968)\n",
      "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0132) | Acc: (99.64%) (5229/5248)\n",
      "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0125) | Acc: (99.69%) (6508/6528)\n",
      "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0130) | Acc: (99.71%) (7785/7808)\n",
      "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.71%) (9062/9088)\n",
      "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0130) | Acc: (99.71%) (10338/10368)\n",
      "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0129) | Acc: (99.73%) (11616/11648)\n",
      "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0126) | Acc: (99.74%) (12894/12928)\n",
      "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0127) | Acc: (99.73%) (14169/14208)\n",
      "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0125) | Acc: (99.74%) (15447/15488)\n",
      "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0123) | Acc: (99.75%) (16726/16768)\n",
      "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0127) | Acc: (99.73%) (17999/18048)\n",
      "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0130) | Acc: (99.73%) (19275/19328)\n",
      "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0128) | Acc: (99.73%) (20553/20608)\n",
      "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0127) | Acc: (99.74%) (21831/21888)\n",
      "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0127) | Acc: (99.74%) (23108/23168)\n",
      "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0128) | Acc: (99.73%) (24381/24448)\n",
      "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0127) | Acc: (99.73%) (25659/25728)\n",
      "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0128) | Acc: (99.72%) (26933/27008)\n",
      "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0128) | Acc: (99.73%) (28212/28288)\n",
      "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0130) | Acc: (99.73%) (29489/29568)\n",
      "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0129) | Acc: (99.73%) (30764/30848)\n",
      "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.73%) (32040/32128)\n",
      "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.72%) (33315/33408)\n",
      "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.72%) (34591/34688)\n",
      "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.73%) (35870/35968)\n",
      "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.72%) (37143/37248)\n",
      "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.72%) (38420/38528)\n",
      "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.72%) (39695/39808)\n",
      "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.71%) (40969/41088)\n",
      "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0134) | Acc: (99.71%) (42245/42368)\n",
      "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.72%) (43524/43648)\n",
      "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.71%) (44798/44928)\n",
      "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.71%) (46073/46208)\n",
      "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.71%) (47350/47488)\n",
      "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.70%) (48623/48768)\n",
      "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.70%) (49851/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5914) | Acc: (89.88%) (8988/10000)\n",
      "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0257) | Acc: (99.22%) (127/128)\n",
      "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0106) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0110) | Acc: (99.78%) (2682/2688)\n",
      "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0105) | Acc: (99.77%) (3959/3968)\n",
      "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0123) | Acc: (99.73%) (5234/5248)\n",
      "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0123) | Acc: (99.74%) (6511/6528)\n",
      "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0127) | Acc: (99.71%) (7785/7808)\n",
      "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0128) | Acc: (99.72%) (9063/9088)\n",
      "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0135) | Acc: (99.68%) (10335/10368)\n",
      "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.69%) (11612/11648)\n",
      "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0140) | Acc: (99.66%) (12884/12928)\n",
      "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0140) | Acc: (99.66%) (14160/14208)\n",
      "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0141) | Acc: (99.67%) (15437/15488)\n",
      "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0141) | Acc: (99.68%) (16714/16768)\n",
      "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0143) | Acc: (99.66%) (17987/18048)\n",
      "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0143) | Acc: (99.66%) (19263/19328)\n",
      "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0141) | Acc: (99.67%) (20540/20608)\n",
      "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0139) | Acc: (99.68%) (21817/21888)\n",
      "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0139) | Acc: (99.68%) (23094/23168)\n",
      "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0139) | Acc: (99.68%) (24369/24448)\n",
      "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0135) | Acc: (99.69%) (25649/25728)\n",
      "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0138) | Acc: (99.67%) (26918/27008)\n",
      "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0137) | Acc: (99.67%) (28194/28288)\n",
      "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0138) | Acc: (99.67%) (29469/29568)\n",
      "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.67%) (30747/30848)\n",
      "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.68%) (32024/32128)\n",
      "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.68%) (33300/33408)\n",
      "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0134) | Acc: (99.68%) (34578/34688)\n",
      "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.68%) (35854/35968)\n",
      "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.69%) (37132/37248)\n",
      "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0134) | Acc: (99.69%) (38407/38528)\n",
      "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0133) | Acc: (99.69%) (39684/39808)\n",
      "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.69%) (40959/41088)\n",
      "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.68%) (42233/42368)\n",
      "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.67%) (43506/43648)\n",
      "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.67%) (44781/44928)\n",
      "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0135) | Acc: (99.68%) (46058/46208)\n",
      "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.67%) (47330/47488)\n",
      "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.67%) (48606/48768)\n",
      "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.67%) (49833/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6082) | Acc: (89.72%) (8972/10000)\n",
      "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0165) | Acc: (98.44%) (126/128)\n",
      "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0128) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0121) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0116) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0149) | Acc: (99.60%) (5227/5248)\n",
      "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0141) | Acc: (99.65%) (6505/6528)\n",
      "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0138) | Acc: (99.64%) (7780/7808)\n",
      "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0134) | Acc: (99.66%) (9057/9088)\n",
      "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0134) | Acc: (99.67%) (10334/10368)\n",
      "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0133) | Acc: (99.70%) (11613/11648)\n",
      "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0133) | Acc: (99.69%) (12888/12928)\n",
      "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0135) | Acc: (99.66%) (14160/14208)\n",
      "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0131) | Acc: (99.68%) (15439/15488)\n",
      "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0132) | Acc: (99.66%) (16711/16768)\n",
      "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0132) | Acc: (99.67%) (17989/18048)\n",
      "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0129) | Acc: (99.69%) (19269/19328)\n",
      "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0129) | Acc: (99.70%) (20546/20608)\n",
      "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0128) | Acc: (99.71%) (21824/21888)\n",
      "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0128) | Acc: (99.69%) (23097/23168)\n",
      "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0128) | Acc: (99.69%) (24373/24448)\n",
      "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0130) | Acc: (99.69%) (25649/25728)\n",
      "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.69%) (26925/27008)\n",
      "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0131) | Acc: (99.68%) (28198/28288)\n",
      "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0132) | Acc: (99.68%) (29474/29568)\n",
      "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0132) | Acc: (99.69%) (30753/30848)\n",
      "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.68%) (32025/32128)\n",
      "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0134) | Acc: (99.67%) (33299/33408)\n",
      "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0134) | Acc: (99.67%) (34573/34688)\n",
      "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.67%) (35849/35968)\n",
      "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0136) | Acc: (99.67%) (37125/37248)\n",
      "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0135) | Acc: (99.67%) (38401/38528)\n",
      "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.67%) (39678/39808)\n",
      "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.68%) (40956/41088)\n",
      "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0134) | Acc: (99.68%) (42233/42368)\n",
      "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.69%) (43512/43648)\n",
      "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.69%) (44788/44928)\n",
      "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.69%) (46063/46208)\n",
      "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.69%) (47340/47488)\n",
      "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.69%) (48618/48768)\n",
      "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.69%) (49845/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5772) | Acc: (89.84%) (8984/10000)\n",
      "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0111) | Acc: (100.00%) (128/128)\n",
      "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0132) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0134) | Acc: (99.67%) (2679/2688)\n",
      "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0127) | Acc: (99.72%) (3957/3968)\n",
      "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.70%) (5232/5248)\n",
      "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0126) | Acc: (99.72%) (6510/6528)\n",
      "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0122) | Acc: (99.73%) (7787/7808)\n",
      "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0130) | Acc: (99.69%) (9060/9088)\n",
      "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0139) | Acc: (99.62%) (10329/10368)\n",
      "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0141) | Acc: (99.60%) (11601/11648)\n",
      "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0138) | Acc: (99.61%) (12878/12928)\n",
      "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.63%) (14155/14208)\n",
      "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0134) | Acc: (99.63%) (15431/15488)\n",
      "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0135) | Acc: (99.64%) (16708/16768)\n",
      "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0133) | Acc: (99.66%) (17987/18048)\n",
      "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0132) | Acc: (99.67%) (19265/19328)\n",
      "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0131) | Acc: (99.67%) (20540/20608)\n",
      "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0135) | Acc: (99.65%) (21811/21888)\n",
      "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0136) | Acc: (99.64%) (23084/23168)\n",
      "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0136) | Acc: (99.64%) (24360/24448)\n",
      "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0134) | Acc: (99.65%) (25638/25728)\n",
      "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.63%) (26909/27008)\n",
      "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0135) | Acc: (99.64%) (28185/28288)\n",
      "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.64%) (29461/29568)\n",
      "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0135) | Acc: (99.63%) (30735/30848)\n",
      "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0134) | Acc: (99.64%) (32011/32128)\n",
      "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.64%) (33289/33408)\n",
      "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.63%) (34559/34688)\n",
      "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0139) | Acc: (99.62%) (35832/35968)\n",
      "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0138) | Acc: (99.62%) (37107/37248)\n",
      "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.62%) (38380/38528)\n",
      "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0140) | Acc: (99.61%) (39653/39808)\n",
      "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0140) | Acc: (99.61%) (40928/41088)\n",
      "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.62%) (42205/42368)\n",
      "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0138) | Acc: (99.63%) (43485/43648)\n",
      "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0139) | Acc: (99.63%) (44760/44928)\n",
      "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0140) | Acc: (99.62%) (46032/46208)\n",
      "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0140) | Acc: (99.62%) (47308/47488)\n",
      "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.62%) (48583/48768)\n",
      "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0140) | Acc: (99.62%) (49810/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5786) | Acc: (90.10%) (9010/10000)\n",
      "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0124) | Acc: (100.00%) (128/128)\n",
      "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0147) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0136) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0150) | Acc: (99.65%) (3954/3968)\n",
      "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0137) | Acc: (99.70%) (5232/5248)\n",
      "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0147) | Acc: (99.65%) (6505/6528)\n",
      "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0141) | Acc: (99.68%) (7783/7808)\n",
      "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0146) | Acc: (99.65%) (9056/9088)\n",
      "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0153) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0152) | Acc: (99.61%) (11602/11648)\n",
      "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0150) | Acc: (99.62%) (12879/12928)\n",
      "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0143) | Acc: (99.64%) (26910/27008)\n",
      "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.62%) (28181/28288)\n",
      "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0146) | Acc: (99.62%) (29456/29568)\n",
      "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0144) | Acc: (99.63%) (30735/30848)\n",
      "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0142) | Acc: (99.64%) (32013/32128)\n",
      "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0142) | Acc: (99.65%) (33290/33408)\n",
      "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0142) | Acc: (99.65%) (34565/34688)\n",
      "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.64%) (35840/35968)\n",
      "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0141) | Acc: (99.66%) (37120/37248)\n",
      "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0141) | Acc: (99.66%) (38398/38528)\n",
      "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.66%) (39673/39808)\n",
      "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0142) | Acc: (99.66%) (40947/41088)\n",
      "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0143) | Acc: (99.65%) (42220/42368)\n",
      "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0142) | Acc: (99.65%) (43497/43648)\n",
      "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0143) | Acc: (99.65%) (44772/44928)\n",
      "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0142) | Acc: (99.65%) (46046/46208)\n",
      "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0143) | Acc: (99.64%) (47318/47488)\n",
      "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0142) | Acc: (99.64%) (48594/48768)\n",
      "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.65%) (49823/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5853) | Acc: (90.02%) (9002/10000)\n",
      "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0086) | Acc: (100.00%) (128/128)\n",
      "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0119) | Acc: (99.86%) (1406/1408)\n",
      "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0100) | Acc: (99.93%) (2686/2688)\n",
      "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0098) | Acc: (99.90%) (3964/3968)\n",
      "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0115) | Acc: (99.81%) (5238/5248)\n",
      "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0120) | Acc: (99.79%) (6514/6528)\n",
      "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0122) | Acc: (99.77%) (7790/7808)\n",
      "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0131) | Acc: (99.74%) (9064/9088)\n",
      "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0145) | Acc: (99.67%) (10334/10368)\n",
      "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0140) | Acc: (99.69%) (11612/11648)\n",
      "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0136) | Acc: (99.71%) (12891/12928)\n",
      "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.70%) (14165/14208)\n",
      "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0137) | Acc: (99.69%) (15440/15488)\n",
      "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0134) | Acc: (99.70%) (16718/16768)\n",
      "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0135) | Acc: (99.70%) (17994/18048)\n",
      "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.70%) (19270/19328)\n",
      "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0140) | Acc: (99.70%) (20546/20608)\n",
      "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0140) | Acc: (99.69%) (21821/21888)\n",
      "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0140) | Acc: (99.68%) (23095/23168)\n",
      "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0139) | Acc: (99.69%) (24372/24448)\n",
      "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0142) | Acc: (99.67%) (25643/25728)\n",
      "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0141) | Acc: (99.67%) (26920/27008)\n",
      "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0143) | Acc: (99.67%) (28194/28288)\n",
      "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0145) | Acc: (99.66%) (29467/29568)\n",
      "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0145) | Acc: (99.67%) (30745/30848)\n",
      "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0144) | Acc: (99.66%) (32020/32128)\n",
      "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.67%) (33298/33408)\n",
      "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0144) | Acc: (99.67%) (34572/34688)\n",
      "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.67%) (35850/35968)\n",
      "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0142) | Acc: (99.68%) (37127/37248)\n",
      "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0145) | Acc: (99.66%) (38398/38528)\n",
      "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0146) | Acc: (99.66%) (39674/39808)\n",
      "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0146) | Acc: (99.65%) (40946/41088)\n",
      "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0146) | Acc: (99.65%) (42220/42368)\n",
      "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0145) | Acc: (99.65%) (43497/43648)\n",
      "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0146) | Acc: (99.65%) (44769/44928)\n",
      "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0145) | Acc: (99.65%) (46045/46208)\n",
      "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0145) | Acc: (99.65%) (47320/47488)\n",
      "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0145) | Acc: (99.65%) (48596/48768)\n",
      "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0145) | Acc: (99.64%) (49822/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5924) | Acc: (89.62%) (8962/10000)\n",
      "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0087) | Acc: (100.00%) (128/128)\n",
      "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0179) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0194) | Acc: (99.44%) (2673/2688)\n",
      "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0177) | Acc: (99.47%) (3947/3968)\n",
      "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0167) | Acc: (99.50%) (5222/5248)\n",
      "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0158) | Acc: (99.53%) (6497/6528)\n",
      "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0150) | Acc: (99.58%) (7775/7808)\n",
      "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0156) | Acc: (99.57%) (9049/9088)\n",
      "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0159) | Acc: (99.57%) (10323/10368)\n",
      "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0157) | Acc: (99.57%) (11598/11648)\n",
      "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0152) | Acc: (99.59%) (12875/12928)\n",
      "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0150) | Acc: (99.60%) (14151/14208)\n",
      "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0150) | Acc: (99.60%) (15426/15488)\n",
      "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0149) | Acc: (99.60%) (16701/16768)\n",
      "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0151) | Acc: (99.59%) (17974/18048)\n",
      "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0148) | Acc: (99.60%) (19251/19328)\n",
      "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0147) | Acc: (99.60%) (20526/20608)\n",
      "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0145) | Acc: (99.62%) (21805/21888)\n",
      "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0142) | Acc: (99.63%) (23083/23168)\n",
      "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.63%) (24357/24448)\n",
      "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0145) | Acc: (99.62%) (25631/25728)\n",
      "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0143) | Acc: (99.63%) (26909/27008)\n",
      "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0143) | Acc: (99.63%) (28183/28288)\n",
      "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0144) | Acc: (99.62%) (29457/29568)\n",
      "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0145) | Acc: (99.62%) (30730/30848)\n",
      "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0144) | Acc: (99.62%) (32006/32128)\n",
      "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0145) | Acc: (99.61%) (33278/33408)\n",
      "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0143) | Acc: (99.62%) (34556/34688)\n",
      "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.62%) (35831/35968)\n",
      "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0142) | Acc: (99.63%) (37110/37248)\n",
      "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0142) | Acc: (99.63%) (38384/38528)\n",
      "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.62%) (39656/39808)\n",
      "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0142) | Acc: (99.62%) (40933/41088)\n",
      "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.62%) (42209/42368)\n",
      "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0142) | Acc: (99.63%) (43486/43648)\n",
      "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.63%) (44761/44928)\n",
      "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.63%) (46039/46208)\n",
      "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.64%) (47316/47488)\n",
      "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0141) | Acc: (99.64%) (48591/48768)\n",
      "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0142) | Acc: (99.64%) (49820/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5827) | Acc: (89.88%) (8988/10000)\n",
      "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0111) | Acc: (100.00%) (128/128)\n",
      "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0136) | Acc: (99.67%) (3955/3968)\n",
      "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0147) | Acc: (99.66%) (5230/5248)\n",
      "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0145) | Acc: (99.66%) (6506/6528)\n",
      "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0143) | Acc: (99.67%) (7782/7808)\n",
      "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.69%) (9060/9088)\n",
      "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0135) | Acc: (99.72%) (10339/10368)\n",
      "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.71%) (11614/11648)\n",
      "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.71%) (12890/12928)\n",
      "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.70%) (14166/14208)\n",
      "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0133) | Acc: (99.72%) (15444/15488)\n",
      "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0134) | Acc: (99.71%) (16720/16768)\n",
      "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0131) | Acc: (99.72%) (17997/18048)\n",
      "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0133) | Acc: (99.72%) (19273/19328)\n",
      "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0135) | Acc: (99.70%) (20547/20608)\n",
      "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0137) | Acc: (99.69%) (21820/21888)\n",
      "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0137) | Acc: (99.68%) (23095/23168)\n",
      "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0137) | Acc: (99.69%) (24371/24448)\n",
      "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0138) | Acc: (99.68%) (25646/25728)\n",
      "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0138) | Acc: (99.68%) (26922/27008)\n",
      "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0139) | Acc: (99.67%) (28195/28288)\n",
      "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0141) | Acc: (99.67%) (29469/29568)\n",
      "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0140) | Acc: (99.67%) (30746/30848)\n",
      "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.66%) (32019/32128)\n",
      "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.65%) (33292/33408)\n",
      "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0142) | Acc: (99.66%) (34570/34688)\n",
      "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0144) | Acc: (99.65%) (35841/35968)\n",
      "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0144) | Acc: (99.65%) (37117/37248)\n",
      "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.64%) (38391/38528)\n",
      "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.65%) (39669/39808)\n",
      "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.65%) (40943/41088)\n",
      "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0143) | Acc: (99.65%) (42220/42368)\n",
      "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0141) | Acc: (99.66%) (43499/43648)\n",
      "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.66%) (44775/44928)\n",
      "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0140) | Acc: (99.65%) (46047/46208)\n",
      "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0142) | Acc: (99.65%) (47320/47488)\n",
      "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0143) | Acc: (99.64%) (48591/48768)\n",
      "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0143) | Acc: (99.64%) (49819/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5716) | Acc: (90.30%) (9030/10000)\n",
      "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0129) | Acc: (100.00%) (128/128)\n",
      "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0126) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0116) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0115) | Acc: (99.77%) (3959/3968)\n",
      "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.70%) (5232/5248)\n",
      "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0128) | Acc: (99.69%) (6508/6528)\n",
      "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0137) | Acc: (99.64%) (7780/7808)\n",
      "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0132) | Acc: (99.66%) (9057/9088)\n",
      "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0134) | Acc: (99.67%) (10334/10368)\n",
      "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0139) | Acc: (99.67%) (11609/11648)\n",
      "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.68%) (12886/12928)\n",
      "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.69%) (14164/14208)\n",
      "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0133) | Acc: (99.68%) (15438/15488)\n",
      "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0134) | Acc: (99.67%) (16713/16768)\n",
      "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0135) | Acc: (99.68%) (17990/18048)\n",
      "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0138) | Acc: (99.67%) (19264/19328)\n",
      "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0138) | Acc: (99.66%) (20537/20608)\n",
      "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0137) | Acc: (99.65%) (21812/21888)\n",
      "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0136) | Acc: (99.65%) (23088/23168)\n",
      "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0138) | Acc: (99.64%) (24360/24448)\n",
      "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0141) | Acc: (99.62%) (25630/25728)\n",
      "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.62%) (26906/27008)\n",
      "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0139) | Acc: (99.63%) (28184/28288)\n",
      "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0138) | Acc: (99.64%) (29461/29568)\n",
      "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0139) | Acc: (99.63%) (30734/30848)\n",
      "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0138) | Acc: (99.64%) (32013/32128)\n",
      "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0140) | Acc: (99.64%) (33288/33408)\n",
      "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0140) | Acc: (99.64%) (34563/34688)\n",
      "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0138) | Acc: (99.65%) (35842/35968)\n",
      "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0137) | Acc: (99.65%) (37117/37248)\n",
      "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0135) | Acc: (99.66%) (38397/38528)\n",
      "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.66%) (39672/39808)\n",
      "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.65%) (40946/41088)\n",
      "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.65%) (42221/42368)\n",
      "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.65%) (43495/43648)\n",
      "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.65%) (44771/44928)\n",
      "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.65%) (46044/46208)\n",
      "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.65%) (47320/47488)\n",
      "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.65%) (48596/48768)\n",
      "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.65%) (49824/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5892) | Acc: (90.00%) (9000/10000)\n",
      "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0214) | Acc: (99.22%) (127/128)\n",
      "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0139) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0122) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0126) | Acc: (99.70%) (3956/3968)\n",
      "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0148) | Acc: (99.58%) (5226/5248)\n",
      "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0146) | Acc: (99.57%) (6500/6528)\n",
      "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0150) | Acc: (99.56%) (7774/7808)\n",
      "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.54%) (9046/9088)\n",
      "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0155) | Acc: (99.54%) (10320/10368)\n",
      "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0156) | Acc: (99.54%) (11594/11648)\n",
      "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.54%) (12868/12928)\n",
      "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0154) | Acc: (99.56%) (14145/14208)\n",
      "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0155) | Acc: (99.55%) (15419/15488)\n",
      "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0150) | Acc: (99.56%) (16695/16768)\n",
      "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0149) | Acc: (99.58%) (17972/18048)\n",
      "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0150) | Acc: (99.58%) (19246/19328)\n",
      "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0147) | Acc: (99.59%) (20524/20608)\n",
      "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0145) | Acc: (99.61%) (21802/21888)\n",
      "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0148) | Acc: (99.60%) (23075/23168)\n",
      "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0146) | Acc: (99.61%) (24352/24448)\n",
      "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0146) | Acc: (99.62%) (25629/25728)\n",
      "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0147) | Acc: (99.60%) (26900/27008)\n",
      "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0147) | Acc: (99.60%) (28174/28288)\n",
      "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0146) | Acc: (99.60%) (29450/29568)\n",
      "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0147) | Acc: (99.59%) (30723/30848)\n",
      "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0146) | Acc: (99.60%) (32000/32128)\n",
      "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0145) | Acc: (99.61%) (33277/33408)\n",
      "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0145) | Acc: (99.61%) (34552/34688)\n",
      "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.62%) (35831/35968)\n",
      "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0143) | Acc: (99.62%) (37107/37248)\n",
      "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.62%) (38382/38528)\n",
      "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.63%) (39659/39808)\n",
      "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0144) | Acc: (99.62%) (40932/41088)\n",
      "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0145) | Acc: (99.61%) (42204/42368)\n",
      "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0146) | Acc: (99.61%) (43478/43648)\n",
      "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0145) | Acc: (99.62%) (44756/44928)\n",
      "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0144) | Acc: (99.63%) (46035/46208)\n",
      "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0143) | Acc: (99.63%) (47313/47488)\n",
      "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0145) | Acc: (99.62%) (48583/48768)\n",
      "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0144) | Acc: (99.63%) (49814/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5714) | Acc: (90.01%) (9001/10000)\n",
      "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0023) | Acc: (100.00%) (128/128)\n",
      "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0149) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0138) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0133) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0140) | Acc: (99.71%) (5233/5248)\n",
      "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0146) | Acc: (99.69%) (6508/6528)\n",
      "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0144) | Acc: (99.71%) (7785/7808)\n",
      "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0139) | Acc: (99.71%) (9062/9088)\n",
      "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.69%) (10336/10368)\n",
      "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.70%) (11613/11648)\n",
      "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0135) | Acc: (99.69%) (12888/12928)\n",
      "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.69%) (14164/14208)\n",
      "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0135) | Acc: (99.68%) (15439/15488)\n",
      "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.69%) (16716/16768)\n",
      "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0135) | Acc: (99.70%) (17993/18048)\n",
      "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.68%) (19266/19328)\n",
      "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0136) | Acc: (99.69%) (20544/20608)\n",
      "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.69%) (21821/21888)\n",
      "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0137) | Acc: (99.69%) (23097/23168)\n",
      "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0139) | Acc: (99.67%) (24368/24448)\n",
      "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0137) | Acc: (99.68%) (25646/25728)\n",
      "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0137) | Acc: (99.69%) (26924/27008)\n",
      "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0136) | Acc: (99.70%) (28203/28288)\n",
      "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.70%) (29479/29568)\n",
      "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0135) | Acc: (99.71%) (30757/30848)\n",
      "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.70%) (32032/32128)\n",
      "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0137) | Acc: (99.69%) (33306/33408)\n",
      "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0135) | Acc: (99.70%) (34584/34688)\n",
      "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.70%) (35859/35968)\n",
      "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0136) | Acc: (99.69%) (37133/37248)\n",
      "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0137) | Acc: (99.69%) (38407/38528)\n",
      "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0137) | Acc: (99.69%) (39684/39808)\n",
      "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.69%) (40961/41088)\n",
      "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.69%) (42237/42368)\n",
      "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.70%) (43515/43648)\n",
      "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.69%) (44790/44928)\n",
      "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.69%) (46065/46208)\n",
      "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.69%) (47341/47488)\n",
      "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.68%) (48614/48768)\n",
      "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.68%) (49841/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5823) | Acc: (90.03%) (9003/10000)\n",
      "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0402) | Acc: (99.22%) (127/128)\n",
      "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0154) | Acc: (99.57%) (1402/1408)\n",
      "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0178) | Acc: (99.52%) (2675/2688)\n",
      "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0168) | Acc: (99.52%) (3949/3968)\n",
      "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0162) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0164) | Acc: (99.56%) (6499/6528)\n",
      "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0157) | Acc: (99.58%) (7775/7808)\n",
      "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0162) | Acc: (99.54%) (9046/9088)\n",
      "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0155) | Acc: (99.57%) (10323/10368)\n",
      "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0150) | Acc: (99.61%) (11602/11648)\n",
      "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0149) | Acc: (99.62%) (12879/12928)\n",
      "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0146) | Acc: (99.61%) (14153/14208)\n",
      "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0147) | Acc: (99.61%) (15428/15488)\n",
      "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0147) | Acc: (99.59%) (16699/16768)\n",
      "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0147) | Acc: (99.60%) (17976/18048)\n",
      "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0145) | Acc: (99.62%) (19254/19328)\n",
      "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0147) | Acc: (99.61%) (20527/20608)\n",
      "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.61%) (21803/21888)\n",
      "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0149) | Acc: (99.61%) (23077/23168)\n",
      "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0149) | Acc: (99.61%) (24352/24448)\n",
      "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0147) | Acc: (99.63%) (25632/25728)\n",
      "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0145) | Acc: (99.64%) (26910/27008)\n",
      "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0143) | Acc: (99.64%) (28187/28288)\n",
      "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0142) | Acc: (99.65%) (29464/29568)\n",
      "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0140) | Acc: (99.65%) (30741/30848)\n",
      "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.66%) (32018/32128)\n",
      "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.67%) (33297/33408)\n",
      "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.67%) (34574/34688)\n",
      "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0136) | Acc: (99.68%) (35853/35968)\n",
      "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0135) | Acc: (99.69%) (37131/37248)\n",
      "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0134) | Acc: (99.69%) (38409/38528)\n",
      "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0133) | Acc: (99.69%) (39684/39808)\n",
      "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.69%) (40961/41088)\n",
      "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0133) | Acc: (99.69%) (42236/42368)\n",
      "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.70%) (43515/43648)\n",
      "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.69%) (44790/44928)\n",
      "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.69%) (46066/46208)\n",
      "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0134) | Acc: (99.69%) (47343/47488)\n",
      "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.70%) (48621/48768)\n",
      "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.69%) (49847/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5944) | Acc: (89.96%) (8996/10000)\n",
      "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0089) | Acc: (100.00%) (128/128)\n",
      "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0165) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0161) | Acc: (99.59%) (2677/2688)\n",
      "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0158) | Acc: (99.62%) (3953/3968)\n",
      "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0157) | Acc: (99.58%) (5226/5248)\n",
      "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0159) | Acc: (99.56%) (6499/6528)\n",
      "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0153) | Acc: (99.58%) (7775/7808)\n",
      "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0153) | Acc: (99.59%) (9051/9088)\n",
      "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0150) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.61%) (11603/11648)\n",
      "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0152) | Acc: (99.61%) (12877/12928)\n",
      "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0147) | Acc: (99.63%) (14155/14208)\n",
      "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0152) | Acc: (99.61%) (15428/15488)\n",
      "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0150) | Acc: (99.62%) (16705/16768)\n",
      "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0147) | Acc: (99.65%) (17984/18048)\n",
      "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0145) | Acc: (99.65%) (19261/19328)\n",
      "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0144) | Acc: (99.67%) (20539/20608)\n",
      "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0142) | Acc: (99.68%) (21818/21888)\n",
      "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0142) | Acc: (99.67%) (23091/23168)\n",
      "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0141) | Acc: (99.67%) (24367/24448)\n",
      "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0139) | Acc: (99.68%) (25645/25728)\n",
      "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0138) | Acc: (99.67%) (26920/27008)\n",
      "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0137) | Acc: (99.68%) (28197/28288)\n",
      "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.68%) (29474/29568)\n",
      "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.69%) (30752/30848)\n",
      "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0132) | Acc: (99.69%) (32030/32128)\n",
      "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.70%) (33308/33408)\n",
      "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.70%) (34585/34688)\n",
      "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.71%) (35863/35968)\n",
      "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.70%) (37138/37248)\n",
      "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.70%) (38414/38528)\n",
      "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0131) | Acc: (99.71%) (39693/39808)\n",
      "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.71%) (40969/41088)\n",
      "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0133) | Acc: (99.71%) (42244/42368)\n",
      "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.70%) (43518/43648)\n",
      "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0134) | Acc: (99.70%) (44791/44928)\n",
      "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.70%) (46070/46208)\n",
      "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.70%) (47345/47488)\n",
      "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.70%) (48623/48768)\n",
      "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.70%) (49850/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5989) | Acc: (89.98%) (8998/10000)\n",
      "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0062) | Acc: (100.00%) (128/128)\n",
      "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0177) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0182) | Acc: (99.48%) (2674/2688)\n",
      "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0161) | Acc: (99.57%) (3951/3968)\n",
      "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0162) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0168) | Acc: (99.51%) (6496/6528)\n",
      "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0159) | Acc: (99.55%) (7773/7808)\n",
      "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0159) | Acc: (99.54%) (9046/9088)\n",
      "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0160) | Acc: (99.54%) (10320/10368)\n",
      "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0153) | Acc: (99.58%) (11599/11648)\n",
      "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0151) | Acc: (99.58%) (12874/12928)\n",
      "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0152) | Acc: (99.57%) (14147/14208)\n",
      "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0151) | Acc: (99.59%) (15424/15488)\n",
      "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0155) | Acc: (99.58%) (16698/16768)\n",
      "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0154) | Acc: (99.57%) (17971/18048)\n",
      "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.59%) (19249/19328)\n",
      "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0150) | Acc: (99.60%) (20526/20608)\n",
      "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0147) | Acc: (99.62%) (21805/21888)\n",
      "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0147) | Acc: (99.62%) (23081/23168)\n",
      "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0146) | Acc: (99.62%) (24356/24448)\n",
      "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0145) | Acc: (99.63%) (25632/25728)\n",
      "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0144) | Acc: (99.64%) (26910/27008)\n",
      "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.63%) (28183/28288)\n",
      "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0146) | Acc: (99.63%) (29458/29568)\n",
      "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0148) | Acc: (99.62%) (30730/30848)\n",
      "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0147) | Acc: (99.62%) (32007/32128)\n",
      "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0145) | Acc: (99.63%) (33285/33408)\n",
      "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0145) | Acc: (99.63%) (34558/34688)\n",
      "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0145) | Acc: (99.62%) (35833/35968)\n",
      "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0146) | Acc: (99.62%) (37107/37248)\n",
      "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.63%) (38385/38528)\n",
      "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.63%) (39661/39808)\n",
      "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0144) | Acc: (99.63%) (40936/41088)\n",
      "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0144) | Acc: (99.63%) (42211/42368)\n",
      "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0144) | Acc: (99.63%) (43486/43648)\n",
      "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0141) | Acc: (99.64%) (44766/44928)\n",
      "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0142) | Acc: (99.64%) (46040/46208)\n",
      "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0142) | Acc: (99.63%) (47314/47488)\n",
      "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0141) | Acc: (99.64%) (48591/48768)\n",
      "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.64%) (49819/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5769) | Acc: (89.93%) (8993/10000)\n",
      "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0184) | Acc: (99.22%) (127/128)\n",
      "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0124) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0157) | Acc: (99.48%) (2674/2688)\n",
      "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0149) | Acc: (99.57%) (3951/3968)\n",
      "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0160) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0156) | Acc: (99.56%) (6499/6528)\n",
      "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0154) | Acc: (99.55%) (7773/7808)\n",
      "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0151) | Acc: (99.54%) (9046/9088)\n",
      "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0152) | Acc: (99.56%) (10322/10368)\n",
      "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0149) | Acc: (99.57%) (11598/11648)\n",
      "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0146) | Acc: (99.58%) (12874/12928)\n",
      "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0142) | Acc: (99.60%) (14151/14208)\n",
      "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0148) | Acc: (99.59%) (15424/15488)\n",
      "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0152) | Acc: (99.59%) (16699/16768)\n",
      "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0153) | Acc: (99.59%) (17974/18048)\n",
      "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.61%) (19252/19328)\n",
      "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0152) | Acc: (99.61%) (20527/20608)\n",
      "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0152) | Acc: (99.60%) (21800/21888)\n",
      "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0150) | Acc: (99.61%) (23078/23168)\n",
      "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0149) | Acc: (99.62%) (24355/24448)\n",
      "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0148) | Acc: (99.63%) (25633/25728)\n",
      "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0147) | Acc: (99.64%) (26911/27008)\n",
      "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0148) | Acc: (99.63%) (28184/28288)\n",
      "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0150) | Acc: (99.63%) (29458/29568)\n",
      "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0148) | Acc: (99.63%) (30735/30848)\n",
      "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0146) | Acc: (99.64%) (32012/32128)\n",
      "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0146) | Acc: (99.64%) (33289/33408)\n",
      "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0146) | Acc: (99.64%) (34564/34688)\n",
      "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0144) | Acc: (99.65%) (35842/35968)\n",
      "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0144) | Acc: (99.66%) (37121/37248)\n",
      "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.66%) (38398/38528)\n",
      "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0141) | Acc: (99.67%) (39677/39808)\n",
      "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0141) | Acc: (99.66%) (40950/41088)\n",
      "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0140) | Acc: (99.67%) (42227/42368)\n",
      "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0139) | Acc: (99.67%) (43505/43648)\n",
      "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0138) | Acc: (99.68%) (44782/44928)\n",
      "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0139) | Acc: (99.68%) (46058/46208)\n",
      "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0139) | Acc: (99.67%) (47333/47488)\n",
      "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0139) | Acc: (99.67%) (48609/48768)\n",
      "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.67%) (49836/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5896) | Acc: (89.96%) (8996/10000)\n",
      "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0117) | Acc: (100.00%) (128/128)\n",
      "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0155) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0133) | Acc: (99.78%) (2682/2688)\n",
      "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0125) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0134) | Acc: (99.73%) (5234/5248)\n",
      "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0134) | Acc: (99.74%) (6511/6528)\n",
      "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0130) | Acc: (99.72%) (7786/7808)\n",
      "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0131) | Acc: (99.69%) (9060/9088)\n",
      "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0126) | Acc: (99.72%) (10339/10368)\n",
      "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0127) | Acc: (99.72%) (11615/11648)\n",
      "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.68%) (12887/12928)\n",
      "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.69%) (14164/14208)\n",
      "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0134) | Acc: (99.69%) (15440/15488)\n",
      "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0134) | Acc: (99.70%) (16717/16768)\n",
      "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0136) | Acc: (99.70%) (17993/18048)\n",
      "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0133) | Acc: (99.71%) (19271/19328)\n",
      "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0133) | Acc: (99.71%) (20548/20608)\n",
      "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0134) | Acc: (99.70%) (21823/21888)\n",
      "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0135) | Acc: (99.70%) (23098/23168)\n",
      "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.70%) (24375/24448)\n",
      "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0134) | Acc: (99.70%) (25650/25728)\n",
      "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0133) | Acc: (99.70%) (26927/27008)\n",
      "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0134) | Acc: (99.69%) (28199/28288)\n",
      "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.68%) (29472/29568)\n",
      "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.67%) (30746/30848)\n",
      "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.67%) (32023/32128)\n",
      "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.67%) (33298/33408)\n",
      "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0134) | Acc: (99.68%) (34576/34688)\n",
      "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0132) | Acc: (99.68%) (35854/35968)\n",
      "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0133) | Acc: (99.68%) (37128/37248)\n",
      "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0134) | Acc: (99.68%) (38403/38528)\n",
      "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0134) | Acc: (99.68%) (39681/39808)\n",
      "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.68%) (40955/41088)\n",
      "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0134) | Acc: (99.68%) (42232/42368)\n",
      "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0134) | Acc: (99.68%) (43509/43648)\n",
      "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0134) | Acc: (99.68%) (44784/44928)\n",
      "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.68%) (46062/46208)\n",
      "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.68%) (47337/47488)\n",
      "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.67%) (48609/48768)\n",
      "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.66%) (49831/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5835) | Acc: (90.08%) (9008/10000)\n",
      "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
      "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0152) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0156) | Acc: (99.78%) (2682/2688)\n",
      "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0146) | Acc: (99.70%) (3956/3968)\n",
      "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0137) | Acc: (99.71%) (5233/5248)\n",
      "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.71%) (6509/6528)\n",
      "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0132) | Acc: (99.72%) (7786/7808)\n",
      "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0131) | Acc: (99.74%) (9064/9088)\n",
      "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0134) | Acc: (99.69%) (10336/10368)\n",
      "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0139) | Acc: (99.67%) (11610/11648)\n",
      "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0142) | Acc: (99.64%) (12882/12928)\n",
      "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0145) | Acc: (99.62%) (14154/14208)\n",
      "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0142) | Acc: (99.63%) (15431/15488)\n",
      "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0139) | Acc: (99.64%) (16708/16768)\n",
      "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.65%) (17985/18048)\n",
      "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.66%) (19263/19328)\n",
      "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0136) | Acc: (99.66%) (20538/20608)\n",
      "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0135) | Acc: (99.67%) (21815/21888)\n",
      "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0135) | Acc: (99.68%) (23093/23168)\n",
      "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.68%) (24369/24448)\n",
      "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0131) | Acc: (99.69%) (25647/25728)\n",
      "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0134) | Acc: (99.67%) (26919/27008)\n",
      "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0134) | Acc: (99.68%) (28197/28288)\n",
      "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0134) | Acc: (99.68%) (29474/29568)\n",
      "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.67%) (30746/30848)\n",
      "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.67%) (32022/32128)\n",
      "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0134) | Acc: (99.66%) (33294/33408)\n",
      "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0135) | Acc: (99.66%) (34570/34688)\n",
      "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0138) | Acc: (99.65%) (35842/35968)\n",
      "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0139) | Acc: (99.65%) (37117/37248)\n",
      "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.65%) (38394/38528)\n",
      "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0138) | Acc: (99.66%) (39672/39808)\n",
      "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0137) | Acc: (99.66%) (40950/41088)\n",
      "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.67%) (42228/42368)\n",
      "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0137) | Acc: (99.66%) (43501/43648)\n",
      "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0137) | Acc: (99.66%) (44774/44928)\n",
      "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.66%) (46051/46208)\n",
      "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.66%) (47325/47488)\n",
      "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.65%) (48599/48768)\n",
      "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.65%) (49825/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5985) | Acc: (89.98%) (8998/10000)\n",
      "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0166) | Acc: (100.00%) (128/128)\n",
      "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0180) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0159) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0151) | Acc: (99.55%) (3950/3968)\n",
      "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0145) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.62%) (6503/6528)\n",
      "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0139) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0137) | Acc: (99.63%) (9054/9088)\n",
      "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0136) | Acc: (99.63%) (10330/10368)\n",
      "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.64%) (11606/11648)\n",
      "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0138) | Acc: (99.63%) (12880/12928)\n",
      "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.62%) (14154/14208)\n",
      "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0140) | Acc: (99.62%) (15429/15488)\n",
      "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0140) | Acc: (99.62%) (16704/16768)\n",
      "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.63%) (17982/18048)\n",
      "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0138) | Acc: (99.63%) (19257/19328)\n",
      "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0139) | Acc: (99.63%) (20531/20608)\n",
      "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0141) | Acc: (99.63%) (21807/21888)\n",
      "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0143) | Acc: (99.62%) (23079/23168)\n",
      "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0146) | Acc: (99.60%) (24350/24448)\n",
      "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0143) | Acc: (99.60%) (25626/25728)\n",
      "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.61%) (26904/27008)\n",
      "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0142) | Acc: (99.61%) (28178/28288)\n",
      "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0142) | Acc: (99.61%) (29452/29568)\n",
      "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0140) | Acc: (99.62%) (30730/30848)\n",
      "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0139) | Acc: (99.63%) (32008/32128)\n",
      "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.63%) (33285/33408)\n",
      "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.63%) (34558/34688)\n",
      "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0140) | Acc: (99.62%) (35832/35968)\n",
      "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0140) | Acc: (99.62%) (37107/37248)\n",
      "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.63%) (38384/38528)\n",
      "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0139) | Acc: (99.63%) (39661/39808)\n",
      "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0138) | Acc: (99.63%) (40938/41088)\n",
      "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0137) | Acc: (99.63%) (42213/42368)\n",
      "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0137) | Acc: (99.64%) (43489/43648)\n",
      "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0137) | Acc: (99.63%) (44761/44928)\n",
      "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0138) | Acc: (99.62%) (46034/46208)\n",
      "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.63%) (47312/47488)\n",
      "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.64%) (48590/48768)\n",
      "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.64%) (49819/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5667) | Acc: (90.13%) (9013/10000)\n",
      "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0113) | Acc: (100.00%) (128/128)\n",
      "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0120) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0150) | Acc: (99.48%) (2674/2688)\n",
      "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0134) | Acc: (99.65%) (3954/3968)\n",
      "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0139) | Acc: (99.62%) (5228/5248)\n",
      "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0150) | Acc: (99.59%) (6501/6528)\n",
      "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0151) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0147) | Acc: (99.63%) (9054/9088)\n",
      "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0144) | Acc: (99.62%) (10329/10368)\n",
      "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0139) | Acc: (99.65%) (11607/11648)\n",
      "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0141) | Acc: (99.63%) (12880/12928)\n",
      "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.64%) (14157/14208)\n",
      "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0137) | Acc: (99.65%) (15434/15488)\n",
      "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.66%) (16711/16768)\n",
      "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0140) | Acc: (99.65%) (17984/18048)\n",
      "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0142) | Acc: (99.63%) (19256/19328)\n",
      "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0141) | Acc: (99.64%) (20534/20608)\n",
      "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0137) | Acc: (99.66%) (21813/21888)\n",
      "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0138) | Acc: (99.65%) (23087/23168)\n",
      "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0141) | Acc: (99.64%) (24360/24448)\n",
      "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0141) | Acc: (99.64%) (25635/25728)\n",
      "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0141) | Acc: (99.64%) (26910/27008)\n",
      "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0142) | Acc: (99.63%) (28184/28288)\n",
      "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0141) | Acc: (99.64%) (29461/29568)\n",
      "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0139) | Acc: (99.65%) (30739/30848)\n",
      "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.65%) (32016/32128)\n",
      "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0142) | Acc: (99.64%) (33288/33408)\n",
      "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0141) | Acc: (99.64%) (34563/34688)\n",
      "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0139) | Acc: (99.65%) (35843/35968)\n",
      "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0138) | Acc: (99.66%) (37121/37248)\n",
      "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0138) | Acc: (99.66%) (38398/38528)\n",
      "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0137) | Acc: (99.67%) (39676/39808)\n",
      "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0137) | Acc: (99.67%) (40953/41088)\n",
      "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.67%) (42230/42368)\n",
      "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.67%) (43505/43648)\n",
      "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0135) | Acc: (99.68%) (44783/44928)\n",
      "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.67%) (46057/46208)\n",
      "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.67%) (47331/47488)\n",
      "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.67%) (48609/48768)\n",
      "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.67%) (49837/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5755) | Acc: (90.10%) (9010/10000)\n",
      "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0088) | Acc: (100.00%) (128/128)\n",
      "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0141) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0139) | Acc: (99.78%) (2682/2688)\n",
      "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0153) | Acc: (99.65%) (3954/3968)\n",
      "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.71%) (5233/5248)\n",
      "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0144) | Acc: (99.72%) (6510/6528)\n",
      "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0141) | Acc: (99.72%) (7786/7808)\n",
      "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.74%) (9064/9088)\n",
      "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.70%) (10337/10368)\n",
      "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0138) | Acc: (99.73%) (11617/11648)\n",
      "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.73%) (12893/12928)\n",
      "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.74%) (14171/14208)\n",
      "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0135) | Acc: (99.74%) (15448/15488)\n",
      "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0138) | Acc: (99.72%) (16721/16768)\n",
      "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.71%) (17996/18048)\n",
      "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0137) | Acc: (99.71%) (19272/19328)\n",
      "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0134) | Acc: (99.71%) (20549/20608)\n",
      "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0132) | Acc: (99.72%) (21826/21888)\n",
      "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0130) | Acc: (99.72%) (23103/23168)\n",
      "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0129) | Acc: (99.72%) (24380/24448)\n",
      "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0127) | Acc: (99.73%) (25659/25728)\n",
      "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.73%) (26934/27008)\n",
      "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0130) | Acc: (99.72%) (28210/28288)\n",
      "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0131) | Acc: (99.72%) (29484/29568)\n",
      "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0130) | Acc: (99.71%) (30760/30848)\n",
      "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0132) | Acc: (99.70%) (32033/32128)\n",
      "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0130) | Acc: (99.71%) (33312/33408)\n",
      "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0130) | Acc: (99.71%) (34587/34688)\n",
      "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.70%) (35861/35968)\n",
      "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0132) | Acc: (99.69%) (37133/37248)\n",
      "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0133) | Acc: (99.69%) (38407/38528)\n",
      "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.69%) (39683/39808)\n",
      "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.69%) (40962/41088)\n",
      "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0131) | Acc: (99.69%) (42238/42368)\n",
      "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.69%) (43511/43648)\n",
      "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0131) | Acc: (99.69%) (44788/44928)\n",
      "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0131) | Acc: (99.69%) (46065/46208)\n",
      "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0130) | Acc: (99.69%) (47340/47488)\n",
      "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0130) | Acc: (99.69%) (48616/48768)\n",
      "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0129) | Acc: (99.70%) (49848/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5906) | Acc: (89.90%) (8990/10000)\n",
      "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0154) | Acc: (99.22%) (127/128)\n",
      "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0161) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0149) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0148) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0145) | Acc: (99.73%) (5234/5248)\n",
      "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0156) | Acc: (99.66%) (6506/6528)\n",
      "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0154) | Acc: (99.67%) (7782/7808)\n",
      "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0148) | Acc: (99.68%) (9059/9088)\n",
      "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0149) | Acc: (99.67%) (10334/10368)\n",
      "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0146) | Acc: (99.66%) (11608/11648)\n",
      "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0154) | Acc: (99.61%) (12877/12928)\n",
      "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0154) | Acc: (99.61%) (14152/14208)\n",
      "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0153) | Acc: (99.61%) (15427/15488)\n",
      "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0151) | Acc: (99.61%) (16703/16768)\n",
      "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0151) | Acc: (99.61%) (17978/18048)\n",
      "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0149) | Acc: (99.61%) (19253/19328)\n",
      "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0147) | Acc: (99.62%) (20530/20608)\n",
      "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.63%) (21807/21888)\n",
      "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0145) | Acc: (99.64%) (23085/23168)\n",
      "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0144) | Acc: (99.66%) (24364/24448)\n",
      "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0143) | Acc: (99.66%) (25640/25728)\n",
      "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.66%) (26916/27008)\n",
      "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0142) | Acc: (99.65%) (28189/28288)\n",
      "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0141) | Acc: (99.65%) (29464/29568)\n",
      "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0140) | Acc: (99.65%) (30739/30848)\n",
      "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0141) | Acc: (99.64%) (32012/32128)\n",
      "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0141) | Acc: (99.63%) (33285/33408)\n",
      "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0140) | Acc: (99.63%) (34561/34688)\n",
      "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0138) | Acc: (99.65%) (35841/35968)\n",
      "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0138) | Acc: (99.65%) (37117/37248)\n",
      "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0137) | Acc: (99.65%) (38394/38528)\n",
      "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0136) | Acc: (99.66%) (39671/39808)\n",
      "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.66%) (40949/41088)\n",
      "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.66%) (42225/42368)\n",
      "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.67%) (43502/43648)\n",
      "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0137) | Acc: (99.66%) (44775/44928)\n",
      "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.66%) (46050/46208)\n",
      "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.66%) (47326/47488)\n",
      "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.66%) (48602/48768)\n",
      "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.66%) (49831/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5649) | Acc: (90.26%) (9026/10000)\n",
      "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0295) | Acc: (99.22%) (127/128)\n",
      "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0133) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0147) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0135) | Acc: (99.75%) (3958/3968)\n",
      "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0122) | Acc: (99.79%) (5237/5248)\n",
      "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0122) | Acc: (99.80%) (6515/6528)\n",
      "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0124) | Acc: (99.80%) (7792/7808)\n",
      "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0119) | Acc: (99.80%) (9070/9088)\n",
      "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0119) | Acc: (99.80%) (10347/10368)\n",
      "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0122) | Acc: (99.79%) (11623/11648)\n",
      "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0124) | Acc: (99.75%) (12896/12928)\n",
      "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0129) | Acc: (99.73%) (14170/14208)\n",
      "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0130) | Acc: (99.74%) (15447/15488)\n",
      "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0127) | Acc: (99.76%) (16727/16768)\n",
      "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0128) | Acc: (99.75%) (18003/18048)\n",
      "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0126) | Acc: (99.76%) (19282/19328)\n",
      "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0130) | Acc: (99.76%) (20558/20608)\n",
      "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.74%) (21831/21888)\n",
      "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0130) | Acc: (99.74%) (23108/23168)\n",
      "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0129) | Acc: (99.73%) (24383/24448)\n",
      "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0129) | Acc: (99.73%) (25659/25728)\n",
      "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.72%) (26933/27008)\n",
      "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0131) | Acc: (99.70%) (28204/28288)\n",
      "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0130) | Acc: (99.71%) (29481/29568)\n",
      "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.70%) (30756/30848)\n",
      "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.70%) (32033/32128)\n",
      "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.68%) (33302/33408)\n",
      "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0133) | Acc: (99.69%) (34580/34688)\n",
      "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0133) | Acc: (99.68%) (35854/35968)\n",
      "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.68%) (37129/37248)\n",
      "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0133) | Acc: (99.69%) (38408/38528)\n",
      "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0134) | Acc: (99.69%) (39684/39808)\n",
      "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0135) | Acc: (99.69%) (40959/41088)\n",
      "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.69%) (42236/42368)\n",
      "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.69%) (43511/43648)\n",
      "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0134) | Acc: (99.69%) (44790/44928)\n",
      "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.69%) (46067/46208)\n",
      "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0132) | Acc: (99.70%) (47345/47488)\n",
      "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.69%) (48617/48768)\n",
      "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.70%) (49848/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5891) | Acc: (90.07%) (9007/10000)\n",
      "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0071) | Acc: (100.00%) (128/128)\n",
      "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0093) | Acc: (99.79%) (1405/1408)\n",
      "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0125) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0128) | Acc: (99.80%) (3960/3968)\n",
      "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.77%) (5236/5248)\n",
      "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0136) | Acc: (99.75%) (6512/6528)\n",
      "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0140) | Acc: (99.74%) (7788/7808)\n",
      "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.75%) (9065/9088)\n",
      "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.74%) (10341/10368)\n",
      "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0141) | Acc: (99.73%) (11617/11648)\n",
      "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0145) | Acc: (99.67%) (12885/12928)\n",
      "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0144) | Acc: (99.67%) (14161/14208)\n",
      "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0142) | Acc: (99.68%) (15439/15488)\n",
      "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0142) | Acc: (99.69%) (16716/16768)\n",
      "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0141) | Acc: (99.68%) (17991/18048)\n",
      "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0140) | Acc: (99.69%) (19269/19328)\n",
      "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0140) | Acc: (99.69%) (20544/20608)\n",
      "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0138) | Acc: (99.69%) (21821/21888)\n",
      "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0136) | Acc: (99.69%) (23096/23168)\n",
      "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0136) | Acc: (99.69%) (24371/24448)\n",
      "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0135) | Acc: (99.69%) (25647/25728)\n",
      "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.68%) (26922/27008)\n",
      "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0137) | Acc: (99.68%) (28198/28288)\n",
      "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.68%) (29473/29568)\n",
      "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0136) | Acc: (99.68%) (30749/30848)\n",
      "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0135) | Acc: (99.69%) (32027/32128)\n",
      "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0134) | Acc: (99.69%) (33305/33408)\n",
      "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0136) | Acc: (99.69%) (34579/34688)\n",
      "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0136) | Acc: (99.68%) (35854/35968)\n",
      "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0135) | Acc: (99.68%) (37128/37248)\n",
      "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0134) | Acc: (99.68%) (38405/38528)\n",
      "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0136) | Acc: (99.67%) (39678/39808)\n",
      "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.67%) (40953/41088)\n",
      "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0137) | Acc: (99.67%) (42227/42368)\n",
      "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.67%) (43504/43648)\n",
      "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.67%) (44779/44928)\n",
      "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.66%) (46053/46208)\n",
      "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.66%) (47328/47488)\n",
      "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0139) | Acc: (99.66%) (48602/48768)\n",
      "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0139) | Acc: (99.66%) (49829/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5982) | Acc: (89.95%) (8995/10000)\n",
      "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0121) | Acc: (100.00%) (128/128)\n",
      "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0163) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0134) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0128) | Acc: (99.77%) (3959/3968)\n",
      "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.77%) (5236/5248)\n",
      "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0123) | Acc: (99.80%) (6515/6528)\n",
      "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0123) | Acc: (99.78%) (7791/7808)\n",
      "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.77%) (9067/9088)\n",
      "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0127) | Acc: (99.76%) (10343/10368)\n",
      "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0128) | Acc: (99.74%) (11618/11648)\n",
      "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0125) | Acc: (99.75%) (12896/12928)\n",
      "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0128) | Acc: (99.73%) (14169/14208)\n",
      "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0126) | Acc: (99.73%) (15446/15488)\n",
      "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0128) | Acc: (99.73%) (16723/16768)\n",
      "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0127) | Acc: (99.72%) (17998/18048)\n",
      "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0126) | Acc: (99.74%) (19277/19328)\n",
      "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0129) | Acc: (99.72%) (20550/20608)\n",
      "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0129) | Acc: (99.72%) (21826/21888)\n",
      "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0128) | Acc: (99.71%) (23101/23168)\n",
      "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0130) | Acc: (99.70%) (24374/24448)\n",
      "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0129) | Acc: (99.69%) (25649/25728)\n",
      "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0129) | Acc: (99.70%) (26927/27008)\n",
      "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0130) | Acc: (99.69%) (28201/28288)\n",
      "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0130) | Acc: (99.69%) (29477/29568)\n",
      "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0130) | Acc: (99.69%) (30751/30848)\n",
      "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.68%) (32025/32128)\n",
      "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.68%) (33301/33408)\n",
      "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.68%) (34578/34688)\n",
      "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0132) | Acc: (99.68%) (35853/35968)\n",
      "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.68%) (37130/37248)\n",
      "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0130) | Acc: (99.69%) (38407/38528)\n",
      "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.68%) (39679/39808)\n",
      "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.67%) (40954/41088)\n",
      "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.68%) (42232/42368)\n",
      "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.67%) (43505/43648)\n",
      "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.67%) (44780/44928)\n",
      "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.67%) (46055/46208)\n",
      "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0132) | Acc: (99.67%) (47333/47488)\n",
      "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.67%) (48607/48768)\n",
      "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0132) | Acc: (99.67%) (49834/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5762) | Acc: (90.18%) (9018/10000)\n",
      "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0101) | Acc: (100.00%) (128/128)\n",
      "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0129) | Acc: (99.70%) (2680/2688)\n",
      "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0147) | Acc: (99.62%) (3953/3968)\n",
      "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0142) | Acc: (99.66%) (5230/5248)\n",
      "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0130) | Acc: (99.71%) (6509/6528)\n",
      "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0128) | Acc: (99.71%) (7785/7808)\n",
      "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.71%) (9062/9088)\n",
      "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0127) | Acc: (99.71%) (10338/10368)\n",
      "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0126) | Acc: (99.71%) (11614/11648)\n",
      "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0122) | Acc: (99.72%) (12892/12928)\n",
      "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0127) | Acc: (99.69%) (14164/14208)\n",
      "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0131) | Acc: (99.67%) (15437/15488)\n",
      "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0128) | Acc: (99.69%) (16716/16768)\n",
      "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0130) | Acc: (99.69%) (17992/18048)\n",
      "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0128) | Acc: (99.69%) (19269/19328)\n",
      "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0127) | Acc: (99.69%) (20545/20608)\n",
      "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.69%) (21820/21888)\n",
      "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0126) | Acc: (99.69%) (23096/23168)\n",
      "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0125) | Acc: (99.69%) (24373/24448)\n",
      "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.70%) (25650/25728)\n",
      "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0125) | Acc: (99.71%) (26929/27008)\n",
      "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0126) | Acc: (99.70%) (28204/28288)\n",
      "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0127) | Acc: (99.70%) (29480/29568)\n",
      "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0127) | Acc: (99.71%) (30757/30848)\n",
      "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.68%) (32026/32128)\n",
      "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.69%) (33304/33408)\n",
      "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.69%) (34580/34688)\n",
      "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.70%) (35859/35968)\n",
      "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0130) | Acc: (99.70%) (37137/37248)\n",
      "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.70%) (38412/38528)\n",
      "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0131) | Acc: (99.70%) (39688/39808)\n",
      "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.70%) (40963/41088)\n",
      "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0131) | Acc: (99.69%) (42237/42368)\n",
      "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.69%) (43513/43648)\n",
      "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0131) | Acc: (99.69%) (44788/44928)\n",
      "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.69%) (46063/46208)\n",
      "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0131) | Acc: (99.69%) (47340/47488)\n",
      "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0131) | Acc: (99.69%) (48615/48768)\n",
      "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0131) | Acc: (99.68%) (49841/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5919) | Acc: (89.81%) (8981/10000)\n",
      "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0075) | Acc: (100.00%) (128/128)\n",
      "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0118) | Acc: (99.86%) (1406/1408)\n",
      "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0111) | Acc: (99.74%) (2681/2688)\n",
      "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0109) | Acc: (99.72%) (3957/3968)\n",
      "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0111) | Acc: (99.71%) (5233/5248)\n",
      "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0108) | Acc: (99.72%) (6510/6528)\n",
      "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0107) | Acc: (99.76%) (7789/7808)\n",
      "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0108) | Acc: (99.75%) (9065/9088)\n",
      "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0110) | Acc: (99.73%) (10340/10368)\n",
      "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0113) | Acc: (99.71%) (11614/11648)\n",
      "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0114) | Acc: (99.71%) (12891/12928)\n",
      "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0114) | Acc: (99.72%) (14168/14208)\n",
      "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0117) | Acc: (99.71%) (15443/15488)\n",
      "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0119) | Acc: (99.70%) (16717/16768)\n",
      "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0120) | Acc: (99.70%) (17993/18048)\n",
      "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0123) | Acc: (99.70%) (19270/19328)\n",
      "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0125) | Acc: (99.68%) (20543/20608)\n",
      "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0125) | Acc: (99.69%) (21820/21888)\n",
      "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0125) | Acc: (99.69%) (23096/23168)\n",
      "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0125) | Acc: (99.70%) (24374/24448)\n",
      "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0125) | Acc: (99.69%) (25648/25728)\n",
      "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0126) | Acc: (99.69%) (26925/27008)\n",
      "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0126) | Acc: (99.69%) (28200/28288)\n",
      "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0126) | Acc: (99.69%) (29476/29568)\n",
      "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0128) | Acc: (99.69%) (30751/30848)\n",
      "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0129) | Acc: (99.69%) (32028/32128)\n",
      "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0129) | Acc: (99.69%) (33306/33408)\n",
      "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0130) | Acc: (99.69%) (34579/34688)\n",
      "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0129) | Acc: (99.69%) (35857/35968)\n",
      "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0128) | Acc: (99.69%) (37134/37248)\n",
      "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0129) | Acc: (99.69%) (38407/38528)\n",
      "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0129) | Acc: (99.68%) (39682/39808)\n",
      "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.68%) (40956/41088)\n",
      "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.67%) (42228/42368)\n",
      "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.67%) (43504/43648)\n",
      "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.67%) (44778/44928)\n",
      "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.67%) (46054/46208)\n",
      "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.67%) (47330/47488)\n",
      "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0134) | Acc: (99.66%) (48603/48768)\n",
      "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.66%) (49831/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5853) | Acc: (90.06%) (9006/10000)\n",
      "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0090) | Acc: (100.00%) (128/128)\n",
      "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0140) | Acc: (99.43%) (1400/1408)\n",
      "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0137) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.55%) (3950/3968)\n",
      "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0137) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0137) | Acc: (99.60%) (6502/6528)\n",
      "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0135) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0139) | Acc: (99.59%) (9051/9088)\n",
      "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0138) | Acc: (99.59%) (10325/10368)\n",
      "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0132) | Acc: (99.61%) (11603/11648)\n",
      "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0132) | Acc: (99.61%) (12877/12928)\n",
      "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0129) | Acc: (99.63%) (14156/14208)\n",
      "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0127) | Acc: (99.65%) (15434/15488)\n",
      "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0129) | Acc: (99.65%) (16710/16768)\n",
      "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0129) | Acc: (99.66%) (17986/18048)\n",
      "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0127) | Acc: (99.67%) (19264/19328)\n",
      "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0126) | Acc: (99.67%) (20540/20608)\n",
      "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.68%) (21817/21888)\n",
      "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0127) | Acc: (99.67%) (23092/23168)\n",
      "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0127) | Acc: (99.68%) (24369/24448)\n",
      "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.69%) (25648/25728)\n",
      "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0124) | Acc: (99.70%) (26928/27008)\n",
      "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0122) | Acc: (99.71%) (28206/28288)\n",
      "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0122) | Acc: (99.71%) (29482/29568)\n",
      "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0122) | Acc: (99.71%) (30758/30848)\n",
      "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0124) | Acc: (99.70%) (32031/32128)\n",
      "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0126) | Acc: (99.69%) (33305/33408)\n",
      "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0125) | Acc: (99.69%) (34582/34688)\n",
      "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0125) | Acc: (99.70%) (35859/35968)\n",
      "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0125) | Acc: (99.70%) (37135/37248)\n",
      "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0127) | Acc: (99.69%) (38409/38528)\n",
      "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0126) | Acc: (99.70%) (39687/39808)\n",
      "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0126) | Acc: (99.70%) (40963/41088)\n",
      "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0127) | Acc: (99.69%) (42237/42368)\n",
      "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0128) | Acc: (99.69%) (43514/43648)\n",
      "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0128) | Acc: (99.69%) (44789/44928)\n",
      "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0129) | Acc: (99.69%) (46063/46208)\n",
      "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0130) | Acc: (99.69%) (47341/47488)\n",
      "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0130) | Acc: (99.69%) (48619/48768)\n",
      "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0129) | Acc: (99.70%) (49849/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5877) | Acc: (89.86%) (8986/10000)\n",
      "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0051) | Acc: (100.00%) (128/128)\n",
      "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0155) | Acc: (99.64%) (1403/1408)\n",
      "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0149) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0150) | Acc: (99.62%) (3953/3968)\n",
      "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0150) | Acc: (99.60%) (5227/5248)\n",
      "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.62%) (6503/6528)\n",
      "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0138) | Acc: (99.67%) (7782/7808)\n",
      "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.64%) (9055/9088)\n",
      "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0143) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.61%) (11602/11648)\n",
      "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0138) | Acc: (99.64%) (12882/12928)\n",
      "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.67%) (14161/14208)\n",
      "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0132) | Acc: (99.67%) (15437/15488)\n",
      "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0135) | Acc: (99.66%) (16711/16768)\n",
      "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0136) | Acc: (99.65%) (17985/18048)\n",
      "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0137) | Acc: (99.65%) (19260/19328)\n",
      "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0137) | Acc: (99.65%) (20536/20608)\n",
      "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0138) | Acc: (99.65%) (21811/21888)\n",
      "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0138) | Acc: (99.65%) (23088/23168)\n",
      "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0140) | Acc: (99.64%) (24359/24448)\n",
      "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0141) | Acc: (99.63%) (25633/25728)\n",
      "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0144) | Acc: (99.62%) (26906/27008)\n",
      "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.62%) (28180/28288)\n",
      "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0144) | Acc: (99.62%) (29455/29568)\n",
      "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0147) | Acc: (99.61%) (30727/30848)\n",
      "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0145) | Acc: (99.61%) (32003/32128)\n",
      "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.62%) (33282/33408)\n",
      "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0142) | Acc: (99.63%) (34560/34688)\n",
      "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0142) | Acc: (99.64%) (35838/35968)\n",
      "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0141) | Acc: (99.64%) (37114/37248)\n",
      "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0141) | Acc: (99.64%) (38390/38528)\n",
      "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0140) | Acc: (99.64%) (39664/39808)\n",
      "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.64%) (40939/41088)\n",
      "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.64%) (42217/42368)\n",
      "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0139) | Acc: (99.64%) (43491/43648)\n",
      "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.64%) (44766/44928)\n",
      "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0139) | Acc: (99.64%) (46042/46208)\n",
      "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0139) | Acc: (99.65%) (47320/47488)\n",
      "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0138) | Acc: (99.65%) (48599/48768)\n",
      "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.65%) (49827/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5719) | Acc: (90.23%) (9023/10000)\n",
      "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0070) | Acc: (100.00%) (128/128)\n",
      "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0161) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0143) | Acc: (99.67%) (2679/2688)\n",
      "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0138) | Acc: (99.70%) (3956/3968)\n",
      "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0134) | Acc: (99.73%) (5234/5248)\n",
      "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0125) | Acc: (99.77%) (6513/6528)\n",
      "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0130) | Acc: (99.76%) (7789/7808)\n",
      "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.78%) (9068/9088)\n",
      "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0126) | Acc: (99.80%) (10347/10368)\n",
      "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0123) | Acc: (99.79%) (11623/11648)\n",
      "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0125) | Acc: (99.76%) (12897/12928)\n",
      "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0131) | Acc: (99.71%) (14167/14208)\n",
      "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0128) | Acc: (99.74%) (15447/15488)\n",
      "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0129) | Acc: (99.73%) (16722/16768)\n",
      "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0133) | Acc: (99.71%) (17996/18048)\n",
      "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0133) | Acc: (99.68%) (19267/19328)\n",
      "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0135) | Acc: (99.67%) (20541/20608)\n",
      "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0135) | Acc: (99.68%) (21817/21888)\n",
      "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0135) | Acc: (99.68%) (23093/23168)\n",
      "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.68%) (24369/24448)\n",
      "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0135) | Acc: (99.67%) (25644/25728)\n",
      "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0134) | Acc: (99.67%) (26920/27008)\n",
      "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0133) | Acc: (99.68%) (28198/28288)\n",
      "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0134) | Acc: (99.68%) (29472/29568)\n",
      "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0133) | Acc: (99.68%) (30748/30848)\n",
      "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.69%) (32027/32128)\n",
      "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.68%) (33301/33408)\n",
      "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.68%) (34578/34688)\n",
      "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0132) | Acc: (99.68%) (35854/35968)\n",
      "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.69%) (37132/37248)\n",
      "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.69%) (38409/38528)\n",
      "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0130) | Acc: (99.69%) (39686/39808)\n",
      "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.70%) (40963/41088)\n",
      "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0131) | Acc: (99.70%) (42240/42368)\n",
      "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.70%) (43517/43648)\n",
      "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.70%) (44793/44928)\n",
      "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0131) | Acc: (99.70%) (46071/46208)\n",
      "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0131) | Acc: (99.70%) (47346/47488)\n",
      "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0131) | Acc: (99.70%) (48623/48768)\n",
      "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.70%) (49848/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5757) | Acc: (90.21%) (9021/10000)\n",
      "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0068) | Acc: (100.00%) (128/128)\n",
      "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0124) | Acc: (99.50%) (1401/1408)\n",
      "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0145) | Acc: (99.55%) (2676/2688)\n",
      "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0143) | Acc: (99.65%) (3954/3968)\n",
      "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0139) | Acc: (99.64%) (5229/5248)\n",
      "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.57%) (6500/6528)\n",
      "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0145) | Acc: (99.59%) (7776/7808)\n",
      "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0149) | Acc: (99.59%) (9051/9088)\n",
      "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0150) | Acc: (99.59%) (10326/10368)\n",
      "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0151) | Acc: (99.60%) (11601/11648)\n",
      "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0150) | Acc: (99.60%) (12876/12928)\n",
      "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0143) | Acc: (99.63%) (14155/14208)\n",
      "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0142) | Acc: (99.63%) (15430/15488)\n",
      "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0144) | Acc: (99.63%) (16706/16768)\n",
      "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0148) | Acc: (99.61%) (17977/18048)\n",
      "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0146) | Acc: (99.62%) (19255/19328)\n",
      "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0143) | Acc: (99.64%) (20533/20608)\n",
      "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0142) | Acc: (99.64%) (21810/21888)\n",
      "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0142) | Acc: (99.64%) (23085/23168)\n",
      "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0142) | Acc: (99.65%) (24363/24448)\n",
      "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0142) | Acc: (99.65%) (25639/25728)\n",
      "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.65%) (26914/27008)\n",
      "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.66%) (28191/28288)\n",
      "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0140) | Acc: (99.67%) (29469/29568)\n",
      "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0138) | Acc: (99.68%) (30748/30848)\n",
      "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.67%) (32021/32128)\n",
      "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0140) | Acc: (99.66%) (33296/33408)\n",
      "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0139) | Acc: (99.66%) (34571/34688)\n",
      "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0140) | Acc: (99.66%) (35845/35968)\n",
      "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0139) | Acc: (99.66%) (37121/37248)\n",
      "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0138) | Acc: (99.66%) (38398/38528)\n",
      "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0138) | Acc: (99.66%) (39674/39808)\n",
      "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.66%) (40950/41088)\n",
      "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0138) | Acc: (99.67%) (42228/42368)\n",
      "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0140) | Acc: (99.66%) (43498/43648)\n",
      "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.65%) (44772/44928)\n",
      "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.65%) (46046/46208)\n",
      "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0140) | Acc: (99.65%) (47324/47488)\n",
      "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0141) | Acc: (99.65%) (48595/48768)\n",
      "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0140) | Acc: (99.65%) (49823/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5888) | Acc: (90.07%) (9007/10000)\n",
      "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0147) | Acc: (100.00%) (128/128)\n",
      "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0149) | Acc: (99.36%) (1399/1408)\n",
      "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0146) | Acc: (99.44%) (2673/2688)\n",
      "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.57%) (3951/3968)\n",
      "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0141) | Acc: (99.56%) (5225/5248)\n",
      "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.56%) (6499/6528)\n",
      "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0139) | Acc: (99.60%) (7777/7808)\n",
      "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0136) | Acc: (99.61%) (9053/9088)\n",
      "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0133) | Acc: (99.64%) (10331/10368)\n",
      "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0130) | Acc: (99.66%) (11608/11648)\n",
      "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0127) | Acc: (99.68%) (12887/12928)\n",
      "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.65%) (14158/14208)\n",
      "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0135) | Acc: (99.64%) (15433/15488)\n",
      "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0133) | Acc: (99.65%) (16709/16768)\n",
      "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0132) | Acc: (99.65%) (17984/18048)\n",
      "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0133) | Acc: (99.65%) (19260/19328)\n",
      "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0133) | Acc: (99.65%) (20535/20608)\n",
      "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.65%) (21812/21888)\n",
      "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0131) | Acc: (99.65%) (23086/23168)\n",
      "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0133) | Acc: (99.64%) (24360/24448)\n",
      "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0134) | Acc: (99.63%) (25634/25728)\n",
      "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0133) | Acc: (99.64%) (26912/27008)\n",
      "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0133) | Acc: (99.65%) (28188/28288)\n",
      "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0133) | Acc: (99.65%) (29465/29568)\n",
      "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.65%) (30741/30848)\n",
      "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.66%) (32018/32128)\n",
      "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0134) | Acc: (99.66%) (33293/33408)\n",
      "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0133) | Acc: (99.66%) (34570/34688)\n",
      "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.66%) (35844/35968)\n",
      "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0137) | Acc: (99.65%) (37116/37248)\n",
      "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0136) | Acc: (99.65%) (38392/38528)\n",
      "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.65%) (39668/39808)\n",
      "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0135) | Acc: (99.65%) (40945/41088)\n",
      "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.65%) (42221/42368)\n",
      "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.65%) (43497/43648)\n",
      "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0134) | Acc: (99.66%) (44775/44928)\n",
      "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0134) | Acc: (99.66%) (46051/46208)\n",
      "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.67%) (47330/47488)\n",
      "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0134) | Acc: (99.66%) (48602/48768)\n",
      "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.66%) (49832/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5761) | Acc: (90.10%) (9010/10000)\n",
      "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0154) | Acc: (100.00%) (128/128)\n",
      "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0135) | Acc: (99.72%) (1404/1408)\n",
      "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0166) | Acc: (99.63%) (2678/2688)\n",
      "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0154) | Acc: (99.67%) (3955/3968)\n",
      "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0158) | Acc: (99.64%) (5229/5248)\n",
      "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0150) | Acc: (99.66%) (6506/6528)\n",
      "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0170) | Acc: (99.58%) (7775/7808)\n",
      "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0162) | Acc: (99.61%) (9053/9088)\n",
      "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0158) | Acc: (99.61%) (10328/10368)\n",
      "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0156) | Acc: (99.63%) (11605/11648)\n",
      "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0154) | Acc: (99.64%) (12881/12928)\n",
      "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0153) | Acc: (99.63%) (14156/14208)\n",
      "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0155) | Acc: (99.63%) (15431/15488)\n",
      "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0155) | Acc: (99.64%) (16707/16768)\n",
      "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.65%) (17985/18048)\n",
      "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0149) | Acc: (99.66%) (19262/19328)\n",
      "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0148) | Acc: (99.66%) (20537/20608)\n",
      "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.67%) (21816/21888)\n",
      "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0146) | Acc: (99.68%) (23093/23168)\n",
      "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0146) | Acc: (99.67%) (24367/24448)\n",
      "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0144) | Acc: (99.67%) (25643/25728)\n",
      "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0144) | Acc: (99.66%) (26917/27008)\n",
      "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0142) | Acc: (99.67%) (28195/28288)\n",
      "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0141) | Acc: (99.68%) (29473/29568)\n",
      "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0139) | Acc: (99.68%) (30750/30848)\n",
      "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0139) | Acc: (99.68%) (32026/32128)\n",
      "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.69%) (33303/33408)\n",
      "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0139) | Acc: (99.68%) (34577/34688)\n",
      "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0138) | Acc: (99.68%) (35854/35968)\n",
      "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0138) | Acc: (99.68%) (37129/37248)\n",
      "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.67%) (38402/38528)\n",
      "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0139) | Acc: (99.68%) (39679/39808)\n",
      "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.67%) (40952/41088)\n",
      "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0137) | Acc: (99.68%) (42231/42368)\n",
      "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0137) | Acc: (99.68%) (43508/43648)\n",
      "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0138) | Acc: (99.68%) (44783/44928)\n",
      "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.68%) (46058/46208)\n",
      "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.66%) (47327/47488)\n",
      "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0138) | Acc: (99.67%) (48606/48768)\n",
      "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.67%) (49833/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5731) | Acc: (90.12%) (9012/10000)\n",
      "9 hours 6 mins 42 secs for training\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4,\n",
    "                                nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")\n",
    "\n",
    "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "for epoch in range(start_epoch, 165):\n",
    "\n",
    "    if epoch < 80:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 120:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f1a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f178cf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bad03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
