{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fc5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "USE 1 GPUs!\n",
      "Epoch: 0 | Batch_idx: 0 |  Loss: (2.5535) | Acc: (11.72%) (15/128)\n",
      "Epoch: 0 | Batch_idx: 10 |  Loss: (2.3504) | Acc: (13.35%) (188/1408)\n",
      "Epoch: 0 | Batch_idx: 20 |  Loss: (2.2779) | Acc: (16.41%) (441/2688)\n",
      "Epoch: 0 | Batch_idx: 30 |  Loss: (2.2215) | Acc: (18.42%) (731/3968)\n",
      "Epoch: 0 | Batch_idx: 40 |  Loss: (2.1699) | Acc: (20.81%) (1092/5248)\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (2.1337) | Acc: (22.26%) (1453/6528)\n",
      "Epoch: 0 | Batch_idx: 60 |  Loss: (2.0970) | Acc: (23.32%) (1821/7808)\n",
      "Epoch: 0 | Batch_idx: 70 |  Loss: (2.0703) | Acc: (24.36%) (2214/9088)\n",
      "Epoch: 0 | Batch_idx: 80 |  Loss: (2.0420) | Acc: (25.74%) (2669/10368)\n",
      "Epoch: 0 | Batch_idx: 90 |  Loss: (2.0217) | Acc: (26.31%) (3065/11648)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (2.0005) | Acc: (26.96%) (3486/12928)\n",
      "Epoch: 0 | Batch_idx: 110 |  Loss: (1.9807) | Acc: (27.70%) (3936/14208)\n",
      "Epoch: 0 | Batch_idx: 120 |  Loss: (1.9627) | Acc: (28.15%) (4360/15488)\n",
      "Epoch: 0 | Batch_idx: 130 |  Loss: (1.9446) | Acc: (28.74%) (4819/16768)\n",
      "Epoch: 0 | Batch_idx: 140 |  Loss: (1.9298) | Acc: (29.25%) (5279/18048)\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (1.9155) | Acc: (29.85%) (5769/19328)\n",
      "Epoch: 0 | Batch_idx: 160 |  Loss: (1.9007) | Acc: (30.24%) (6232/20608)\n",
      "Epoch: 0 | Batch_idx: 170 |  Loss: (1.8863) | Acc: (30.81%) (6744/21888)\n",
      "Epoch: 0 | Batch_idx: 180 |  Loss: (1.8718) | Acc: (31.32%) (7256/23168)\n",
      "Epoch: 0 | Batch_idx: 190 |  Loss: (1.8606) | Acc: (31.53%) (7709/24448)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (1.8507) | Acc: (31.92%) (8213/25728)\n",
      "Epoch: 0 | Batch_idx: 210 |  Loss: (1.8398) | Acc: (32.31%) (8727/27008)\n",
      "Epoch: 0 | Batch_idx: 220 |  Loss: (1.8283) | Acc: (32.66%) (9240/28288)\n",
      "Epoch: 0 | Batch_idx: 230 |  Loss: (1.8188) | Acc: (32.99%) (9754/29568)\n",
      "Epoch: 0 | Batch_idx: 240 |  Loss: (1.8078) | Acc: (33.39%) (10300/30848)\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (1.7987) | Acc: (33.80%) (10859/32128)\n",
      "Epoch: 0 | Batch_idx: 260 |  Loss: (1.7899) | Acc: (34.16%) (11413/33408)\n",
      "Epoch: 0 | Batch_idx: 270 |  Loss: (1.7807) | Acc: (34.50%) (11966/34688)\n",
      "Epoch: 0 | Batch_idx: 280 |  Loss: (1.7714) | Acc: (34.86%) (12539/35968)\n",
      "Epoch: 0 | Batch_idx: 290 |  Loss: (1.7637) | Acc: (35.18%) (13103/37248)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (1.7560) | Acc: (35.48%) (13668/38528)\n",
      "Epoch: 0 | Batch_idx: 310 |  Loss: (1.7487) | Acc: (35.76%) (14234/39808)\n",
      "Epoch: 0 | Batch_idx: 320 |  Loss: (1.7400) | Acc: (36.09%) (14829/41088)\n",
      "Epoch: 0 | Batch_idx: 330 |  Loss: (1.7341) | Acc: (36.28%) (15369/42368)\n",
      "Epoch: 0 | Batch_idx: 340 |  Loss: (1.7280) | Acc: (36.51%) (15938/43648)\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (1.7215) | Acc: (36.76%) (16514/44928)\n",
      "Epoch: 0 | Batch_idx: 360 |  Loss: (1.7149) | Acc: (36.96%) (17078/46208)\n",
      "Epoch: 0 | Batch_idx: 370 |  Loss: (1.7086) | Acc: (37.19%) (17659/47488)\n",
      "Epoch: 0 | Batch_idx: 380 |  Loss: (1.7032) | Acc: (37.42%) (18249/48768)\n",
      "Epoch: 0 | Batch_idx: 390 |  Loss: (1.6970) | Acc: (37.69%) (18845/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.4656) | Acc: (46.19%) (4619/10000)\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (1.4339) | Acc: (44.53%) (57/128)\n",
      "Epoch: 1 | Batch_idx: 10 |  Loss: (1.4661) | Acc: (44.46%) (626/1408)\n",
      "Epoch: 1 | Batch_idx: 20 |  Loss: (1.4717) | Acc: (45.09%) (1212/2688)\n",
      "Epoch: 1 | Batch_idx: 30 |  Loss: (1.4697) | Acc: (45.54%) (1807/3968)\n",
      "Epoch: 1 | Batch_idx: 40 |  Loss: (1.4541) | Acc: (46.15%) (2422/5248)\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (1.4471) | Acc: (46.40%) (3029/6528)\n",
      "Epoch: 1 | Batch_idx: 60 |  Loss: (1.4407) | Acc: (46.45%) (3627/7808)\n",
      "Epoch: 1 | Batch_idx: 70 |  Loss: (1.4373) | Acc: (46.83%) (4256/9088)\n",
      "Epoch: 1 | Batch_idx: 80 |  Loss: (1.4344) | Acc: (47.04%) (4877/10368)\n",
      "Epoch: 1 | Batch_idx: 90 |  Loss: (1.4287) | Acc: (47.39%) (5520/11648)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (1.4277) | Acc: (47.65%) (6160/12928)\n",
      "Epoch: 1 | Batch_idx: 110 |  Loss: (1.4287) | Acc: (47.70%) (6777/14208)\n",
      "Epoch: 1 | Batch_idx: 120 |  Loss: (1.4239) | Acc: (47.95%) (7427/15488)\n",
      "Epoch: 1 | Batch_idx: 130 |  Loss: (1.4219) | Acc: (47.94%) (8038/16768)\n",
      "Epoch: 1 | Batch_idx: 140 |  Loss: (1.4199) | Acc: (48.01%) (8665/18048)\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (1.4171) | Acc: (48.20%) (9316/19328)\n",
      "Epoch: 1 | Batch_idx: 160 |  Loss: (1.4162) | Acc: (48.19%) (9930/20608)\n",
      "Epoch: 1 | Batch_idx: 170 |  Loss: (1.4092) | Acc: (48.43%) (10601/21888)\n",
      "Epoch: 1 | Batch_idx: 180 |  Loss: (1.4072) | Acc: (48.60%) (11259/23168)\n",
      "Epoch: 1 | Batch_idx: 190 |  Loss: (1.4039) | Acc: (48.69%) (11903/24448)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (1.4013) | Acc: (48.78%) (12549/25728)\n",
      "Epoch: 1 | Batch_idx: 210 |  Loss: (1.3979) | Acc: (48.89%) (13205/27008)\n",
      "Epoch: 1 | Batch_idx: 220 |  Loss: (1.3953) | Acc: (48.98%) (13856/28288)\n",
      "Epoch: 1 | Batch_idx: 230 |  Loss: (1.3920) | Acc: (49.08%) (14512/29568)\n",
      "Epoch: 1 | Batch_idx: 240 |  Loss: (1.3884) | Acc: (49.22%) (15182/30848)\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (1.3857) | Acc: (49.31%) (15843/32128)\n",
      "Epoch: 1 | Batch_idx: 260 |  Loss: (1.3818) | Acc: (49.50%) (16538/33408)\n",
      "Epoch: 1 | Batch_idx: 270 |  Loss: (1.3798) | Acc: (49.64%) (17219/34688)\n",
      "Epoch: 1 | Batch_idx: 280 |  Loss: (1.3789) | Acc: (49.68%) (17869/35968)\n",
      "Epoch: 1 | Batch_idx: 290 |  Loss: (1.3782) | Acc: (49.73%) (18522/37248)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (1.3757) | Acc: (49.86%) (19209/38528)\n",
      "Epoch: 1 | Batch_idx: 310 |  Loss: (1.3727) | Acc: (50.00%) (19903/39808)\n",
      "Epoch: 1 | Batch_idx: 320 |  Loss: (1.3710) | Acc: (50.04%) (20559/41088)\n",
      "Epoch: 1 | Batch_idx: 330 |  Loss: (1.3688) | Acc: (50.14%) (21243/42368)\n",
      "Epoch: 1 | Batch_idx: 340 |  Loss: (1.3665) | Acc: (50.19%) (21909/43648)\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (1.3640) | Acc: (50.35%) (22623/44928)\n",
      "Epoch: 1 | Batch_idx: 360 |  Loss: (1.3622) | Acc: (50.45%) (23312/46208)\n",
      "Epoch: 1 | Batch_idx: 370 |  Loss: (1.3594) | Acc: (50.57%) (24017/47488)\n",
      "Epoch: 1 | Batch_idx: 380 |  Loss: (1.3573) | Acc: (50.69%) (24720/48768)\n",
      "Epoch: 1 | Batch_idx: 390 |  Loss: (1.3550) | Acc: (50.77%) (25386/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.3256) | Acc: (51.60%) (5160/10000)\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (1.2851) | Acc: (50.00%) (64/128)\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (1.2601) | Acc: (54.12%) (762/1408)\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (1.2607) | Acc: (54.20%) (1457/2688)\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (1.2421) | Acc: (54.89%) (2178/3968)\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (1.2394) | Acc: (55.09%) (2891/5248)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (1.2480) | Acc: (54.55%) (3561/6528)\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (1.2454) | Acc: (54.61%) (4264/7808)\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (1.2429) | Acc: (54.61%) (4963/9088)\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (1.2458) | Acc: (54.60%) (5661/10368)\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (1.2508) | Acc: (54.44%) (6341/11648)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (1.2461) | Acc: (54.70%) (7072/12928)\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (1.2433) | Acc: (54.93%) (7805/14208)\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (1.2414) | Acc: (54.97%) (8514/15488)\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (1.2412) | Acc: (54.98%) (9219/16768)\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (1.2380) | Acc: (55.15%) (9953/18048)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (1.2322) | Acc: (55.37%) (10701/19328)\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (1.2295) | Acc: (55.36%) (11409/20608)\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (1.2276) | Acc: (55.52%) (12152/21888)\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (1.2284) | Acc: (55.43%) (12841/23168)\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (1.2289) | Acc: (55.37%) (13536/24448)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (1.2300) | Acc: (55.33%) (14236/25728)\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (1.2268) | Acc: (55.44%) (14972/27008)\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (1.2239) | Acc: (55.57%) (15721/28288)\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (1.2216) | Acc: (55.66%) (16459/29568)\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (1.2210) | Acc: (55.77%) (17203/30848)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (1.2178) | Acc: (55.94%) (17973/32128)\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (1.2148) | Acc: (56.08%) (18736/33408)\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (1.2127) | Acc: (56.13%) (19469/34688)\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (1.2110) | Acc: (56.19%) (20210/35968)\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (1.2090) | Acc: (56.30%) (20970/37248)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (1.2082) | Acc: (56.31%) (21694/38528)\n",
      "Epoch: 2 | Batch_idx: 310 |  Loss: (1.2053) | Acc: (56.41%) (22456/39808)\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (1.2025) | Acc: (56.54%) (23232/41088)\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (1.1991) | Acc: (56.66%) (24006/42368)\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (1.1966) | Acc: (56.70%) (24750/43648)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (1.1950) | Acc: (56.79%) (25514/44928)\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (1.1935) | Acc: (56.90%) (26291/46208)\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (1.1917) | Acc: (57.02%) (27076/47488)\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (1.1907) | Acc: (57.08%) (27838/48768)\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (1.1894) | Acc: (57.10%) (28550/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1991) | Acc: (57.18%) (5718/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (1.1438) | Acc: (57.03%) (73/128)\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (1.1019) | Acc: (60.23%) (848/1408)\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (1.1031) | Acc: (59.82%) (1608/2688)\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (1.1147) | Acc: (59.60%) (2365/3968)\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (1.1207) | Acc: (59.39%) (3117/5248)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (1.1171) | Acc: (59.34%) (3874/6528)\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (1.1146) | Acc: (59.70%) (4661/7808)\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (1.1054) | Acc: (59.94%) (5447/9088)\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (1.1067) | Acc: (59.98%) (6219/10368)\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (1.1086) | Acc: (59.98%) (6986/11648)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (1.1105) | Acc: (59.85%) (7737/12928)\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (1.1105) | Acc: (59.83%) (8500/14208)\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (1.1080) | Acc: (59.92%) (9281/15488)\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (1.1086) | Acc: (60.08%) (10075/16768)\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (1.1085) | Acc: (60.08%) (10843/18048)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (1.1081) | Acc: (60.14%) (11623/19328)\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (1.1069) | Acc: (60.13%) (12392/20608)\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (1.1056) | Acc: (60.19%) (13174/21888)\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (1.1042) | Acc: (60.35%) (13983/23168)\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (1.1029) | Acc: (60.47%) (14784/24448)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (1.1021) | Acc: (60.52%) (15570/25728)\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (1.1002) | Acc: (60.58%) (16362/27008)\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (1.0981) | Acc: (60.65%) (17157/28288)\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (1.0957) | Acc: (60.75%) (17962/29568)\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (1.0939) | Acc: (60.83%) (18764/30848)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (1.0926) | Acc: (60.88%) (19560/32128)\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (1.0902) | Acc: (60.95%) (20363/33408)\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (1.0889) | Acc: (61.05%) (21178/34688)\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (1.0870) | Acc: (61.16%) (21998/35968)\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (1.0857) | Acc: (61.20%) (22794/37248)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (1.0850) | Acc: (61.24%) (23596/38528)\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (1.0844) | Acc: (61.28%) (24396/39808)\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (1.0844) | Acc: (61.30%) (25188/41088)\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (1.0832) | Acc: (61.36%) (25999/42368)\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (1.0812) | Acc: (61.44%) (26817/43648)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (1.0804) | Acc: (61.45%) (27608/44928)\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (1.0782) | Acc: (61.52%) (28425/46208)\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (1.0780) | Acc: (61.56%) (29234/47488)\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (1.0762) | Acc: (61.63%) (30057/48768)\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (1.0748) | Acc: (61.71%) (30857/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.1258) | Acc: (60.22%) (6022/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (0.9960) | Acc: (63.28%) (81/128)\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (0.9917) | Acc: (64.63%) (910/1408)\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (1.0471) | Acc: (62.54%) (1681/2688)\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (1.0254) | Acc: (63.61%) (2524/3968)\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (1.0279) | Acc: (63.62%) (3339/5248)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (1.0231) | Acc: (63.60%) (4152/6528)\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (1.0260) | Acc: (63.42%) (4952/7808)\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (1.0184) | Acc: (63.80%) (5798/9088)\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (1.0197) | Acc: (63.97%) (6632/10368)\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (1.0237) | Acc: (63.83%) (7435/11648)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (1.0232) | Acc: (63.86%) (8256/12928)\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (1.0250) | Acc: (63.75%) (9057/14208)\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (1.0243) | Acc: (63.66%) (9859/15488)\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (1.0223) | Acc: (63.53%) (10653/16768)\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (1.0167) | Acc: (63.75%) (11506/18048)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (1.0165) | Acc: (63.73%) (12318/19328)\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (1.0184) | Acc: (63.69%) (13125/20608)\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (1.0167) | Acc: (63.76%) (13955/21888)\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (1.0170) | Acc: (63.71%) (14761/23168)\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (1.0167) | Acc: (63.68%) (15568/24448)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (1.0143) | Acc: (63.74%) (16398/25728)\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (1.0133) | Acc: (63.73%) (17213/27008)\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (1.0126) | Acc: (63.81%) (18050/28288)\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (1.0110) | Acc: (63.88%) (18889/29568)\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (1.0113) | Acc: (63.78%) (19676/30848)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (1.0108) | Acc: (63.84%) (20510/32128)\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (1.0097) | Acc: (63.92%) (21353/33408)\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (1.0075) | Acc: (64.06%) (22222/34688)\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (1.0071) | Acc: (64.07%) (23046/35968)\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (1.0076) | Acc: (64.06%) (23860/37248)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (1.0057) | Acc: (64.08%) (24689/38528)\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (1.0031) | Acc: (64.20%) (25555/39808)\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (1.0034) | Acc: (64.21%) (26383/41088)\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (1.0009) | Acc: (64.29%) (27237/42368)\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (1.0007) | Acc: (64.29%) (28062/43648)\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (0.9991) | Acc: (64.34%) (28906/44928)\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (0.9966) | Acc: (64.43%) (29772/46208)\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (0.9952) | Acc: (64.50%) (30631/47488)\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (0.9938) | Acc: (64.55%) (31480/48768)\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (0.9927) | Acc: (64.58%) (32290/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (1.0945) | Acc: (61.16%) (6116/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (0.8792) | Acc: (68.75%) (88/128)\n",
      "Epoch: 5 | Batch_idx: 10 |  Loss: (0.9970) | Acc: (63.99%) (901/1408)\n",
      "Epoch: 5 | Batch_idx: 20 |  Loss: (0.9604) | Acc: (65.55%) (1762/2688)\n",
      "Epoch: 5 | Batch_idx: 30 |  Loss: (0.9625) | Acc: (65.12%) (2584/3968)\n",
      "Epoch: 5 | Batch_idx: 40 |  Loss: (0.9516) | Acc: (65.72%) (3449/5248)\n",
      "Epoch: 5 | Batch_idx: 50 |  Loss: (0.9503) | Acc: (65.98%) (4307/6528)\n",
      "Epoch: 5 | Batch_idx: 60 |  Loss: (0.9476) | Acc: (65.79%) (5137/7808)\n",
      "Epoch: 5 | Batch_idx: 70 |  Loss: (0.9446) | Acc: (65.87%) (5986/9088)\n",
      "Epoch: 5 | Batch_idx: 80 |  Loss: (0.9523) | Acc: (65.75%) (6817/10368)\n",
      "Epoch: 5 | Batch_idx: 90 |  Loss: (0.9488) | Acc: (65.92%) (7678/11648)\n",
      "Epoch: 5 | Batch_idx: 100 |  Loss: (0.9502) | Acc: (66.00%) (8532/12928)\n",
      "Epoch: 5 | Batch_idx: 110 |  Loss: (0.9485) | Acc: (66.20%) (9405/14208)\n",
      "Epoch: 5 | Batch_idx: 120 |  Loss: (0.9490) | Acc: (66.22%) (10256/15488)\n",
      "Epoch: 5 | Batch_idx: 130 |  Loss: (0.9489) | Acc: (66.19%) (11098/16768)\n",
      "Epoch: 5 | Batch_idx: 140 |  Loss: (0.9489) | Acc: (66.17%) (11942/18048)\n",
      "Epoch: 5 | Batch_idx: 150 |  Loss: (0.9444) | Acc: (66.32%) (12819/19328)\n",
      "Epoch: 5 | Batch_idx: 160 |  Loss: (0.9456) | Acc: (66.22%) (13647/20608)\n",
      "Epoch: 5 | Batch_idx: 170 |  Loss: (0.9428) | Acc: (66.37%) (14526/21888)\n",
      "Epoch: 5 | Batch_idx: 180 |  Loss: (0.9421) | Acc: (66.40%) (15383/23168)\n",
      "Epoch: 5 | Batch_idx: 190 |  Loss: (0.9407) | Acc: (66.45%) (16245/24448)\n",
      "Epoch: 5 | Batch_idx: 200 |  Loss: (0.9368) | Acc: (66.64%) (17146/25728)\n",
      "Epoch: 5 | Batch_idx: 210 |  Loss: (0.9370) | Acc: (66.57%) (17978/27008)\n",
      "Epoch: 5 | Batch_idx: 220 |  Loss: (0.9380) | Acc: (66.49%) (18808/28288)\n",
      "Epoch: 5 | Batch_idx: 230 |  Loss: (0.9398) | Acc: (66.39%) (19631/29568)\n",
      "Epoch: 5 | Batch_idx: 240 |  Loss: (0.9351) | Acc: (66.59%) (20542/30848)\n",
      "Epoch: 5 | Batch_idx: 250 |  Loss: (0.9334) | Acc: (66.65%) (21412/32128)\n",
      "Epoch: 5 | Batch_idx: 260 |  Loss: (0.9321) | Acc: (66.72%) (22290/33408)\n",
      "Epoch: 5 | Batch_idx: 270 |  Loss: (0.9310) | Acc: (66.78%) (23166/34688)\n",
      "Epoch: 5 | Batch_idx: 280 |  Loss: (0.9305) | Acc: (66.77%) (24016/35968)\n",
      "Epoch: 5 | Batch_idx: 290 |  Loss: (0.9293) | Acc: (66.80%) (24882/37248)\n",
      "Epoch: 5 | Batch_idx: 300 |  Loss: (0.9292) | Acc: (66.82%) (25746/38528)\n",
      "Epoch: 5 | Batch_idx: 310 |  Loss: (0.9275) | Acc: (66.88%) (26623/39808)\n",
      "Epoch: 5 | Batch_idx: 320 |  Loss: (0.9277) | Acc: (66.83%) (27459/41088)\n",
      "Epoch: 5 | Batch_idx: 330 |  Loss: (0.9274) | Acc: (66.85%) (28325/42368)\n",
      "Epoch: 5 | Batch_idx: 340 |  Loss: (0.9270) | Acc: (66.87%) (29186/43648)\n",
      "Epoch: 5 | Batch_idx: 350 |  Loss: (0.9264) | Acc: (66.92%) (30068/44928)\n",
      "Epoch: 5 | Batch_idx: 360 |  Loss: (0.9262) | Acc: (66.94%) (30933/46208)\n",
      "Epoch: 5 | Batch_idx: 370 |  Loss: (0.9255) | Acc: (67.01%) (31821/47488)\n",
      "Epoch: 5 | Batch_idx: 380 |  Loss: (0.9252) | Acc: (67.03%) (32690/48768)\n",
      "Epoch: 5 | Batch_idx: 390 |  Loss: (0.9251) | Acc: (67.06%) (33531/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9156) | Acc: (67.60%) (6760/10000)\n",
      "Epoch: 6 | Batch_idx: 0 |  Loss: (0.9109) | Acc: (64.06%) (82/128)\n",
      "Epoch: 6 | Batch_idx: 10 |  Loss: (0.8834) | Acc: (69.11%) (973/1408)\n",
      "Epoch: 6 | Batch_idx: 20 |  Loss: (0.8957) | Acc: (68.38%) (1838/2688)\n",
      "Epoch: 6 | Batch_idx: 30 |  Loss: (0.8986) | Acc: (68.37%) (2713/3968)\n",
      "Epoch: 6 | Batch_idx: 40 |  Loss: (0.8941) | Acc: (68.58%) (3599/5248)\n",
      "Epoch: 6 | Batch_idx: 50 |  Loss: (0.8976) | Acc: (68.47%) (4470/6528)\n",
      "Epoch: 6 | Batch_idx: 60 |  Loss: (0.8992) | Acc: (68.31%) (5334/7808)\n",
      "Epoch: 6 | Batch_idx: 70 |  Loss: (0.8978) | Acc: (68.52%) (6227/9088)\n",
      "Epoch: 6 | Batch_idx: 80 |  Loss: (0.8940) | Acc: (68.54%) (7106/10368)\n",
      "Epoch: 6 | Batch_idx: 90 |  Loss: (0.8927) | Acc: (68.72%) (8005/11648)\n",
      "Epoch: 6 | Batch_idx: 100 |  Loss: (0.8868) | Acc: (68.93%) (8911/12928)\n",
      "Epoch: 6 | Batch_idx: 110 |  Loss: (0.8858) | Acc: (68.86%) (9784/14208)\n",
      "Epoch: 6 | Batch_idx: 120 |  Loss: (0.8836) | Acc: (68.92%) (10674/15488)\n",
      "Epoch: 6 | Batch_idx: 130 |  Loss: (0.8833) | Acc: (68.80%) (11537/16768)\n",
      "Epoch: 6 | Batch_idx: 140 |  Loss: (0.8868) | Acc: (68.61%) (12382/18048)\n",
      "Epoch: 6 | Batch_idx: 150 |  Loss: (0.8851) | Acc: (68.66%) (13271/19328)\n",
      "Epoch: 6 | Batch_idx: 160 |  Loss: (0.8857) | Acc: (68.71%) (14160/20608)\n",
      "Epoch: 6 | Batch_idx: 170 |  Loss: (0.8856) | Acc: (68.66%) (15028/21888)\n",
      "Epoch: 6 | Batch_idx: 180 |  Loss: (0.8836) | Acc: (68.79%) (15938/23168)\n",
      "Epoch: 6 | Batch_idx: 190 |  Loss: (0.8822) | Acc: (68.85%) (16832/24448)\n",
      "Epoch: 6 | Batch_idx: 200 |  Loss: (0.8795) | Acc: (68.96%) (17741/25728)\n",
      "Epoch: 6 | Batch_idx: 210 |  Loss: (0.8788) | Acc: (68.93%) (18616/27008)\n",
      "Epoch: 6 | Batch_idx: 220 |  Loss: (0.8764) | Acc: (69.05%) (19534/28288)\n",
      "Epoch: 6 | Batch_idx: 230 |  Loss: (0.8765) | Acc: (69.05%) (20416/29568)\n",
      "Epoch: 6 | Batch_idx: 240 |  Loss: (0.8758) | Acc: (69.05%) (21300/30848)\n",
      "Epoch: 6 | Batch_idx: 250 |  Loss: (0.8751) | Acc: (69.09%) (22198/32128)\n",
      "Epoch: 6 | Batch_idx: 260 |  Loss: (0.8733) | Acc: (69.16%) (23104/33408)\n",
      "Epoch: 6 | Batch_idx: 270 |  Loss: (0.8719) | Acc: (69.20%) (24005/34688)\n",
      "Epoch: 6 | Batch_idx: 280 |  Loss: (0.8714) | Acc: (69.27%) (24916/35968)\n",
      "Epoch: 6 | Batch_idx: 290 |  Loss: (0.8718) | Acc: (69.28%) (25804/37248)\n",
      "Epoch: 6 | Batch_idx: 300 |  Loss: (0.8713) | Acc: (69.31%) (26702/38528)\n",
      "Epoch: 6 | Batch_idx: 310 |  Loss: (0.8713) | Acc: (69.25%) (27569/39808)\n",
      "Epoch: 6 | Batch_idx: 320 |  Loss: (0.8707) | Acc: (69.30%) (28474/41088)\n",
      "Epoch: 6 | Batch_idx: 330 |  Loss: (0.8688) | Acc: (69.39%) (29401/42368)\n",
      "Epoch: 6 | Batch_idx: 340 |  Loss: (0.8681) | Acc: (69.40%) (30293/43648)\n",
      "Epoch: 6 | Batch_idx: 350 |  Loss: (0.8681) | Acc: (69.39%) (31177/44928)\n",
      "Epoch: 6 | Batch_idx: 360 |  Loss: (0.8671) | Acc: (69.43%) (32083/46208)\n",
      "Epoch: 6 | Batch_idx: 370 |  Loss: (0.8665) | Acc: (69.48%) (32993/47488)\n",
      "Epoch: 6 | Batch_idx: 380 |  Loss: (0.8666) | Acc: (69.48%) (33882/48768)\n",
      "Epoch: 6 | Batch_idx: 390 |  Loss: (0.8653) | Acc: (69.53%) (34767/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9296) | Acc: (67.64%) (6764/10000)\n",
      "Epoch: 7 | Batch_idx: 0 |  Loss: (0.7523) | Acc: (71.09%) (91/128)\n",
      "Epoch: 7 | Batch_idx: 10 |  Loss: (0.8518) | Acc: (69.32%) (976/1408)\n",
      "Epoch: 7 | Batch_idx: 20 |  Loss: (0.8313) | Acc: (70.83%) (1904/2688)\n",
      "Epoch: 7 | Batch_idx: 30 |  Loss: (0.8243) | Acc: (70.79%) (2809/3968)\n",
      "Epoch: 7 | Batch_idx: 40 |  Loss: (0.8363) | Acc: (70.45%) (3697/5248)\n",
      "Epoch: 7 | Batch_idx: 50 |  Loss: (0.8285) | Acc: (70.91%) (4629/6528)\n",
      "Epoch: 7 | Batch_idx: 60 |  Loss: (0.8256) | Acc: (71.07%) (5549/7808)\n",
      "Epoch: 7 | Batch_idx: 70 |  Loss: (0.8241) | Acc: (71.21%) (6472/9088)\n",
      "Epoch: 7 | Batch_idx: 80 |  Loss: (0.8317) | Acc: (70.86%) (7347/10368)\n",
      "Epoch: 7 | Batch_idx: 90 |  Loss: (0.8345) | Acc: (70.70%) (8235/11648)\n",
      "Epoch: 7 | Batch_idx: 100 |  Loss: (0.8348) | Acc: (70.79%) (9152/12928)\n",
      "Epoch: 7 | Batch_idx: 110 |  Loss: (0.8326) | Acc: (70.82%) (10062/14208)\n",
      "Epoch: 7 | Batch_idx: 120 |  Loss: (0.8333) | Acc: (70.82%) (10968/15488)\n",
      "Epoch: 7 | Batch_idx: 130 |  Loss: (0.8284) | Acc: (70.99%) (11904/16768)\n",
      "Epoch: 7 | Batch_idx: 140 |  Loss: (0.8291) | Acc: (71.03%) (12819/18048)\n",
      "Epoch: 7 | Batch_idx: 150 |  Loss: (0.8255) | Acc: (71.08%) (13738/19328)\n",
      "Epoch: 7 | Batch_idx: 160 |  Loss: (0.8276) | Acc: (71.03%) (14638/20608)\n",
      "Epoch: 7 | Batch_idx: 170 |  Loss: (0.8270) | Acc: (71.01%) (15542/21888)\n",
      "Epoch: 7 | Batch_idx: 180 |  Loss: (0.8247) | Acc: (71.06%) (16464/23168)\n",
      "Epoch: 7 | Batch_idx: 190 |  Loss: (0.8241) | Acc: (71.04%) (17369/24448)\n",
      "Epoch: 7 | Batch_idx: 200 |  Loss: (0.8231) | Acc: (71.07%) (18286/25728)\n",
      "Epoch: 7 | Batch_idx: 210 |  Loss: (0.8260) | Acc: (70.98%) (19170/27008)\n",
      "Epoch: 7 | Batch_idx: 220 |  Loss: (0.8254) | Acc: (70.96%) (20073/28288)\n",
      "Epoch: 7 | Batch_idx: 230 |  Loss: (0.8261) | Acc: (70.96%) (20982/29568)\n",
      "Epoch: 7 | Batch_idx: 240 |  Loss: (0.8249) | Acc: (71.03%) (21910/30848)\n",
      "Epoch: 7 | Batch_idx: 250 |  Loss: (0.8256) | Acc: (70.96%) (22798/32128)\n",
      "Epoch: 7 | Batch_idx: 260 |  Loss: (0.8240) | Acc: (70.98%) (23713/33408)\n",
      "Epoch: 7 | Batch_idx: 270 |  Loss: (0.8231) | Acc: (70.99%) (24625/34688)\n",
      "Epoch: 7 | Batch_idx: 280 |  Loss: (0.8230) | Acc: (71.00%) (25538/35968)\n",
      "Epoch: 7 | Batch_idx: 290 |  Loss: (0.8220) | Acc: (71.08%) (26477/37248)\n",
      "Epoch: 7 | Batch_idx: 300 |  Loss: (0.8216) | Acc: (71.10%) (27393/38528)\n",
      "Epoch: 7 | Batch_idx: 310 |  Loss: (0.8222) | Acc: (71.04%) (28281/39808)\n",
      "Epoch: 7 | Batch_idx: 320 |  Loss: (0.8223) | Acc: (71.03%) (29184/41088)\n",
      "Epoch: 7 | Batch_idx: 330 |  Loss: (0.8220) | Acc: (71.04%) (30100/42368)\n",
      "Epoch: 7 | Batch_idx: 340 |  Loss: (0.8208) | Acc: (71.07%) (31019/43648)\n",
      "Epoch: 7 | Batch_idx: 350 |  Loss: (0.8209) | Acc: (71.08%) (31934/44928)\n",
      "Epoch: 7 | Batch_idx: 360 |  Loss: (0.8212) | Acc: (71.05%) (32831/46208)\n",
      "Epoch: 7 | Batch_idx: 370 |  Loss: (0.8204) | Acc: (71.08%) (33755/47488)\n",
      "Epoch: 7 | Batch_idx: 380 |  Loss: (0.8215) | Acc: (71.07%) (34661/48768)\n",
      "Epoch: 7 | Batch_idx: 390 |  Loss: (0.8207) | Acc: (71.07%) (35533/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.9251) | Acc: (67.47%) (6747/10000)\n",
      "Epoch: 8 | Batch_idx: 0 |  Loss: (0.7601) | Acc: (71.09%) (91/128)\n",
      "Epoch: 8 | Batch_idx: 10 |  Loss: (0.8260) | Acc: (70.60%) (994/1408)\n",
      "Epoch: 8 | Batch_idx: 20 |  Loss: (0.8082) | Acc: (70.50%) (1895/2688)\n",
      "Epoch: 8 | Batch_idx: 30 |  Loss: (0.7958) | Acc: (71.35%) (2831/3968)\n",
      "Epoch: 8 | Batch_idx: 40 |  Loss: (0.7997) | Acc: (71.34%) (3744/5248)\n",
      "Epoch: 8 | Batch_idx: 50 |  Loss: (0.8023) | Acc: (71.46%) (4665/6528)\n",
      "Epoch: 8 | Batch_idx: 60 |  Loss: (0.8021) | Acc: (71.58%) (5589/7808)\n",
      "Epoch: 8 | Batch_idx: 70 |  Loss: (0.7984) | Acc: (71.79%) (6524/9088)\n",
      "Epoch: 8 | Batch_idx: 80 |  Loss: (0.7980) | Acc: (71.91%) (7456/10368)\n",
      "Epoch: 8 | Batch_idx: 90 |  Loss: (0.7976) | Acc: (72.06%) (8394/11648)\n",
      "Epoch: 8 | Batch_idx: 100 |  Loss: (0.7936) | Acc: (72.23%) (9338/12928)\n",
      "Epoch: 8 | Batch_idx: 110 |  Loss: (0.7934) | Acc: (72.23%) (10263/14208)\n",
      "Epoch: 8 | Batch_idx: 120 |  Loss: (0.7911) | Acc: (72.24%) (11189/15488)\n",
      "Epoch: 8 | Batch_idx: 130 |  Loss: (0.7875) | Acc: (72.35%) (12132/16768)\n",
      "Epoch: 8 | Batch_idx: 140 |  Loss: (0.7864) | Acc: (72.42%) (13070/18048)\n",
      "Epoch: 8 | Batch_idx: 150 |  Loss: (0.7879) | Acc: (72.32%) (13978/19328)\n",
      "Epoch: 8 | Batch_idx: 160 |  Loss: (0.7865) | Acc: (72.35%) (14910/20608)\n",
      "Epoch: 8 | Batch_idx: 170 |  Loss: (0.7853) | Acc: (72.42%) (15852/21888)\n",
      "Epoch: 8 | Batch_idx: 180 |  Loss: (0.7851) | Acc: (72.36%) (16764/23168)\n",
      "Epoch: 8 | Batch_idx: 190 |  Loss: (0.7845) | Acc: (72.36%) (17691/24448)\n",
      "Epoch: 8 | Batch_idx: 200 |  Loss: (0.7835) | Acc: (72.32%) (18606/25728)\n",
      "Epoch: 8 | Batch_idx: 210 |  Loss: (0.7828) | Acc: (72.30%) (19528/27008)\n",
      "Epoch: 8 | Batch_idx: 220 |  Loss: (0.7830) | Acc: (72.35%) (20465/28288)\n",
      "Epoch: 8 | Batch_idx: 230 |  Loss: (0.7831) | Acc: (72.34%) (21390/29568)\n",
      "Epoch: 8 | Batch_idx: 240 |  Loss: (0.7827) | Acc: (72.36%) (22322/30848)\n",
      "Epoch: 8 | Batch_idx: 250 |  Loss: (0.7824) | Acc: (72.39%) (23256/32128)\n",
      "Epoch: 8 | Batch_idx: 260 |  Loss: (0.7820) | Acc: (72.37%) (24178/33408)\n",
      "Epoch: 8 | Batch_idx: 270 |  Loss: (0.7822) | Acc: (72.30%) (25080/34688)\n",
      "Epoch: 8 | Batch_idx: 280 |  Loss: (0.7824) | Acc: (72.32%) (26013/35968)\n",
      "Epoch: 8 | Batch_idx: 290 |  Loss: (0.7815) | Acc: (72.36%) (26951/37248)\n",
      "Epoch: 8 | Batch_idx: 300 |  Loss: (0.7808) | Acc: (72.36%) (27877/38528)\n",
      "Epoch: 8 | Batch_idx: 310 |  Loss: (0.7799) | Acc: (72.41%) (28825/39808)\n",
      "Epoch: 8 | Batch_idx: 320 |  Loss: (0.7794) | Acc: (72.44%) (29764/41088)\n",
      "Epoch: 8 | Batch_idx: 330 |  Loss: (0.7788) | Acc: (72.50%) (30716/42368)\n",
      "Epoch: 8 | Batch_idx: 340 |  Loss: (0.7778) | Acc: (72.56%) (31672/43648)\n",
      "Epoch: 8 | Batch_idx: 350 |  Loss: (0.7772) | Acc: (72.59%) (32612/44928)\n",
      "Epoch: 8 | Batch_idx: 360 |  Loss: (0.7749) | Acc: (72.67%) (33580/46208)\n",
      "Epoch: 8 | Batch_idx: 370 |  Loss: (0.7744) | Acc: (72.71%) (34528/47488)\n",
      "Epoch: 8 | Batch_idx: 380 |  Loss: (0.7735) | Acc: (72.74%) (35474/48768)\n",
      "Epoch: 8 | Batch_idx: 390 |  Loss: (0.7732) | Acc: (72.73%) (36363/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8323) | Acc: (70.87%) (7087/10000)\n",
      "Epoch: 9 | Batch_idx: 0 |  Loss: (0.7958) | Acc: (75.78%) (97/128)\n",
      "Epoch: 9 | Batch_idx: 10 |  Loss: (0.7863) | Acc: (72.16%) (1016/1408)\n",
      "Epoch: 9 | Batch_idx: 20 |  Loss: (0.7751) | Acc: (72.88%) (1959/2688)\n",
      "Epoch: 9 | Batch_idx: 30 |  Loss: (0.7827) | Acc: (72.96%) (2895/3968)\n",
      "Epoch: 9 | Batch_idx: 40 |  Loss: (0.7636) | Acc: (73.55%) (3860/5248)\n",
      "Epoch: 9 | Batch_idx: 50 |  Loss: (0.7592) | Acc: (73.90%) (4824/6528)\n",
      "Epoch: 9 | Batch_idx: 60 |  Loss: (0.7624) | Acc: (73.50%) (5739/7808)\n",
      "Epoch: 9 | Batch_idx: 70 |  Loss: (0.7526) | Acc: (74.04%) (6729/9088)\n",
      "Epoch: 9 | Batch_idx: 80 |  Loss: (0.7544) | Acc: (73.83%) (7655/10368)\n",
      "Epoch: 9 | Batch_idx: 90 |  Loss: (0.7521) | Acc: (74.04%) (8624/11648)\n",
      "Epoch: 9 | Batch_idx: 100 |  Loss: (0.7492) | Acc: (74.05%) (9573/12928)\n",
      "Epoch: 9 | Batch_idx: 110 |  Loss: (0.7475) | Acc: (74.10%) (10528/14208)\n",
      "Epoch: 9 | Batch_idx: 120 |  Loss: (0.7449) | Acc: (74.10%) (11476/15488)\n",
      "Epoch: 9 | Batch_idx: 130 |  Loss: (0.7405) | Acc: (74.18%) (12438/16768)\n",
      "Epoch: 9 | Batch_idx: 140 |  Loss: (0.7438) | Acc: (74.06%) (13367/18048)\n",
      "Epoch: 9 | Batch_idx: 150 |  Loss: (0.7430) | Acc: (73.98%) (14299/19328)\n",
      "Epoch: 9 | Batch_idx: 160 |  Loss: (0.7417) | Acc: (74.00%) (15249/20608)\n",
      "Epoch: 9 | Batch_idx: 170 |  Loss: (0.7413) | Acc: (74.03%) (16203/21888)\n",
      "Epoch: 9 | Batch_idx: 180 |  Loss: (0.7421) | Acc: (74.00%) (17144/23168)\n",
      "Epoch: 9 | Batch_idx: 190 |  Loss: (0.7425) | Acc: (73.93%) (18074/24448)\n",
      "Epoch: 9 | Batch_idx: 200 |  Loss: (0.7439) | Acc: (73.87%) (19006/25728)\n",
      "Epoch: 9 | Batch_idx: 210 |  Loss: (0.7431) | Acc: (73.88%) (19954/27008)\n",
      "Epoch: 9 | Batch_idx: 220 |  Loss: (0.7430) | Acc: (73.92%) (20910/28288)\n",
      "Epoch: 9 | Batch_idx: 230 |  Loss: (0.7400) | Acc: (73.97%) (21870/29568)\n",
      "Epoch: 9 | Batch_idx: 240 |  Loss: (0.7403) | Acc: (73.96%) (22814/30848)\n",
      "Epoch: 9 | Batch_idx: 250 |  Loss: (0.7384) | Acc: (74.03%) (23783/32128)\n",
      "Epoch: 9 | Batch_idx: 260 |  Loss: (0.7371) | Acc: (74.07%) (24744/33408)\n",
      "Epoch: 9 | Batch_idx: 270 |  Loss: (0.7373) | Acc: (74.10%) (25703/34688)\n",
      "Epoch: 9 | Batch_idx: 280 |  Loss: (0.7357) | Acc: (74.20%) (26687/35968)\n",
      "Epoch: 9 | Batch_idx: 290 |  Loss: (0.7352) | Acc: (74.21%) (27643/37248)\n",
      "Epoch: 9 | Batch_idx: 300 |  Loss: (0.7363) | Acc: (74.17%) (28576/38528)\n",
      "Epoch: 9 | Batch_idx: 310 |  Loss: (0.7359) | Acc: (74.18%) (29531/39808)\n",
      "Epoch: 9 | Batch_idx: 320 |  Loss: (0.7353) | Acc: (74.24%) (30502/41088)\n",
      "Epoch: 9 | Batch_idx: 330 |  Loss: (0.7351) | Acc: (74.23%) (31450/42368)\n",
      "Epoch: 9 | Batch_idx: 340 |  Loss: (0.7339) | Acc: (74.25%) (32407/43648)\n",
      "Epoch: 9 | Batch_idx: 350 |  Loss: (0.7336) | Acc: (74.25%) (33361/44928)\n",
      "Epoch: 9 | Batch_idx: 360 |  Loss: (0.7332) | Acc: (74.25%) (34308/46208)\n",
      "Epoch: 9 | Batch_idx: 370 |  Loss: (0.7322) | Acc: (74.27%) (35270/47488)\n",
      "Epoch: 9 | Batch_idx: 380 |  Loss: (0.7317) | Acc: (74.30%) (36233/48768)\n",
      "Epoch: 9 | Batch_idx: 390 |  Loss: (0.7313) | Acc: (74.31%) (37156/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7613) | Acc: (73.45%) (7345/10000)\n",
      "Epoch: 10 | Batch_idx: 0 |  Loss: (0.7093) | Acc: (75.00%) (96/128)\n",
      "Epoch: 10 | Batch_idx: 10 |  Loss: (0.6378) | Acc: (77.13%) (1086/1408)\n",
      "Epoch: 10 | Batch_idx: 20 |  Loss: (0.6724) | Acc: (76.00%) (2043/2688)\n",
      "Epoch: 10 | Batch_idx: 30 |  Loss: (0.6816) | Acc: (75.73%) (3005/3968)\n",
      "Epoch: 10 | Batch_idx: 40 |  Loss: (0.6822) | Acc: (75.95%) (3986/5248)\n",
      "Epoch: 10 | Batch_idx: 50 |  Loss: (0.6879) | Acc: (75.80%) (4948/6528)\n",
      "Epoch: 10 | Batch_idx: 60 |  Loss: (0.6920) | Acc: (75.54%) (5898/7808)\n",
      "Epoch: 10 | Batch_idx: 70 |  Loss: (0.6881) | Acc: (75.67%) (6877/9088)\n",
      "Epoch: 10 | Batch_idx: 80 |  Loss: (0.6900) | Acc: (75.60%) (7838/10368)\n",
      "Epoch: 10 | Batch_idx: 90 |  Loss: (0.6892) | Acc: (75.78%) (8827/11648)\n",
      "Epoch: 10 | Batch_idx: 100 |  Loss: (0.6883) | Acc: (75.77%) (9795/12928)\n",
      "Epoch: 10 | Batch_idx: 110 |  Loss: (0.6890) | Acc: (75.67%) (10751/14208)\n",
      "Epoch: 10 | Batch_idx: 120 |  Loss: (0.6892) | Acc: (75.70%) (11725/15488)\n",
      "Epoch: 10 | Batch_idx: 130 |  Loss: (0.6883) | Acc: (75.78%) (12706/16768)\n",
      "Epoch: 10 | Batch_idx: 140 |  Loss: (0.6903) | Acc: (75.56%) (13637/18048)\n",
      "Epoch: 10 | Batch_idx: 150 |  Loss: (0.6946) | Acc: (75.46%) (14585/19328)\n",
      "Epoch: 10 | Batch_idx: 160 |  Loss: (0.6958) | Acc: (75.47%) (15553/20608)\n",
      "Epoch: 10 | Batch_idx: 170 |  Loss: (0.6947) | Acc: (75.51%) (16528/21888)\n",
      "Epoch: 10 | Batch_idx: 180 |  Loss: (0.6982) | Acc: (75.45%) (17480/23168)\n",
      "Epoch: 10 | Batch_idx: 190 |  Loss: (0.6962) | Acc: (75.49%) (18456/24448)\n",
      "Epoch: 10 | Batch_idx: 200 |  Loss: (0.6981) | Acc: (75.44%) (19409/25728)\n",
      "Epoch: 10 | Batch_idx: 210 |  Loss: (0.7001) | Acc: (75.36%) (20352/27008)\n",
      "Epoch: 10 | Batch_idx: 220 |  Loss: (0.6987) | Acc: (75.41%) (21332/28288)\n",
      "Epoch: 10 | Batch_idx: 230 |  Loss: (0.6983) | Acc: (75.40%) (22293/29568)\n",
      "Epoch: 10 | Batch_idx: 240 |  Loss: (0.7001) | Acc: (75.38%) (23254/30848)\n",
      "Epoch: 10 | Batch_idx: 250 |  Loss: (0.6992) | Acc: (75.41%) (24228/32128)\n",
      "Epoch: 10 | Batch_idx: 260 |  Loss: (0.6983) | Acc: (75.47%) (25212/33408)\n",
      "Epoch: 10 | Batch_idx: 270 |  Loss: (0.6986) | Acc: (75.45%) (26173/34688)\n",
      "Epoch: 10 | Batch_idx: 280 |  Loss: (0.7005) | Acc: (75.42%) (27128/35968)\n",
      "Epoch: 10 | Batch_idx: 290 |  Loss: (0.7002) | Acc: (75.44%) (28099/37248)\n",
      "Epoch: 10 | Batch_idx: 300 |  Loss: (0.6998) | Acc: (75.50%) (29090/38528)\n",
      "Epoch: 10 | Batch_idx: 310 |  Loss: (0.6996) | Acc: (75.50%) (30057/39808)\n",
      "Epoch: 10 | Batch_idx: 320 |  Loss: (0.6993) | Acc: (75.57%) (31052/41088)\n",
      "Epoch: 10 | Batch_idx: 330 |  Loss: (0.6977) | Acc: (75.61%) (32036/42368)\n",
      "Epoch: 10 | Batch_idx: 340 |  Loss: (0.6971) | Acc: (75.64%) (33014/43648)\n",
      "Epoch: 10 | Batch_idx: 350 |  Loss: (0.6979) | Acc: (75.62%) (33976/44928)\n",
      "Epoch: 10 | Batch_idx: 360 |  Loss: (0.6966) | Acc: (75.68%) (34969/46208)\n",
      "Epoch: 10 | Batch_idx: 370 |  Loss: (0.6962) | Acc: (75.69%) (35946/47488)\n",
      "Epoch: 10 | Batch_idx: 380 |  Loss: (0.6960) | Acc: (75.69%) (36914/48768)\n",
      "Epoch: 10 | Batch_idx: 390 |  Loss: (0.6962) | Acc: (75.66%) (37832/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8156) | Acc: (71.91%) (7191/10000)\n",
      "Epoch: 11 | Batch_idx: 0 |  Loss: (0.7983) | Acc: (68.75%) (88/128)\n",
      "Epoch: 11 | Batch_idx: 10 |  Loss: (0.6604) | Acc: (77.27%) (1088/1408)\n",
      "Epoch: 11 | Batch_idx: 20 |  Loss: (0.6538) | Acc: (77.90%) (2094/2688)\n",
      "Epoch: 11 | Batch_idx: 30 |  Loss: (0.6602) | Acc: (77.32%) (3068/3968)\n",
      "Epoch: 11 | Batch_idx: 40 |  Loss: (0.6641) | Acc: (77.15%) (4049/5248)\n",
      "Epoch: 11 | Batch_idx: 50 |  Loss: (0.6563) | Acc: (77.41%) (5053/6528)\n",
      "Epoch: 11 | Batch_idx: 60 |  Loss: (0.6579) | Acc: (77.28%) (6034/7808)\n",
      "Epoch: 11 | Batch_idx: 70 |  Loss: (0.6593) | Acc: (77.15%) (7011/9088)\n",
      "Epoch: 11 | Batch_idx: 80 |  Loss: (0.6617) | Acc: (77.14%) (7998/10368)\n",
      "Epoch: 11 | Batch_idx: 90 |  Loss: (0.6601) | Acc: (77.15%) (8986/11648)\n",
      "Epoch: 11 | Batch_idx: 100 |  Loss: (0.6575) | Acc: (77.19%) (9979/12928)\n",
      "Epoch: 11 | Batch_idx: 110 |  Loss: (0.6608) | Acc: (77.10%) (10955/14208)\n",
      "Epoch: 11 | Batch_idx: 120 |  Loss: (0.6652) | Acc: (76.79%) (11893/15488)\n",
      "Epoch: 11 | Batch_idx: 130 |  Loss: (0.6661) | Acc: (76.73%) (12866/16768)\n",
      "Epoch: 11 | Batch_idx: 140 |  Loss: (0.6665) | Acc: (76.73%) (13848/18048)\n",
      "Epoch: 11 | Batch_idx: 150 |  Loss: (0.6676) | Acc: (76.74%) (14833/19328)\n",
      "Epoch: 11 | Batch_idx: 160 |  Loss: (0.6659) | Acc: (76.77%) (15820/20608)\n",
      "Epoch: 11 | Batch_idx: 170 |  Loss: (0.6647) | Acc: (76.84%) (16819/21888)\n",
      "Epoch: 11 | Batch_idx: 180 |  Loss: (0.6652) | Acc: (76.79%) (17790/23168)\n",
      "Epoch: 11 | Batch_idx: 190 |  Loss: (0.6647) | Acc: (76.79%) (18773/24448)\n",
      "Epoch: 11 | Batch_idx: 200 |  Loss: (0.6644) | Acc: (76.77%) (19752/25728)\n",
      "Epoch: 11 | Batch_idx: 210 |  Loss: (0.6630) | Acc: (76.83%) (20750/27008)\n",
      "Epoch: 11 | Batch_idx: 220 |  Loss: (0.6660) | Acc: (76.69%) (21694/28288)\n",
      "Epoch: 11 | Batch_idx: 230 |  Loss: (0.6659) | Acc: (76.66%) (22667/29568)\n",
      "Epoch: 11 | Batch_idx: 240 |  Loss: (0.6642) | Acc: (76.72%) (23668/30848)\n",
      "Epoch: 11 | Batch_idx: 250 |  Loss: (0.6648) | Acc: (76.65%) (24625/32128)\n",
      "Epoch: 11 | Batch_idx: 260 |  Loss: (0.6649) | Acc: (76.65%) (25606/33408)\n",
      "Epoch: 11 | Batch_idx: 270 |  Loss: (0.6648) | Acc: (76.66%) (26591/34688)\n",
      "Epoch: 11 | Batch_idx: 280 |  Loss: (0.6625) | Acc: (76.74%) (27602/35968)\n",
      "Epoch: 11 | Batch_idx: 290 |  Loss: (0.6616) | Acc: (76.81%) (28610/37248)\n",
      "Epoch: 11 | Batch_idx: 300 |  Loss: (0.6599) | Acc: (76.89%) (29623/38528)\n",
      "Epoch: 11 | Batch_idx: 310 |  Loss: (0.6603) | Acc: (76.88%) (30605/39808)\n",
      "Epoch: 11 | Batch_idx: 320 |  Loss: (0.6601) | Acc: (76.91%) (31601/41088)\n",
      "Epoch: 11 | Batch_idx: 330 |  Loss: (0.6601) | Acc: (76.92%) (32588/42368)\n",
      "Epoch: 11 | Batch_idx: 340 |  Loss: (0.6595) | Acc: (76.92%) (33572/43648)\n",
      "Epoch: 11 | Batch_idx: 350 |  Loss: (0.6596) | Acc: (76.92%) (34559/44928)\n",
      "Epoch: 11 | Batch_idx: 360 |  Loss: (0.6590) | Acc: (76.94%) (35554/46208)\n",
      "Epoch: 11 | Batch_idx: 370 |  Loss: (0.6593) | Acc: (76.95%) (36544/47488)\n",
      "Epoch: 11 | Batch_idx: 380 |  Loss: (0.6594) | Acc: (76.95%) (37525/48768)\n",
      "Epoch: 11 | Batch_idx: 390 |  Loss: (0.6582) | Acc: (76.97%) (38486/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7746) | Acc: (73.45%) (7345/10000)\n",
      "Epoch: 12 | Batch_idx: 0 |  Loss: (0.7145) | Acc: (75.00%) (96/128)\n",
      "Epoch: 12 | Batch_idx: 10 |  Loss: (0.6186) | Acc: (79.33%) (1117/1408)\n",
      "Epoch: 12 | Batch_idx: 20 |  Loss: (0.6089) | Acc: (79.13%) (2127/2688)\n",
      "Epoch: 12 | Batch_idx: 30 |  Loss: (0.6181) | Acc: (78.02%) (3096/3968)\n",
      "Epoch: 12 | Batch_idx: 40 |  Loss: (0.6198) | Acc: (78.11%) (4099/5248)\n",
      "Epoch: 12 | Batch_idx: 50 |  Loss: (0.6124) | Acc: (78.48%) (5123/6528)\n",
      "Epoch: 12 | Batch_idx: 60 |  Loss: (0.6257) | Acc: (78.07%) (6096/7808)\n",
      "Epoch: 12 | Batch_idx: 70 |  Loss: (0.6265) | Acc: (78.10%) (7098/9088)\n",
      "Epoch: 12 | Batch_idx: 80 |  Loss: (0.6273) | Acc: (78.05%) (8092/10368)\n",
      "Epoch: 12 | Batch_idx: 90 |  Loss: (0.6250) | Acc: (78.05%) (9091/11648)\n",
      "Epoch: 12 | Batch_idx: 100 |  Loss: (0.6254) | Acc: (78.04%) (10089/12928)\n",
      "Epoch: 12 | Batch_idx: 110 |  Loss: (0.6281) | Acc: (77.96%) (11076/14208)\n",
      "Epoch: 12 | Batch_idx: 120 |  Loss: (0.6265) | Acc: (78.05%) (12089/15488)\n",
      "Epoch: 12 | Batch_idx: 130 |  Loss: (0.6276) | Acc: (78.08%) (13092/16768)\n",
      "Epoch: 12 | Batch_idx: 140 |  Loss: (0.6283) | Acc: (78.12%) (14100/18048)\n",
      "Epoch: 12 | Batch_idx: 150 |  Loss: (0.6256) | Acc: (78.26%) (15127/19328)\n",
      "Epoch: 12 | Batch_idx: 160 |  Loss: (0.6269) | Acc: (78.15%) (16106/20608)\n",
      "Epoch: 12 | Batch_idx: 170 |  Loss: (0.6295) | Acc: (78.09%) (17092/21888)\n",
      "Epoch: 12 | Batch_idx: 180 |  Loss: (0.6290) | Acc: (78.01%) (18074/23168)\n",
      "Epoch: 12 | Batch_idx: 190 |  Loss: (0.6294) | Acc: (77.99%) (19066/24448)\n",
      "Epoch: 12 | Batch_idx: 200 |  Loss: (0.6295) | Acc: (77.97%) (20061/25728)\n",
      "Epoch: 12 | Batch_idx: 210 |  Loss: (0.6283) | Acc: (78.02%) (21071/27008)\n",
      "Epoch: 12 | Batch_idx: 220 |  Loss: (0.6289) | Acc: (78.00%) (22065/28288)\n",
      "Epoch: 12 | Batch_idx: 230 |  Loss: (0.6303) | Acc: (77.94%) (23046/29568)\n",
      "Epoch: 12 | Batch_idx: 240 |  Loss: (0.6311) | Acc: (77.93%) (24041/30848)\n",
      "Epoch: 12 | Batch_idx: 250 |  Loss: (0.6333) | Acc: (77.82%) (25001/32128)\n",
      "Epoch: 12 | Batch_idx: 260 |  Loss: (0.6348) | Acc: (77.74%) (25970/33408)\n",
      "Epoch: 12 | Batch_idx: 270 |  Loss: (0.6347) | Acc: (77.72%) (26961/34688)\n",
      "Epoch: 12 | Batch_idx: 280 |  Loss: (0.6333) | Acc: (77.75%) (27966/35968)\n",
      "Epoch: 12 | Batch_idx: 290 |  Loss: (0.6349) | Acc: (77.70%) (28942/37248)\n",
      "Epoch: 12 | Batch_idx: 300 |  Loss: (0.6334) | Acc: (77.77%) (29962/38528)\n",
      "Epoch: 12 | Batch_idx: 310 |  Loss: (0.6340) | Acc: (77.71%) (30936/39808)\n",
      "Epoch: 12 | Batch_idx: 320 |  Loss: (0.6343) | Acc: (77.68%) (31917/41088)\n",
      "Epoch: 12 | Batch_idx: 330 |  Loss: (0.6334) | Acc: (77.71%) (32924/42368)\n",
      "Epoch: 12 | Batch_idx: 340 |  Loss: (0.6325) | Acc: (77.78%) (33949/43648)\n",
      "Epoch: 12 | Batch_idx: 350 |  Loss: (0.6328) | Acc: (77.77%) (34942/44928)\n",
      "Epoch: 12 | Batch_idx: 360 |  Loss: (0.6327) | Acc: (77.79%) (35943/46208)\n",
      "Epoch: 12 | Batch_idx: 370 |  Loss: (0.6315) | Acc: (77.82%) (36957/47488)\n",
      "Epoch: 12 | Batch_idx: 380 |  Loss: (0.6303) | Acc: (77.85%) (37967/48768)\n",
      "Epoch: 12 | Batch_idx: 390 |  Loss: (0.6301) | Acc: (77.89%) (38943/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7065) | Acc: (75.54%) (7554/10000)\n",
      "Epoch: 13 | Batch_idx: 0 |  Loss: (0.6737) | Acc: (75.78%) (97/128)\n",
      "Epoch: 13 | Batch_idx: 10 |  Loss: (0.6304) | Acc: (78.62%) (1107/1408)\n",
      "Epoch: 13 | Batch_idx: 20 |  Loss: (0.6170) | Acc: (79.20%) (2129/2688)\n",
      "Epoch: 13 | Batch_idx: 30 |  Loss: (0.6131) | Acc: (79.06%) (3137/3968)\n",
      "Epoch: 13 | Batch_idx: 40 |  Loss: (0.6071) | Acc: (79.50%) (4172/5248)\n",
      "Epoch: 13 | Batch_idx: 50 |  Loss: (0.6023) | Acc: (79.58%) (5195/6528)\n",
      "Epoch: 13 | Batch_idx: 60 |  Loss: (0.6071) | Acc: (79.34%) (6195/7808)\n",
      "Epoch: 13 | Batch_idx: 70 |  Loss: (0.6037) | Acc: (79.36%) (7212/9088)\n",
      "Epoch: 13 | Batch_idx: 80 |  Loss: (0.5999) | Acc: (79.33%) (8225/10368)\n",
      "Epoch: 13 | Batch_idx: 90 |  Loss: (0.6000) | Acc: (79.10%) (9214/11648)\n",
      "Epoch: 13 | Batch_idx: 100 |  Loss: (0.5991) | Acc: (79.08%) (10224/12928)\n",
      "Epoch: 13 | Batch_idx: 110 |  Loss: (0.6002) | Acc: (79.07%) (11234/14208)\n",
      "Epoch: 13 | Batch_idx: 120 |  Loss: (0.5993) | Acc: (79.10%) (12251/15488)\n",
      "Epoch: 13 | Batch_idx: 130 |  Loss: (0.6020) | Acc: (78.99%) (13245/16768)\n",
      "Epoch: 13 | Batch_idx: 140 |  Loss: (0.6041) | Acc: (78.89%) (14238/18048)\n",
      "Epoch: 13 | Batch_idx: 150 |  Loss: (0.6058) | Acc: (78.96%) (15261/19328)\n",
      "Epoch: 13 | Batch_idx: 160 |  Loss: (0.6056) | Acc: (78.89%) (16258/20608)\n",
      "Epoch: 13 | Batch_idx: 170 |  Loss: (0.6083) | Acc: (78.79%) (17246/21888)\n",
      "Epoch: 13 | Batch_idx: 180 |  Loss: (0.6071) | Acc: (78.85%) (18269/23168)\n",
      "Epoch: 13 | Batch_idx: 190 |  Loss: (0.6053) | Acc: (78.91%) (19293/24448)\n",
      "Epoch: 13 | Batch_idx: 200 |  Loss: (0.6064) | Acc: (78.88%) (20293/25728)\n",
      "Epoch: 13 | Batch_idx: 210 |  Loss: (0.6070) | Acc: (78.85%) (21295/27008)\n",
      "Epoch: 13 | Batch_idx: 220 |  Loss: (0.6081) | Acc: (78.79%) (22289/28288)\n",
      "Epoch: 13 | Batch_idx: 230 |  Loss: (0.6094) | Acc: (78.76%) (23287/29568)\n",
      "Epoch: 13 | Batch_idx: 240 |  Loss: (0.6098) | Acc: (78.76%) (24295/30848)\n",
      "Epoch: 13 | Batch_idx: 250 |  Loss: (0.6094) | Acc: (78.74%) (25296/32128)\n",
      "Epoch: 13 | Batch_idx: 260 |  Loss: (0.6085) | Acc: (78.74%) (26305/33408)\n",
      "Epoch: 13 | Batch_idx: 270 |  Loss: (0.6086) | Acc: (78.72%) (27308/34688)\n",
      "Epoch: 13 | Batch_idx: 280 |  Loss: (0.6076) | Acc: (78.73%) (28318/35968)\n",
      "Epoch: 13 | Batch_idx: 290 |  Loss: (0.6079) | Acc: (78.74%) (29330/37248)\n",
      "Epoch: 13 | Batch_idx: 300 |  Loss: (0.6061) | Acc: (78.82%) (30368/38528)\n",
      "Epoch: 13 | Batch_idx: 310 |  Loss: (0.6055) | Acc: (78.82%) (31378/39808)\n",
      "Epoch: 13 | Batch_idx: 320 |  Loss: (0.6052) | Acc: (78.83%) (32388/41088)\n",
      "Epoch: 13 | Batch_idx: 330 |  Loss: (0.6045) | Acc: (78.83%) (33400/42368)\n",
      "Epoch: 13 | Batch_idx: 340 |  Loss: (0.6040) | Acc: (78.85%) (34415/43648)\n",
      "Epoch: 13 | Batch_idx: 350 |  Loss: (0.6052) | Acc: (78.79%) (35400/44928)\n",
      "Epoch: 13 | Batch_idx: 360 |  Loss: (0.6052) | Acc: (78.75%) (36390/46208)\n",
      "Epoch: 13 | Batch_idx: 370 |  Loss: (0.6053) | Acc: (78.77%) (37406/47488)\n",
      "Epoch: 13 | Batch_idx: 380 |  Loss: (0.6059) | Acc: (78.72%) (38390/48768)\n",
      "Epoch: 13 | Batch_idx: 390 |  Loss: (0.6063) | Acc: (78.71%) (39355/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6575) | Acc: (77.22%) (7722/10000)\n",
      "Epoch: 14 | Batch_idx: 0 |  Loss: (0.5407) | Acc: (77.34%) (99/128)\n",
      "Epoch: 14 | Batch_idx: 10 |  Loss: (0.5750) | Acc: (78.91%) (1111/1408)\n",
      "Epoch: 14 | Batch_idx: 20 |  Loss: (0.5760) | Acc: (79.91%) (2148/2688)\n",
      "Epoch: 14 | Batch_idx: 30 |  Loss: (0.5763) | Acc: (80.14%) (3180/3968)\n",
      "Epoch: 14 | Batch_idx: 40 |  Loss: (0.5677) | Acc: (80.32%) (4215/5248)\n",
      "Epoch: 14 | Batch_idx: 50 |  Loss: (0.5742) | Acc: (79.98%) (5221/6528)\n",
      "Epoch: 14 | Batch_idx: 60 |  Loss: (0.5740) | Acc: (79.98%) (6245/7808)\n",
      "Epoch: 14 | Batch_idx: 70 |  Loss: (0.5752) | Acc: (79.96%) (7267/9088)\n",
      "Epoch: 14 | Batch_idx: 80 |  Loss: (0.5750) | Acc: (79.90%) (8284/10368)\n",
      "Epoch: 14 | Batch_idx: 90 |  Loss: (0.5790) | Acc: (79.89%) (9306/11648)\n",
      "Epoch: 14 | Batch_idx: 100 |  Loss: (0.5860) | Acc: (79.64%) (10296/12928)\n",
      "Epoch: 14 | Batch_idx: 110 |  Loss: (0.5812) | Acc: (79.84%) (11343/14208)\n",
      "Epoch: 14 | Batch_idx: 120 |  Loss: (0.5855) | Acc: (79.65%) (12336/15488)\n",
      "Epoch: 14 | Batch_idx: 130 |  Loss: (0.5856) | Acc: (79.64%) (13354/16768)\n",
      "Epoch: 14 | Batch_idx: 140 |  Loss: (0.5836) | Acc: (79.68%) (14380/18048)\n",
      "Epoch: 14 | Batch_idx: 150 |  Loss: (0.5845) | Acc: (79.61%) (15387/19328)\n",
      "Epoch: 14 | Batch_idx: 160 |  Loss: (0.5847) | Acc: (79.64%) (16412/20608)\n",
      "Epoch: 14 | Batch_idx: 170 |  Loss: (0.5848) | Acc: (79.68%) (17440/21888)\n",
      "Epoch: 14 | Batch_idx: 180 |  Loss: (0.5847) | Acc: (79.68%) (18460/23168)\n",
      "Epoch: 14 | Batch_idx: 190 |  Loss: (0.5831) | Acc: (79.75%) (19498/24448)\n",
      "Epoch: 14 | Batch_idx: 200 |  Loss: (0.5831) | Acc: (79.77%) (20522/25728)\n",
      "Epoch: 14 | Batch_idx: 210 |  Loss: (0.5830) | Acc: (79.81%) (21555/27008)\n",
      "Epoch: 14 | Batch_idx: 220 |  Loss: (0.5840) | Acc: (79.81%) (22576/28288)\n",
      "Epoch: 14 | Batch_idx: 230 |  Loss: (0.5829) | Acc: (79.88%) (23619/29568)\n",
      "Epoch: 14 | Batch_idx: 240 |  Loss: (0.5822) | Acc: (79.83%) (24627/30848)\n",
      "Epoch: 14 | Batch_idx: 250 |  Loss: (0.5838) | Acc: (79.78%) (25631/32128)\n",
      "Epoch: 14 | Batch_idx: 260 |  Loss: (0.5848) | Acc: (79.75%) (26642/33408)\n",
      "Epoch: 14 | Batch_idx: 270 |  Loss: (0.5837) | Acc: (79.78%) (27674/34688)\n",
      "Epoch: 14 | Batch_idx: 280 |  Loss: (0.5843) | Acc: (79.77%) (28693/35968)\n",
      "Epoch: 14 | Batch_idx: 290 |  Loss: (0.5835) | Acc: (79.78%) (29716/37248)\n",
      "Epoch: 14 | Batch_idx: 300 |  Loss: (0.5831) | Acc: (79.77%) (30733/38528)\n",
      "Epoch: 14 | Batch_idx: 310 |  Loss: (0.5825) | Acc: (79.79%) (31763/39808)\n",
      "Epoch: 14 | Batch_idx: 320 |  Loss: (0.5821) | Acc: (79.83%) (32800/41088)\n",
      "Epoch: 14 | Batch_idx: 330 |  Loss: (0.5826) | Acc: (79.79%) (33806/42368)\n",
      "Epoch: 14 | Batch_idx: 340 |  Loss: (0.5842) | Acc: (79.73%) (34802/43648)\n",
      "Epoch: 14 | Batch_idx: 350 |  Loss: (0.5845) | Acc: (79.71%) (35811/44928)\n",
      "Epoch: 14 | Batch_idx: 360 |  Loss: (0.5843) | Acc: (79.71%) (36831/46208)\n",
      "Epoch: 14 | Batch_idx: 370 |  Loss: (0.5851) | Acc: (79.67%) (37834/47488)\n",
      "Epoch: 14 | Batch_idx: 380 |  Loss: (0.5843) | Acc: (79.70%) (38868/48768)\n",
      "Epoch: 14 | Batch_idx: 390 |  Loss: (0.5836) | Acc: (79.72%) (39862/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6767) | Acc: (76.64%) (7664/10000)\n",
      "Epoch: 15 | Batch_idx: 0 |  Loss: (0.7492) | Acc: (73.44%) (94/128)\n",
      "Epoch: 15 | Batch_idx: 10 |  Loss: (0.5903) | Acc: (80.18%) (1129/1408)\n",
      "Epoch: 15 | Batch_idx: 20 |  Loss: (0.5697) | Acc: (80.62%) (2167/2688)\n",
      "Epoch: 15 | Batch_idx: 30 |  Loss: (0.5616) | Acc: (80.90%) (3210/3968)\n",
      "Epoch: 15 | Batch_idx: 40 |  Loss: (0.5667) | Acc: (80.39%) (4219/5248)\n",
      "Epoch: 15 | Batch_idx: 50 |  Loss: (0.5684) | Acc: (80.25%) (5239/6528)\n",
      "Epoch: 15 | Batch_idx: 60 |  Loss: (0.5641) | Acc: (80.20%) (6262/7808)\n",
      "Epoch: 15 | Batch_idx: 70 |  Loss: (0.5668) | Acc: (80.18%) (7287/9088)\n",
      "Epoch: 15 | Batch_idx: 80 |  Loss: (0.5698) | Acc: (80.05%) (8300/10368)\n",
      "Epoch: 15 | Batch_idx: 90 |  Loss: (0.5671) | Acc: (80.26%) (9349/11648)\n",
      "Epoch: 15 | Batch_idx: 100 |  Loss: (0.5615) | Acc: (80.54%) (10412/12928)\n",
      "Epoch: 15 | Batch_idx: 110 |  Loss: (0.5550) | Acc: (80.77%) (11476/14208)\n",
      "Epoch: 15 | Batch_idx: 120 |  Loss: (0.5558) | Acc: (80.65%) (12491/15488)\n",
      "Epoch: 15 | Batch_idx: 130 |  Loss: (0.5554) | Acc: (80.72%) (13535/16768)\n",
      "Epoch: 15 | Batch_idx: 140 |  Loss: (0.5556) | Acc: (80.60%) (14546/18048)\n",
      "Epoch: 15 | Batch_idx: 150 |  Loss: (0.5558) | Acc: (80.62%) (15583/19328)\n",
      "Epoch: 15 | Batch_idx: 160 |  Loss: (0.5549) | Acc: (80.68%) (16626/20608)\n",
      "Epoch: 15 | Batch_idx: 170 |  Loss: (0.5566) | Acc: (80.66%) (17654/21888)\n",
      "Epoch: 15 | Batch_idx: 180 |  Loss: (0.5582) | Acc: (80.66%) (18688/23168)\n",
      "Epoch: 15 | Batch_idx: 190 |  Loss: (0.5583) | Acc: (80.66%) (19719/24448)\n",
      "Epoch: 15 | Batch_idx: 200 |  Loss: (0.5593) | Acc: (80.59%) (20735/25728)\n",
      "Epoch: 15 | Batch_idx: 210 |  Loss: (0.5595) | Acc: (80.59%) (21765/27008)\n",
      "Epoch: 15 | Batch_idx: 220 |  Loss: (0.5587) | Acc: (80.57%) (22793/28288)\n",
      "Epoch: 15 | Batch_idx: 230 |  Loss: (0.5603) | Acc: (80.43%) (23783/29568)\n",
      "Epoch: 15 | Batch_idx: 240 |  Loss: (0.5608) | Acc: (80.41%) (24805/30848)\n",
      "Epoch: 15 | Batch_idx: 250 |  Loss: (0.5592) | Acc: (80.51%) (25865/32128)\n",
      "Epoch: 15 | Batch_idx: 260 |  Loss: (0.5590) | Acc: (80.54%) (26906/33408)\n",
      "Epoch: 15 | Batch_idx: 270 |  Loss: (0.5591) | Acc: (80.54%) (27937/34688)\n",
      "Epoch: 15 | Batch_idx: 280 |  Loss: (0.5583) | Acc: (80.53%) (28965/35968)\n",
      "Epoch: 15 | Batch_idx: 290 |  Loss: (0.5580) | Acc: (80.55%) (30003/37248)\n",
      "Epoch: 15 | Batch_idx: 300 |  Loss: (0.5574) | Acc: (80.56%) (31039/38528)\n",
      "Epoch: 15 | Batch_idx: 310 |  Loss: (0.5569) | Acc: (80.58%) (32078/39808)\n",
      "Epoch: 15 | Batch_idx: 320 |  Loss: (0.5571) | Acc: (80.58%) (33107/41088)\n",
      "Epoch: 15 | Batch_idx: 330 |  Loss: (0.5567) | Acc: (80.60%) (34147/42368)\n",
      "Epoch: 15 | Batch_idx: 340 |  Loss: (0.5569) | Acc: (80.56%) (35161/43648)\n",
      "Epoch: 15 | Batch_idx: 350 |  Loss: (0.5569) | Acc: (80.56%) (36195/44928)\n",
      "Epoch: 15 | Batch_idx: 360 |  Loss: (0.5567) | Acc: (80.56%) (37223/46208)\n",
      "Epoch: 15 | Batch_idx: 370 |  Loss: (0.5578) | Acc: (80.51%) (38234/47488)\n",
      "Epoch: 15 | Batch_idx: 380 |  Loss: (0.5582) | Acc: (80.49%) (39252/48768)\n",
      "Epoch: 15 | Batch_idx: 390 |  Loss: (0.5590) | Acc: (80.48%) (40239/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6553) | Acc: (77.76%) (7776/10000)\n",
      "Epoch: 16 | Batch_idx: 0 |  Loss: (0.5002) | Acc: (85.94%) (110/128)\n",
      "Epoch: 16 | Batch_idx: 10 |  Loss: (0.5484) | Acc: (81.11%) (1142/1408)\n",
      "Epoch: 16 | Batch_idx: 20 |  Loss: (0.5404) | Acc: (81.85%) (2200/2688)\n",
      "Epoch: 16 | Batch_idx: 30 |  Loss: (0.5200) | Acc: (82.56%) (3276/3968)\n",
      "Epoch: 16 | Batch_idx: 40 |  Loss: (0.5148) | Acc: (82.53%) (4331/5248)\n",
      "Epoch: 16 | Batch_idx: 50 |  Loss: (0.5190) | Acc: (82.29%) (5372/6528)\n",
      "Epoch: 16 | Batch_idx: 60 |  Loss: (0.5160) | Acc: (82.44%) (6437/7808)\n",
      "Epoch: 16 | Batch_idx: 70 |  Loss: (0.5252) | Acc: (82.10%) (7461/9088)\n",
      "Epoch: 16 | Batch_idx: 80 |  Loss: (0.5257) | Acc: (81.98%) (8500/10368)\n",
      "Epoch: 16 | Batch_idx: 90 |  Loss: (0.5291) | Acc: (81.77%) (9525/11648)\n",
      "Epoch: 16 | Batch_idx: 100 |  Loss: (0.5295) | Acc: (81.78%) (10573/12928)\n",
      "Epoch: 16 | Batch_idx: 110 |  Loss: (0.5309) | Acc: (81.71%) (11610/14208)\n",
      "Epoch: 16 | Batch_idx: 120 |  Loss: (0.5296) | Acc: (81.66%) (12648/15488)\n",
      "Epoch: 16 | Batch_idx: 130 |  Loss: (0.5327) | Acc: (81.49%) (13665/16768)\n",
      "Epoch: 16 | Batch_idx: 140 |  Loss: (0.5327) | Acc: (81.54%) (14717/18048)\n",
      "Epoch: 16 | Batch_idx: 150 |  Loss: (0.5314) | Acc: (81.52%) (15756/19328)\n",
      "Epoch: 16 | Batch_idx: 160 |  Loss: (0.5329) | Acc: (81.45%) (16785/20608)\n",
      "Epoch: 16 | Batch_idx: 170 |  Loss: (0.5336) | Acc: (81.42%) (17822/21888)\n",
      "Epoch: 16 | Batch_idx: 180 |  Loss: (0.5339) | Acc: (81.41%) (18861/23168)\n",
      "Epoch: 16 | Batch_idx: 190 |  Loss: (0.5353) | Acc: (81.36%) (19890/24448)\n",
      "Epoch: 16 | Batch_idx: 200 |  Loss: (0.5342) | Acc: (81.37%) (20936/25728)\n",
      "Epoch: 16 | Batch_idx: 210 |  Loss: (0.5340) | Acc: (81.34%) (21967/27008)\n",
      "Epoch: 16 | Batch_idx: 220 |  Loss: (0.5349) | Acc: (81.35%) (23013/28288)\n",
      "Epoch: 16 | Batch_idx: 230 |  Loss: (0.5358) | Acc: (81.36%) (24056/29568)\n",
      "Epoch: 16 | Batch_idx: 240 |  Loss: (0.5351) | Acc: (81.40%) (25110/30848)\n",
      "Epoch: 16 | Batch_idx: 250 |  Loss: (0.5353) | Acc: (81.39%) (26150/32128)\n",
      "Epoch: 16 | Batch_idx: 260 |  Loss: (0.5351) | Acc: (81.41%) (27199/33408)\n",
      "Epoch: 16 | Batch_idx: 270 |  Loss: (0.5339) | Acc: (81.42%) (28244/34688)\n",
      "Epoch: 16 | Batch_idx: 280 |  Loss: (0.5334) | Acc: (81.43%) (29287/35968)\n",
      "Epoch: 16 | Batch_idx: 290 |  Loss: (0.5345) | Acc: (81.40%) (30321/37248)\n",
      "Epoch: 16 | Batch_idx: 300 |  Loss: (0.5354) | Acc: (81.36%) (31347/38528)\n",
      "Epoch: 16 | Batch_idx: 310 |  Loss: (0.5361) | Acc: (81.34%) (32380/39808)\n",
      "Epoch: 16 | Batch_idx: 320 |  Loss: (0.5378) | Acc: (81.28%) (33397/41088)\n",
      "Epoch: 16 | Batch_idx: 330 |  Loss: (0.5384) | Acc: (81.23%) (34416/42368)\n",
      "Epoch: 16 | Batch_idx: 340 |  Loss: (0.5378) | Acc: (81.24%) (35459/43648)\n",
      "Epoch: 16 | Batch_idx: 350 |  Loss: (0.5381) | Acc: (81.24%) (36498/44928)\n",
      "Epoch: 16 | Batch_idx: 360 |  Loss: (0.5367) | Acc: (81.29%) (37561/46208)\n",
      "Epoch: 16 | Batch_idx: 370 |  Loss: (0.5376) | Acc: (81.21%) (38564/47488)\n",
      "Epoch: 16 | Batch_idx: 380 |  Loss: (0.5381) | Acc: (81.17%) (39585/48768)\n",
      "Epoch: 16 | Batch_idx: 390 |  Loss: (0.5377) | Acc: (81.19%) (40597/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6274) | Acc: (79.00%) (7900/10000)\n",
      "Epoch: 17 | Batch_idx: 0 |  Loss: (0.6199) | Acc: (82.03%) (105/128)\n",
      "Epoch: 17 | Batch_idx: 10 |  Loss: (0.5546) | Acc: (81.11%) (1142/1408)\n",
      "Epoch: 17 | Batch_idx: 20 |  Loss: (0.5412) | Acc: (81.14%) (2181/2688)\n",
      "Epoch: 17 | Batch_idx: 30 |  Loss: (0.5329) | Acc: (81.96%) (3252/3968)\n",
      "Epoch: 17 | Batch_idx: 40 |  Loss: (0.5360) | Acc: (81.71%) (4288/5248)\n",
      "Epoch: 17 | Batch_idx: 50 |  Loss: (0.5346) | Acc: (81.69%) (5333/6528)\n",
      "Epoch: 17 | Batch_idx: 60 |  Loss: (0.5226) | Acc: (82.15%) (6414/7808)\n",
      "Epoch: 17 | Batch_idx: 70 |  Loss: (0.5187) | Acc: (82.25%) (7475/9088)\n",
      "Epoch: 17 | Batch_idx: 80 |  Loss: (0.5229) | Acc: (82.04%) (8506/10368)\n",
      "Epoch: 17 | Batch_idx: 90 |  Loss: (0.5267) | Acc: (81.72%) (9519/11648)\n",
      "Epoch: 17 | Batch_idx: 100 |  Loss: (0.5292) | Acc: (81.64%) (10554/12928)\n",
      "Epoch: 17 | Batch_idx: 110 |  Loss: (0.5259) | Acc: (81.66%) (11602/14208)\n",
      "Epoch: 17 | Batch_idx: 120 |  Loss: (0.5233) | Acc: (81.82%) (12672/15488)\n",
      "Epoch: 17 | Batch_idx: 130 |  Loss: (0.5251) | Acc: (81.80%) (13716/16768)\n",
      "Epoch: 17 | Batch_idx: 140 |  Loss: (0.5221) | Acc: (81.94%) (14788/18048)\n",
      "Epoch: 17 | Batch_idx: 150 |  Loss: (0.5208) | Acc: (81.94%) (15837/19328)\n",
      "Epoch: 17 | Batch_idx: 160 |  Loss: (0.5176) | Acc: (82.15%) (16930/20608)\n",
      "Epoch: 17 | Batch_idx: 170 |  Loss: (0.5178) | Acc: (82.10%) (17969/21888)\n",
      "Epoch: 17 | Batch_idx: 180 |  Loss: (0.5191) | Acc: (82.03%) (19004/23168)\n",
      "Epoch: 17 | Batch_idx: 190 |  Loss: (0.5206) | Acc: (81.97%) (20039/24448)\n",
      "Epoch: 17 | Batch_idx: 200 |  Loss: (0.5214) | Acc: (81.97%) (21089/25728)\n",
      "Epoch: 17 | Batch_idx: 210 |  Loss: (0.5208) | Acc: (81.99%) (22144/27008)\n",
      "Epoch: 17 | Batch_idx: 220 |  Loss: (0.5213) | Acc: (81.98%) (23191/28288)\n",
      "Epoch: 17 | Batch_idx: 230 |  Loss: (0.5230) | Acc: (81.94%) (24227/29568)\n",
      "Epoch: 17 | Batch_idx: 240 |  Loss: (0.5232) | Acc: (81.92%) (25272/30848)\n",
      "Epoch: 17 | Batch_idx: 250 |  Loss: (0.5226) | Acc: (81.93%) (26323/32128)\n",
      "Epoch: 17 | Batch_idx: 260 |  Loss: (0.5237) | Acc: (81.87%) (27350/33408)\n",
      "Epoch: 17 | Batch_idx: 270 |  Loss: (0.5236) | Acc: (81.86%) (28395/34688)\n",
      "Epoch: 17 | Batch_idx: 280 |  Loss: (0.5231) | Acc: (81.87%) (29448/35968)\n",
      "Epoch: 17 | Batch_idx: 290 |  Loss: (0.5237) | Acc: (81.85%) (30487/37248)\n",
      "Epoch: 17 | Batch_idx: 300 |  Loss: (0.5233) | Acc: (81.82%) (31525/38528)\n",
      "Epoch: 17 | Batch_idx: 310 |  Loss: (0.5232) | Acc: (81.79%) (32560/39808)\n",
      "Epoch: 17 | Batch_idx: 320 |  Loss: (0.5233) | Acc: (81.80%) (33612/41088)\n",
      "Epoch: 17 | Batch_idx: 330 |  Loss: (0.5239) | Acc: (81.75%) (34637/42368)\n",
      "Epoch: 17 | Batch_idx: 340 |  Loss: (0.5245) | Acc: (81.73%) (35673/43648)\n",
      "Epoch: 17 | Batch_idx: 350 |  Loss: (0.5245) | Acc: (81.73%) (36719/44928)\n",
      "Epoch: 17 | Batch_idx: 360 |  Loss: (0.5241) | Acc: (81.74%) (37771/46208)\n",
      "Epoch: 17 | Batch_idx: 370 |  Loss: (0.5235) | Acc: (81.81%) (38848/47488)\n",
      "Epoch: 17 | Batch_idx: 380 |  Loss: (0.5223) | Acc: (81.84%) (39914/48768)\n",
      "Epoch: 17 | Batch_idx: 390 |  Loss: (0.5234) | Acc: (81.81%) (40906/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5855) | Acc: (79.95%) (7995/10000)\n",
      "Epoch: 18 | Batch_idx: 0 |  Loss: (0.4795) | Acc: (79.69%) (102/128)\n",
      "Epoch: 18 | Batch_idx: 10 |  Loss: (0.4625) | Acc: (84.16%) (1185/1408)\n",
      "Epoch: 18 | Batch_idx: 20 |  Loss: (0.4950) | Acc: (83.22%) (2237/2688)\n",
      "Epoch: 18 | Batch_idx: 30 |  Loss: (0.5024) | Acc: (82.81%) (3286/3968)\n",
      "Epoch: 18 | Batch_idx: 40 |  Loss: (0.5061) | Acc: (82.34%) (4321/5248)\n",
      "Epoch: 18 | Batch_idx: 50 |  Loss: (0.5018) | Acc: (82.51%) (5386/6528)\n",
      "Epoch: 18 | Batch_idx: 60 |  Loss: (0.5065) | Acc: (82.27%) (6424/7808)\n",
      "Epoch: 18 | Batch_idx: 70 |  Loss: (0.5099) | Acc: (82.15%) (7466/9088)\n",
      "Epoch: 18 | Batch_idx: 80 |  Loss: (0.5127) | Acc: (82.10%) (8512/10368)\n",
      "Epoch: 18 | Batch_idx: 90 |  Loss: (0.5128) | Acc: (82.22%) (9577/11648)\n",
      "Epoch: 18 | Batch_idx: 100 |  Loss: (0.5127) | Acc: (82.19%) (10626/12928)\n",
      "Epoch: 18 | Batch_idx: 110 |  Loss: (0.5124) | Acc: (82.20%) (11679/14208)\n",
      "Epoch: 18 | Batch_idx: 120 |  Loss: (0.5097) | Acc: (82.23%) (12736/15488)\n",
      "Epoch: 18 | Batch_idx: 130 |  Loss: (0.5124) | Acc: (82.16%) (13777/16768)\n",
      "Epoch: 18 | Batch_idx: 140 |  Loss: (0.5111) | Acc: (82.18%) (14832/18048)\n",
      "Epoch: 18 | Batch_idx: 150 |  Loss: (0.5093) | Acc: (82.31%) (15909/19328)\n",
      "Epoch: 18 | Batch_idx: 160 |  Loss: (0.5088) | Acc: (82.28%) (16957/20608)\n",
      "Epoch: 18 | Batch_idx: 170 |  Loss: (0.5090) | Acc: (82.24%) (18001/21888)\n",
      "Epoch: 18 | Batch_idx: 180 |  Loss: (0.5095) | Acc: (82.23%) (19052/23168)\n",
      "Epoch: 18 | Batch_idx: 190 |  Loss: (0.5080) | Acc: (82.31%) (20123/24448)\n",
      "Epoch: 18 | Batch_idx: 200 |  Loss: (0.5061) | Acc: (82.34%) (21185/25728)\n",
      "Epoch: 18 | Batch_idx: 210 |  Loss: (0.5077) | Acc: (82.30%) (22227/27008)\n",
      "Epoch: 18 | Batch_idx: 220 |  Loss: (0.5061) | Acc: (82.35%) (23295/28288)\n",
      "Epoch: 18 | Batch_idx: 230 |  Loss: (0.5066) | Acc: (82.34%) (24347/29568)\n",
      "Epoch: 18 | Batch_idx: 240 |  Loss: (0.5066) | Acc: (82.37%) (25408/30848)\n",
      "Epoch: 18 | Batch_idx: 250 |  Loss: (0.5068) | Acc: (82.39%) (26470/32128)\n",
      "Epoch: 18 | Batch_idx: 260 |  Loss: (0.5070) | Acc: (82.39%) (27525/33408)\n",
      "Epoch: 18 | Batch_idx: 270 |  Loss: (0.5071) | Acc: (82.38%) (28575/34688)\n",
      "Epoch: 18 | Batch_idx: 280 |  Loss: (0.5080) | Acc: (82.32%) (29608/35968)\n",
      "Epoch: 18 | Batch_idx: 290 |  Loss: (0.5085) | Acc: (82.31%) (30657/37248)\n",
      "Epoch: 18 | Batch_idx: 300 |  Loss: (0.5082) | Acc: (82.31%) (31711/38528)\n",
      "Epoch: 18 | Batch_idx: 310 |  Loss: (0.5077) | Acc: (82.34%) (32779/39808)\n",
      "Epoch: 18 | Batch_idx: 320 |  Loss: (0.5090) | Acc: (82.28%) (33809/41088)\n",
      "Epoch: 18 | Batch_idx: 330 |  Loss: (0.5102) | Acc: (82.24%) (34845/42368)\n",
      "Epoch: 18 | Batch_idx: 340 |  Loss: (0.5099) | Acc: (82.25%) (35900/43648)\n",
      "Epoch: 18 | Batch_idx: 350 |  Loss: (0.5085) | Acc: (82.28%) (36969/44928)\n",
      "Epoch: 18 | Batch_idx: 360 |  Loss: (0.5086) | Acc: (82.27%) (38014/46208)\n",
      "Epoch: 18 | Batch_idx: 370 |  Loss: (0.5088) | Acc: (82.29%) (39077/47488)\n",
      "Epoch: 18 | Batch_idx: 380 |  Loss: (0.5080) | Acc: (82.32%) (40148/48768)\n",
      "Epoch: 18 | Batch_idx: 390 |  Loss: (0.5081) | Acc: (82.31%) (41154/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5955) | Acc: (79.95%) (7995/10000)\n",
      "Epoch: 19 | Batch_idx: 0 |  Loss: (0.5316) | Acc: (81.25%) (104/128)\n",
      "Epoch: 19 | Batch_idx: 10 |  Loss: (0.4965) | Acc: (82.88%) (1167/1408)\n",
      "Epoch: 19 | Batch_idx: 20 |  Loss: (0.4778) | Acc: (83.41%) (2242/2688)\n",
      "Epoch: 19 | Batch_idx: 30 |  Loss: (0.4940) | Acc: (82.89%) (3289/3968)\n",
      "Epoch: 19 | Batch_idx: 40 |  Loss: (0.4930) | Acc: (82.83%) (4347/5248)\n",
      "Epoch: 19 | Batch_idx: 50 |  Loss: (0.4860) | Acc: (83.12%) (5426/6528)\n",
      "Epoch: 19 | Batch_idx: 60 |  Loss: (0.4892) | Acc: (82.93%) (6475/7808)\n",
      "Epoch: 19 | Batch_idx: 70 |  Loss: (0.4912) | Acc: (82.81%) (7526/9088)\n",
      "Epoch: 19 | Batch_idx: 80 |  Loss: (0.4914) | Acc: (82.77%) (8582/10368)\n",
      "Epoch: 19 | Batch_idx: 90 |  Loss: (0.4890) | Acc: (82.86%) (9652/11648)\n",
      "Epoch: 19 | Batch_idx: 100 |  Loss: (0.4929) | Acc: (82.80%) (10704/12928)\n",
      "Epoch: 19 | Batch_idx: 110 |  Loss: (0.4919) | Acc: (82.81%) (11766/14208)\n",
      "Epoch: 19 | Batch_idx: 120 |  Loss: (0.4915) | Acc: (82.86%) (12834/15488)\n",
      "Epoch: 19 | Batch_idx: 130 |  Loss: (0.4936) | Acc: (82.85%) (13893/16768)\n",
      "Epoch: 19 | Batch_idx: 140 |  Loss: (0.4932) | Acc: (82.82%) (14948/18048)\n",
      "Epoch: 19 | Batch_idx: 150 |  Loss: (0.4947) | Acc: (82.79%) (16001/19328)\n",
      "Epoch: 19 | Batch_idx: 160 |  Loss: (0.4983) | Acc: (82.64%) (17030/20608)\n",
      "Epoch: 19 | Batch_idx: 170 |  Loss: (0.4965) | Acc: (82.65%) (18091/21888)\n",
      "Epoch: 19 | Batch_idx: 180 |  Loss: (0.4973) | Acc: (82.70%) (19161/23168)\n",
      "Epoch: 19 | Batch_idx: 190 |  Loss: (0.4966) | Acc: (82.70%) (20218/24448)\n",
      "Epoch: 19 | Batch_idx: 200 |  Loss: (0.4958) | Acc: (82.68%) (21272/25728)\n",
      "Epoch: 19 | Batch_idx: 210 |  Loss: (0.4948) | Acc: (82.71%) (22338/27008)\n",
      "Epoch: 19 | Batch_idx: 220 |  Loss: (0.4945) | Acc: (82.73%) (23403/28288)\n",
      "Epoch: 19 | Batch_idx: 230 |  Loss: (0.4941) | Acc: (82.68%) (24448/29568)\n",
      "Epoch: 19 | Batch_idx: 240 |  Loss: (0.4934) | Acc: (82.70%) (25512/30848)\n",
      "Epoch: 19 | Batch_idx: 250 |  Loss: (0.4913) | Acc: (82.78%) (26595/32128)\n",
      "Epoch: 19 | Batch_idx: 260 |  Loss: (0.4911) | Acc: (82.79%) (27659/33408)\n",
      "Epoch: 19 | Batch_idx: 270 |  Loss: (0.4901) | Acc: (82.85%) (28739/34688)\n",
      "Epoch: 19 | Batch_idx: 280 |  Loss: (0.4889) | Acc: (82.86%) (29804/35968)\n",
      "Epoch: 19 | Batch_idx: 290 |  Loss: (0.4892) | Acc: (82.87%) (30868/37248)\n",
      "Epoch: 19 | Batch_idx: 300 |  Loss: (0.4900) | Acc: (82.85%) (31920/38528)\n",
      "Epoch: 19 | Batch_idx: 310 |  Loss: (0.4896) | Acc: (82.86%) (32986/39808)\n",
      "Epoch: 19 | Batch_idx: 320 |  Loss: (0.4895) | Acc: (82.83%) (34034/41088)\n",
      "Epoch: 19 | Batch_idx: 330 |  Loss: (0.4890) | Acc: (82.87%) (35111/42368)\n",
      "Epoch: 19 | Batch_idx: 340 |  Loss: (0.4891) | Acc: (82.87%) (36173/43648)\n",
      "Epoch: 19 | Batch_idx: 350 |  Loss: (0.4884) | Acc: (82.91%) (37251/44928)\n",
      "Epoch: 19 | Batch_idx: 360 |  Loss: (0.4874) | Acc: (82.98%) (38344/46208)\n",
      "Epoch: 19 | Batch_idx: 370 |  Loss: (0.4873) | Acc: (83.01%) (39419/47488)\n",
      "Epoch: 19 | Batch_idx: 380 |  Loss: (0.4875) | Acc: (83.00%) (40479/48768)\n",
      "Epoch: 19 | Batch_idx: 390 |  Loss: (0.4885) | Acc: (82.98%) (41490/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5551) | Acc: (81.35%) (8135/10000)\n",
      "Epoch: 20 | Batch_idx: 0 |  Loss: (0.4632) | Acc: (85.94%) (110/128)\n",
      "Epoch: 20 | Batch_idx: 10 |  Loss: (0.4609) | Acc: (84.16%) (1185/1408)\n",
      "Epoch: 20 | Batch_idx: 20 |  Loss: (0.4779) | Acc: (83.97%) (2257/2688)\n",
      "Epoch: 20 | Batch_idx: 30 |  Loss: (0.4575) | Acc: (84.80%) (3365/3968)\n",
      "Epoch: 20 | Batch_idx: 40 |  Loss: (0.4742) | Acc: (83.82%) (4399/5248)\n",
      "Epoch: 20 | Batch_idx: 50 |  Loss: (0.4721) | Acc: (83.93%) (5479/6528)\n",
      "Epoch: 20 | Batch_idx: 60 |  Loss: (0.4723) | Acc: (83.76%) (6540/7808)\n",
      "Epoch: 20 | Batch_idx: 70 |  Loss: (0.4755) | Acc: (83.62%) (7599/9088)\n",
      "Epoch: 20 | Batch_idx: 80 |  Loss: (0.4757) | Acc: (83.49%) (8656/10368)\n",
      "Epoch: 20 | Batch_idx: 90 |  Loss: (0.4735) | Acc: (83.66%) (9745/11648)\n",
      "Epoch: 20 | Batch_idx: 100 |  Loss: (0.4722) | Acc: (83.70%) (10821/12928)\n",
      "Epoch: 20 | Batch_idx: 110 |  Loss: (0.4708) | Acc: (83.76%) (11900/14208)\n",
      "Epoch: 20 | Batch_idx: 120 |  Loss: (0.4726) | Acc: (83.66%) (12957/15488)\n",
      "Epoch: 20 | Batch_idx: 130 |  Loss: (0.4757) | Acc: (83.51%) (14003/16768)\n",
      "Epoch: 20 | Batch_idx: 140 |  Loss: (0.4770) | Acc: (83.47%) (15065/18048)\n",
      "Epoch: 20 | Batch_idx: 150 |  Loss: (0.4750) | Acc: (83.59%) (16157/19328)\n",
      "Epoch: 20 | Batch_idx: 160 |  Loss: (0.4754) | Acc: (83.57%) (17223/20608)\n",
      "Epoch: 20 | Batch_idx: 170 |  Loss: (0.4759) | Acc: (83.54%) (18285/21888)\n",
      "Epoch: 20 | Batch_idx: 180 |  Loss: (0.4750) | Acc: (83.55%) (19356/23168)\n",
      "Epoch: 20 | Batch_idx: 190 |  Loss: (0.4744) | Acc: (83.57%) (20431/24448)\n",
      "Epoch: 20 | Batch_idx: 200 |  Loss: (0.4748) | Acc: (83.59%) (21506/25728)\n",
      "Epoch: 20 | Batch_idx: 210 |  Loss: (0.4745) | Acc: (83.61%) (22582/27008)\n",
      "Epoch: 20 | Batch_idx: 220 |  Loss: (0.4748) | Acc: (83.63%) (23656/28288)\n",
      "Epoch: 20 | Batch_idx: 230 |  Loss: (0.4765) | Acc: (83.60%) (24718/29568)\n",
      "Epoch: 20 | Batch_idx: 240 |  Loss: (0.4776) | Acc: (83.57%) (25781/30848)\n",
      "Epoch: 20 | Batch_idx: 250 |  Loss: (0.4764) | Acc: (83.61%) (26861/32128)\n",
      "Epoch: 20 | Batch_idx: 260 |  Loss: (0.4773) | Acc: (83.55%) (27911/33408)\n",
      "Epoch: 20 | Batch_idx: 270 |  Loss: (0.4774) | Acc: (83.53%) (28976/34688)\n",
      "Epoch: 20 | Batch_idx: 280 |  Loss: (0.4765) | Acc: (83.58%) (30061/35968)\n",
      "Epoch: 20 | Batch_idx: 290 |  Loss: (0.4767) | Acc: (83.55%) (31121/37248)\n",
      "Epoch: 20 | Batch_idx: 300 |  Loss: (0.4761) | Acc: (83.59%) (32206/38528)\n",
      "Epoch: 20 | Batch_idx: 310 |  Loss: (0.4761) | Acc: (83.56%) (33263/39808)\n",
      "Epoch: 20 | Batch_idx: 320 |  Loss: (0.4753) | Acc: (83.58%) (34343/41088)\n",
      "Epoch: 20 | Batch_idx: 330 |  Loss: (0.4759) | Acc: (83.55%) (35398/42368)\n",
      "Epoch: 20 | Batch_idx: 340 |  Loss: (0.4767) | Acc: (83.53%) (36460/43648)\n",
      "Epoch: 20 | Batch_idx: 350 |  Loss: (0.4755) | Acc: (83.60%) (37559/44928)\n",
      "Epoch: 20 | Batch_idx: 360 |  Loss: (0.4756) | Acc: (83.57%) (38616/46208)\n",
      "Epoch: 20 | Batch_idx: 370 |  Loss: (0.4765) | Acc: (83.53%) (39668/47488)\n",
      "Epoch: 20 | Batch_idx: 380 |  Loss: (0.4766) | Acc: (83.52%) (40733/48768)\n",
      "Epoch: 20 | Batch_idx: 390 |  Loss: (0.4770) | Acc: (83.52%) (41762/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5892) | Acc: (79.99%) (7999/10000)\n",
      "Epoch: 21 | Batch_idx: 0 |  Loss: (0.4229) | Acc: (84.38%) (108/128)\n",
      "Epoch: 21 | Batch_idx: 10 |  Loss: (0.4704) | Acc: (83.03%) (1169/1408)\n",
      "Epoch: 21 | Batch_idx: 20 |  Loss: (0.4615) | Acc: (83.26%) (2238/2688)\n",
      "Epoch: 21 | Batch_idx: 30 |  Loss: (0.4597) | Acc: (83.52%) (3314/3968)\n",
      "Epoch: 21 | Batch_idx: 40 |  Loss: (0.4539) | Acc: (83.92%) (4404/5248)\n",
      "Epoch: 21 | Batch_idx: 50 |  Loss: (0.4539) | Acc: (83.88%) (5476/6528)\n",
      "Epoch: 21 | Batch_idx: 60 |  Loss: (0.4546) | Acc: (83.93%) (6553/7808)\n",
      "Epoch: 21 | Batch_idx: 70 |  Loss: (0.4625) | Acc: (83.81%) (7617/9088)\n",
      "Epoch: 21 | Batch_idx: 80 |  Loss: (0.4653) | Acc: (83.77%) (8685/10368)\n",
      "Epoch: 21 | Batch_idx: 90 |  Loss: (0.4618) | Acc: (83.79%) (9760/11648)\n",
      "Epoch: 21 | Batch_idx: 100 |  Loss: (0.4613) | Acc: (83.95%) (10853/12928)\n",
      "Epoch: 21 | Batch_idx: 110 |  Loss: (0.4609) | Acc: (83.96%) (11929/14208)\n",
      "Epoch: 21 | Batch_idx: 120 |  Loss: (0.4612) | Acc: (83.88%) (12991/15488)\n",
      "Epoch: 21 | Batch_idx: 130 |  Loss: (0.4619) | Acc: (83.96%) (14079/16768)\n",
      "Epoch: 21 | Batch_idx: 140 |  Loss: (0.4603) | Acc: (84.01%) (15162/18048)\n",
      "Epoch: 21 | Batch_idx: 150 |  Loss: (0.4603) | Acc: (83.97%) (16229/19328)\n",
      "Epoch: 21 | Batch_idx: 160 |  Loss: (0.4607) | Acc: (83.96%) (17302/20608)\n",
      "Epoch: 21 | Batch_idx: 170 |  Loss: (0.4610) | Acc: (83.93%) (18371/21888)\n",
      "Epoch: 21 | Batch_idx: 180 |  Loss: (0.4615) | Acc: (83.93%) (19446/23168)\n",
      "Epoch: 21 | Batch_idx: 190 |  Loss: (0.4620) | Acc: (83.94%) (20522/24448)\n",
      "Epoch: 21 | Batch_idx: 200 |  Loss: (0.4611) | Acc: (83.92%) (21591/25728)\n",
      "Epoch: 21 | Batch_idx: 210 |  Loss: (0.4603) | Acc: (83.96%) (22675/27008)\n",
      "Epoch: 21 | Batch_idx: 220 |  Loss: (0.4607) | Acc: (83.99%) (23759/28288)\n",
      "Epoch: 21 | Batch_idx: 230 |  Loss: (0.4599) | Acc: (84.07%) (24857/29568)\n",
      "Epoch: 21 | Batch_idx: 240 |  Loss: (0.4596) | Acc: (84.10%) (25942/30848)\n",
      "Epoch: 21 | Batch_idx: 250 |  Loss: (0.4613) | Acc: (84.02%) (26994/32128)\n",
      "Epoch: 21 | Batch_idx: 260 |  Loss: (0.4609) | Acc: (84.04%) (28076/33408)\n",
      "Epoch: 21 | Batch_idx: 270 |  Loss: (0.4612) | Acc: (84.00%) (29139/34688)\n",
      "Epoch: 21 | Batch_idx: 280 |  Loss: (0.4610) | Acc: (84.00%) (30214/35968)\n",
      "Epoch: 21 | Batch_idx: 290 |  Loss: (0.4603) | Acc: (84.01%) (31293/37248)\n",
      "Epoch: 21 | Batch_idx: 300 |  Loss: (0.4606) | Acc: (84.03%) (32374/38528)\n",
      "Epoch: 21 | Batch_idx: 310 |  Loss: (0.4615) | Acc: (84.01%) (33443/39808)\n",
      "Epoch: 21 | Batch_idx: 320 |  Loss: (0.4606) | Acc: (84.06%) (34540/41088)\n",
      "Epoch: 21 | Batch_idx: 330 |  Loss: (0.4597) | Acc: (84.08%) (35621/42368)\n",
      "Epoch: 21 | Batch_idx: 340 |  Loss: (0.4600) | Acc: (84.06%) (36689/43648)\n",
      "Epoch: 21 | Batch_idx: 350 |  Loss: (0.4584) | Acc: (84.11%) (37788/44928)\n",
      "Epoch: 21 | Batch_idx: 360 |  Loss: (0.4582) | Acc: (84.13%) (38873/46208)\n",
      "Epoch: 21 | Batch_idx: 370 |  Loss: (0.4580) | Acc: (84.12%) (39946/47488)\n",
      "Epoch: 21 | Batch_idx: 380 |  Loss: (0.4588) | Acc: (84.11%) (41018/48768)\n",
      "Epoch: 21 | Batch_idx: 390 |  Loss: (0.4574) | Acc: (84.14%) (42071/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6002) | Acc: (80.22%) (8022/10000)\n",
      "Epoch: 22 | Batch_idx: 0 |  Loss: (0.5279) | Acc: (84.38%) (108/128)\n",
      "Epoch: 22 | Batch_idx: 10 |  Loss: (0.4303) | Acc: (84.30%) (1187/1408)\n",
      "Epoch: 22 | Batch_idx: 20 |  Loss: (0.4355) | Acc: (84.67%) (2276/2688)\n",
      "Epoch: 22 | Batch_idx: 30 |  Loss: (0.4429) | Acc: (84.35%) (3347/3968)\n",
      "Epoch: 22 | Batch_idx: 40 |  Loss: (0.4391) | Acc: (84.76%) (4448/5248)\n",
      "Epoch: 22 | Batch_idx: 50 |  Loss: (0.4422) | Acc: (84.70%) (5529/6528)\n",
      "Epoch: 22 | Batch_idx: 60 |  Loss: (0.4403) | Acc: (84.76%) (6618/7808)\n",
      "Epoch: 22 | Batch_idx: 70 |  Loss: (0.4441) | Acc: (84.65%) (7693/9088)\n",
      "Epoch: 22 | Batch_idx: 80 |  Loss: (0.4476) | Acc: (84.44%) (8755/10368)\n",
      "Epoch: 22 | Batch_idx: 90 |  Loss: (0.4465) | Acc: (84.42%) (9833/11648)\n",
      "Epoch: 22 | Batch_idx: 100 |  Loss: (0.4468) | Acc: (84.27%) (10894/12928)\n",
      "Epoch: 22 | Batch_idx: 110 |  Loss: (0.4446) | Acc: (84.39%) (11990/14208)\n",
      "Epoch: 22 | Batch_idx: 120 |  Loss: (0.4494) | Acc: (84.32%) (13059/15488)\n",
      "Epoch: 22 | Batch_idx: 130 |  Loss: (0.4476) | Acc: (84.38%) (14149/16768)\n",
      "Epoch: 22 | Batch_idx: 140 |  Loss: (0.4453) | Acc: (84.42%) (15236/18048)\n",
      "Epoch: 22 | Batch_idx: 150 |  Loss: (0.4457) | Acc: (84.41%) (16315/19328)\n",
      "Epoch: 22 | Batch_idx: 160 |  Loss: (0.4469) | Acc: (84.43%) (17400/20608)\n",
      "Epoch: 22 | Batch_idx: 170 |  Loss: (0.4463) | Acc: (84.48%) (18491/21888)\n",
      "Epoch: 22 | Batch_idx: 180 |  Loss: (0.4461) | Acc: (84.49%) (19575/23168)\n",
      "Epoch: 22 | Batch_idx: 190 |  Loss: (0.4467) | Acc: (84.45%) (20647/24448)\n",
      "Epoch: 22 | Batch_idx: 200 |  Loss: (0.4479) | Acc: (84.44%) (21724/25728)\n",
      "Epoch: 22 | Batch_idx: 210 |  Loss: (0.4484) | Acc: (84.36%) (22784/27008)\n",
      "Epoch: 22 | Batch_idx: 220 |  Loss: (0.4478) | Acc: (84.38%) (23868/28288)\n",
      "Epoch: 22 | Batch_idx: 230 |  Loss: (0.4496) | Acc: (84.33%) (24936/29568)\n",
      "Epoch: 22 | Batch_idx: 240 |  Loss: (0.4538) | Acc: (84.16%) (25961/30848)\n",
      "Epoch: 22 | Batch_idx: 250 |  Loss: (0.4558) | Acc: (84.09%) (27015/32128)\n",
      "Epoch: 22 | Batch_idx: 260 |  Loss: (0.4561) | Acc: (84.07%) (28085/33408)\n",
      "Epoch: 22 | Batch_idx: 270 |  Loss: (0.4545) | Acc: (84.12%) (29178/34688)\n",
      "Epoch: 22 | Batch_idx: 280 |  Loss: (0.4532) | Acc: (84.20%) (30284/35968)\n",
      "Epoch: 22 | Batch_idx: 290 |  Loss: (0.4540) | Acc: (84.20%) (31363/37248)\n",
      "Epoch: 22 | Batch_idx: 300 |  Loss: (0.4548) | Acc: (84.17%) (32429/38528)\n",
      "Epoch: 22 | Batch_idx: 310 |  Loss: (0.4552) | Acc: (84.11%) (33482/39808)\n",
      "Epoch: 22 | Batch_idx: 320 |  Loss: (0.4557) | Acc: (84.09%) (34552/41088)\n",
      "Epoch: 22 | Batch_idx: 330 |  Loss: (0.4547) | Acc: (84.13%) (35645/42368)\n",
      "Epoch: 22 | Batch_idx: 340 |  Loss: (0.4548) | Acc: (84.15%) (36728/43648)\n",
      "Epoch: 22 | Batch_idx: 350 |  Loss: (0.4547) | Acc: (84.13%) (37796/44928)\n",
      "Epoch: 22 | Batch_idx: 360 |  Loss: (0.4543) | Acc: (84.15%) (38883/46208)\n",
      "Epoch: 22 | Batch_idx: 370 |  Loss: (0.4536) | Acc: (84.16%) (39965/47488)\n",
      "Epoch: 22 | Batch_idx: 380 |  Loss: (0.4532) | Acc: (84.18%) (41052/48768)\n",
      "Epoch: 22 | Batch_idx: 390 |  Loss: (0.4527) | Acc: (84.19%) (42097/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5686) | Acc: (80.80%) (8080/10000)\n",
      "Epoch: 23 | Batch_idx: 0 |  Loss: (0.5536) | Acc: (82.03%) (105/128)\n",
      "Epoch: 23 | Batch_idx: 10 |  Loss: (0.4393) | Acc: (84.73%) (1193/1408)\n",
      "Epoch: 23 | Batch_idx: 20 |  Loss: (0.4418) | Acc: (84.82%) (2280/2688)\n",
      "Epoch: 23 | Batch_idx: 30 |  Loss: (0.4348) | Acc: (84.83%) (3366/3968)\n",
      "Epoch: 23 | Batch_idx: 40 |  Loss: (0.4258) | Acc: (85.42%) (4483/5248)\n",
      "Epoch: 23 | Batch_idx: 50 |  Loss: (0.4331) | Acc: (85.22%) (5563/6528)\n",
      "Epoch: 23 | Batch_idx: 60 |  Loss: (0.4301) | Acc: (85.35%) (6664/7808)\n",
      "Epoch: 23 | Batch_idx: 70 |  Loss: (0.4254) | Acc: (85.52%) (7772/9088)\n",
      "Epoch: 23 | Batch_idx: 80 |  Loss: (0.4331) | Acc: (85.14%) (8827/10368)\n",
      "Epoch: 23 | Batch_idx: 90 |  Loss: (0.4332) | Acc: (85.21%) (9925/11648)\n",
      "Epoch: 23 | Batch_idx: 100 |  Loss: (0.4321) | Acc: (85.20%) (11015/12928)\n",
      "Epoch: 23 | Batch_idx: 110 |  Loss: (0.4285) | Acc: (85.25%) (12112/14208)\n",
      "Epoch: 23 | Batch_idx: 120 |  Loss: (0.4303) | Acc: (85.20%) (13196/15488)\n",
      "Epoch: 23 | Batch_idx: 130 |  Loss: (0.4315) | Acc: (85.15%) (14278/16768)\n",
      "Epoch: 23 | Batch_idx: 140 |  Loss: (0.4351) | Acc: (85.03%) (15347/18048)\n",
      "Epoch: 23 | Batch_idx: 150 |  Loss: (0.4321) | Acc: (85.07%) (16442/19328)\n",
      "Epoch: 23 | Batch_idx: 160 |  Loss: (0.4321) | Acc: (85.06%) (17529/20608)\n",
      "Epoch: 23 | Batch_idx: 170 |  Loss: (0.4318) | Acc: (85.13%) (18633/21888)\n",
      "Epoch: 23 | Batch_idx: 180 |  Loss: (0.4326) | Acc: (85.12%) (19720/23168)\n",
      "Epoch: 23 | Batch_idx: 190 |  Loss: (0.4349) | Acc: (85.02%) (20785/24448)\n",
      "Epoch: 23 | Batch_idx: 200 |  Loss: (0.4354) | Acc: (84.98%) (21863/25728)\n",
      "Epoch: 23 | Batch_idx: 210 |  Loss: (0.4358) | Acc: (84.98%) (22951/27008)\n",
      "Epoch: 23 | Batch_idx: 220 |  Loss: (0.4349) | Acc: (85.01%) (24047/28288)\n",
      "Epoch: 23 | Batch_idx: 230 |  Loss: (0.4348) | Acc: (84.98%) (25128/29568)\n",
      "Epoch: 23 | Batch_idx: 240 |  Loss: (0.4343) | Acc: (84.99%) (26219/30848)\n",
      "Epoch: 23 | Batch_idx: 250 |  Loss: (0.4348) | Acc: (84.97%) (27300/32128)\n",
      "Epoch: 23 | Batch_idx: 260 |  Loss: (0.4363) | Acc: (84.93%) (28373/33408)\n",
      "Epoch: 23 | Batch_idx: 270 |  Loss: (0.4369) | Acc: (84.89%) (29445/34688)\n",
      "Epoch: 23 | Batch_idx: 280 |  Loss: (0.4373) | Acc: (84.87%) (30527/35968)\n",
      "Epoch: 23 | Batch_idx: 290 |  Loss: (0.4379) | Acc: (84.83%) (31596/37248)\n",
      "Epoch: 23 | Batch_idx: 300 |  Loss: (0.4384) | Acc: (84.82%) (32678/38528)\n",
      "Epoch: 23 | Batch_idx: 310 |  Loss: (0.4384) | Acc: (84.81%) (33761/39808)\n",
      "Epoch: 23 | Batch_idx: 320 |  Loss: (0.4388) | Acc: (84.79%) (34839/41088)\n",
      "Epoch: 23 | Batch_idx: 330 |  Loss: (0.4395) | Acc: (84.78%) (35918/42368)\n",
      "Epoch: 23 | Batch_idx: 340 |  Loss: (0.4387) | Acc: (84.79%) (37009/43648)\n",
      "Epoch: 23 | Batch_idx: 350 |  Loss: (0.4385) | Acc: (84.81%) (38104/44928)\n",
      "Epoch: 23 | Batch_idx: 360 |  Loss: (0.4384) | Acc: (84.80%) (39185/46208)\n",
      "Epoch: 23 | Batch_idx: 370 |  Loss: (0.4377) | Acc: (84.80%) (40270/47488)\n",
      "Epoch: 23 | Batch_idx: 380 |  Loss: (0.4366) | Acc: (84.84%) (41373/48768)\n",
      "Epoch: 23 | Batch_idx: 390 |  Loss: (0.4361) | Acc: (84.84%) (42422/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5326) | Acc: (81.92%) (8192/10000)\n",
      "Epoch: 24 | Batch_idx: 0 |  Loss: (0.3028) | Acc: (90.62%) (116/128)\n",
      "Epoch: 24 | Batch_idx: 10 |  Loss: (0.3968) | Acc: (85.87%) (1209/1408)\n",
      "Epoch: 24 | Batch_idx: 20 |  Loss: (0.4182) | Acc: (85.45%) (2297/2688)\n",
      "Epoch: 24 | Batch_idx: 30 |  Loss: (0.4270) | Acc: (85.38%) (3388/3968)\n",
      "Epoch: 24 | Batch_idx: 40 |  Loss: (0.4291) | Acc: (85.31%) (4477/5248)\n",
      "Epoch: 24 | Batch_idx: 50 |  Loss: (0.4314) | Acc: (85.39%) (5574/6528)\n",
      "Epoch: 24 | Batch_idx: 60 |  Loss: (0.4318) | Acc: (85.31%) (6661/7808)\n",
      "Epoch: 24 | Batch_idx: 70 |  Loss: (0.4272) | Acc: (85.44%) (7765/9088)\n",
      "Epoch: 24 | Batch_idx: 80 |  Loss: (0.4255) | Acc: (85.44%) (8858/10368)\n",
      "Epoch: 24 | Batch_idx: 90 |  Loss: (0.4264) | Acc: (85.43%) (9951/11648)\n",
      "Epoch: 24 | Batch_idx: 100 |  Loss: (0.4237) | Acc: (85.47%) (11050/12928)\n",
      "Epoch: 24 | Batch_idx: 110 |  Loss: (0.4233) | Acc: (85.51%) (12149/14208)\n",
      "Epoch: 24 | Batch_idx: 120 |  Loss: (0.4217) | Acc: (85.47%) (13237/15488)\n",
      "Epoch: 24 | Batch_idx: 130 |  Loss: (0.4238) | Acc: (85.37%) (14315/16768)\n",
      "Epoch: 24 | Batch_idx: 140 |  Loss: (0.4254) | Acc: (85.30%) (15395/18048)\n",
      "Epoch: 24 | Batch_idx: 150 |  Loss: (0.4263) | Acc: (85.25%) (16477/19328)\n",
      "Epoch: 24 | Batch_idx: 160 |  Loss: (0.4261) | Acc: (85.26%) (17571/20608)\n",
      "Epoch: 24 | Batch_idx: 170 |  Loss: (0.4269) | Acc: (85.24%) (18658/21888)\n",
      "Epoch: 24 | Batch_idx: 180 |  Loss: (0.4271) | Acc: (85.25%) (19750/23168)\n",
      "Epoch: 24 | Batch_idx: 190 |  Loss: (0.4251) | Acc: (85.28%) (20849/24448)\n",
      "Epoch: 24 | Batch_idx: 200 |  Loss: (0.4255) | Acc: (85.28%) (21942/25728)\n",
      "Epoch: 24 | Batch_idx: 210 |  Loss: (0.4262) | Acc: (85.23%) (23018/27008)\n",
      "Epoch: 24 | Batch_idx: 220 |  Loss: (0.4265) | Acc: (85.24%) (24113/28288)\n",
      "Epoch: 24 | Batch_idx: 230 |  Loss: (0.4253) | Acc: (85.27%) (25214/29568)\n",
      "Epoch: 24 | Batch_idx: 240 |  Loss: (0.4264) | Acc: (85.19%) (26278/30848)\n",
      "Epoch: 24 | Batch_idx: 250 |  Loss: (0.4254) | Acc: (85.18%) (27366/32128)\n",
      "Epoch: 24 | Batch_idx: 260 |  Loss: (0.4261) | Acc: (85.15%) (28447/33408)\n",
      "Epoch: 24 | Batch_idx: 270 |  Loss: (0.4248) | Acc: (85.23%) (29565/34688)\n",
      "Epoch: 24 | Batch_idx: 280 |  Loss: (0.4248) | Acc: (85.25%) (30662/35968)\n",
      "Epoch: 24 | Batch_idx: 290 |  Loss: (0.4247) | Acc: (85.27%) (31762/37248)\n",
      "Epoch: 24 | Batch_idx: 300 |  Loss: (0.4242) | Acc: (85.30%) (32863/38528)\n",
      "Epoch: 24 | Batch_idx: 310 |  Loss: (0.4233) | Acc: (85.34%) (33974/39808)\n",
      "Epoch: 24 | Batch_idx: 320 |  Loss: (0.4229) | Acc: (85.34%) (35066/41088)\n",
      "Epoch: 24 | Batch_idx: 330 |  Loss: (0.4224) | Acc: (85.34%) (36155/42368)\n",
      "Epoch: 24 | Batch_idx: 340 |  Loss: (0.4224) | Acc: (85.33%) (37245/43648)\n",
      "Epoch: 24 | Batch_idx: 350 |  Loss: (0.4213) | Acc: (85.36%) (38352/44928)\n",
      "Epoch: 24 | Batch_idx: 360 |  Loss: (0.4224) | Acc: (85.29%) (39410/46208)\n",
      "Epoch: 24 | Batch_idx: 370 |  Loss: (0.4230) | Acc: (85.25%) (40483/47488)\n",
      "Epoch: 24 | Batch_idx: 380 |  Loss: (0.4236) | Acc: (85.24%) (41569/48768)\n",
      "Epoch: 24 | Batch_idx: 390 |  Loss: (0.4241) | Acc: (85.26%) (42628/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.7201) | Acc: (76.81%) (7681/10000)\n",
      "Epoch: 25 | Batch_idx: 0 |  Loss: (0.4830) | Acc: (82.03%) (105/128)\n",
      "Epoch: 25 | Batch_idx: 10 |  Loss: (0.4024) | Acc: (86.01%) (1211/1408)\n",
      "Epoch: 25 | Batch_idx: 20 |  Loss: (0.4293) | Acc: (85.83%) (2307/2688)\n",
      "Epoch: 25 | Batch_idx: 30 |  Loss: (0.4280) | Acc: (85.58%) (3396/3968)\n",
      "Epoch: 25 | Batch_idx: 40 |  Loss: (0.4220) | Acc: (85.67%) (4496/5248)\n",
      "Epoch: 25 | Batch_idx: 50 |  Loss: (0.4180) | Acc: (85.89%) (5607/6528)\n",
      "Epoch: 25 | Batch_idx: 60 |  Loss: (0.4144) | Acc: (85.96%) (6712/7808)\n",
      "Epoch: 25 | Batch_idx: 70 |  Loss: (0.4145) | Acc: (85.86%) (7803/9088)\n",
      "Epoch: 25 | Batch_idx: 80 |  Loss: (0.4159) | Acc: (85.89%) (8905/10368)\n",
      "Epoch: 25 | Batch_idx: 90 |  Loss: (0.4168) | Acc: (85.82%) (9996/11648)\n",
      "Epoch: 25 | Batch_idx: 100 |  Loss: (0.4162) | Acc: (85.88%) (11102/12928)\n",
      "Epoch: 25 | Batch_idx: 110 |  Loss: (0.4166) | Acc: (85.78%) (12188/14208)\n",
      "Epoch: 25 | Batch_idx: 120 |  Loss: (0.4159) | Acc: (85.87%) (13299/15488)\n",
      "Epoch: 25 | Batch_idx: 130 |  Loss: (0.4175) | Acc: (85.72%) (14374/16768)\n",
      "Epoch: 25 | Batch_idx: 140 |  Loss: (0.4166) | Acc: (85.77%) (15479/18048)\n",
      "Epoch: 25 | Batch_idx: 150 |  Loss: (0.4141) | Acc: (85.87%) (16597/19328)\n",
      "Epoch: 25 | Batch_idx: 160 |  Loss: (0.4137) | Acc: (85.86%) (17694/20608)\n",
      "Epoch: 25 | Batch_idx: 170 |  Loss: (0.4119) | Acc: (85.97%) (18818/21888)\n",
      "Epoch: 25 | Batch_idx: 180 |  Loss: (0.4113) | Acc: (85.99%) (19922/23168)\n",
      "Epoch: 25 | Batch_idx: 190 |  Loss: (0.4105) | Acc: (85.97%) (21019/24448)\n",
      "Epoch: 25 | Batch_idx: 200 |  Loss: (0.4110) | Acc: (85.96%) (22117/25728)\n",
      "Epoch: 25 | Batch_idx: 210 |  Loss: (0.4124) | Acc: (85.91%) (23202/27008)\n",
      "Epoch: 25 | Batch_idx: 220 |  Loss: (0.4111) | Acc: (85.88%) (24295/28288)\n",
      "Epoch: 25 | Batch_idx: 230 |  Loss: (0.4109) | Acc: (85.88%) (25394/29568)\n",
      "Epoch: 25 | Batch_idx: 240 |  Loss: (0.4098) | Acc: (85.91%) (26503/30848)\n",
      "Epoch: 25 | Batch_idx: 250 |  Loss: (0.4101) | Acc: (85.89%) (27595/32128)\n",
      "Epoch: 25 | Batch_idx: 260 |  Loss: (0.4104) | Acc: (85.87%) (28688/33408)\n",
      "Epoch: 25 | Batch_idx: 270 |  Loss: (0.4127) | Acc: (85.80%) (29763/34688)\n",
      "Epoch: 25 | Batch_idx: 280 |  Loss: (0.4131) | Acc: (85.81%) (30864/35968)\n",
      "Epoch: 25 | Batch_idx: 290 |  Loss: (0.4126) | Acc: (85.82%) (31968/37248)\n",
      "Epoch: 25 | Batch_idx: 300 |  Loss: (0.4130) | Acc: (85.81%) (33062/38528)\n",
      "Epoch: 25 | Batch_idx: 310 |  Loss: (0.4138) | Acc: (85.76%) (34141/39808)\n",
      "Epoch: 25 | Batch_idx: 320 |  Loss: (0.4137) | Acc: (85.74%) (35230/41088)\n",
      "Epoch: 25 | Batch_idx: 330 |  Loss: (0.4140) | Acc: (85.72%) (36318/42368)\n",
      "Epoch: 25 | Batch_idx: 340 |  Loss: (0.4145) | Acc: (85.65%) (37386/43648)\n",
      "Epoch: 25 | Batch_idx: 350 |  Loss: (0.4140) | Acc: (85.67%) (38489/44928)\n",
      "Epoch: 25 | Batch_idx: 360 |  Loss: (0.4139) | Acc: (85.66%) (39583/46208)\n",
      "Epoch: 25 | Batch_idx: 370 |  Loss: (0.4151) | Acc: (85.59%) (40647/47488)\n",
      "Epoch: 25 | Batch_idx: 380 |  Loss: (0.4154) | Acc: (85.57%) (41731/48768)\n",
      "Epoch: 25 | Batch_idx: 390 |  Loss: (0.4163) | Acc: (85.56%) (42779/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5882) | Acc: (80.92%) (8092/10000)\n",
      "Epoch: 26 | Batch_idx: 0 |  Loss: (0.4262) | Acc: (86.72%) (111/128)\n",
      "Epoch: 26 | Batch_idx: 10 |  Loss: (0.4162) | Acc: (85.44%) (1203/1408)\n",
      "Epoch: 26 | Batch_idx: 20 |  Loss: (0.4171) | Acc: (85.45%) (2297/2688)\n",
      "Epoch: 26 | Batch_idx: 30 |  Loss: (0.4108) | Acc: (85.74%) (3402/3968)\n",
      "Epoch: 26 | Batch_idx: 40 |  Loss: (0.4020) | Acc: (85.84%) (4505/5248)\n",
      "Epoch: 26 | Batch_idx: 50 |  Loss: (0.4127) | Acc: (85.51%) (5582/6528)\n",
      "Epoch: 26 | Batch_idx: 60 |  Loss: (0.4053) | Acc: (85.51%) (6677/7808)\n",
      "Epoch: 26 | Batch_idx: 70 |  Loss: (0.4031) | Acc: (85.62%) (7781/9088)\n",
      "Epoch: 26 | Batch_idx: 80 |  Loss: (0.4021) | Acc: (85.71%) (8886/10368)\n",
      "Epoch: 26 | Batch_idx: 90 |  Loss: (0.4034) | Acc: (85.61%) (9972/11648)\n",
      "Epoch: 26 | Batch_idx: 100 |  Loss: (0.4020) | Acc: (85.64%) (11072/12928)\n",
      "Epoch: 26 | Batch_idx: 110 |  Loss: (0.4002) | Acc: (85.78%) (12187/14208)\n",
      "Epoch: 26 | Batch_idx: 120 |  Loss: (0.3985) | Acc: (85.87%) (13299/15488)\n",
      "Epoch: 26 | Batch_idx: 130 |  Loss: (0.3981) | Acc: (86.05%) (14429/16768)\n",
      "Epoch: 26 | Batch_idx: 140 |  Loss: (0.3975) | Acc: (86.11%) (15542/18048)\n",
      "Epoch: 26 | Batch_idx: 150 |  Loss: (0.3963) | Acc: (86.10%) (16641/19328)\n",
      "Epoch: 26 | Batch_idx: 160 |  Loss: (0.3978) | Acc: (86.08%) (17740/20608)\n",
      "Epoch: 26 | Batch_idx: 170 |  Loss: (0.3998) | Acc: (86.04%) (18832/21888)\n",
      "Epoch: 26 | Batch_idx: 180 |  Loss: (0.3994) | Acc: (86.09%) (19946/23168)\n",
      "Epoch: 26 | Batch_idx: 190 |  Loss: (0.4011) | Acc: (86.05%) (21038/24448)\n",
      "Epoch: 26 | Batch_idx: 200 |  Loss: (0.4012) | Acc: (86.03%) (22135/25728)\n",
      "Epoch: 26 | Batch_idx: 210 |  Loss: (0.4013) | Acc: (86.03%) (23236/27008)\n",
      "Epoch: 26 | Batch_idx: 220 |  Loss: (0.4016) | Acc: (86.02%) (24333/28288)\n",
      "Epoch: 26 | Batch_idx: 230 |  Loss: (0.4027) | Acc: (85.94%) (25412/29568)\n",
      "Epoch: 26 | Batch_idx: 240 |  Loss: (0.4033) | Acc: (85.93%) (26507/30848)\n",
      "Epoch: 26 | Batch_idx: 250 |  Loss: (0.4031) | Acc: (85.97%) (27619/32128)\n",
      "Epoch: 26 | Batch_idx: 260 |  Loss: (0.4024) | Acc: (86.01%) (28733/33408)\n",
      "Epoch: 26 | Batch_idx: 270 |  Loss: (0.4031) | Acc: (85.99%) (29828/34688)\n",
      "Epoch: 26 | Batch_idx: 280 |  Loss: (0.4026) | Acc: (86.04%) (30946/35968)\n",
      "Epoch: 26 | Batch_idx: 290 |  Loss: (0.4027) | Acc: (86.05%) (32052/37248)\n",
      "Epoch: 26 | Batch_idx: 300 |  Loss: (0.4016) | Acc: (86.06%) (33158/38528)\n",
      "Epoch: 26 | Batch_idx: 310 |  Loss: (0.4013) | Acc: (86.08%) (34265/39808)\n",
      "Epoch: 26 | Batch_idx: 320 |  Loss: (0.4018) | Acc: (86.03%) (35349/41088)\n",
      "Epoch: 26 | Batch_idx: 330 |  Loss: (0.4027) | Acc: (85.99%) (36433/42368)\n",
      "Epoch: 26 | Batch_idx: 340 |  Loss: (0.4032) | Acc: (86.00%) (37536/43648)\n",
      "Epoch: 26 | Batch_idx: 350 |  Loss: (0.4029) | Acc: (86.02%) (38649/44928)\n",
      "Epoch: 26 | Batch_idx: 360 |  Loss: (0.4031) | Acc: (86.04%) (39759/46208)\n",
      "Epoch: 26 | Batch_idx: 370 |  Loss: (0.4032) | Acc: (86.06%) (40868/47488)\n",
      "Epoch: 26 | Batch_idx: 380 |  Loss: (0.4032) | Acc: (86.06%) (41969/48768)\n",
      "Epoch: 26 | Batch_idx: 390 |  Loss: (0.4033) | Acc: (86.06%) (43032/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5301) | Acc: (82.60%) (8260/10000)\n",
      "Epoch: 27 | Batch_idx: 0 |  Loss: (0.3589) | Acc: (89.84%) (115/128)\n",
      "Epoch: 27 | Batch_idx: 10 |  Loss: (0.4011) | Acc: (86.51%) (1218/1408)\n",
      "Epoch: 27 | Batch_idx: 20 |  Loss: (0.3812) | Acc: (87.39%) (2349/2688)\n",
      "Epoch: 27 | Batch_idx: 30 |  Loss: (0.3899) | Acc: (87.02%) (3453/3968)\n",
      "Epoch: 27 | Batch_idx: 40 |  Loss: (0.3902) | Acc: (86.85%) (4558/5248)\n",
      "Epoch: 27 | Batch_idx: 50 |  Loss: (0.3911) | Acc: (86.76%) (5664/6528)\n",
      "Epoch: 27 | Batch_idx: 60 |  Loss: (0.3938) | Acc: (86.68%) (6768/7808)\n",
      "Epoch: 27 | Batch_idx: 70 |  Loss: (0.3892) | Acc: (86.75%) (7884/9088)\n",
      "Epoch: 27 | Batch_idx: 80 |  Loss: (0.3907) | Acc: (86.67%) (8986/10368)\n",
      "Epoch: 27 | Batch_idx: 90 |  Loss: (0.3893) | Acc: (86.75%) (10105/11648)\n",
      "Epoch: 27 | Batch_idx: 100 |  Loss: (0.3886) | Acc: (86.73%) (11212/12928)\n",
      "Epoch: 27 | Batch_idx: 110 |  Loss: (0.3880) | Acc: (86.69%) (12317/14208)\n",
      "Epoch: 27 | Batch_idx: 120 |  Loss: (0.3874) | Acc: (86.69%) (13426/15488)\n",
      "Epoch: 27 | Batch_idx: 130 |  Loss: (0.3875) | Acc: (86.72%) (14542/16768)\n",
      "Epoch: 27 | Batch_idx: 140 |  Loss: (0.3884) | Acc: (86.74%) (15655/18048)\n",
      "Epoch: 27 | Batch_idx: 150 |  Loss: (0.3866) | Acc: (86.78%) (16773/19328)\n",
      "Epoch: 27 | Batch_idx: 160 |  Loss: (0.3865) | Acc: (86.80%) (17888/20608)\n",
      "Epoch: 27 | Batch_idx: 170 |  Loss: (0.3904) | Acc: (86.59%) (18953/21888)\n",
      "Epoch: 27 | Batch_idx: 180 |  Loss: (0.3895) | Acc: (86.62%) (20068/23168)\n",
      "Epoch: 27 | Batch_idx: 190 |  Loss: (0.3888) | Acc: (86.66%) (21187/24448)\n",
      "Epoch: 27 | Batch_idx: 200 |  Loss: (0.3906) | Acc: (86.59%) (22279/25728)\n",
      "Epoch: 27 | Batch_idx: 210 |  Loss: (0.3893) | Acc: (86.63%) (23396/27008)\n",
      "Epoch: 27 | Batch_idx: 220 |  Loss: (0.3895) | Acc: (86.63%) (24506/28288)\n",
      "Epoch: 27 | Batch_idx: 230 |  Loss: (0.3902) | Acc: (86.61%) (25609/29568)\n",
      "Epoch: 27 | Batch_idx: 240 |  Loss: (0.3898) | Acc: (86.63%) (26725/30848)\n",
      "Epoch: 27 | Batch_idx: 250 |  Loss: (0.3926) | Acc: (86.51%) (27795/32128)\n",
      "Epoch: 27 | Batch_idx: 260 |  Loss: (0.3938) | Acc: (86.45%) (28880/33408)\n",
      "Epoch: 27 | Batch_idx: 270 |  Loss: (0.3922) | Acc: (86.55%) (30024/34688)\n",
      "Epoch: 27 | Batch_idx: 280 |  Loss: (0.3933) | Acc: (86.50%) (31112/35968)\n",
      "Epoch: 27 | Batch_idx: 290 |  Loss: (0.3933) | Acc: (86.50%) (32220/37248)\n",
      "Epoch: 27 | Batch_idx: 300 |  Loss: (0.3932) | Acc: (86.49%) (33323/38528)\n",
      "Epoch: 27 | Batch_idx: 310 |  Loss: (0.3930) | Acc: (86.52%) (34440/39808)\n",
      "Epoch: 27 | Batch_idx: 320 |  Loss: (0.3930) | Acc: (86.54%) (35558/41088)\n",
      "Epoch: 27 | Batch_idx: 330 |  Loss: (0.3927) | Acc: (86.56%) (36673/42368)\n",
      "Epoch: 27 | Batch_idx: 340 |  Loss: (0.3928) | Acc: (86.54%) (37774/43648)\n",
      "Epoch: 27 | Batch_idx: 350 |  Loss: (0.3928) | Acc: (86.54%) (38881/44928)\n",
      "Epoch: 27 | Batch_idx: 360 |  Loss: (0.3921) | Acc: (86.55%) (39992/46208)\n",
      "Epoch: 27 | Batch_idx: 370 |  Loss: (0.3915) | Acc: (86.57%) (41109/47488)\n",
      "Epoch: 27 | Batch_idx: 380 |  Loss: (0.3926) | Acc: (86.50%) (42185/48768)\n",
      "Epoch: 27 | Batch_idx: 390 |  Loss: (0.3935) | Acc: (86.47%) (43234/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5247) | Acc: (82.17%) (8217/10000)\n",
      "Epoch: 28 | Batch_idx: 0 |  Loss: (0.4260) | Acc: (85.94%) (110/128)\n",
      "Epoch: 28 | Batch_idx: 10 |  Loss: (0.3926) | Acc: (86.65%) (1220/1408)\n",
      "Epoch: 28 | Batch_idx: 20 |  Loss: (0.3956) | Acc: (86.61%) (2328/2688)\n",
      "Epoch: 28 | Batch_idx: 30 |  Loss: (0.3941) | Acc: (86.54%) (3434/3968)\n",
      "Epoch: 28 | Batch_idx: 40 |  Loss: (0.4017) | Acc: (86.24%) (4526/5248)\n",
      "Epoch: 28 | Batch_idx: 50 |  Loss: (0.3966) | Acc: (86.34%) (5636/6528)\n",
      "Epoch: 28 | Batch_idx: 60 |  Loss: (0.3947) | Acc: (86.46%) (6751/7808)\n",
      "Epoch: 28 | Batch_idx: 70 |  Loss: (0.3896) | Acc: (86.67%) (7877/9088)\n",
      "Epoch: 28 | Batch_idx: 80 |  Loss: (0.3929) | Acc: (86.56%) (8975/10368)\n",
      "Epoch: 28 | Batch_idx: 90 |  Loss: (0.3907) | Acc: (86.66%) (10094/11648)\n",
      "Epoch: 28 | Batch_idx: 100 |  Loss: (0.3881) | Acc: (86.77%) (11217/12928)\n",
      "Epoch: 28 | Batch_idx: 110 |  Loss: (0.3905) | Acc: (86.73%) (12323/14208)\n",
      "Epoch: 28 | Batch_idx: 120 |  Loss: (0.3878) | Acc: (86.77%) (13439/15488)\n",
      "Epoch: 28 | Batch_idx: 130 |  Loss: (0.3835) | Acc: (86.96%) (14582/16768)\n",
      "Epoch: 28 | Batch_idx: 140 |  Loss: (0.3854) | Acc: (86.85%) (15675/18048)\n",
      "Epoch: 28 | Batch_idx: 150 |  Loss: (0.3856) | Acc: (86.79%) (16774/19328)\n",
      "Epoch: 28 | Batch_idx: 160 |  Loss: (0.3849) | Acc: (86.82%) (17892/20608)\n",
      "Epoch: 28 | Batch_idx: 170 |  Loss: (0.3851) | Acc: (86.81%) (19000/21888)\n",
      "Epoch: 28 | Batch_idx: 180 |  Loss: (0.3878) | Acc: (86.68%) (20082/23168)\n",
      "Epoch: 28 | Batch_idx: 190 |  Loss: (0.3877) | Acc: (86.68%) (21191/24448)\n",
      "Epoch: 28 | Batch_idx: 200 |  Loss: (0.3860) | Acc: (86.75%) (22318/25728)\n",
      "Epoch: 28 | Batch_idx: 210 |  Loss: (0.3878) | Acc: (86.72%) (23420/27008)\n",
      "Epoch: 28 | Batch_idx: 220 |  Loss: (0.3872) | Acc: (86.71%) (24528/28288)\n",
      "Epoch: 28 | Batch_idx: 230 |  Loss: (0.3875) | Acc: (86.63%) (25614/29568)\n",
      "Epoch: 28 | Batch_idx: 240 |  Loss: (0.3880) | Acc: (86.62%) (26722/30848)\n",
      "Epoch: 28 | Batch_idx: 250 |  Loss: (0.3876) | Acc: (86.63%) (27833/32128)\n",
      "Epoch: 28 | Batch_idx: 260 |  Loss: (0.3860) | Acc: (86.66%) (28951/33408)\n",
      "Epoch: 28 | Batch_idx: 270 |  Loss: (0.3850) | Acc: (86.72%) (30081/34688)\n",
      "Epoch: 28 | Batch_idx: 280 |  Loss: (0.3847) | Acc: (86.74%) (31197/35968)\n",
      "Epoch: 28 | Batch_idx: 290 |  Loss: (0.3845) | Acc: (86.74%) (32309/37248)\n",
      "Epoch: 28 | Batch_idx: 300 |  Loss: (0.3834) | Acc: (86.77%) (33431/38528)\n",
      "Epoch: 28 | Batch_idx: 310 |  Loss: (0.3823) | Acc: (86.80%) (34553/39808)\n",
      "Epoch: 28 | Batch_idx: 320 |  Loss: (0.3831) | Acc: (86.77%) (35652/41088)\n",
      "Epoch: 28 | Batch_idx: 330 |  Loss: (0.3837) | Acc: (86.75%) (36754/42368)\n",
      "Epoch: 28 | Batch_idx: 340 |  Loss: (0.3837) | Acc: (86.76%) (37870/43648)\n",
      "Epoch: 28 | Batch_idx: 350 |  Loss: (0.3832) | Acc: (86.79%) (38994/44928)\n",
      "Epoch: 28 | Batch_idx: 360 |  Loss: (0.3827) | Acc: (86.81%) (40111/46208)\n",
      "Epoch: 28 | Batch_idx: 370 |  Loss: (0.3829) | Acc: (86.81%) (41223/47488)\n",
      "Epoch: 28 | Batch_idx: 380 |  Loss: (0.3839) | Acc: (86.76%) (42311/48768)\n",
      "Epoch: 28 | Batch_idx: 390 |  Loss: (0.3833) | Acc: (86.81%) (43403/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5448) | Acc: (82.42%) (8242/10000)\n",
      "Epoch: 29 | Batch_idx: 0 |  Loss: (0.4289) | Acc: (84.38%) (108/128)\n",
      "Epoch: 29 | Batch_idx: 10 |  Loss: (0.3572) | Acc: (87.71%) (1235/1408)\n",
      "Epoch: 29 | Batch_idx: 20 |  Loss: (0.3649) | Acc: (87.46%) (2351/2688)\n",
      "Epoch: 29 | Batch_idx: 30 |  Loss: (0.3610) | Acc: (87.60%) (3476/3968)\n",
      "Epoch: 29 | Batch_idx: 40 |  Loss: (0.3602) | Acc: (87.40%) (4587/5248)\n",
      "Epoch: 29 | Batch_idx: 50 |  Loss: (0.3607) | Acc: (87.27%) (5697/6528)\n",
      "Epoch: 29 | Batch_idx: 60 |  Loss: (0.3652) | Acc: (87.10%) (6801/7808)\n",
      "Epoch: 29 | Batch_idx: 70 |  Loss: (0.3666) | Acc: (87.15%) (7920/9088)\n",
      "Epoch: 29 | Batch_idx: 80 |  Loss: (0.3676) | Acc: (87.09%) (9029/10368)\n",
      "Epoch: 29 | Batch_idx: 90 |  Loss: (0.3679) | Acc: (87.21%) (10158/11648)\n",
      "Epoch: 29 | Batch_idx: 100 |  Loss: (0.3633) | Acc: (87.48%) (11309/12928)\n",
      "Epoch: 29 | Batch_idx: 110 |  Loss: (0.3660) | Acc: (87.42%) (12420/14208)\n",
      "Epoch: 29 | Batch_idx: 120 |  Loss: (0.3698) | Acc: (87.16%) (13499/15488)\n",
      "Epoch: 29 | Batch_idx: 130 |  Loss: (0.3713) | Acc: (87.12%) (14609/16768)\n",
      "Epoch: 29 | Batch_idx: 140 |  Loss: (0.3703) | Acc: (87.07%) (15714/18048)\n",
      "Epoch: 29 | Batch_idx: 150 |  Loss: (0.3690) | Acc: (87.11%) (16836/19328)\n",
      "Epoch: 29 | Batch_idx: 160 |  Loss: (0.3708) | Acc: (87.01%) (17931/20608)\n",
      "Epoch: 29 | Batch_idx: 170 |  Loss: (0.3694) | Acc: (87.13%) (19070/21888)\n",
      "Epoch: 29 | Batch_idx: 180 |  Loss: (0.3698) | Acc: (87.11%) (20182/23168)\n",
      "Epoch: 29 | Batch_idx: 190 |  Loss: (0.3720) | Acc: (87.03%) (21278/24448)\n",
      "Epoch: 29 | Batch_idx: 200 |  Loss: (0.3731) | Acc: (86.99%) (22382/25728)\n",
      "Epoch: 29 | Batch_idx: 210 |  Loss: (0.3716) | Acc: (87.02%) (23502/27008)\n",
      "Epoch: 29 | Batch_idx: 220 |  Loss: (0.3718) | Acc: (87.02%) (24616/28288)\n",
      "Epoch: 29 | Batch_idx: 230 |  Loss: (0.3718) | Acc: (87.03%) (25732/29568)\n",
      "Epoch: 29 | Batch_idx: 240 |  Loss: (0.3719) | Acc: (87.04%) (26850/30848)\n",
      "Epoch: 29 | Batch_idx: 250 |  Loss: (0.3705) | Acc: (87.09%) (27980/32128)\n",
      "Epoch: 29 | Batch_idx: 260 |  Loss: (0.3726) | Acc: (87.01%) (29068/33408)\n",
      "Epoch: 29 | Batch_idx: 270 |  Loss: (0.3725) | Acc: (87.01%) (30181/34688)\n",
      "Epoch: 29 | Batch_idx: 280 |  Loss: (0.3727) | Acc: (86.97%) (31283/35968)\n",
      "Epoch: 29 | Batch_idx: 290 |  Loss: (0.3718) | Acc: (86.99%) (32403/37248)\n",
      "Epoch: 29 | Batch_idx: 300 |  Loss: (0.3736) | Acc: (86.96%) (33504/38528)\n",
      "Epoch: 29 | Batch_idx: 310 |  Loss: (0.3762) | Acc: (86.88%) (34587/39808)\n",
      "Epoch: 29 | Batch_idx: 320 |  Loss: (0.3767) | Acc: (86.90%) (35705/41088)\n",
      "Epoch: 29 | Batch_idx: 330 |  Loss: (0.3777) | Acc: (86.87%) (36807/42368)\n",
      "Epoch: 29 | Batch_idx: 340 |  Loss: (0.3780) | Acc: (86.85%) (37910/43648)\n",
      "Epoch: 29 | Batch_idx: 350 |  Loss: (0.3776) | Acc: (86.87%) (39030/44928)\n",
      "Epoch: 29 | Batch_idx: 360 |  Loss: (0.3775) | Acc: (86.86%) (40138/46208)\n",
      "Epoch: 29 | Batch_idx: 370 |  Loss: (0.3783) | Acc: (86.86%) (41250/47488)\n",
      "Epoch: 29 | Batch_idx: 380 |  Loss: (0.3792) | Acc: (86.83%) (42346/48768)\n",
      "Epoch: 29 | Batch_idx: 390 |  Loss: (0.3797) | Acc: (86.80%) (43398/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5462) | Acc: (82.14%) (8214/10000)\n",
      "Epoch: 30 | Batch_idx: 0 |  Loss: (0.2369) | Acc: (90.62%) (116/128)\n",
      "Epoch: 30 | Batch_idx: 10 |  Loss: (0.3415) | Acc: (88.42%) (1245/1408)\n",
      "Epoch: 30 | Batch_idx: 20 |  Loss: (0.3445) | Acc: (87.80%) (2360/2688)\n",
      "Epoch: 30 | Batch_idx: 30 |  Loss: (0.3501) | Acc: (87.40%) (3468/3968)\n",
      "Epoch: 30 | Batch_idx: 40 |  Loss: (0.3514) | Acc: (87.46%) (4590/5248)\n",
      "Epoch: 30 | Batch_idx: 50 |  Loss: (0.3596) | Acc: (87.15%) (5689/6528)\n",
      "Epoch: 30 | Batch_idx: 60 |  Loss: (0.3555) | Acc: (87.28%) (6815/7808)\n",
      "Epoch: 30 | Batch_idx: 70 |  Loss: (0.3628) | Acc: (87.18%) (7923/9088)\n",
      "Epoch: 30 | Batch_idx: 80 |  Loss: (0.3636) | Acc: (87.22%) (9043/10368)\n",
      "Epoch: 30 | Batch_idx: 90 |  Loss: (0.3672) | Acc: (87.09%) (10144/11648)\n",
      "Epoch: 30 | Batch_idx: 100 |  Loss: (0.3682) | Acc: (87.06%) (11255/12928)\n",
      "Epoch: 30 | Batch_idx: 110 |  Loss: (0.3683) | Acc: (87.21%) (12391/14208)\n",
      "Epoch: 30 | Batch_idx: 120 |  Loss: (0.3674) | Acc: (87.26%) (13515/15488)\n",
      "Epoch: 30 | Batch_idx: 130 |  Loss: (0.3656) | Acc: (87.30%) (14638/16768)\n",
      "Epoch: 30 | Batch_idx: 140 |  Loss: (0.3668) | Acc: (87.20%) (15737/18048)\n",
      "Epoch: 30 | Batch_idx: 150 |  Loss: (0.3669) | Acc: (87.23%) (16860/19328)\n",
      "Epoch: 30 | Batch_idx: 160 |  Loss: (0.3673) | Acc: (87.18%) (17967/20608)\n",
      "Epoch: 30 | Batch_idx: 170 |  Loss: (0.3666) | Acc: (87.17%) (19080/21888)\n",
      "Epoch: 30 | Batch_idx: 180 |  Loss: (0.3670) | Acc: (87.18%) (20198/23168)\n",
      "Epoch: 30 | Batch_idx: 190 |  Loss: (0.3665) | Acc: (87.19%) (21317/24448)\n",
      "Epoch: 30 | Batch_idx: 200 |  Loss: (0.3673) | Acc: (87.15%) (22423/25728)\n",
      "Epoch: 30 | Batch_idx: 210 |  Loss: (0.3659) | Acc: (87.26%) (23567/27008)\n",
      "Epoch: 30 | Batch_idx: 220 |  Loss: (0.3666) | Acc: (87.27%) (24688/28288)\n",
      "Epoch: 30 | Batch_idx: 230 |  Loss: (0.3673) | Acc: (87.23%) (25792/29568)\n",
      "Epoch: 30 | Batch_idx: 240 |  Loss: (0.3662) | Acc: (87.23%) (26910/30848)\n",
      "Epoch: 30 | Batch_idx: 250 |  Loss: (0.3665) | Acc: (87.21%) (28018/32128)\n",
      "Epoch: 30 | Batch_idx: 260 |  Loss: (0.3670) | Acc: (87.19%) (29130/33408)\n",
      "Epoch: 30 | Batch_idx: 270 |  Loss: (0.3674) | Acc: (87.18%) (30241/34688)\n",
      "Epoch: 30 | Batch_idx: 280 |  Loss: (0.3684) | Acc: (87.16%) (31351/35968)\n",
      "Epoch: 30 | Batch_idx: 290 |  Loss: (0.3681) | Acc: (87.19%) (32477/37248)\n",
      "Epoch: 30 | Batch_idx: 300 |  Loss: (0.3699) | Acc: (87.13%) (33568/38528)\n",
      "Epoch: 30 | Batch_idx: 310 |  Loss: (0.3710) | Acc: (87.10%) (34673/39808)\n",
      "Epoch: 30 | Batch_idx: 320 |  Loss: (0.3704) | Acc: (87.12%) (35797/41088)\n",
      "Epoch: 30 | Batch_idx: 330 |  Loss: (0.3696) | Acc: (87.16%) (36928/42368)\n",
      "Epoch: 30 | Batch_idx: 340 |  Loss: (0.3695) | Acc: (87.17%) (38046/43648)\n",
      "Epoch: 30 | Batch_idx: 350 |  Loss: (0.3686) | Acc: (87.18%) (39169/44928)\n",
      "Epoch: 30 | Batch_idx: 360 |  Loss: (0.3679) | Acc: (87.20%) (40294/46208)\n",
      "Epoch: 30 | Batch_idx: 370 |  Loss: (0.3680) | Acc: (87.19%) (41403/47488)\n",
      "Epoch: 30 | Batch_idx: 380 |  Loss: (0.3669) | Acc: (87.23%) (42542/48768)\n",
      "Epoch: 30 | Batch_idx: 390 |  Loss: (0.3662) | Acc: (87.26%) (43629/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5209) | Acc: (82.70%) (8270/10000)\n",
      "Epoch: 31 | Batch_idx: 0 |  Loss: (0.3207) | Acc: (89.84%) (115/128)\n",
      "Epoch: 31 | Batch_idx: 10 |  Loss: (0.3643) | Acc: (86.72%) (1221/1408)\n",
      "Epoch: 31 | Batch_idx: 20 |  Loss: (0.3464) | Acc: (87.87%) (2362/2688)\n",
      "Epoch: 31 | Batch_idx: 30 |  Loss: (0.3392) | Acc: (88.03%) (3493/3968)\n",
      "Epoch: 31 | Batch_idx: 40 |  Loss: (0.3321) | Acc: (88.55%) (4647/5248)\n",
      "Epoch: 31 | Batch_idx: 50 |  Loss: (0.3384) | Acc: (88.30%) (5764/6528)\n",
      "Epoch: 31 | Batch_idx: 60 |  Loss: (0.3417) | Acc: (88.14%) (6882/7808)\n",
      "Epoch: 31 | Batch_idx: 70 |  Loss: (0.3436) | Acc: (88.14%) (8010/9088)\n",
      "Epoch: 31 | Batch_idx: 80 |  Loss: (0.3426) | Acc: (88.13%) (9137/10368)\n",
      "Epoch: 31 | Batch_idx: 90 |  Loss: (0.3418) | Acc: (88.19%) (10272/11648)\n",
      "Epoch: 31 | Batch_idx: 100 |  Loss: (0.3444) | Acc: (88.00%) (11376/12928)\n",
      "Epoch: 31 | Batch_idx: 110 |  Loss: (0.3475) | Acc: (87.85%) (12482/14208)\n",
      "Epoch: 31 | Batch_idx: 120 |  Loss: (0.3479) | Acc: (87.84%) (13605/15488)\n",
      "Epoch: 31 | Batch_idx: 130 |  Loss: (0.3470) | Acc: (87.88%) (14736/16768)\n",
      "Epoch: 31 | Batch_idx: 140 |  Loss: (0.3497) | Acc: (87.80%) (15847/18048)\n",
      "Epoch: 31 | Batch_idx: 150 |  Loss: (0.3521) | Acc: (87.77%) (16965/19328)\n",
      "Epoch: 31 | Batch_idx: 160 |  Loss: (0.3509) | Acc: (87.81%) (18095/20608)\n",
      "Epoch: 31 | Batch_idx: 170 |  Loss: (0.3489) | Acc: (87.92%) (19245/21888)\n",
      "Epoch: 31 | Batch_idx: 180 |  Loss: (0.3481) | Acc: (88.01%) (20390/23168)\n",
      "Epoch: 31 | Batch_idx: 190 |  Loss: (0.3484) | Acc: (87.97%) (21507/24448)\n",
      "Epoch: 31 | Batch_idx: 200 |  Loss: (0.3512) | Acc: (87.88%) (22611/25728)\n",
      "Epoch: 31 | Batch_idx: 210 |  Loss: (0.3513) | Acc: (87.89%) (23738/27008)\n",
      "Epoch: 31 | Batch_idx: 220 |  Loss: (0.3528) | Acc: (87.83%) (24846/28288)\n",
      "Epoch: 31 | Batch_idx: 230 |  Loss: (0.3547) | Acc: (87.75%) (25945/29568)\n",
      "Epoch: 31 | Batch_idx: 240 |  Loss: (0.3536) | Acc: (87.78%) (27078/30848)\n",
      "Epoch: 31 | Batch_idx: 250 |  Loss: (0.3527) | Acc: (87.81%) (28213/32128)\n",
      "Epoch: 31 | Batch_idx: 260 |  Loss: (0.3537) | Acc: (87.81%) (29335/33408)\n",
      "Epoch: 31 | Batch_idx: 270 |  Loss: (0.3557) | Acc: (87.76%) (30441/34688)\n",
      "Epoch: 31 | Batch_idx: 280 |  Loss: (0.3552) | Acc: (87.75%) (31561/35968)\n",
      "Epoch: 31 | Batch_idx: 290 |  Loss: (0.3547) | Acc: (87.79%) (32701/37248)\n",
      "Epoch: 31 | Batch_idx: 300 |  Loss: (0.3547) | Acc: (87.81%) (33831/38528)\n",
      "Epoch: 31 | Batch_idx: 310 |  Loss: (0.3540) | Acc: (87.80%) (34950/39808)\n",
      "Epoch: 31 | Batch_idx: 320 |  Loss: (0.3535) | Acc: (87.80%) (36077/41088)\n",
      "Epoch: 31 | Batch_idx: 330 |  Loss: (0.3546) | Acc: (87.75%) (37179/42368)\n",
      "Epoch: 31 | Batch_idx: 340 |  Loss: (0.3544) | Acc: (87.76%) (38307/43648)\n",
      "Epoch: 31 | Batch_idx: 350 |  Loss: (0.3545) | Acc: (87.75%) (39423/44928)\n",
      "Epoch: 31 | Batch_idx: 360 |  Loss: (0.3552) | Acc: (87.73%) (40539/46208)\n",
      "Epoch: 31 | Batch_idx: 370 |  Loss: (0.3547) | Acc: (87.77%) (41678/47488)\n",
      "Epoch: 31 | Batch_idx: 380 |  Loss: (0.3549) | Acc: (87.78%) (42807/48768)\n",
      "Epoch: 31 | Batch_idx: 390 |  Loss: (0.3545) | Acc: (87.78%) (43888/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5483) | Acc: (82.20%) (8220/10000)\n",
      "Epoch: 32 | Batch_idx: 0 |  Loss: (0.3651) | Acc: (87.50%) (112/128)\n",
      "Epoch: 32 | Batch_idx: 10 |  Loss: (0.3717) | Acc: (87.50%) (1232/1408)\n",
      "Epoch: 32 | Batch_idx: 20 |  Loss: (0.3618) | Acc: (87.39%) (2349/2688)\n",
      "Epoch: 32 | Batch_idx: 30 |  Loss: (0.3618) | Acc: (87.12%) (3457/3968)\n",
      "Epoch: 32 | Batch_idx: 40 |  Loss: (0.3486) | Acc: (87.69%) (4602/5248)\n",
      "Epoch: 32 | Batch_idx: 50 |  Loss: (0.3485) | Acc: (87.91%) (5739/6528)\n",
      "Epoch: 32 | Batch_idx: 60 |  Loss: (0.3461) | Acc: (88.13%) (6881/7808)\n",
      "Epoch: 32 | Batch_idx: 70 |  Loss: (0.3495) | Acc: (88.05%) (8002/9088)\n",
      "Epoch: 32 | Batch_idx: 80 |  Loss: (0.3521) | Acc: (87.94%) (9118/10368)\n",
      "Epoch: 32 | Batch_idx: 90 |  Loss: (0.3485) | Acc: (88.02%) (10252/11648)\n",
      "Epoch: 32 | Batch_idx: 100 |  Loss: (0.3463) | Acc: (88.06%) (11384/12928)\n",
      "Epoch: 32 | Batch_idx: 110 |  Loss: (0.3470) | Acc: (88.02%) (12506/14208)\n",
      "Epoch: 32 | Batch_idx: 120 |  Loss: (0.3469) | Acc: (88.00%) (13630/15488)\n",
      "Epoch: 32 | Batch_idx: 130 |  Loss: (0.3452) | Acc: (88.11%) (14775/16768)\n",
      "Epoch: 32 | Batch_idx: 140 |  Loss: (0.3459) | Acc: (88.12%) (15903/18048)\n",
      "Epoch: 32 | Batch_idx: 150 |  Loss: (0.3473) | Acc: (88.01%) (17011/19328)\n",
      "Epoch: 32 | Batch_idx: 160 |  Loss: (0.3488) | Acc: (88.03%) (18142/20608)\n",
      "Epoch: 32 | Batch_idx: 170 |  Loss: (0.3478) | Acc: (88.06%) (19274/21888)\n",
      "Epoch: 32 | Batch_idx: 180 |  Loss: (0.3491) | Acc: (88.02%) (20392/23168)\n",
      "Epoch: 32 | Batch_idx: 190 |  Loss: (0.3480) | Acc: (88.04%) (21525/24448)\n",
      "Epoch: 32 | Batch_idx: 200 |  Loss: (0.3480) | Acc: (88.01%) (22643/25728)\n",
      "Epoch: 32 | Batch_idx: 210 |  Loss: (0.3464) | Acc: (88.05%) (23780/27008)\n",
      "Epoch: 32 | Batch_idx: 220 |  Loss: (0.3476) | Acc: (87.96%) (24883/28288)\n",
      "Epoch: 32 | Batch_idx: 230 |  Loss: (0.3454) | Acc: (88.04%) (26032/29568)\n",
      "Epoch: 32 | Batch_idx: 240 |  Loss: (0.3463) | Acc: (88.02%) (27152/30848)\n",
      "Epoch: 32 | Batch_idx: 250 |  Loss: (0.3459) | Acc: (88.02%) (28279/32128)\n",
      "Epoch: 32 | Batch_idx: 260 |  Loss: (0.3464) | Acc: (87.98%) (29394/33408)\n",
      "Epoch: 32 | Batch_idx: 270 |  Loss: (0.3466) | Acc: (87.98%) (30519/34688)\n",
      "Epoch: 32 | Batch_idx: 280 |  Loss: (0.3474) | Acc: (87.95%) (31634/35968)\n",
      "Epoch: 32 | Batch_idx: 290 |  Loss: (0.3479) | Acc: (87.94%) (32755/37248)\n",
      "Epoch: 32 | Batch_idx: 300 |  Loss: (0.3485) | Acc: (87.91%) (33871/38528)\n",
      "Epoch: 32 | Batch_idx: 310 |  Loss: (0.3479) | Acc: (87.93%) (35004/39808)\n",
      "Epoch: 32 | Batch_idx: 320 |  Loss: (0.3493) | Acc: (87.89%) (36111/41088)\n",
      "Epoch: 32 | Batch_idx: 330 |  Loss: (0.3490) | Acc: (87.93%) (37256/42368)\n",
      "Epoch: 32 | Batch_idx: 340 |  Loss: (0.3489) | Acc: (87.94%) (38382/43648)\n",
      "Epoch: 32 | Batch_idx: 350 |  Loss: (0.3488) | Acc: (87.91%) (39498/44928)\n",
      "Epoch: 32 | Batch_idx: 360 |  Loss: (0.3486) | Acc: (87.90%) (40619/46208)\n",
      "Epoch: 32 | Batch_idx: 370 |  Loss: (0.3476) | Acc: (87.95%) (41767/47488)\n",
      "Epoch: 32 | Batch_idx: 380 |  Loss: (0.3472) | Acc: (87.96%) (42897/48768)\n",
      "Epoch: 32 | Batch_idx: 390 |  Loss: (0.3473) | Acc: (87.96%) (43980/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6690) | Acc: (80.04%) (8004/10000)\n",
      "Epoch: 33 | Batch_idx: 0 |  Loss: (0.3093) | Acc: (85.94%) (110/128)\n",
      "Epoch: 33 | Batch_idx: 10 |  Loss: (0.3462) | Acc: (86.86%) (1223/1408)\n",
      "Epoch: 33 | Batch_idx: 20 |  Loss: (0.3454) | Acc: (86.98%) (2338/2688)\n",
      "Epoch: 33 | Batch_idx: 30 |  Loss: (0.3415) | Acc: (87.42%) (3469/3968)\n",
      "Epoch: 33 | Batch_idx: 40 |  Loss: (0.3398) | Acc: (87.42%) (4588/5248)\n",
      "Epoch: 33 | Batch_idx: 50 |  Loss: (0.3379) | Acc: (87.75%) (5728/6528)\n",
      "Epoch: 33 | Batch_idx: 60 |  Loss: (0.3367) | Acc: (87.97%) (6869/7808)\n",
      "Epoch: 33 | Batch_idx: 70 |  Loss: (0.3331) | Acc: (88.08%) (8005/9088)\n",
      "Epoch: 33 | Batch_idx: 80 |  Loss: (0.3336) | Acc: (88.09%) (9133/10368)\n",
      "Epoch: 33 | Batch_idx: 90 |  Loss: (0.3353) | Acc: (87.92%) (10241/11648)\n",
      "Epoch: 33 | Batch_idx: 100 |  Loss: (0.3358) | Acc: (87.86%) (11359/12928)\n",
      "Epoch: 33 | Batch_idx: 110 |  Loss: (0.3356) | Acc: (87.86%) (12483/14208)\n",
      "Epoch: 33 | Batch_idx: 120 |  Loss: (0.3376) | Acc: (87.89%) (13612/15488)\n",
      "Epoch: 33 | Batch_idx: 130 |  Loss: (0.3374) | Acc: (87.82%) (14726/16768)\n",
      "Epoch: 33 | Batch_idx: 140 |  Loss: (0.3387) | Acc: (87.88%) (15860/18048)\n",
      "Epoch: 33 | Batch_idx: 150 |  Loss: (0.3394) | Acc: (87.90%) (16989/19328)\n",
      "Epoch: 33 | Batch_idx: 160 |  Loss: (0.3403) | Acc: (87.82%) (18097/20608)\n",
      "Epoch: 33 | Batch_idx: 170 |  Loss: (0.3409) | Acc: (87.81%) (19219/21888)\n",
      "Epoch: 33 | Batch_idx: 180 |  Loss: (0.3416) | Acc: (87.85%) (20353/23168)\n",
      "Epoch: 33 | Batch_idx: 190 |  Loss: (0.3415) | Acc: (87.88%) (21486/24448)\n",
      "Epoch: 33 | Batch_idx: 200 |  Loss: (0.3400) | Acc: (87.92%) (22620/25728)\n",
      "Epoch: 33 | Batch_idx: 210 |  Loss: (0.3404) | Acc: (87.93%) (23748/27008)\n",
      "Epoch: 33 | Batch_idx: 220 |  Loss: (0.3396) | Acc: (87.95%) (24880/28288)\n",
      "Epoch: 33 | Batch_idx: 230 |  Loss: (0.3399) | Acc: (87.97%) (26012/29568)\n",
      "Epoch: 33 | Batch_idx: 240 |  Loss: (0.3387) | Acc: (88.02%) (27152/30848)\n",
      "Epoch: 33 | Batch_idx: 250 |  Loss: (0.3388) | Acc: (88.03%) (28282/32128)\n",
      "Epoch: 33 | Batch_idx: 260 |  Loss: (0.3393) | Acc: (88.03%) (29410/33408)\n",
      "Epoch: 33 | Batch_idx: 270 |  Loss: (0.3393) | Acc: (88.03%) (30536/34688)\n",
      "Epoch: 33 | Batch_idx: 280 |  Loss: (0.3379) | Acc: (88.09%) (31686/35968)\n",
      "Epoch: 33 | Batch_idx: 290 |  Loss: (0.3385) | Acc: (88.10%) (32814/37248)\n",
      "Epoch: 33 | Batch_idx: 300 |  Loss: (0.3384) | Acc: (88.12%) (33951/38528)\n",
      "Epoch: 33 | Batch_idx: 310 |  Loss: (0.3383) | Acc: (88.17%) (35097/39808)\n",
      "Epoch: 33 | Batch_idx: 320 |  Loss: (0.3390) | Acc: (88.17%) (36226/41088)\n",
      "Epoch: 33 | Batch_idx: 330 |  Loss: (0.3397) | Acc: (88.13%) (37339/42368)\n",
      "Epoch: 33 | Batch_idx: 340 |  Loss: (0.3402) | Acc: (88.13%) (38467/43648)\n",
      "Epoch: 33 | Batch_idx: 350 |  Loss: (0.3396) | Acc: (88.16%) (39608/44928)\n",
      "Epoch: 33 | Batch_idx: 360 |  Loss: (0.3402) | Acc: (88.14%) (40728/46208)\n",
      "Epoch: 33 | Batch_idx: 370 |  Loss: (0.3397) | Acc: (88.16%) (41865/47488)\n",
      "Epoch: 33 | Batch_idx: 380 |  Loss: (0.3395) | Acc: (88.19%) (43007/48768)\n",
      "Epoch: 33 | Batch_idx: 390 |  Loss: (0.3397) | Acc: (88.17%) (44084/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5500) | Acc: (82.67%) (8267/10000)\n",
      "Epoch: 34 | Batch_idx: 0 |  Loss: (0.3691) | Acc: (88.28%) (113/128)\n",
      "Epoch: 34 | Batch_idx: 10 |  Loss: (0.3386) | Acc: (87.93%) (1238/1408)\n",
      "Epoch: 34 | Batch_idx: 20 |  Loss: (0.3295) | Acc: (87.98%) (2365/2688)\n",
      "Epoch: 34 | Batch_idx: 30 |  Loss: (0.3364) | Acc: (87.98%) (3491/3968)\n",
      "Epoch: 34 | Batch_idx: 40 |  Loss: (0.3341) | Acc: (88.15%) (4626/5248)\n",
      "Epoch: 34 | Batch_idx: 50 |  Loss: (0.3411) | Acc: (88.01%) (5745/6528)\n",
      "Epoch: 34 | Batch_idx: 60 |  Loss: (0.3414) | Acc: (87.96%) (6868/7808)\n",
      "Epoch: 34 | Batch_idx: 70 |  Loss: (0.3356) | Acc: (88.14%) (8010/9088)\n",
      "Epoch: 34 | Batch_idx: 80 |  Loss: (0.3339) | Acc: (88.21%) (9146/10368)\n",
      "Epoch: 34 | Batch_idx: 90 |  Loss: (0.3386) | Acc: (87.98%) (10248/11648)\n",
      "Epoch: 34 | Batch_idx: 100 |  Loss: (0.3398) | Acc: (88.01%) (11378/12928)\n",
      "Epoch: 34 | Batch_idx: 110 |  Loss: (0.3396) | Acc: (88.06%) (12511/14208)\n",
      "Epoch: 34 | Batch_idx: 120 |  Loss: (0.3370) | Acc: (88.16%) (13654/15488)\n",
      "Epoch: 34 | Batch_idx: 130 |  Loss: (0.3353) | Acc: (88.22%) (14792/16768)\n",
      "Epoch: 34 | Batch_idx: 140 |  Loss: (0.3324) | Acc: (88.37%) (15949/18048)\n",
      "Epoch: 34 | Batch_idx: 150 |  Loss: (0.3314) | Acc: (88.42%) (17089/19328)\n",
      "Epoch: 34 | Batch_idx: 160 |  Loss: (0.3322) | Acc: (88.41%) (18219/20608)\n",
      "Epoch: 34 | Batch_idx: 170 |  Loss: (0.3313) | Acc: (88.45%) (19361/21888)\n",
      "Epoch: 34 | Batch_idx: 180 |  Loss: (0.3337) | Acc: (88.33%) (20465/23168)\n",
      "Epoch: 34 | Batch_idx: 190 |  Loss: (0.3335) | Acc: (88.34%) (21598/24448)\n",
      "Epoch: 34 | Batch_idx: 200 |  Loss: (0.3335) | Acc: (88.37%) (22736/25728)\n",
      "Epoch: 34 | Batch_idx: 210 |  Loss: (0.3321) | Acc: (88.40%) (23874/27008)\n",
      "Epoch: 34 | Batch_idx: 220 |  Loss: (0.3311) | Acc: (88.45%) (25022/28288)\n",
      "Epoch: 34 | Batch_idx: 230 |  Loss: (0.3313) | Acc: (88.42%) (26145/29568)\n",
      "Epoch: 34 | Batch_idx: 240 |  Loss: (0.3317) | Acc: (88.47%) (27291/30848)\n",
      "Epoch: 34 | Batch_idx: 250 |  Loss: (0.3318) | Acc: (88.45%) (28417/32128)\n",
      "Epoch: 34 | Batch_idx: 260 |  Loss: (0.3315) | Acc: (88.44%) (29546/33408)\n",
      "Epoch: 34 | Batch_idx: 270 |  Loss: (0.3308) | Acc: (88.45%) (30683/34688)\n",
      "Epoch: 34 | Batch_idx: 280 |  Loss: (0.3316) | Acc: (88.46%) (31817/35968)\n",
      "Epoch: 34 | Batch_idx: 290 |  Loss: (0.3323) | Acc: (88.44%) (32941/37248)\n",
      "Epoch: 34 | Batch_idx: 300 |  Loss: (0.3335) | Acc: (88.41%) (34062/38528)\n",
      "Epoch: 34 | Batch_idx: 310 |  Loss: (0.3332) | Acc: (88.43%) (35201/39808)\n",
      "Epoch: 34 | Batch_idx: 320 |  Loss: (0.3329) | Acc: (88.45%) (36342/41088)\n",
      "Epoch: 34 | Batch_idx: 330 |  Loss: (0.3326) | Acc: (88.46%) (37480/42368)\n",
      "Epoch: 34 | Batch_idx: 340 |  Loss: (0.3332) | Acc: (88.44%) (38603/43648)\n",
      "Epoch: 34 | Batch_idx: 350 |  Loss: (0.3326) | Acc: (88.45%) (39738/44928)\n",
      "Epoch: 34 | Batch_idx: 360 |  Loss: (0.3332) | Acc: (88.41%) (40853/46208)\n",
      "Epoch: 34 | Batch_idx: 370 |  Loss: (0.3348) | Acc: (88.33%) (41946/47488)\n",
      "Epoch: 34 | Batch_idx: 380 |  Loss: (0.3339) | Acc: (88.38%) (43102/48768)\n",
      "Epoch: 34 | Batch_idx: 390 |  Loss: (0.3341) | Acc: (88.40%) (44202/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4895) | Acc: (83.81%) (8381/10000)\n",
      "Epoch: 35 | Batch_idx: 0 |  Loss: (0.2766) | Acc: (91.41%) (117/128)\n",
      "Epoch: 35 | Batch_idx: 10 |  Loss: (0.2944) | Acc: (90.20%) (1270/1408)\n",
      "Epoch: 35 | Batch_idx: 20 |  Loss: (0.3174) | Acc: (89.43%) (2404/2688)\n",
      "Epoch: 35 | Batch_idx: 30 |  Loss: (0.3127) | Acc: (89.21%) (3540/3968)\n",
      "Epoch: 35 | Batch_idx: 40 |  Loss: (0.3139) | Acc: (89.18%) (4680/5248)\n",
      "Epoch: 35 | Batch_idx: 50 |  Loss: (0.3168) | Acc: (89.09%) (5816/6528)\n",
      "Epoch: 35 | Batch_idx: 60 |  Loss: (0.3260) | Acc: (88.77%) (6931/7808)\n",
      "Epoch: 35 | Batch_idx: 70 |  Loss: (0.3263) | Acc: (88.69%) (8060/9088)\n",
      "Epoch: 35 | Batch_idx: 80 |  Loss: (0.3263) | Acc: (88.70%) (9196/10368)\n",
      "Epoch: 35 | Batch_idx: 90 |  Loss: (0.3262) | Acc: (88.70%) (10332/11648)\n",
      "Epoch: 35 | Batch_idx: 100 |  Loss: (0.3276) | Acc: (88.60%) (11454/12928)\n",
      "Epoch: 35 | Batch_idx: 110 |  Loss: (0.3284) | Acc: (88.58%) (12585/14208)\n",
      "Epoch: 35 | Batch_idx: 120 |  Loss: (0.3308) | Acc: (88.44%) (13697/15488)\n",
      "Epoch: 35 | Batch_idx: 130 |  Loss: (0.3303) | Acc: (88.42%) (14826/16768)\n",
      "Epoch: 35 | Batch_idx: 140 |  Loss: (0.3318) | Acc: (88.35%) (15945/18048)\n",
      "Epoch: 35 | Batch_idx: 150 |  Loss: (0.3316) | Acc: (88.36%) (17079/19328)\n",
      "Epoch: 35 | Batch_idx: 160 |  Loss: (0.3315) | Acc: (88.35%) (18207/20608)\n",
      "Epoch: 35 | Batch_idx: 170 |  Loss: (0.3313) | Acc: (88.29%) (19324/21888)\n",
      "Epoch: 35 | Batch_idx: 180 |  Loss: (0.3311) | Acc: (88.29%) (20455/23168)\n",
      "Epoch: 35 | Batch_idx: 190 |  Loss: (0.3304) | Acc: (88.33%) (21596/24448)\n",
      "Epoch: 35 | Batch_idx: 200 |  Loss: (0.3311) | Acc: (88.36%) (22732/25728)\n",
      "Epoch: 35 | Batch_idx: 210 |  Loss: (0.3323) | Acc: (88.29%) (23845/27008)\n",
      "Epoch: 35 | Batch_idx: 220 |  Loss: (0.3313) | Acc: (88.37%) (24997/28288)\n",
      "Epoch: 35 | Batch_idx: 230 |  Loss: (0.3308) | Acc: (88.45%) (26153/29568)\n",
      "Epoch: 35 | Batch_idx: 240 |  Loss: (0.3309) | Acc: (88.44%) (27282/30848)\n",
      "Epoch: 35 | Batch_idx: 250 |  Loss: (0.3305) | Acc: (88.49%) (28431/32128)\n",
      "Epoch: 35 | Batch_idx: 260 |  Loss: (0.3296) | Acc: (88.53%) (29577/33408)\n",
      "Epoch: 35 | Batch_idx: 270 |  Loss: (0.3299) | Acc: (88.51%) (30703/34688)\n",
      "Epoch: 35 | Batch_idx: 280 |  Loss: (0.3309) | Acc: (88.46%) (31819/35968)\n",
      "Epoch: 35 | Batch_idx: 290 |  Loss: (0.3310) | Acc: (88.47%) (32952/37248)\n",
      "Epoch: 35 | Batch_idx: 300 |  Loss: (0.3314) | Acc: (88.48%) (34090/38528)\n",
      "Epoch: 35 | Batch_idx: 310 |  Loss: (0.3303) | Acc: (88.51%) (35235/39808)\n",
      "Epoch: 35 | Batch_idx: 320 |  Loss: (0.3299) | Acc: (88.54%) (36381/41088)\n",
      "Epoch: 35 | Batch_idx: 330 |  Loss: (0.3291) | Acc: (88.59%) (37534/42368)\n",
      "Epoch: 35 | Batch_idx: 340 |  Loss: (0.3289) | Acc: (88.57%) (38657/43648)\n",
      "Epoch: 35 | Batch_idx: 350 |  Loss: (0.3274) | Acc: (88.61%) (39811/44928)\n",
      "Epoch: 35 | Batch_idx: 360 |  Loss: (0.3262) | Acc: (88.65%) (40962/46208)\n",
      "Epoch: 35 | Batch_idx: 370 |  Loss: (0.3274) | Acc: (88.59%) (42068/47488)\n",
      "Epoch: 35 | Batch_idx: 380 |  Loss: (0.3263) | Acc: (88.62%) (43220/48768)\n",
      "Epoch: 35 | Batch_idx: 390 |  Loss: (0.3262) | Acc: (88.62%) (44310/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5419) | Acc: (82.82%) (8282/10000)\n",
      "Epoch: 36 | Batch_idx: 0 |  Loss: (0.2535) | Acc: (90.62%) (116/128)\n",
      "Epoch: 36 | Batch_idx: 10 |  Loss: (0.3354) | Acc: (87.78%) (1236/1408)\n",
      "Epoch: 36 | Batch_idx: 20 |  Loss: (0.3293) | Acc: (88.69%) (2384/2688)\n",
      "Epoch: 36 | Batch_idx: 30 |  Loss: (0.3192) | Acc: (88.96%) (3530/3968)\n",
      "Epoch: 36 | Batch_idx: 40 |  Loss: (0.3155) | Acc: (88.85%) (4663/5248)\n",
      "Epoch: 36 | Batch_idx: 50 |  Loss: (0.3093) | Acc: (89.03%) (5812/6528)\n",
      "Epoch: 36 | Batch_idx: 60 |  Loss: (0.3107) | Acc: (89.05%) (6953/7808)\n",
      "Epoch: 36 | Batch_idx: 70 |  Loss: (0.3094) | Acc: (89.10%) (8097/9088)\n",
      "Epoch: 36 | Batch_idx: 80 |  Loss: (0.3134) | Acc: (89.06%) (9234/10368)\n",
      "Epoch: 36 | Batch_idx: 90 |  Loss: (0.3135) | Acc: (88.96%) (10362/11648)\n",
      "Epoch: 36 | Batch_idx: 100 |  Loss: (0.3154) | Acc: (88.94%) (11498/12928)\n",
      "Epoch: 36 | Batch_idx: 110 |  Loss: (0.3181) | Acc: (88.88%) (12628/14208)\n",
      "Epoch: 36 | Batch_idx: 120 |  Loss: (0.3200) | Acc: (88.84%) (13760/15488)\n",
      "Epoch: 36 | Batch_idx: 130 |  Loss: (0.3195) | Acc: (88.85%) (14898/16768)\n",
      "Epoch: 36 | Batch_idx: 140 |  Loss: (0.3203) | Acc: (88.80%) (16027/18048)\n",
      "Epoch: 36 | Batch_idx: 150 |  Loss: (0.3199) | Acc: (88.81%) (17165/19328)\n",
      "Epoch: 36 | Batch_idx: 160 |  Loss: (0.3216) | Acc: (88.70%) (18280/20608)\n",
      "Epoch: 36 | Batch_idx: 170 |  Loss: (0.3211) | Acc: (88.74%) (19424/21888)\n",
      "Epoch: 36 | Batch_idx: 180 |  Loss: (0.3199) | Acc: (88.81%) (20576/23168)\n",
      "Epoch: 36 | Batch_idx: 190 |  Loss: (0.3205) | Acc: (88.81%) (21712/24448)\n",
      "Epoch: 36 | Batch_idx: 200 |  Loss: (0.3190) | Acc: (88.88%) (22868/25728)\n",
      "Epoch: 36 | Batch_idx: 210 |  Loss: (0.3192) | Acc: (88.91%) (24014/27008)\n",
      "Epoch: 36 | Batch_idx: 220 |  Loss: (0.3186) | Acc: (88.94%) (25158/28288)\n",
      "Epoch: 36 | Batch_idx: 230 |  Loss: (0.3186) | Acc: (88.94%) (26299/29568)\n",
      "Epoch: 36 | Batch_idx: 240 |  Loss: (0.3177) | Acc: (88.97%) (27445/30848)\n",
      "Epoch: 36 | Batch_idx: 250 |  Loss: (0.3170) | Acc: (88.99%) (28591/32128)\n",
      "Epoch: 36 | Batch_idx: 260 |  Loss: (0.3175) | Acc: (89.00%) (29734/33408)\n",
      "Epoch: 36 | Batch_idx: 270 |  Loss: (0.3191) | Acc: (88.97%) (30861/34688)\n",
      "Epoch: 36 | Batch_idx: 280 |  Loss: (0.3192) | Acc: (88.97%) (32000/35968)\n",
      "Epoch: 36 | Batch_idx: 290 |  Loss: (0.3194) | Acc: (88.99%) (33148/37248)\n",
      "Epoch: 36 | Batch_idx: 300 |  Loss: (0.3198) | Acc: (88.96%) (34274/38528)\n",
      "Epoch: 36 | Batch_idx: 310 |  Loss: (0.3196) | Acc: (88.97%) (35417/39808)\n",
      "Epoch: 36 | Batch_idx: 320 |  Loss: (0.3186) | Acc: (89.00%) (36568/41088)\n",
      "Epoch: 36 | Batch_idx: 330 |  Loss: (0.3178) | Acc: (89.02%) (37714/42368)\n",
      "Epoch: 36 | Batch_idx: 340 |  Loss: (0.3178) | Acc: (89.01%) (38852/43648)\n",
      "Epoch: 36 | Batch_idx: 350 |  Loss: (0.3186) | Acc: (88.97%) (39971/44928)\n",
      "Epoch: 36 | Batch_idx: 360 |  Loss: (0.3188) | Acc: (88.95%) (41103/46208)\n",
      "Epoch: 36 | Batch_idx: 370 |  Loss: (0.3187) | Acc: (88.97%) (42248/47488)\n",
      "Epoch: 36 | Batch_idx: 380 |  Loss: (0.3182) | Acc: (88.99%) (43400/48768)\n",
      "Epoch: 36 | Batch_idx: 390 |  Loss: (0.3187) | Acc: (88.95%) (44476/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4676) | Acc: (84.77%) (8477/10000)\n",
      "Epoch: 37 | Batch_idx: 0 |  Loss: (0.3356) | Acc: (88.28%) (113/128)\n",
      "Epoch: 37 | Batch_idx: 10 |  Loss: (0.3013) | Acc: (89.99%) (1267/1408)\n",
      "Epoch: 37 | Batch_idx: 20 |  Loss: (0.3148) | Acc: (89.62%) (2409/2688)\n",
      "Epoch: 37 | Batch_idx: 30 |  Loss: (0.3069) | Acc: (89.97%) (3570/3968)\n",
      "Epoch: 37 | Batch_idx: 40 |  Loss: (0.3143) | Acc: (89.52%) (4698/5248)\n",
      "Epoch: 37 | Batch_idx: 50 |  Loss: (0.3087) | Acc: (89.58%) (5848/6528)\n",
      "Epoch: 37 | Batch_idx: 60 |  Loss: (0.3017) | Acc: (89.81%) (7012/7808)\n",
      "Epoch: 37 | Batch_idx: 70 |  Loss: (0.3051) | Acc: (89.77%) (8158/9088)\n",
      "Epoch: 37 | Batch_idx: 80 |  Loss: (0.3005) | Acc: (89.91%) (9322/10368)\n",
      "Epoch: 37 | Batch_idx: 90 |  Loss: (0.3050) | Acc: (89.65%) (10442/11648)\n",
      "Epoch: 37 | Batch_idx: 100 |  Loss: (0.3048) | Acc: (89.67%) (11592/12928)\n",
      "Epoch: 37 | Batch_idx: 110 |  Loss: (0.3012) | Acc: (89.79%) (12757/14208)\n",
      "Epoch: 37 | Batch_idx: 120 |  Loss: (0.3007) | Acc: (89.80%) (13908/15488)\n",
      "Epoch: 37 | Batch_idx: 130 |  Loss: (0.3014) | Acc: (89.76%) (15051/16768)\n",
      "Epoch: 37 | Batch_idx: 140 |  Loss: (0.3030) | Acc: (89.70%) (16189/18048)\n",
      "Epoch: 37 | Batch_idx: 150 |  Loss: (0.3046) | Acc: (89.65%) (17328/19328)\n",
      "Epoch: 37 | Batch_idx: 160 |  Loss: (0.3049) | Acc: (89.69%) (18484/20608)\n",
      "Epoch: 37 | Batch_idx: 170 |  Loss: (0.3053) | Acc: (89.67%) (19627/21888)\n",
      "Epoch: 37 | Batch_idx: 180 |  Loss: (0.3058) | Acc: (89.63%) (20766/23168)\n",
      "Epoch: 37 | Batch_idx: 190 |  Loss: (0.3056) | Acc: (89.60%) (21905/24448)\n",
      "Epoch: 37 | Batch_idx: 200 |  Loss: (0.3072) | Acc: (89.55%) (23040/25728)\n",
      "Epoch: 37 | Batch_idx: 210 |  Loss: (0.3079) | Acc: (89.47%) (24164/27008)\n",
      "Epoch: 37 | Batch_idx: 220 |  Loss: (0.3074) | Acc: (89.46%) (25306/28288)\n",
      "Epoch: 37 | Batch_idx: 230 |  Loss: (0.3081) | Acc: (89.46%) (26451/29568)\n",
      "Epoch: 37 | Batch_idx: 240 |  Loss: (0.3086) | Acc: (89.46%) (27596/30848)\n",
      "Epoch: 37 | Batch_idx: 250 |  Loss: (0.3094) | Acc: (89.39%) (28718/32128)\n",
      "Epoch: 37 | Batch_idx: 260 |  Loss: (0.3101) | Acc: (89.35%) (29849/33408)\n",
      "Epoch: 37 | Batch_idx: 270 |  Loss: (0.3106) | Acc: (89.31%) (30981/34688)\n",
      "Epoch: 37 | Batch_idx: 280 |  Loss: (0.3113) | Acc: (89.30%) (32118/35968)\n",
      "Epoch: 37 | Batch_idx: 290 |  Loss: (0.3103) | Acc: (89.30%) (33264/37248)\n",
      "Epoch: 37 | Batch_idx: 300 |  Loss: (0.3112) | Acc: (89.26%) (34390/38528)\n",
      "Epoch: 37 | Batch_idx: 310 |  Loss: (0.3122) | Acc: (89.23%) (35519/39808)\n",
      "Epoch: 37 | Batch_idx: 320 |  Loss: (0.3126) | Acc: (89.22%) (36659/41088)\n",
      "Epoch: 37 | Batch_idx: 330 |  Loss: (0.3126) | Acc: (89.20%) (37793/42368)\n",
      "Epoch: 37 | Batch_idx: 340 |  Loss: (0.3120) | Acc: (89.23%) (38946/43648)\n",
      "Epoch: 37 | Batch_idx: 350 |  Loss: (0.3120) | Acc: (89.22%) (40085/44928)\n",
      "Epoch: 37 | Batch_idx: 360 |  Loss: (0.3126) | Acc: (89.22%) (41225/46208)\n",
      "Epoch: 37 | Batch_idx: 370 |  Loss: (0.3127) | Acc: (89.23%) (42372/47488)\n",
      "Epoch: 37 | Batch_idx: 380 |  Loss: (0.3126) | Acc: (89.22%) (43512/48768)\n",
      "Epoch: 37 | Batch_idx: 390 |  Loss: (0.3129) | Acc: (89.23%) (44615/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5078) | Acc: (83.66%) (8366/10000)\n",
      "Epoch: 38 | Batch_idx: 0 |  Loss: (0.2289) | Acc: (92.97%) (119/128)\n",
      "Epoch: 38 | Batch_idx: 10 |  Loss: (0.2793) | Acc: (90.84%) (1279/1408)\n",
      "Epoch: 38 | Batch_idx: 20 |  Loss: (0.2736) | Acc: (90.74%) (2439/2688)\n",
      "Epoch: 38 | Batch_idx: 30 |  Loss: (0.2749) | Acc: (90.65%) (3597/3968)\n",
      "Epoch: 38 | Batch_idx: 40 |  Loss: (0.2824) | Acc: (90.24%) (4736/5248)\n",
      "Epoch: 38 | Batch_idx: 50 |  Loss: (0.2874) | Acc: (90.07%) (5880/6528)\n",
      "Epoch: 38 | Batch_idx: 60 |  Loss: (0.2886) | Acc: (90.10%) (7035/7808)\n",
      "Epoch: 38 | Batch_idx: 70 |  Loss: (0.2924) | Acc: (90.01%) (8180/9088)\n",
      "Epoch: 38 | Batch_idx: 80 |  Loss: (0.2934) | Acc: (89.96%) (9327/10368)\n",
      "Epoch: 38 | Batch_idx: 90 |  Loss: (0.2953) | Acc: (89.85%) (10466/11648)\n",
      "Epoch: 38 | Batch_idx: 100 |  Loss: (0.2949) | Acc: (89.93%) (11626/12928)\n",
      "Epoch: 38 | Batch_idx: 110 |  Loss: (0.2968) | Acc: (89.91%) (12775/14208)\n",
      "Epoch: 38 | Batch_idx: 120 |  Loss: (0.2991) | Acc: (89.84%) (13914/15488)\n",
      "Epoch: 38 | Batch_idx: 130 |  Loss: (0.2960) | Acc: (89.92%) (15077/16768)\n",
      "Epoch: 38 | Batch_idx: 140 |  Loss: (0.2985) | Acc: (89.83%) (16213/18048)\n",
      "Epoch: 38 | Batch_idx: 150 |  Loss: (0.2995) | Acc: (89.80%) (17357/19328)\n",
      "Epoch: 38 | Batch_idx: 160 |  Loss: (0.2999) | Acc: (89.79%) (18504/20608)\n",
      "Epoch: 38 | Batch_idx: 170 |  Loss: (0.3007) | Acc: (89.76%) (19647/21888)\n",
      "Epoch: 38 | Batch_idx: 180 |  Loss: (0.3024) | Acc: (89.69%) (20779/23168)\n",
      "Epoch: 38 | Batch_idx: 190 |  Loss: (0.3043) | Acc: (89.64%) (21914/24448)\n",
      "Epoch: 38 | Batch_idx: 200 |  Loss: (0.3023) | Acc: (89.73%) (23085/25728)\n",
      "Epoch: 38 | Batch_idx: 210 |  Loss: (0.3025) | Acc: (89.69%) (24223/27008)\n",
      "Epoch: 38 | Batch_idx: 220 |  Loss: (0.3028) | Acc: (89.71%) (25376/28288)\n",
      "Epoch: 38 | Batch_idx: 230 |  Loss: (0.3032) | Acc: (89.67%) (26514/29568)\n",
      "Epoch: 38 | Batch_idx: 240 |  Loss: (0.3039) | Acc: (89.64%) (27651/30848)\n",
      "Epoch: 38 | Batch_idx: 250 |  Loss: (0.3049) | Acc: (89.59%) (28783/32128)\n",
      "Epoch: 38 | Batch_idx: 260 |  Loss: (0.3043) | Acc: (89.62%) (29939/33408)\n",
      "Epoch: 38 | Batch_idx: 270 |  Loss: (0.3040) | Acc: (89.61%) (31084/34688)\n",
      "Epoch: 38 | Batch_idx: 280 |  Loss: (0.3032) | Acc: (89.67%) (32253/35968)\n",
      "Epoch: 38 | Batch_idx: 290 |  Loss: (0.3026) | Acc: (89.71%) (33415/37248)\n",
      "Epoch: 38 | Batch_idx: 300 |  Loss: (0.3022) | Acc: (89.73%) (34573/38528)\n",
      "Epoch: 38 | Batch_idx: 310 |  Loss: (0.3029) | Acc: (89.68%) (35698/39808)\n",
      "Epoch: 38 | Batch_idx: 320 |  Loss: (0.3035) | Acc: (89.68%) (36848/41088)\n",
      "Epoch: 38 | Batch_idx: 330 |  Loss: (0.3025) | Acc: (89.69%) (37999/42368)\n",
      "Epoch: 38 | Batch_idx: 340 |  Loss: (0.3018) | Acc: (89.69%) (39149/43648)\n",
      "Epoch: 38 | Batch_idx: 350 |  Loss: (0.3022) | Acc: (89.68%) (40290/44928)\n",
      "Epoch: 38 | Batch_idx: 360 |  Loss: (0.3033) | Acc: (89.65%) (41426/46208)\n",
      "Epoch: 38 | Batch_idx: 370 |  Loss: (0.3029) | Acc: (89.67%) (42584/47488)\n",
      "Epoch: 38 | Batch_idx: 380 |  Loss: (0.3044) | Acc: (89.61%) (43700/48768)\n",
      "Epoch: 38 | Batch_idx: 390 |  Loss: (0.3052) | Acc: (89.57%) (44783/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5131) | Acc: (83.72%) (8372/10000)\n",
      "Epoch: 39 | Batch_idx: 0 |  Loss: (0.3818) | Acc: (86.72%) (111/128)\n",
      "Epoch: 39 | Batch_idx: 10 |  Loss: (0.3262) | Acc: (87.93%) (1238/1408)\n",
      "Epoch: 39 | Batch_idx: 20 |  Loss: (0.3252) | Acc: (88.32%) (2374/2688)\n",
      "Epoch: 39 | Batch_idx: 30 |  Loss: (0.3249) | Acc: (88.81%) (3524/3968)\n",
      "Epoch: 39 | Batch_idx: 40 |  Loss: (0.3154) | Acc: (89.02%) (4672/5248)\n",
      "Epoch: 39 | Batch_idx: 50 |  Loss: (0.3135) | Acc: (89.03%) (5812/6528)\n",
      "Epoch: 39 | Batch_idx: 60 |  Loss: (0.3046) | Acc: (89.55%) (6992/7808)\n",
      "Epoch: 39 | Batch_idx: 70 |  Loss: (0.3035) | Acc: (89.61%) (8144/9088)\n",
      "Epoch: 39 | Batch_idx: 80 |  Loss: (0.2992) | Acc: (89.71%) (9301/10368)\n",
      "Epoch: 39 | Batch_idx: 90 |  Loss: (0.2984) | Acc: (89.73%) (10452/11648)\n",
      "Epoch: 39 | Batch_idx: 100 |  Loss: (0.2976) | Acc: (89.73%) (11600/12928)\n",
      "Epoch: 39 | Batch_idx: 110 |  Loss: (0.2967) | Acc: (89.75%) (12751/14208)\n",
      "Epoch: 39 | Batch_idx: 120 |  Loss: (0.2972) | Acc: (89.76%) (13902/15488)\n",
      "Epoch: 39 | Batch_idx: 130 |  Loss: (0.2969) | Acc: (89.78%) (15054/16768)\n",
      "Epoch: 39 | Batch_idx: 140 |  Loss: (0.2983) | Acc: (89.73%) (16194/18048)\n",
      "Epoch: 39 | Batch_idx: 150 |  Loss: (0.2978) | Acc: (89.70%) (17338/19328)\n",
      "Epoch: 39 | Batch_idx: 160 |  Loss: (0.2990) | Acc: (89.64%) (18473/20608)\n",
      "Epoch: 39 | Batch_idx: 170 |  Loss: (0.2989) | Acc: (89.58%) (19607/21888)\n",
      "Epoch: 39 | Batch_idx: 180 |  Loss: (0.2994) | Acc: (89.56%) (20750/23168)\n",
      "Epoch: 39 | Batch_idx: 190 |  Loss: (0.2997) | Acc: (89.59%) (21902/24448)\n",
      "Epoch: 39 | Batch_idx: 200 |  Loss: (0.3000) | Acc: (89.59%) (23049/25728)\n",
      "Epoch: 39 | Batch_idx: 210 |  Loss: (0.3009) | Acc: (89.55%) (24185/27008)\n",
      "Epoch: 39 | Batch_idx: 220 |  Loss: (0.3016) | Acc: (89.50%) (25319/28288)\n",
      "Epoch: 39 | Batch_idx: 230 |  Loss: (0.3013) | Acc: (89.50%) (26464/29568)\n",
      "Epoch: 39 | Batch_idx: 240 |  Loss: (0.3006) | Acc: (89.51%) (27612/30848)\n",
      "Epoch: 39 | Batch_idx: 250 |  Loss: (0.3005) | Acc: (89.52%) (28761/32128)\n",
      "Epoch: 39 | Batch_idx: 260 |  Loss: (0.3010) | Acc: (89.49%) (29896/33408)\n",
      "Epoch: 39 | Batch_idx: 270 |  Loss: (0.3008) | Acc: (89.50%) (31045/34688)\n",
      "Epoch: 39 | Batch_idx: 280 |  Loss: (0.3009) | Acc: (89.49%) (32186/35968)\n",
      "Epoch: 39 | Batch_idx: 290 |  Loss: (0.3004) | Acc: (89.51%) (33342/37248)\n",
      "Epoch: 39 | Batch_idx: 300 |  Loss: (0.3006) | Acc: (89.51%) (34486/38528)\n",
      "Epoch: 39 | Batch_idx: 310 |  Loss: (0.3000) | Acc: (89.52%) (35637/39808)\n",
      "Epoch: 39 | Batch_idx: 320 |  Loss: (0.3003) | Acc: (89.51%) (36777/41088)\n",
      "Epoch: 39 | Batch_idx: 330 |  Loss: (0.3014) | Acc: (89.47%) (37906/42368)\n",
      "Epoch: 39 | Batch_idx: 340 |  Loss: (0.3023) | Acc: (89.46%) (39048/43648)\n",
      "Epoch: 39 | Batch_idx: 350 |  Loss: (0.3022) | Acc: (89.45%) (40186/44928)\n",
      "Epoch: 39 | Batch_idx: 360 |  Loss: (0.3024) | Acc: (89.45%) (41331/46208)\n",
      "Epoch: 39 | Batch_idx: 370 |  Loss: (0.3017) | Acc: (89.47%) (42487/47488)\n",
      "Epoch: 39 | Batch_idx: 380 |  Loss: (0.3005) | Acc: (89.51%) (43652/48768)\n",
      "Epoch: 39 | Batch_idx: 390 |  Loss: (0.3007) | Acc: (89.51%) (44754/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4849) | Acc: (84.87%) (8487/10000)\n",
      "Epoch: 40 | Batch_idx: 0 |  Loss: (0.2105) | Acc: (92.97%) (119/128)\n",
      "Epoch: 40 | Batch_idx: 10 |  Loss: (0.2514) | Acc: (91.90%) (1294/1408)\n",
      "Epoch: 40 | Batch_idx: 20 |  Loss: (0.2697) | Acc: (91.03%) (2447/2688)\n",
      "Epoch: 40 | Batch_idx: 30 |  Loss: (0.2704) | Acc: (90.68%) (3598/3968)\n",
      "Epoch: 40 | Batch_idx: 40 |  Loss: (0.2729) | Acc: (90.45%) (4747/5248)\n",
      "Epoch: 40 | Batch_idx: 50 |  Loss: (0.2750) | Acc: (90.56%) (5912/6528)\n",
      "Epoch: 40 | Batch_idx: 60 |  Loss: (0.2714) | Acc: (90.65%) (7078/7808)\n",
      "Epoch: 40 | Batch_idx: 70 |  Loss: (0.2764) | Acc: (90.42%) (8217/9088)\n",
      "Epoch: 40 | Batch_idx: 80 |  Loss: (0.2810) | Acc: (90.29%) (9361/10368)\n",
      "Epoch: 40 | Batch_idx: 90 |  Loss: (0.2808) | Acc: (90.36%) (10525/11648)\n",
      "Epoch: 40 | Batch_idx: 100 |  Loss: (0.2826) | Acc: (90.21%) (11662/12928)\n",
      "Epoch: 40 | Batch_idx: 110 |  Loss: (0.2839) | Acc: (90.13%) (12805/14208)\n",
      "Epoch: 40 | Batch_idx: 120 |  Loss: (0.2849) | Acc: (90.10%) (13954/15488)\n",
      "Epoch: 40 | Batch_idx: 130 |  Loss: (0.2861) | Acc: (90.07%) (15103/16768)\n",
      "Epoch: 40 | Batch_idx: 140 |  Loss: (0.2894) | Acc: (89.93%) (16230/18048)\n",
      "Epoch: 40 | Batch_idx: 150 |  Loss: (0.2921) | Acc: (89.83%) (17363/19328)\n",
      "Epoch: 40 | Batch_idx: 160 |  Loss: (0.2913) | Acc: (89.90%) (18526/20608)\n",
      "Epoch: 40 | Batch_idx: 170 |  Loss: (0.2916) | Acc: (89.87%) (19671/21888)\n",
      "Epoch: 40 | Batch_idx: 180 |  Loss: (0.2918) | Acc: (89.90%) (20828/23168)\n",
      "Epoch: 40 | Batch_idx: 190 |  Loss: (0.2912) | Acc: (89.94%) (21988/24448)\n",
      "Epoch: 40 | Batch_idx: 200 |  Loss: (0.2921) | Acc: (89.85%) (23117/25728)\n",
      "Epoch: 40 | Batch_idx: 210 |  Loss: (0.2930) | Acc: (89.84%) (24264/27008)\n",
      "Epoch: 40 | Batch_idx: 220 |  Loss: (0.2928) | Acc: (89.86%) (25420/28288)\n",
      "Epoch: 40 | Batch_idx: 230 |  Loss: (0.2933) | Acc: (89.83%) (26562/29568)\n",
      "Epoch: 40 | Batch_idx: 240 |  Loss: (0.2933) | Acc: (89.87%) (27724/30848)\n",
      "Epoch: 40 | Batch_idx: 250 |  Loss: (0.2937) | Acc: (89.89%) (28879/32128)\n",
      "Epoch: 40 | Batch_idx: 260 |  Loss: (0.2937) | Acc: (89.89%) (30029/33408)\n",
      "Epoch: 40 | Batch_idx: 270 |  Loss: (0.2935) | Acc: (89.92%) (31190/34688)\n",
      "Epoch: 40 | Batch_idx: 280 |  Loss: (0.2941) | Acc: (89.92%) (32342/35968)\n",
      "Epoch: 40 | Batch_idx: 290 |  Loss: (0.2942) | Acc: (89.90%) (33486/37248)\n",
      "Epoch: 40 | Batch_idx: 300 |  Loss: (0.2941) | Acc: (89.91%) (34640/38528)\n",
      "Epoch: 40 | Batch_idx: 310 |  Loss: (0.2939) | Acc: (89.90%) (35787/39808)\n",
      "Epoch: 40 | Batch_idx: 320 |  Loss: (0.2948) | Acc: (89.88%) (36929/41088)\n",
      "Epoch: 40 | Batch_idx: 330 |  Loss: (0.2947) | Acc: (89.87%) (38075/42368)\n",
      "Epoch: 40 | Batch_idx: 340 |  Loss: (0.2944) | Acc: (89.84%) (39214/43648)\n",
      "Epoch: 40 | Batch_idx: 350 |  Loss: (0.2949) | Acc: (89.83%) (40358/44928)\n",
      "Epoch: 40 | Batch_idx: 360 |  Loss: (0.2944) | Acc: (89.84%) (41513/46208)\n",
      "Epoch: 40 | Batch_idx: 370 |  Loss: (0.2943) | Acc: (89.81%) (42651/47488)\n",
      "Epoch: 40 | Batch_idx: 380 |  Loss: (0.2940) | Acc: (89.82%) (43803/48768)\n",
      "Epoch: 40 | Batch_idx: 390 |  Loss: (0.2940) | Acc: (89.83%) (44913/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4826) | Acc: (84.62%) (8462/10000)\n",
      "Epoch: 41 | Batch_idx: 0 |  Loss: (0.2145) | Acc: (92.97%) (119/128)\n",
      "Epoch: 41 | Batch_idx: 10 |  Loss: (0.3100) | Acc: (89.06%) (1254/1408)\n",
      "Epoch: 41 | Batch_idx: 20 |  Loss: (0.3105) | Acc: (89.25%) (2399/2688)\n",
      "Epoch: 41 | Batch_idx: 30 |  Loss: (0.2959) | Acc: (89.84%) (3565/3968)\n",
      "Epoch: 41 | Batch_idx: 40 |  Loss: (0.3078) | Acc: (89.58%) (4701/5248)\n",
      "Epoch: 41 | Batch_idx: 50 |  Loss: (0.3036) | Acc: (89.74%) (5858/6528)\n",
      "Epoch: 41 | Batch_idx: 60 |  Loss: (0.3005) | Acc: (89.77%) (7009/7808)\n",
      "Epoch: 41 | Batch_idx: 70 |  Loss: (0.2965) | Acc: (90.00%) (8179/9088)\n",
      "Epoch: 41 | Batch_idx: 80 |  Loss: (0.2936) | Acc: (90.05%) (9336/10368)\n",
      "Epoch: 41 | Batch_idx: 90 |  Loss: (0.2909) | Acc: (90.12%) (10497/11648)\n",
      "Epoch: 41 | Batch_idx: 100 |  Loss: (0.2935) | Acc: (89.97%) (11631/12928)\n",
      "Epoch: 41 | Batch_idx: 110 |  Loss: (0.2888) | Acc: (90.16%) (12810/14208)\n",
      "Epoch: 41 | Batch_idx: 120 |  Loss: (0.2892) | Acc: (90.15%) (13962/15488)\n",
      "Epoch: 41 | Batch_idx: 130 |  Loss: (0.2881) | Acc: (90.14%) (15115/16768)\n",
      "Epoch: 41 | Batch_idx: 140 |  Loss: (0.2871) | Acc: (90.13%) (16266/18048)\n",
      "Epoch: 41 | Batch_idx: 150 |  Loss: (0.2866) | Acc: (90.13%) (17420/19328)\n",
      "Epoch: 41 | Batch_idx: 160 |  Loss: (0.2870) | Acc: (90.06%) (18559/20608)\n",
      "Epoch: 41 | Batch_idx: 170 |  Loss: (0.2868) | Acc: (90.09%) (19719/21888)\n",
      "Epoch: 41 | Batch_idx: 180 |  Loss: (0.2865) | Acc: (90.08%) (20870/23168)\n",
      "Epoch: 41 | Batch_idx: 190 |  Loss: (0.2861) | Acc: (90.11%) (22029/24448)\n",
      "Epoch: 41 | Batch_idx: 200 |  Loss: (0.2843) | Acc: (90.16%) (23197/25728)\n",
      "Epoch: 41 | Batch_idx: 210 |  Loss: (0.2846) | Acc: (90.12%) (24339/27008)\n",
      "Epoch: 41 | Batch_idx: 220 |  Loss: (0.2839) | Acc: (90.13%) (25495/28288)\n",
      "Epoch: 41 | Batch_idx: 230 |  Loss: (0.2842) | Acc: (90.16%) (26658/29568)\n",
      "Epoch: 41 | Batch_idx: 240 |  Loss: (0.2822) | Acc: (90.24%) (27836/30848)\n",
      "Epoch: 41 | Batch_idx: 250 |  Loss: (0.2824) | Acc: (90.22%) (28985/32128)\n",
      "Epoch: 41 | Batch_idx: 260 |  Loss: (0.2823) | Acc: (90.21%) (30137/33408)\n",
      "Epoch: 41 | Batch_idx: 270 |  Loss: (0.2828) | Acc: (90.21%) (31292/34688)\n",
      "Epoch: 41 | Batch_idx: 280 |  Loss: (0.2826) | Acc: (90.18%) (32435/35968)\n",
      "Epoch: 41 | Batch_idx: 290 |  Loss: (0.2829) | Acc: (90.18%) (33592/37248)\n",
      "Epoch: 41 | Batch_idx: 300 |  Loss: (0.2826) | Acc: (90.23%) (34762/38528)\n",
      "Epoch: 41 | Batch_idx: 310 |  Loss: (0.2821) | Acc: (90.24%) (35922/39808)\n",
      "Epoch: 41 | Batch_idx: 320 |  Loss: (0.2823) | Acc: (90.21%) (37066/41088)\n",
      "Epoch: 41 | Batch_idx: 330 |  Loss: (0.2819) | Acc: (90.24%) (38233/42368)\n",
      "Epoch: 41 | Batch_idx: 340 |  Loss: (0.2816) | Acc: (90.25%) (39392/43648)\n",
      "Epoch: 41 | Batch_idx: 350 |  Loss: (0.2813) | Acc: (90.26%) (40551/44928)\n",
      "Epoch: 41 | Batch_idx: 360 |  Loss: (0.2813) | Acc: (90.26%) (41709/46208)\n",
      "Epoch: 41 | Batch_idx: 370 |  Loss: (0.2816) | Acc: (90.26%) (42862/47488)\n",
      "Epoch: 41 | Batch_idx: 380 |  Loss: (0.2809) | Acc: (90.29%) (44034/48768)\n",
      "Epoch: 41 | Batch_idx: 390 |  Loss: (0.2812) | Acc: (90.28%) (45138/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5173) | Acc: (84.26%) (8426/10000)\n",
      "Epoch: 42 | Batch_idx: 0 |  Loss: (0.3139) | Acc: (89.84%) (115/128)\n",
      "Epoch: 42 | Batch_idx: 10 |  Loss: (0.2805) | Acc: (91.34%) (1286/1408)\n",
      "Epoch: 42 | Batch_idx: 20 |  Loss: (0.2682) | Acc: (91.52%) (2460/2688)\n",
      "Epoch: 42 | Batch_idx: 30 |  Loss: (0.2663) | Acc: (91.33%) (3624/3968)\n",
      "Epoch: 42 | Batch_idx: 40 |  Loss: (0.2657) | Acc: (91.10%) (4781/5248)\n",
      "Epoch: 42 | Batch_idx: 50 |  Loss: (0.2707) | Acc: (91.05%) (5944/6528)\n",
      "Epoch: 42 | Batch_idx: 60 |  Loss: (0.2696) | Acc: (91.10%) (7113/7808)\n",
      "Epoch: 42 | Batch_idx: 70 |  Loss: (0.2738) | Acc: (90.79%) (8251/9088)\n",
      "Epoch: 42 | Batch_idx: 80 |  Loss: (0.2708) | Acc: (90.88%) (9422/10368)\n",
      "Epoch: 42 | Batch_idx: 90 |  Loss: (0.2726) | Acc: (90.81%) (10577/11648)\n",
      "Epoch: 42 | Batch_idx: 100 |  Loss: (0.2729) | Acc: (90.72%) (11728/12928)\n",
      "Epoch: 42 | Batch_idx: 110 |  Loss: (0.2717) | Acc: (90.74%) (12893/14208)\n",
      "Epoch: 42 | Batch_idx: 120 |  Loss: (0.2692) | Acc: (90.81%) (14065/15488)\n",
      "Epoch: 42 | Batch_idx: 130 |  Loss: (0.2700) | Acc: (90.71%) (15211/16768)\n",
      "Epoch: 42 | Batch_idx: 140 |  Loss: (0.2684) | Acc: (90.72%) (16374/18048)\n",
      "Epoch: 42 | Batch_idx: 150 |  Loss: (0.2716) | Acc: (90.60%) (17511/19328)\n",
      "Epoch: 42 | Batch_idx: 160 |  Loss: (0.2726) | Acc: (90.56%) (18662/20608)\n",
      "Epoch: 42 | Batch_idx: 170 |  Loss: (0.2728) | Acc: (90.60%) (19830/21888)\n",
      "Epoch: 42 | Batch_idx: 180 |  Loss: (0.2729) | Acc: (90.58%) (20986/23168)\n",
      "Epoch: 42 | Batch_idx: 190 |  Loss: (0.2727) | Acc: (90.60%) (22151/24448)\n",
      "Epoch: 42 | Batch_idx: 200 |  Loss: (0.2729) | Acc: (90.60%) (23309/25728)\n",
      "Epoch: 42 | Batch_idx: 210 |  Loss: (0.2722) | Acc: (90.58%) (24464/27008)\n",
      "Epoch: 42 | Batch_idx: 220 |  Loss: (0.2735) | Acc: (90.53%) (25610/28288)\n",
      "Epoch: 42 | Batch_idx: 230 |  Loss: (0.2745) | Acc: (90.52%) (26764/29568)\n",
      "Epoch: 42 | Batch_idx: 240 |  Loss: (0.2749) | Acc: (90.48%) (27912/30848)\n",
      "Epoch: 42 | Batch_idx: 250 |  Loss: (0.2746) | Acc: (90.49%) (29074/32128)\n",
      "Epoch: 42 | Batch_idx: 260 |  Loss: (0.2756) | Acc: (90.46%) (30222/33408)\n",
      "Epoch: 42 | Batch_idx: 270 |  Loss: (0.2765) | Acc: (90.44%) (31372/34688)\n",
      "Epoch: 42 | Batch_idx: 280 |  Loss: (0.2763) | Acc: (90.43%) (32527/35968)\n",
      "Epoch: 42 | Batch_idx: 290 |  Loss: (0.2782) | Acc: (90.34%) (33650/37248)\n",
      "Epoch: 42 | Batch_idx: 300 |  Loss: (0.2783) | Acc: (90.34%) (34805/38528)\n",
      "Epoch: 42 | Batch_idx: 310 |  Loss: (0.2793) | Acc: (90.27%) (35935/39808)\n",
      "Epoch: 42 | Batch_idx: 320 |  Loss: (0.2781) | Acc: (90.30%) (37102/41088)\n",
      "Epoch: 42 | Batch_idx: 330 |  Loss: (0.2785) | Acc: (90.25%) (38238/42368)\n",
      "Epoch: 42 | Batch_idx: 340 |  Loss: (0.2791) | Acc: (90.23%) (39384/43648)\n",
      "Epoch: 42 | Batch_idx: 350 |  Loss: (0.2788) | Acc: (90.24%) (40545/44928)\n",
      "Epoch: 42 | Batch_idx: 360 |  Loss: (0.2794) | Acc: (90.23%) (41694/46208)\n",
      "Epoch: 42 | Batch_idx: 370 |  Loss: (0.2797) | Acc: (90.21%) (42841/47488)\n",
      "Epoch: 42 | Batch_idx: 380 |  Loss: (0.2802) | Acc: (90.19%) (43985/48768)\n",
      "Epoch: 42 | Batch_idx: 390 |  Loss: (0.2804) | Acc: (90.18%) (45091/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4949) | Acc: (84.18%) (8418/10000)\n",
      "Epoch: 43 | Batch_idx: 0 |  Loss: (0.2348) | Acc: (93.75%) (120/128)\n",
      "Epoch: 43 | Batch_idx: 10 |  Loss: (0.2569) | Acc: (91.05%) (1282/1408)\n",
      "Epoch: 43 | Batch_idx: 20 |  Loss: (0.2641) | Acc: (91.07%) (2448/2688)\n",
      "Epoch: 43 | Batch_idx: 30 |  Loss: (0.2703) | Acc: (90.78%) (3602/3968)\n",
      "Epoch: 43 | Batch_idx: 40 |  Loss: (0.2666) | Acc: (90.85%) (4768/5248)\n",
      "Epoch: 43 | Batch_idx: 50 |  Loss: (0.2683) | Acc: (90.73%) (5923/6528)\n",
      "Epoch: 43 | Batch_idx: 60 |  Loss: (0.2686) | Acc: (90.87%) (7095/7808)\n",
      "Epoch: 43 | Batch_idx: 70 |  Loss: (0.2691) | Acc: (90.90%) (8261/9088)\n",
      "Epoch: 43 | Batch_idx: 80 |  Loss: (0.2693) | Acc: (90.90%) (9424/10368)\n",
      "Epoch: 43 | Batch_idx: 90 |  Loss: (0.2696) | Acc: (90.88%) (10586/11648)\n",
      "Epoch: 43 | Batch_idx: 100 |  Loss: (0.2684) | Acc: (90.90%) (11752/12928)\n",
      "Epoch: 43 | Batch_idx: 110 |  Loss: (0.2692) | Acc: (90.91%) (12917/14208)\n",
      "Epoch: 43 | Batch_idx: 120 |  Loss: (0.2698) | Acc: (90.81%) (14064/15488)\n",
      "Epoch: 43 | Batch_idx: 130 |  Loss: (0.2692) | Acc: (90.86%) (15236/16768)\n",
      "Epoch: 43 | Batch_idx: 140 |  Loss: (0.2678) | Acc: (90.90%) (16406/18048)\n",
      "Epoch: 43 | Batch_idx: 150 |  Loss: (0.2658) | Acc: (90.97%) (17583/19328)\n",
      "Epoch: 43 | Batch_idx: 160 |  Loss: (0.2659) | Acc: (90.97%) (18747/20608)\n",
      "Epoch: 43 | Batch_idx: 170 |  Loss: (0.2668) | Acc: (90.91%) (19899/21888)\n",
      "Epoch: 43 | Batch_idx: 180 |  Loss: (0.2675) | Acc: (90.85%) (21048/23168)\n",
      "Epoch: 43 | Batch_idx: 190 |  Loss: (0.2672) | Acc: (90.85%) (22212/24448)\n",
      "Epoch: 43 | Batch_idx: 200 |  Loss: (0.2694) | Acc: (90.79%) (23359/25728)\n",
      "Epoch: 43 | Batch_idx: 210 |  Loss: (0.2696) | Acc: (90.81%) (24526/27008)\n",
      "Epoch: 43 | Batch_idx: 220 |  Loss: (0.2683) | Acc: (90.84%) (25697/28288)\n",
      "Epoch: 43 | Batch_idx: 230 |  Loss: (0.2687) | Acc: (90.80%) (26847/29568)\n",
      "Epoch: 43 | Batch_idx: 240 |  Loss: (0.2704) | Acc: (90.72%) (27986/30848)\n",
      "Epoch: 43 | Batch_idx: 250 |  Loss: (0.2711) | Acc: (90.71%) (29142/32128)\n",
      "Epoch: 43 | Batch_idx: 260 |  Loss: (0.2709) | Acc: (90.73%) (30312/33408)\n",
      "Epoch: 43 | Batch_idx: 270 |  Loss: (0.2708) | Acc: (90.72%) (31470/34688)\n",
      "Epoch: 43 | Batch_idx: 280 |  Loss: (0.2709) | Acc: (90.74%) (32638/35968)\n",
      "Epoch: 43 | Batch_idx: 290 |  Loss: (0.2709) | Acc: (90.74%) (33797/37248)\n",
      "Epoch: 43 | Batch_idx: 300 |  Loss: (0.2712) | Acc: (90.73%) (34955/38528)\n",
      "Epoch: 43 | Batch_idx: 310 |  Loss: (0.2711) | Acc: (90.73%) (36119/39808)\n",
      "Epoch: 43 | Batch_idx: 320 |  Loss: (0.2717) | Acc: (90.71%) (37272/41088)\n",
      "Epoch: 43 | Batch_idx: 330 |  Loss: (0.2712) | Acc: (90.71%) (38433/42368)\n",
      "Epoch: 43 | Batch_idx: 340 |  Loss: (0.2713) | Acc: (90.71%) (39595/43648)\n",
      "Epoch: 43 | Batch_idx: 350 |  Loss: (0.2730) | Acc: (90.64%) (40721/44928)\n",
      "Epoch: 43 | Batch_idx: 360 |  Loss: (0.2736) | Acc: (90.61%) (41868/46208)\n",
      "Epoch: 43 | Batch_idx: 370 |  Loss: (0.2741) | Acc: (90.57%) (43012/47488)\n",
      "Epoch: 43 | Batch_idx: 380 |  Loss: (0.2749) | Acc: (90.57%) (44169/48768)\n",
      "Epoch: 43 | Batch_idx: 390 |  Loss: (0.2751) | Acc: (90.55%) (45275/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4297) | Acc: (85.72%) (8572/10000)\n",
      "Epoch: 44 | Batch_idx: 0 |  Loss: (0.1958) | Acc: (92.97%) (119/128)\n",
      "Epoch: 44 | Batch_idx: 10 |  Loss: (0.2599) | Acc: (90.91%) (1280/1408)\n",
      "Epoch: 44 | Batch_idx: 20 |  Loss: (0.2584) | Acc: (91.41%) (2457/2688)\n",
      "Epoch: 44 | Batch_idx: 30 |  Loss: (0.2587) | Acc: (91.08%) (3614/3968)\n",
      "Epoch: 44 | Batch_idx: 40 |  Loss: (0.2564) | Acc: (91.12%) (4782/5248)\n",
      "Epoch: 44 | Batch_idx: 50 |  Loss: (0.2589) | Acc: (91.12%) (5948/6528)\n",
      "Epoch: 44 | Batch_idx: 60 |  Loss: (0.2596) | Acc: (90.98%) (7104/7808)\n",
      "Epoch: 44 | Batch_idx: 70 |  Loss: (0.2609) | Acc: (91.00%) (8270/9088)\n",
      "Epoch: 44 | Batch_idx: 80 |  Loss: (0.2593) | Acc: (91.11%) (9446/10368)\n",
      "Epoch: 44 | Batch_idx: 90 |  Loss: (0.2603) | Acc: (91.10%) (10611/11648)\n",
      "Epoch: 44 | Batch_idx: 100 |  Loss: (0.2602) | Acc: (91.09%) (11776/12928)\n",
      "Epoch: 44 | Batch_idx: 110 |  Loss: (0.2603) | Acc: (91.07%) (12939/14208)\n",
      "Epoch: 44 | Batch_idx: 120 |  Loss: (0.2590) | Acc: (91.11%) (14111/15488)\n",
      "Epoch: 44 | Batch_idx: 130 |  Loss: (0.2601) | Acc: (91.04%) (15266/16768)\n",
      "Epoch: 44 | Batch_idx: 140 |  Loss: (0.2617) | Acc: (90.99%) (16422/18048)\n",
      "Epoch: 44 | Batch_idx: 150 |  Loss: (0.2621) | Acc: (90.95%) (17579/19328)\n",
      "Epoch: 44 | Batch_idx: 160 |  Loss: (0.2629) | Acc: (90.95%) (18744/20608)\n",
      "Epoch: 44 | Batch_idx: 170 |  Loss: (0.2653) | Acc: (90.89%) (19893/21888)\n",
      "Epoch: 44 | Batch_idx: 180 |  Loss: (0.2662) | Acc: (90.85%) (21049/23168)\n",
      "Epoch: 44 | Batch_idx: 190 |  Loss: (0.2670) | Acc: (90.86%) (22214/24448)\n",
      "Epoch: 44 | Batch_idx: 200 |  Loss: (0.2667) | Acc: (90.85%) (23374/25728)\n",
      "Epoch: 44 | Batch_idx: 210 |  Loss: (0.2677) | Acc: (90.84%) (24535/27008)\n",
      "Epoch: 44 | Batch_idx: 220 |  Loss: (0.2700) | Acc: (90.77%) (25676/28288)\n",
      "Epoch: 44 | Batch_idx: 230 |  Loss: (0.2688) | Acc: (90.82%) (26853/29568)\n",
      "Epoch: 44 | Batch_idx: 240 |  Loss: (0.2687) | Acc: (90.83%) (28018/30848)\n",
      "Epoch: 44 | Batch_idx: 250 |  Loss: (0.2682) | Acc: (90.85%) (29187/32128)\n",
      "Epoch: 44 | Batch_idx: 260 |  Loss: (0.2684) | Acc: (90.81%) (30338/33408)\n",
      "Epoch: 44 | Batch_idx: 270 |  Loss: (0.2691) | Acc: (90.80%) (31496/34688)\n",
      "Epoch: 44 | Batch_idx: 280 |  Loss: (0.2686) | Acc: (90.79%) (32656/35968)\n",
      "Epoch: 44 | Batch_idx: 290 |  Loss: (0.2691) | Acc: (90.76%) (33805/37248)\n",
      "Epoch: 44 | Batch_idx: 300 |  Loss: (0.2689) | Acc: (90.75%) (34966/38528)\n",
      "Epoch: 44 | Batch_idx: 310 |  Loss: (0.2694) | Acc: (90.74%) (36123/39808)\n",
      "Epoch: 44 | Batch_idx: 320 |  Loss: (0.2689) | Acc: (90.75%) (37289/41088)\n",
      "Epoch: 44 | Batch_idx: 330 |  Loss: (0.2697) | Acc: (90.73%) (38442/42368)\n",
      "Epoch: 44 | Batch_idx: 340 |  Loss: (0.2694) | Acc: (90.74%) (39605/43648)\n",
      "Epoch: 44 | Batch_idx: 350 |  Loss: (0.2689) | Acc: (90.79%) (40788/44928)\n",
      "Epoch: 44 | Batch_idx: 360 |  Loss: (0.2686) | Acc: (90.81%) (41960/46208)\n",
      "Epoch: 44 | Batch_idx: 370 |  Loss: (0.2691) | Acc: (90.79%) (43116/47488)\n",
      "Epoch: 44 | Batch_idx: 380 |  Loss: (0.2703) | Acc: (90.73%) (44247/48768)\n",
      "Epoch: 44 | Batch_idx: 390 |  Loss: (0.2702) | Acc: (90.73%) (45364/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5563) | Acc: (83.59%) (8359/10000)\n",
      "Epoch: 45 | Batch_idx: 0 |  Loss: (0.2296) | Acc: (90.62%) (116/128)\n",
      "Epoch: 45 | Batch_idx: 10 |  Loss: (0.2424) | Acc: (91.69%) (1291/1408)\n",
      "Epoch: 45 | Batch_idx: 20 |  Loss: (0.2444) | Acc: (91.52%) (2460/2688)\n",
      "Epoch: 45 | Batch_idx: 30 |  Loss: (0.2464) | Acc: (91.36%) (3625/3968)\n",
      "Epoch: 45 | Batch_idx: 40 |  Loss: (0.2495) | Acc: (91.27%) (4790/5248)\n",
      "Epoch: 45 | Batch_idx: 50 |  Loss: (0.2477) | Acc: (91.22%) (5955/6528)\n",
      "Epoch: 45 | Batch_idx: 60 |  Loss: (0.2486) | Acc: (91.18%) (7119/7808)\n",
      "Epoch: 45 | Batch_idx: 70 |  Loss: (0.2490) | Acc: (91.30%) (8297/9088)\n",
      "Epoch: 45 | Batch_idx: 80 |  Loss: (0.2463) | Acc: (91.41%) (9477/10368)\n",
      "Epoch: 45 | Batch_idx: 90 |  Loss: (0.2480) | Acc: (91.42%) (10649/11648)\n",
      "Epoch: 45 | Batch_idx: 100 |  Loss: (0.2467) | Acc: (91.39%) (11815/12928)\n",
      "Epoch: 45 | Batch_idx: 110 |  Loss: (0.2479) | Acc: (91.39%) (12985/14208)\n",
      "Epoch: 45 | Batch_idx: 120 |  Loss: (0.2479) | Acc: (91.34%) (14147/15488)\n",
      "Epoch: 45 | Batch_idx: 130 |  Loss: (0.2485) | Acc: (91.32%) (15312/16768)\n",
      "Epoch: 45 | Batch_idx: 140 |  Loss: (0.2512) | Acc: (91.29%) (16476/18048)\n",
      "Epoch: 45 | Batch_idx: 150 |  Loss: (0.2517) | Acc: (91.29%) (17644/19328)\n",
      "Epoch: 45 | Batch_idx: 160 |  Loss: (0.2512) | Acc: (91.30%) (18815/20608)\n",
      "Epoch: 45 | Batch_idx: 170 |  Loss: (0.2511) | Acc: (91.30%) (19983/21888)\n",
      "Epoch: 45 | Batch_idx: 180 |  Loss: (0.2520) | Acc: (91.28%) (21147/23168)\n",
      "Epoch: 45 | Batch_idx: 190 |  Loss: (0.2515) | Acc: (91.29%) (22318/24448)\n",
      "Epoch: 45 | Batch_idx: 200 |  Loss: (0.2527) | Acc: (91.26%) (23480/25728)\n",
      "Epoch: 45 | Batch_idx: 210 |  Loss: (0.2524) | Acc: (91.26%) (24648/27008)\n",
      "Epoch: 45 | Batch_idx: 220 |  Loss: (0.2535) | Acc: (91.23%) (25806/28288)\n",
      "Epoch: 45 | Batch_idx: 230 |  Loss: (0.2549) | Acc: (91.19%) (26962/29568)\n",
      "Epoch: 45 | Batch_idx: 240 |  Loss: (0.2557) | Acc: (91.15%) (28119/30848)\n",
      "Epoch: 45 | Batch_idx: 250 |  Loss: (0.2551) | Acc: (91.15%) (29285/32128)\n",
      "Epoch: 45 | Batch_idx: 260 |  Loss: (0.2541) | Acc: (91.19%) (30466/33408)\n",
      "Epoch: 45 | Batch_idx: 270 |  Loss: (0.2550) | Acc: (91.16%) (31622/34688)\n",
      "Epoch: 45 | Batch_idx: 280 |  Loss: (0.2552) | Acc: (91.17%) (32791/35968)\n",
      "Epoch: 45 | Batch_idx: 290 |  Loss: (0.2560) | Acc: (91.12%) (33941/37248)\n",
      "Epoch: 45 | Batch_idx: 300 |  Loss: (0.2571) | Acc: (91.09%) (35094/38528)\n",
      "Epoch: 45 | Batch_idx: 310 |  Loss: (0.2582) | Acc: (91.05%) (36246/39808)\n",
      "Epoch: 45 | Batch_idx: 320 |  Loss: (0.2592) | Acc: (91.03%) (37402/41088)\n",
      "Epoch: 45 | Batch_idx: 330 |  Loss: (0.2593) | Acc: (91.02%) (38563/42368)\n",
      "Epoch: 45 | Batch_idx: 340 |  Loss: (0.2602) | Acc: (90.98%) (39711/43648)\n",
      "Epoch: 45 | Batch_idx: 350 |  Loss: (0.2602) | Acc: (90.98%) (40876/44928)\n",
      "Epoch: 45 | Batch_idx: 360 |  Loss: (0.2601) | Acc: (91.00%) (42050/46208)\n",
      "Epoch: 45 | Batch_idx: 370 |  Loss: (0.2608) | Acc: (91.00%) (43213/47488)\n",
      "Epoch: 45 | Batch_idx: 380 |  Loss: (0.2604) | Acc: (91.00%) (44379/48768)\n",
      "Epoch: 45 | Batch_idx: 390 |  Loss: (0.2613) | Acc: (90.97%) (45484/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5250) | Acc: (83.43%) (8343/10000)\n",
      "Epoch: 46 | Batch_idx: 0 |  Loss: (0.2160) | Acc: (92.97%) (119/128)\n",
      "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2672) | Acc: (90.41%) (1273/1408)\n",
      "Epoch: 46 | Batch_idx: 20 |  Loss: (0.2692) | Acc: (90.44%) (2431/2688)\n",
      "Epoch: 46 | Batch_idx: 30 |  Loss: (0.2644) | Acc: (90.47%) (3590/3968)\n",
      "Epoch: 46 | Batch_idx: 40 |  Loss: (0.2597) | Acc: (90.83%) (4767/5248)\n",
      "Epoch: 46 | Batch_idx: 50 |  Loss: (0.2579) | Acc: (90.87%) (5932/6528)\n",
      "Epoch: 46 | Batch_idx: 60 |  Loss: (0.2568) | Acc: (90.88%) (7096/7808)\n",
      "Epoch: 46 | Batch_idx: 70 |  Loss: (0.2571) | Acc: (90.88%) (8259/9088)\n",
      "Epoch: 46 | Batch_idx: 80 |  Loss: (0.2543) | Acc: (91.06%) (9441/10368)\n",
      "Epoch: 46 | Batch_idx: 90 |  Loss: (0.2581) | Acc: (90.89%) (10587/11648)\n",
      "Epoch: 46 | Batch_idx: 100 |  Loss: (0.2582) | Acc: (90.91%) (11753/12928)\n",
      "Epoch: 46 | Batch_idx: 110 |  Loss: (0.2565) | Acc: (91.03%) (12933/14208)\n",
      "Epoch: 46 | Batch_idx: 120 |  Loss: (0.2561) | Acc: (91.08%) (14107/15488)\n",
      "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2566) | Acc: (91.14%) (15282/16768)\n",
      "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2548) | Acc: (91.18%) (16457/18048)\n",
      "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2545) | Acc: (91.20%) (17627/19328)\n",
      "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2561) | Acc: (91.17%) (18789/20608)\n",
      "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2569) | Acc: (91.16%) (19954/21888)\n",
      "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2552) | Acc: (91.23%) (21136/23168)\n",
      "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2552) | Acc: (91.23%) (22305/24448)\n",
      "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2552) | Acc: (91.25%) (23476/25728)\n",
      "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2548) | Acc: (91.30%) (24658/27008)\n",
      "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2550) | Acc: (91.28%) (25822/28288)\n",
      "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2561) | Acc: (91.26%) (26984/29568)\n",
      "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2569) | Acc: (91.22%) (28140/30848)\n",
      "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2582) | Acc: (91.15%) (29286/32128)\n",
      "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2586) | Acc: (91.15%) (30453/33408)\n",
      "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2595) | Acc: (91.13%) (31610/34688)\n",
      "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2596) | Acc: (91.11%) (32772/35968)\n",
      "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2591) | Acc: (91.12%) (33939/37248)\n",
      "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2592) | Acc: (91.10%) (35099/38528)\n",
      "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2603) | Acc: (91.09%) (36261/39808)\n",
      "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2605) | Acc: (91.06%) (37414/41088)\n",
      "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2609) | Acc: (91.04%) (38572/42368)\n",
      "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2609) | Acc: (91.04%) (39739/43648)\n",
      "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2613) | Acc: (91.03%) (40898/44928)\n",
      "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2621) | Acc: (90.99%) (42044/46208)\n",
      "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2625) | Acc: (90.97%) (43201/47488)\n",
      "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2636) | Acc: (90.90%) (44331/48768)\n",
      "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2635) | Acc: (90.90%) (45450/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4958) | Acc: (84.75%) (8475/10000)\n",
      "Epoch: 47 | Batch_idx: 0 |  Loss: (0.1891) | Acc: (92.19%) (118/128)\n",
      "Epoch: 47 | Batch_idx: 10 |  Loss: (0.2266) | Acc: (92.19%) (1298/1408)\n",
      "Epoch: 47 | Batch_idx: 20 |  Loss: (0.2429) | Acc: (91.59%) (2462/2688)\n",
      "Epoch: 47 | Batch_idx: 30 |  Loss: (0.2455) | Acc: (91.56%) (3633/3968)\n",
      "Epoch: 47 | Batch_idx: 40 |  Loss: (0.2601) | Acc: (90.99%) (4775/5248)\n",
      "Epoch: 47 | Batch_idx: 50 |  Loss: (0.2533) | Acc: (91.33%) (5962/6528)\n",
      "Epoch: 47 | Batch_idx: 60 |  Loss: (0.2486) | Acc: (91.48%) (7143/7808)\n",
      "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2457) | Acc: (91.49%) (8315/9088)\n",
      "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2456) | Acc: (91.53%) (9490/10368)\n",
      "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2462) | Acc: (91.53%) (10661/11648)\n",
      "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2479) | Acc: (91.39%) (11815/12928)\n",
      "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2456) | Acc: (91.47%) (12996/14208)\n",
      "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2447) | Acc: (91.59%) (14186/15488)\n",
      "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2452) | Acc: (91.59%) (15358/16768)\n",
      "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2463) | Acc: (91.54%) (16521/18048)\n",
      "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2442) | Acc: (91.61%) (17707/19328)\n",
      "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2444) | Acc: (91.61%) (18880/20608)\n",
      "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2446) | Acc: (91.55%) (20039/21888)\n",
      "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2443) | Acc: (91.58%) (21218/23168)\n",
      "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2442) | Acc: (91.59%) (22391/24448)\n",
      "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2448) | Acc: (91.59%) (23563/25728)\n",
      "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2447) | Acc: (91.61%) (24741/27008)\n",
      "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2439) | Acc: (91.63%) (25921/28288)\n",
      "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2432) | Acc: (91.63%) (27094/29568)\n",
      "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2436) | Acc: (91.63%) (28265/30848)\n",
      "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2449) | Acc: (91.61%) (29433/32128)\n",
      "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2458) | Acc: (91.56%) (30589/33408)\n",
      "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2461) | Acc: (91.56%) (31761/34688)\n",
      "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2470) | Acc: (91.55%) (32930/35968)\n",
      "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2466) | Acc: (91.57%) (34108/37248)\n",
      "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2470) | Acc: (91.55%) (35272/38528)\n",
      "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2467) | Acc: (91.55%) (36446/39808)\n",
      "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2481) | Acc: (91.50%) (37595/41088)\n",
      "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2490) | Acc: (91.47%) (38755/42368)\n",
      "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2513) | Acc: (91.41%) (39899/43648)\n",
      "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2509) | Acc: (91.42%) (41075/44928)\n",
      "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2511) | Acc: (91.39%) (42230/46208)\n",
      "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2515) | Acc: (91.36%) (43385/47488)\n",
      "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2522) | Acc: (91.34%) (44544/48768)\n",
      "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2515) | Acc: (91.35%) (45675/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4491) | Acc: (85.93%) (8593/10000)\n",
      "Epoch: 48 | Batch_idx: 0 |  Loss: (0.1588) | Acc: (94.53%) (121/128)\n",
      "Epoch: 48 | Batch_idx: 10 |  Loss: (0.2457) | Acc: (90.98%) (1281/1408)\n",
      "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2404) | Acc: (91.26%) (2453/2688)\n",
      "Epoch: 48 | Batch_idx: 30 |  Loss: (0.2483) | Acc: (91.10%) (3615/3968)\n",
      "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2507) | Acc: (90.85%) (4768/5248)\n",
      "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2520) | Acc: (90.90%) (5934/6528)\n",
      "Epoch: 48 | Batch_idx: 60 |  Loss: (0.2471) | Acc: (91.25%) (7125/7808)\n",
      "Epoch: 48 | Batch_idx: 70 |  Loss: (0.2471) | Acc: (91.13%) (8282/9088)\n",
      "Epoch: 48 | Batch_idx: 80 |  Loss: (0.2490) | Acc: (91.17%) (9453/10368)\n",
      "Epoch: 48 | Batch_idx: 90 |  Loss: (0.2463) | Acc: (91.33%) (10638/11648)\n",
      "Epoch: 48 | Batch_idx: 100 |  Loss: (0.2474) | Acc: (91.34%) (11808/12928)\n",
      "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2466) | Acc: (91.39%) (12984/14208)\n",
      "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2454) | Acc: (91.41%) (14158/15488)\n",
      "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2455) | Acc: (91.50%) (15342/16768)\n",
      "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2466) | Acc: (91.46%) (16506/18048)\n",
      "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2455) | Acc: (91.49%) (17683/19328)\n",
      "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2457) | Acc: (91.45%) (18846/20608)\n",
      "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2457) | Acc: (91.45%) (20017/21888)\n",
      "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2455) | Acc: (91.46%) (21189/23168)\n",
      "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2439) | Acc: (91.53%) (22377/24448)\n",
      "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2435) | Acc: (91.56%) (23557/25728)\n",
      "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2438) | Acc: (91.55%) (24727/27008)\n",
      "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2440) | Acc: (91.56%) (25900/28288)\n",
      "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2433) | Acc: (91.57%) (27075/29568)\n",
      "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2425) | Acc: (91.60%) (28256/30848)\n",
      "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2433) | Acc: (91.58%) (29422/32128)\n",
      "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2433) | Acc: (91.57%) (30593/33408)\n",
      "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2426) | Acc: (91.58%) (31766/34688)\n",
      "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2422) | Acc: (91.59%) (32942/35968)\n",
      "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2414) | Acc: (91.60%) (34121/37248)\n",
      "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2423) | Acc: (91.59%) (35286/38528)\n",
      "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2424) | Acc: (91.59%) (36460/39808)\n",
      "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2432) | Acc: (91.55%) (37617/41088)\n",
      "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2433) | Acc: (91.56%) (38792/42368)\n",
      "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2438) | Acc: (91.53%) (39951/43648)\n",
      "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2434) | Acc: (91.56%) (41134/44928)\n",
      "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2438) | Acc: (91.54%) (42301/46208)\n",
      "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2434) | Acc: (91.56%) (43479/47488)\n",
      "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2443) | Acc: (91.53%) (44635/48768)\n",
      "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2451) | Acc: (91.50%) (45748/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4799) | Acc: (85.49%) (8549/10000)\n",
      "Epoch: 49 | Batch_idx: 0 |  Loss: (0.3249) | Acc: (85.94%) (110/128)\n",
      "Epoch: 49 | Batch_idx: 10 |  Loss: (0.2280) | Acc: (92.76%) (1306/1408)\n",
      "Epoch: 49 | Batch_idx: 20 |  Loss: (0.2316) | Acc: (92.11%) (2476/2688)\n",
      "Epoch: 49 | Batch_idx: 30 |  Loss: (0.2267) | Acc: (92.44%) (3668/3968)\n",
      "Epoch: 49 | Batch_idx: 40 |  Loss: (0.2199) | Acc: (92.66%) (4863/5248)\n",
      "Epoch: 49 | Batch_idx: 50 |  Loss: (0.2196) | Acc: (92.66%) (6049/6528)\n",
      "Epoch: 49 | Batch_idx: 60 |  Loss: (0.2257) | Acc: (92.42%) (7216/7808)\n",
      "Epoch: 49 | Batch_idx: 70 |  Loss: (0.2285) | Acc: (92.17%) (8376/9088)\n",
      "Epoch: 49 | Batch_idx: 80 |  Loss: (0.2329) | Acc: (91.96%) (9534/10368)\n",
      "Epoch: 49 | Batch_idx: 90 |  Loss: (0.2318) | Acc: (91.99%) (10715/11648)\n",
      "Epoch: 49 | Batch_idx: 100 |  Loss: (0.2312) | Acc: (91.99%) (11893/12928)\n",
      "Epoch: 49 | Batch_idx: 110 |  Loss: (0.2303) | Acc: (92.03%) (13076/14208)\n",
      "Epoch: 49 | Batch_idx: 120 |  Loss: (0.2314) | Acc: (92.01%) (14250/15488)\n",
      "Epoch: 49 | Batch_idx: 130 |  Loss: (0.2309) | Acc: (92.02%) (15430/16768)\n",
      "Epoch: 49 | Batch_idx: 140 |  Loss: (0.2294) | Acc: (92.11%) (16624/18048)\n",
      "Epoch: 49 | Batch_idx: 150 |  Loss: (0.2293) | Acc: (92.14%) (17808/19328)\n",
      "Epoch: 49 | Batch_idx: 160 |  Loss: (0.2289) | Acc: (92.11%) (18983/20608)\n",
      "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2291) | Acc: (92.11%) (20161/21888)\n",
      "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2292) | Acc: (92.09%) (21336/23168)\n",
      "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2315) | Acc: (92.01%) (22495/24448)\n",
      "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2325) | Acc: (91.96%) (23659/25728)\n",
      "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2336) | Acc: (91.89%) (24819/27008)\n",
      "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2340) | Acc: (91.88%) (25990/28288)\n",
      "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2356) | Acc: (91.83%) (27151/29568)\n",
      "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2356) | Acc: (91.83%) (28329/30848)\n",
      "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2348) | Acc: (91.86%) (29514/32128)\n",
      "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2354) | Acc: (91.84%) (30681/33408)\n",
      "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2365) | Acc: (91.80%) (31842/34688)\n",
      "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2368) | Acc: (91.79%) (33016/35968)\n",
      "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2379) | Acc: (91.75%) (34174/37248)\n",
      "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2388) | Acc: (91.72%) (35338/38528)\n",
      "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2396) | Acc: (91.70%) (36505/39808)\n",
      "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2392) | Acc: (91.72%) (37686/41088)\n",
      "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2396) | Acc: (91.70%) (38850/42368)\n",
      "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2399) | Acc: (91.66%) (40009/43648)\n",
      "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2399) | Acc: (91.68%) (41188/44928)\n",
      "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2407) | Acc: (91.64%) (42343/46208)\n",
      "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2412) | Acc: (91.61%) (43505/47488)\n",
      "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2419) | Acc: (91.60%) (44670/48768)\n",
      "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2426) | Acc: (91.59%) (45794/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4554) | Acc: (85.33%) (8533/10000)\n",
      "Epoch: 50 | Batch_idx: 0 |  Loss: (0.2269) | Acc: (89.84%) (115/128)\n",
      "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2216) | Acc: (91.97%) (1295/1408)\n",
      "Epoch: 50 | Batch_idx: 20 |  Loss: (0.2257) | Acc: (92.04%) (2474/2688)\n",
      "Epoch: 50 | Batch_idx: 30 |  Loss: (0.2211) | Acc: (92.19%) (3658/3968)\n",
      "Epoch: 50 | Batch_idx: 40 |  Loss: (0.2254) | Acc: (92.04%) (4830/5248)\n",
      "Epoch: 50 | Batch_idx: 50 |  Loss: (0.2230) | Acc: (92.31%) (6026/6528)\n",
      "Epoch: 50 | Batch_idx: 60 |  Loss: (0.2222) | Acc: (92.37%) (7212/7808)\n",
      "Epoch: 50 | Batch_idx: 70 |  Loss: (0.2245) | Acc: (92.21%) (8380/9088)\n",
      "Epoch: 50 | Batch_idx: 80 |  Loss: (0.2269) | Acc: (92.04%) (9543/10368)\n",
      "Epoch: 50 | Batch_idx: 90 |  Loss: (0.2314) | Acc: (91.97%) (10713/11648)\n",
      "Epoch: 50 | Batch_idx: 100 |  Loss: (0.2328) | Acc: (91.95%) (11887/12928)\n",
      "Epoch: 50 | Batch_idx: 110 |  Loss: (0.2334) | Acc: (91.85%) (13050/14208)\n",
      "Epoch: 50 | Batch_idx: 120 |  Loss: (0.2319) | Acc: (91.92%) (14236/15488)\n",
      "Epoch: 50 | Batch_idx: 130 |  Loss: (0.2341) | Acc: (91.87%) (15405/16768)\n",
      "Epoch: 50 | Batch_idx: 140 |  Loss: (0.2323) | Acc: (91.96%) (16597/18048)\n",
      "Epoch: 50 | Batch_idx: 150 |  Loss: (0.2333) | Acc: (91.91%) (17765/19328)\n",
      "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2322) | Acc: (91.94%) (18946/20608)\n",
      "Epoch: 50 | Batch_idx: 170 |  Loss: (0.2313) | Acc: (91.98%) (20132/21888)\n",
      "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2310) | Acc: (91.99%) (21313/23168)\n",
      "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2316) | Acc: (91.95%) (22481/24448)\n",
      "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2321) | Acc: (91.98%) (23664/25728)\n",
      "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2317) | Acc: (91.97%) (24838/27008)\n",
      "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2317) | Acc: (91.97%) (26016/28288)\n",
      "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2314) | Acc: (91.98%) (27198/29568)\n",
      "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2319) | Acc: (91.97%) (28370/30848)\n",
      "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2326) | Acc: (91.93%) (29536/32128)\n",
      "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2334) | Acc: (91.90%) (30701/33408)\n",
      "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2338) | Acc: (91.88%) (31870/34688)\n",
      "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2348) | Acc: (91.85%) (33036/35968)\n",
      "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2353) | Acc: (91.84%) (34207/37248)\n",
      "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2359) | Acc: (91.80%) (35369/38528)\n",
      "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2370) | Acc: (91.74%) (36519/39808)\n",
      "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2369) | Acc: (91.72%) (37686/41088)\n",
      "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2367) | Acc: (91.72%) (38859/42368)\n",
      "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2357) | Acc: (91.75%) (40048/43648)\n",
      "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2357) | Acc: (91.76%) (41227/44928)\n",
      "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2375) | Acc: (91.68%) (42365/46208)\n",
      "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2373) | Acc: (91.70%) (43548/47488)\n",
      "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2374) | Acc: (91.70%) (44718/48768)\n",
      "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2373) | Acc: (91.69%) (45844/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5043) | Acc: (84.75%) (8475/10000)\n",
      "Epoch: 51 | Batch_idx: 0 |  Loss: (0.2207) | Acc: (91.41%) (117/128)\n",
      "Epoch: 51 | Batch_idx: 10 |  Loss: (0.2236) | Acc: (92.12%) (1297/1408)\n",
      "Epoch: 51 | Batch_idx: 20 |  Loss: (0.2204) | Acc: (92.04%) (2474/2688)\n",
      "Epoch: 51 | Batch_idx: 30 |  Loss: (0.2300) | Acc: (91.68%) (3638/3968)\n",
      "Epoch: 51 | Batch_idx: 40 |  Loss: (0.2364) | Acc: (91.52%) (4803/5248)\n",
      "Epoch: 51 | Batch_idx: 50 |  Loss: (0.2329) | Acc: (91.82%) (5994/6528)\n",
      "Epoch: 51 | Batch_idx: 60 |  Loss: (0.2333) | Acc: (91.82%) (7169/7808)\n",
      "Epoch: 51 | Batch_idx: 70 |  Loss: (0.2332) | Acc: (91.71%) (8335/9088)\n",
      "Epoch: 51 | Batch_idx: 80 |  Loss: (0.2325) | Acc: (91.79%) (9517/10368)\n",
      "Epoch: 51 | Batch_idx: 90 |  Loss: (0.2303) | Acc: (91.81%) (10694/11648)\n",
      "Epoch: 51 | Batch_idx: 100 |  Loss: (0.2307) | Acc: (91.83%) (11872/12928)\n",
      "Epoch: 51 | Batch_idx: 110 |  Loss: (0.2296) | Acc: (91.91%) (13058/14208)\n",
      "Epoch: 51 | Batch_idx: 120 |  Loss: (0.2284) | Acc: (91.97%) (14245/15488)\n",
      "Epoch: 51 | Batch_idx: 130 |  Loss: (0.2285) | Acc: (91.94%) (15417/16768)\n",
      "Epoch: 51 | Batch_idx: 140 |  Loss: (0.2279) | Acc: (91.99%) (16602/18048)\n",
      "Epoch: 51 | Batch_idx: 150 |  Loss: (0.2276) | Acc: (91.97%) (17775/19328)\n",
      "Epoch: 51 | Batch_idx: 160 |  Loss: (0.2279) | Acc: (91.97%) (18953/20608)\n",
      "Epoch: 51 | Batch_idx: 170 |  Loss: (0.2288) | Acc: (91.92%) (20119/21888)\n",
      "Epoch: 51 | Batch_idx: 180 |  Loss: (0.2285) | Acc: (91.89%) (21289/23168)\n",
      "Epoch: 51 | Batch_idx: 190 |  Loss: (0.2278) | Acc: (91.96%) (22483/24448)\n",
      "Epoch: 51 | Batch_idx: 200 |  Loss: (0.2277) | Acc: (91.97%) (23661/25728)\n",
      "Epoch: 51 | Batch_idx: 210 |  Loss: (0.2290) | Acc: (91.91%) (24823/27008)\n",
      "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2281) | Acc: (91.97%) (26017/28288)\n",
      "Epoch: 51 | Batch_idx: 230 |  Loss: (0.2269) | Acc: (92.00%) (27204/29568)\n",
      "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2269) | Acc: (92.03%) (28390/30848)\n",
      "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2264) | Acc: (92.07%) (29579/32128)\n",
      "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2252) | Acc: (92.12%) (30777/33408)\n",
      "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2263) | Acc: (92.06%) (31933/34688)\n",
      "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2270) | Acc: (92.04%) (33106/35968)\n",
      "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2270) | Acc: (92.08%) (34299/37248)\n",
      "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2271) | Acc: (92.08%) (35478/38528)\n",
      "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2266) | Acc: (92.11%) (36666/39808)\n",
      "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2262) | Acc: (92.11%) (37848/41088)\n",
      "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2259) | Acc: (92.11%) (39024/42368)\n",
      "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2263) | Acc: (92.11%) (40204/43648)\n",
      "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2269) | Acc: (92.09%) (41375/44928)\n",
      "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2272) | Acc: (92.08%) (42550/46208)\n",
      "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2280) | Acc: (92.06%) (43716/47488)\n",
      "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2284) | Acc: (92.06%) (44895/48768)\n",
      "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2283) | Acc: (92.07%) (46035/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4668) | Acc: (86.04%) (8604/10000)\n",
      "Epoch: 52 | Batch_idx: 0 |  Loss: (0.2199) | Acc: (94.53%) (121/128)\n",
      "Epoch: 52 | Batch_idx: 10 |  Loss: (0.2206) | Acc: (92.54%) (1303/1408)\n",
      "Epoch: 52 | Batch_idx: 20 |  Loss: (0.2071) | Acc: (92.97%) (2499/2688)\n",
      "Epoch: 52 | Batch_idx: 30 |  Loss: (0.2008) | Acc: (93.32%) (3703/3968)\n",
      "Epoch: 52 | Batch_idx: 40 |  Loss: (0.2014) | Acc: (93.25%) (4894/5248)\n",
      "Epoch: 52 | Batch_idx: 50 |  Loss: (0.2087) | Acc: (92.89%) (6064/6528)\n",
      "Epoch: 52 | Batch_idx: 60 |  Loss: (0.2064) | Acc: (92.90%) (7254/7808)\n",
      "Epoch: 52 | Batch_idx: 70 |  Loss: (0.2081) | Acc: (92.83%) (8436/9088)\n",
      "Epoch: 52 | Batch_idx: 80 |  Loss: (0.2104) | Acc: (92.86%) (9628/10368)\n",
      "Epoch: 52 | Batch_idx: 90 |  Loss: (0.2114) | Acc: (92.91%) (10822/11648)\n",
      "Epoch: 52 | Batch_idx: 100 |  Loss: (0.2113) | Acc: (92.98%) (12020/12928)\n",
      "Epoch: 52 | Batch_idx: 110 |  Loss: (0.2135) | Acc: (92.81%) (13187/14208)\n",
      "Epoch: 52 | Batch_idx: 120 |  Loss: (0.2158) | Acc: (92.66%) (14351/15488)\n",
      "Epoch: 52 | Batch_idx: 130 |  Loss: (0.2170) | Acc: (92.58%) (15523/16768)\n",
      "Epoch: 52 | Batch_idx: 140 |  Loss: (0.2189) | Acc: (92.51%) (16696/18048)\n",
      "Epoch: 52 | Batch_idx: 150 |  Loss: (0.2181) | Acc: (92.52%) (17882/19328)\n",
      "Epoch: 52 | Batch_idx: 160 |  Loss: (0.2178) | Acc: (92.56%) (19075/20608)\n",
      "Epoch: 52 | Batch_idx: 170 |  Loss: (0.2197) | Acc: (92.41%) (20226/21888)\n",
      "Epoch: 52 | Batch_idx: 180 |  Loss: (0.2215) | Acc: (92.38%) (21403/23168)\n",
      "Epoch: 52 | Batch_idx: 190 |  Loss: (0.2216) | Acc: (92.40%) (22591/24448)\n",
      "Epoch: 52 | Batch_idx: 200 |  Loss: (0.2217) | Acc: (92.38%) (23767/25728)\n",
      "Epoch: 52 | Batch_idx: 210 |  Loss: (0.2224) | Acc: (92.31%) (24932/27008)\n",
      "Epoch: 52 | Batch_idx: 220 |  Loss: (0.2239) | Acc: (92.28%) (26105/28288)\n",
      "Epoch: 52 | Batch_idx: 230 |  Loss: (0.2243) | Acc: (92.29%) (27289/29568)\n",
      "Epoch: 52 | Batch_idx: 240 |  Loss: (0.2234) | Acc: (92.31%) (28475/30848)\n",
      "Epoch: 52 | Batch_idx: 250 |  Loss: (0.2238) | Acc: (92.28%) (29649/32128)\n",
      "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2246) | Acc: (92.25%) (30819/33408)\n",
      "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2255) | Acc: (92.20%) (31982/34688)\n",
      "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2259) | Acc: (92.20%) (33163/35968)\n",
      "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2269) | Acc: (92.17%) (34330/37248)\n",
      "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2272) | Acc: (92.15%) (35504/38528)\n",
      "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2273) | Acc: (92.16%) (36686/39808)\n",
      "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2283) | Acc: (92.14%) (37860/41088)\n",
      "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2279) | Acc: (92.19%) (39060/42368)\n",
      "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2275) | Acc: (92.20%) (40244/43648)\n",
      "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2275) | Acc: (92.17%) (41409/44928)\n",
      "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2273) | Acc: (92.17%) (42589/46208)\n",
      "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2272) | Acc: (92.15%) (43761/47488)\n",
      "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2280) | Acc: (92.13%) (44931/48768)\n",
      "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2283) | Acc: (92.11%) (46057/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4543) | Acc: (85.95%) (8595/10000)\n",
      "Epoch: 53 | Batch_idx: 0 |  Loss: (0.1336) | Acc: (96.09%) (123/128)\n",
      "Epoch: 53 | Batch_idx: 10 |  Loss: (0.2323) | Acc: (92.26%) (1299/1408)\n",
      "Epoch: 53 | Batch_idx: 20 |  Loss: (0.2251) | Acc: (92.49%) (2486/2688)\n",
      "Epoch: 53 | Batch_idx: 30 |  Loss: (0.2286) | Acc: (92.01%) (3651/3968)\n",
      "Epoch: 53 | Batch_idx: 40 |  Loss: (0.2231) | Acc: (92.09%) (4833/5248)\n",
      "Epoch: 53 | Batch_idx: 50 |  Loss: (0.2241) | Acc: (92.05%) (6009/6528)\n",
      "Epoch: 53 | Batch_idx: 60 |  Loss: (0.2242) | Acc: (91.97%) (7181/7808)\n",
      "Epoch: 53 | Batch_idx: 70 |  Loss: (0.2231) | Acc: (92.06%) (8366/9088)\n",
      "Epoch: 53 | Batch_idx: 80 |  Loss: (0.2200) | Acc: (92.19%) (9558/10368)\n",
      "Epoch: 53 | Batch_idx: 90 |  Loss: (0.2194) | Acc: (92.26%) (10746/11648)\n",
      "Epoch: 53 | Batch_idx: 100 |  Loss: (0.2175) | Acc: (92.37%) (11941/12928)\n",
      "Epoch: 53 | Batch_idx: 110 |  Loss: (0.2151) | Acc: (92.48%) (13140/14208)\n",
      "Epoch: 53 | Batch_idx: 120 |  Loss: (0.2152) | Acc: (92.46%) (14320/15488)\n",
      "Epoch: 53 | Batch_idx: 130 |  Loss: (0.2138) | Acc: (92.53%) (15516/16768)\n",
      "Epoch: 53 | Batch_idx: 140 |  Loss: (0.2143) | Acc: (92.52%) (16698/18048)\n",
      "Epoch: 53 | Batch_idx: 150 |  Loss: (0.2168) | Acc: (92.41%) (17861/19328)\n",
      "Epoch: 53 | Batch_idx: 160 |  Loss: (0.2178) | Acc: (92.29%) (19019/20608)\n",
      "Epoch: 53 | Batch_idx: 170 |  Loss: (0.2188) | Acc: (92.24%) (20190/21888)\n",
      "Epoch: 53 | Batch_idx: 180 |  Loss: (0.2182) | Acc: (92.26%) (21375/23168)\n",
      "Epoch: 53 | Batch_idx: 190 |  Loss: (0.2192) | Acc: (92.18%) (22537/24448)\n",
      "Epoch: 53 | Batch_idx: 200 |  Loss: (0.2209) | Acc: (92.13%) (23703/25728)\n",
      "Epoch: 53 | Batch_idx: 210 |  Loss: (0.2214) | Acc: (92.15%) (24889/27008)\n",
      "Epoch: 53 | Batch_idx: 220 |  Loss: (0.2227) | Acc: (92.10%) (26054/28288)\n",
      "Epoch: 53 | Batch_idx: 230 |  Loss: (0.2227) | Acc: (92.04%) (27215/29568)\n",
      "Epoch: 53 | Batch_idx: 240 |  Loss: (0.2222) | Acc: (92.04%) (28392/30848)\n",
      "Epoch: 53 | Batch_idx: 250 |  Loss: (0.2214) | Acc: (92.08%) (29584/32128)\n",
      "Epoch: 53 | Batch_idx: 260 |  Loss: (0.2213) | Acc: (92.11%) (30772/33408)\n",
      "Epoch: 53 | Batch_idx: 270 |  Loss: (0.2206) | Acc: (92.15%) (31966/34688)\n",
      "Epoch: 53 | Batch_idx: 280 |  Loss: (0.2202) | Acc: (92.19%) (33158/35968)\n",
      "Epoch: 53 | Batch_idx: 290 |  Loss: (0.2209) | Acc: (92.14%) (34320/37248)\n",
      "Epoch: 53 | Batch_idx: 300 |  Loss: (0.2210) | Acc: (92.11%) (35487/38528)\n",
      "Epoch: 53 | Batch_idx: 310 |  Loss: (0.2207) | Acc: (92.10%) (36665/39808)\n",
      "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2203) | Acc: (92.13%) (37855/41088)\n",
      "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2203) | Acc: (92.15%) (39041/42368)\n",
      "Epoch: 53 | Batch_idx: 340 |  Loss: (0.2203) | Acc: (92.15%) (40223/43648)\n",
      "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2198) | Acc: (92.17%) (41410/44928)\n",
      "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2202) | Acc: (92.17%) (42589/46208)\n",
      "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2203) | Acc: (92.18%) (43776/47488)\n",
      "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2208) | Acc: (92.17%) (44950/48768)\n",
      "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2222) | Acc: (92.14%) (46069/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4531) | Acc: (85.52%) (8552/10000)\n",
      "Epoch: 54 | Batch_idx: 0 |  Loss: (0.1107) | Acc: (97.66%) (125/128)\n",
      "Epoch: 54 | Batch_idx: 10 |  Loss: (0.2053) | Acc: (92.68%) (1305/1408)\n",
      "Epoch: 54 | Batch_idx: 20 |  Loss: (0.1936) | Acc: (93.38%) (2510/2688)\n",
      "Epoch: 54 | Batch_idx: 30 |  Loss: (0.2008) | Acc: (93.04%) (3692/3968)\n",
      "Epoch: 54 | Batch_idx: 40 |  Loss: (0.2043) | Acc: (92.78%) (4869/5248)\n",
      "Epoch: 54 | Batch_idx: 50 |  Loss: (0.2037) | Acc: (92.89%) (6064/6528)\n",
      "Epoch: 54 | Batch_idx: 60 |  Loss: (0.2027) | Acc: (93.05%) (7265/7808)\n",
      "Epoch: 54 | Batch_idx: 70 |  Loss: (0.2016) | Acc: (93.07%) (8458/9088)\n",
      "Epoch: 54 | Batch_idx: 80 |  Loss: (0.2086) | Acc: (92.91%) (9633/10368)\n",
      "Epoch: 54 | Batch_idx: 90 |  Loss: (0.2104) | Acc: (92.89%) (10820/11648)\n",
      "Epoch: 54 | Batch_idx: 100 |  Loss: (0.2096) | Acc: (92.87%) (12006/12928)\n",
      "Epoch: 54 | Batch_idx: 110 |  Loss: (0.2089) | Acc: (92.83%) (13189/14208)\n",
      "Epoch: 54 | Batch_idx: 120 |  Loss: (0.2079) | Acc: (92.83%) (14378/15488)\n",
      "Epoch: 54 | Batch_idx: 130 |  Loss: (0.2085) | Acc: (92.84%) (15568/16768)\n",
      "Epoch: 54 | Batch_idx: 140 |  Loss: (0.2090) | Acc: (92.87%) (16761/18048)\n",
      "Epoch: 54 | Batch_idx: 150 |  Loss: (0.2081) | Acc: (92.91%) (17958/19328)\n",
      "Epoch: 54 | Batch_idx: 160 |  Loss: (0.2101) | Acc: (92.85%) (19134/20608)\n",
      "Epoch: 54 | Batch_idx: 170 |  Loss: (0.2087) | Acc: (92.88%) (20330/21888)\n",
      "Epoch: 54 | Batch_idx: 180 |  Loss: (0.2094) | Acc: (92.83%) (21508/23168)\n",
      "Epoch: 54 | Batch_idx: 190 |  Loss: (0.2092) | Acc: (92.86%) (22702/24448)\n",
      "Epoch: 54 | Batch_idx: 200 |  Loss: (0.2113) | Acc: (92.79%) (23872/25728)\n",
      "Epoch: 54 | Batch_idx: 210 |  Loss: (0.2101) | Acc: (92.85%) (25078/27008)\n",
      "Epoch: 54 | Batch_idx: 220 |  Loss: (0.2111) | Acc: (92.80%) (26251/28288)\n",
      "Epoch: 54 | Batch_idx: 230 |  Loss: (0.2112) | Acc: (92.79%) (27437/29568)\n",
      "Epoch: 54 | Batch_idx: 240 |  Loss: (0.2113) | Acc: (92.79%) (28625/30848)\n",
      "Epoch: 54 | Batch_idx: 250 |  Loss: (0.2121) | Acc: (92.76%) (29802/32128)\n",
      "Epoch: 54 | Batch_idx: 260 |  Loss: (0.2125) | Acc: (92.73%) (30979/33408)\n",
      "Epoch: 54 | Batch_idx: 270 |  Loss: (0.2121) | Acc: (92.74%) (32171/34688)\n",
      "Epoch: 54 | Batch_idx: 280 |  Loss: (0.2122) | Acc: (92.73%) (33354/35968)\n",
      "Epoch: 54 | Batch_idx: 290 |  Loss: (0.2134) | Acc: (92.68%) (34522/37248)\n",
      "Epoch: 54 | Batch_idx: 300 |  Loss: (0.2135) | Acc: (92.69%) (35710/38528)\n",
      "Epoch: 54 | Batch_idx: 310 |  Loss: (0.2139) | Acc: (92.66%) (36888/39808)\n",
      "Epoch: 54 | Batch_idx: 320 |  Loss: (0.2143) | Acc: (92.64%) (38063/41088)\n",
      "Epoch: 54 | Batch_idx: 330 |  Loss: (0.2144) | Acc: (92.63%) (39245/42368)\n",
      "Epoch: 54 | Batch_idx: 340 |  Loss: (0.2148) | Acc: (92.60%) (40417/43648)\n",
      "Epoch: 54 | Batch_idx: 350 |  Loss: (0.2144) | Acc: (92.62%) (41612/44928)\n",
      "Epoch: 54 | Batch_idx: 360 |  Loss: (0.2149) | Acc: (92.61%) (42794/46208)\n",
      "Epoch: 54 | Batch_idx: 370 |  Loss: (0.2144) | Acc: (92.62%) (43984/47488)\n",
      "Epoch: 54 | Batch_idx: 380 |  Loss: (0.2150) | Acc: (92.59%) (45156/48768)\n",
      "Epoch: 54 | Batch_idx: 390 |  Loss: (0.2150) | Acc: (92.58%) (46289/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4585) | Acc: (86.02%) (8602/10000)\n",
      "Epoch: 55 | Batch_idx: 0 |  Loss: (0.2749) | Acc: (90.62%) (116/128)\n",
      "Epoch: 55 | Batch_idx: 10 |  Loss: (0.1988) | Acc: (93.04%) (1310/1408)\n",
      "Epoch: 55 | Batch_idx: 20 |  Loss: (0.1872) | Acc: (93.38%) (2510/2688)\n",
      "Epoch: 55 | Batch_idx: 30 |  Loss: (0.1924) | Acc: (93.50%) (3710/3968)\n",
      "Epoch: 55 | Batch_idx: 40 |  Loss: (0.2067) | Acc: (92.89%) (4875/5248)\n",
      "Epoch: 55 | Batch_idx: 50 |  Loss: (0.2023) | Acc: (93.03%) (6073/6528)\n",
      "Epoch: 55 | Batch_idx: 60 |  Loss: (0.2009) | Acc: (93.22%) (7279/7808)\n",
      "Epoch: 55 | Batch_idx: 70 |  Loss: (0.1997) | Acc: (93.32%) (8481/9088)\n",
      "Epoch: 55 | Batch_idx: 80 |  Loss: (0.2014) | Acc: (93.18%) (9661/10368)\n",
      "Epoch: 55 | Batch_idx: 90 |  Loss: (0.2044) | Acc: (93.08%) (10842/11648)\n",
      "Epoch: 55 | Batch_idx: 100 |  Loss: (0.2030) | Acc: (93.15%) (12042/12928)\n",
      "Epoch: 55 | Batch_idx: 110 |  Loss: (0.2021) | Acc: (93.11%) (13229/14208)\n",
      "Epoch: 55 | Batch_idx: 120 |  Loss: (0.2026) | Acc: (93.06%) (14413/15488)\n",
      "Epoch: 55 | Batch_idx: 130 |  Loss: (0.2043) | Acc: (92.94%) (15585/16768)\n",
      "Epoch: 55 | Batch_idx: 140 |  Loss: (0.2056) | Acc: (92.89%) (16765/18048)\n",
      "Epoch: 55 | Batch_idx: 150 |  Loss: (0.2057) | Acc: (92.83%) (17943/19328)\n",
      "Epoch: 55 | Batch_idx: 160 |  Loss: (0.2066) | Acc: (92.81%) (19126/20608)\n",
      "Epoch: 55 | Batch_idx: 170 |  Loss: (0.2088) | Acc: (92.69%) (20288/21888)\n",
      "Epoch: 55 | Batch_idx: 180 |  Loss: (0.2095) | Acc: (92.69%) (21474/23168)\n",
      "Epoch: 55 | Batch_idx: 190 |  Loss: (0.2097) | Acc: (92.66%) (22653/24448)\n",
      "Epoch: 55 | Batch_idx: 200 |  Loss: (0.2113) | Acc: (92.62%) (23830/25728)\n",
      "Epoch: 55 | Batch_idx: 210 |  Loss: (0.2116) | Acc: (92.61%) (25013/27008)\n",
      "Epoch: 55 | Batch_idx: 220 |  Loss: (0.2119) | Acc: (92.62%) (26201/28288)\n",
      "Epoch: 55 | Batch_idx: 230 |  Loss: (0.2109) | Acc: (92.64%) (27391/29568)\n",
      "Epoch: 55 | Batch_idx: 240 |  Loss: (0.2103) | Acc: (92.66%) (28583/30848)\n",
      "Epoch: 55 | Batch_idx: 250 |  Loss: (0.2107) | Acc: (92.63%) (29760/32128)\n",
      "Epoch: 55 | Batch_idx: 260 |  Loss: (0.2105) | Acc: (92.66%) (30957/33408)\n",
      "Epoch: 55 | Batch_idx: 270 |  Loss: (0.2105) | Acc: (92.64%) (32135/34688)\n",
      "Epoch: 55 | Batch_idx: 280 |  Loss: (0.2105) | Acc: (92.64%) (33320/35968)\n",
      "Epoch: 55 | Batch_idx: 290 |  Loss: (0.2108) | Acc: (92.62%) (34498/37248)\n",
      "Epoch: 55 | Batch_idx: 300 |  Loss: (0.2111) | Acc: (92.62%) (35685/38528)\n",
      "Epoch: 55 | Batch_idx: 310 |  Loss: (0.2117) | Acc: (92.61%) (36867/39808)\n",
      "Epoch: 55 | Batch_idx: 320 |  Loss: (0.2128) | Acc: (92.57%) (38037/41088)\n",
      "Epoch: 55 | Batch_idx: 330 |  Loss: (0.2126) | Acc: (92.57%) (39220/42368)\n",
      "Epoch: 55 | Batch_idx: 340 |  Loss: (0.2128) | Acc: (92.57%) (40405/43648)\n",
      "Epoch: 55 | Batch_idx: 350 |  Loss: (0.2126) | Acc: (92.58%) (41596/44928)\n",
      "Epoch: 55 | Batch_idx: 360 |  Loss: (0.2133) | Acc: (92.57%) (42776/46208)\n",
      "Epoch: 55 | Batch_idx: 370 |  Loss: (0.2133) | Acc: (92.56%) (43955/47488)\n",
      "Epoch: 55 | Batch_idx: 380 |  Loss: (0.2137) | Acc: (92.55%) (45134/48768)\n",
      "Epoch: 55 | Batch_idx: 390 |  Loss: (0.2129) | Acc: (92.57%) (46284/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4458) | Acc: (86.23%) (8623/10000)\n",
      "Epoch: 56 | Batch_idx: 0 |  Loss: (0.2103) | Acc: (92.19%) (118/128)\n",
      "Epoch: 56 | Batch_idx: 10 |  Loss: (0.1883) | Acc: (92.61%) (1304/1408)\n",
      "Epoch: 56 | Batch_idx: 20 |  Loss: (0.1944) | Acc: (92.86%) (2496/2688)\n",
      "Epoch: 56 | Batch_idx: 30 |  Loss: (0.1941) | Acc: (93.07%) (3693/3968)\n",
      "Epoch: 56 | Batch_idx: 40 |  Loss: (0.2040) | Acc: (92.93%) (4877/5248)\n",
      "Epoch: 56 | Batch_idx: 50 |  Loss: (0.2041) | Acc: (92.91%) (6065/6528)\n",
      "Epoch: 56 | Batch_idx: 60 |  Loss: (0.2046) | Acc: (92.92%) (7255/7808)\n",
      "Epoch: 56 | Batch_idx: 70 |  Loss: (0.2001) | Acc: (93.01%) (8453/9088)\n",
      "Epoch: 56 | Batch_idx: 80 |  Loss: (0.2018) | Acc: (92.83%) (9625/10368)\n",
      "Epoch: 56 | Batch_idx: 90 |  Loss: (0.2001) | Acc: (92.92%) (10823/11648)\n",
      "Epoch: 56 | Batch_idx: 100 |  Loss: (0.2013) | Acc: (92.78%) (11995/12928)\n",
      "Epoch: 56 | Batch_idx: 110 |  Loss: (0.2027) | Acc: (92.74%) (13176/14208)\n",
      "Epoch: 56 | Batch_idx: 120 |  Loss: (0.2043) | Acc: (92.68%) (14355/15488)\n",
      "Epoch: 56 | Batch_idx: 130 |  Loss: (0.2023) | Acc: (92.76%) (15554/16768)\n",
      "Epoch: 56 | Batch_idx: 140 |  Loss: (0.2037) | Acc: (92.69%) (16728/18048)\n",
      "Epoch: 56 | Batch_idx: 150 |  Loss: (0.2022) | Acc: (92.72%) (17921/19328)\n",
      "Epoch: 56 | Batch_idx: 160 |  Loss: (0.2011) | Acc: (92.79%) (19122/20608)\n",
      "Epoch: 56 | Batch_idx: 170 |  Loss: (0.2020) | Acc: (92.80%) (20311/21888)\n",
      "Epoch: 56 | Batch_idx: 180 |  Loss: (0.2028) | Acc: (92.81%) (21503/23168)\n",
      "Epoch: 56 | Batch_idx: 190 |  Loss: (0.2036) | Acc: (92.78%) (22683/24448)\n",
      "Epoch: 56 | Batch_idx: 200 |  Loss: (0.2033) | Acc: (92.77%) (23869/25728)\n",
      "Epoch: 56 | Batch_idx: 210 |  Loss: (0.2041) | Acc: (92.74%) (25047/27008)\n",
      "Epoch: 56 | Batch_idx: 220 |  Loss: (0.2038) | Acc: (92.79%) (26248/28288)\n",
      "Epoch: 56 | Batch_idx: 230 |  Loss: (0.2037) | Acc: (92.81%) (27441/29568)\n",
      "Epoch: 56 | Batch_idx: 240 |  Loss: (0.2035) | Acc: (92.80%) (28626/30848)\n",
      "Epoch: 56 | Batch_idx: 250 |  Loss: (0.2050) | Acc: (92.74%) (29796/32128)\n",
      "Epoch: 56 | Batch_idx: 260 |  Loss: (0.2051) | Acc: (92.69%) (30967/33408)\n",
      "Epoch: 56 | Batch_idx: 270 |  Loss: (0.2054) | Acc: (92.70%) (32156/34688)\n",
      "Epoch: 56 | Batch_idx: 280 |  Loss: (0.2057) | Acc: (92.67%) (33333/35968)\n",
      "Epoch: 56 | Batch_idx: 290 |  Loss: (0.2061) | Acc: (92.67%) (34516/37248)\n",
      "Epoch: 56 | Batch_idx: 300 |  Loss: (0.2050) | Acc: (92.71%) (35720/38528)\n",
      "Epoch: 56 | Batch_idx: 310 |  Loss: (0.2045) | Acc: (92.75%) (36921/39808)\n",
      "Epoch: 56 | Batch_idx: 320 |  Loss: (0.2045) | Acc: (92.76%) (38114/41088)\n",
      "Epoch: 56 | Batch_idx: 330 |  Loss: (0.2053) | Acc: (92.74%) (39292/42368)\n",
      "Epoch: 56 | Batch_idx: 340 |  Loss: (0.2057) | Acc: (92.74%) (40477/43648)\n",
      "Epoch: 56 | Batch_idx: 350 |  Loss: (0.2060) | Acc: (92.72%) (41659/44928)\n",
      "Epoch: 56 | Batch_idx: 360 |  Loss: (0.2072) | Acc: (92.67%) (42820/46208)\n",
      "Epoch: 56 | Batch_idx: 370 |  Loss: (0.2082) | Acc: (92.65%) (43998/47488)\n",
      "Epoch: 56 | Batch_idx: 380 |  Loss: (0.2080) | Acc: (92.67%) (45191/48768)\n",
      "Epoch: 56 | Batch_idx: 390 |  Loss: (0.2079) | Acc: (92.68%) (46338/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4464) | Acc: (86.54%) (8654/10000)\n",
      "Epoch: 57 | Batch_idx: 0 |  Loss: (0.2244) | Acc: (89.84%) (115/128)\n",
      "Epoch: 57 | Batch_idx: 10 |  Loss: (0.2079) | Acc: (92.33%) (1300/1408)\n",
      "Epoch: 57 | Batch_idx: 20 |  Loss: (0.1954) | Acc: (93.19%) (2505/2688)\n",
      "Epoch: 57 | Batch_idx: 30 |  Loss: (0.1883) | Acc: (93.35%) (3704/3968)\n",
      "Epoch: 57 | Batch_idx: 40 |  Loss: (0.1888) | Acc: (93.39%) (4901/5248)\n",
      "Epoch: 57 | Batch_idx: 50 |  Loss: (0.1834) | Acc: (93.75%) (6120/6528)\n",
      "Epoch: 57 | Batch_idx: 60 |  Loss: (0.1819) | Acc: (93.87%) (7329/7808)\n",
      "Epoch: 57 | Batch_idx: 70 |  Loss: (0.1842) | Acc: (93.81%) (8525/9088)\n",
      "Epoch: 57 | Batch_idx: 80 |  Loss: (0.1835) | Acc: (93.69%) (9714/10368)\n",
      "Epoch: 57 | Batch_idx: 90 |  Loss: (0.1854) | Acc: (93.66%) (10909/11648)\n",
      "Epoch: 57 | Batch_idx: 100 |  Loss: (0.1862) | Acc: (93.63%) (12105/12928)\n",
      "Epoch: 57 | Batch_idx: 110 |  Loss: (0.1881) | Acc: (93.50%) (13285/14208)\n",
      "Epoch: 57 | Batch_idx: 120 |  Loss: (0.1910) | Acc: (93.36%) (14459/15488)\n",
      "Epoch: 57 | Batch_idx: 130 |  Loss: (0.1930) | Acc: (93.25%) (15636/16768)\n",
      "Epoch: 57 | Batch_idx: 140 |  Loss: (0.1927) | Acc: (93.26%) (16832/18048)\n",
      "Epoch: 57 | Batch_idx: 150 |  Loss: (0.1924) | Acc: (93.25%) (18024/19328)\n",
      "Epoch: 57 | Batch_idx: 160 |  Loss: (0.1925) | Acc: (93.25%) (19216/20608)\n",
      "Epoch: 57 | Batch_idx: 170 |  Loss: (0.1924) | Acc: (93.24%) (20409/21888)\n",
      "Epoch: 57 | Batch_idx: 180 |  Loss: (0.1941) | Acc: (93.18%) (21588/23168)\n",
      "Epoch: 57 | Batch_idx: 190 |  Loss: (0.1963) | Acc: (93.15%) (22773/24448)\n",
      "Epoch: 57 | Batch_idx: 200 |  Loss: (0.1974) | Acc: (93.13%) (23961/25728)\n",
      "Epoch: 57 | Batch_idx: 210 |  Loss: (0.1985) | Acc: (93.09%) (25142/27008)\n",
      "Epoch: 57 | Batch_idx: 220 |  Loss: (0.2004) | Acc: (93.04%) (26320/28288)\n",
      "Epoch: 57 | Batch_idx: 230 |  Loss: (0.2001) | Acc: (93.04%) (27509/29568)\n",
      "Epoch: 57 | Batch_idx: 240 |  Loss: (0.2001) | Acc: (93.04%) (28700/30848)\n",
      "Epoch: 57 | Batch_idx: 250 |  Loss: (0.2016) | Acc: (92.98%) (29872/32128)\n",
      "Epoch: 57 | Batch_idx: 260 |  Loss: (0.2033) | Acc: (92.92%) (31043/33408)\n",
      "Epoch: 57 | Batch_idx: 270 |  Loss: (0.2035) | Acc: (92.92%) (32231/34688)\n",
      "Epoch: 57 | Batch_idx: 280 |  Loss: (0.2031) | Acc: (92.91%) (33419/35968)\n",
      "Epoch: 57 | Batch_idx: 290 |  Loss: (0.2027) | Acc: (92.93%) (34615/37248)\n",
      "Epoch: 57 | Batch_idx: 300 |  Loss: (0.2036) | Acc: (92.91%) (35796/38528)\n",
      "Epoch: 57 | Batch_idx: 310 |  Loss: (0.2031) | Acc: (92.92%) (36989/39808)\n",
      "Epoch: 57 | Batch_idx: 320 |  Loss: (0.2032) | Acc: (92.90%) (38169/41088)\n",
      "Epoch: 57 | Batch_idx: 330 |  Loss: (0.2037) | Acc: (92.90%) (39358/42368)\n",
      "Epoch: 57 | Batch_idx: 340 |  Loss: (0.2037) | Acc: (92.89%) (40546/43648)\n",
      "Epoch: 57 | Batch_idx: 350 |  Loss: (0.2041) | Acc: (92.89%) (41735/44928)\n",
      "Epoch: 57 | Batch_idx: 360 |  Loss: (0.2043) | Acc: (92.88%) (42919/46208)\n",
      "Epoch: 57 | Batch_idx: 370 |  Loss: (0.2041) | Acc: (92.90%) (44115/47488)\n",
      "Epoch: 57 | Batch_idx: 380 |  Loss: (0.2047) | Acc: (92.88%) (45296/48768)\n",
      "Epoch: 57 | Batch_idx: 390 |  Loss: (0.2046) | Acc: (92.89%) (46444/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4506) | Acc: (86.47%) (8647/10000)\n",
      "Epoch: 58 | Batch_idx: 0 |  Loss: (0.2112) | Acc: (92.19%) (118/128)\n",
      "Epoch: 58 | Batch_idx: 10 |  Loss: (0.1939) | Acc: (93.54%) (1317/1408)\n",
      "Epoch: 58 | Batch_idx: 20 |  Loss: (0.2168) | Acc: (92.75%) (2493/2688)\n",
      "Epoch: 58 | Batch_idx: 30 |  Loss: (0.2086) | Acc: (92.77%) (3681/3968)\n",
      "Epoch: 58 | Batch_idx: 40 |  Loss: (0.2055) | Acc: (92.80%) (4870/5248)\n",
      "Epoch: 58 | Batch_idx: 50 |  Loss: (0.1993) | Acc: (93.09%) (6077/6528)\n",
      "Epoch: 58 | Batch_idx: 60 |  Loss: (0.1972) | Acc: (93.22%) (7279/7808)\n",
      "Epoch: 58 | Batch_idx: 70 |  Loss: (0.1961) | Acc: (93.25%) (8475/9088)\n",
      "Epoch: 58 | Batch_idx: 80 |  Loss: (0.1975) | Acc: (93.18%) (9661/10368)\n",
      "Epoch: 58 | Batch_idx: 90 |  Loss: (0.1938) | Acc: (93.34%) (10872/11648)\n",
      "Epoch: 58 | Batch_idx: 100 |  Loss: (0.1957) | Acc: (93.31%) (12063/12928)\n",
      "Epoch: 58 | Batch_idx: 110 |  Loss: (0.1974) | Acc: (93.22%) (13245/14208)\n",
      "Epoch: 58 | Batch_idx: 120 |  Loss: (0.1977) | Acc: (93.19%) (14434/15488)\n",
      "Epoch: 58 | Batch_idx: 130 |  Loss: (0.1981) | Acc: (93.17%) (15623/16768)\n",
      "Epoch: 58 | Batch_idx: 140 |  Loss: (0.1978) | Acc: (93.19%) (16819/18048)\n",
      "Epoch: 58 | Batch_idx: 150 |  Loss: (0.1989) | Acc: (93.12%) (17999/19328)\n",
      "Epoch: 58 | Batch_idx: 160 |  Loss: (0.1980) | Acc: (93.18%) (19202/20608)\n",
      "Epoch: 58 | Batch_idx: 170 |  Loss: (0.1984) | Acc: (93.18%) (20395/21888)\n",
      "Epoch: 58 | Batch_idx: 180 |  Loss: (0.1981) | Acc: (93.22%) (21597/23168)\n",
      "Epoch: 58 | Batch_idx: 190 |  Loss: (0.1967) | Acc: (93.30%) (22809/24448)\n",
      "Epoch: 58 | Batch_idx: 200 |  Loss: (0.1978) | Acc: (93.26%) (23993/25728)\n",
      "Epoch: 58 | Batch_idx: 210 |  Loss: (0.1985) | Acc: (93.26%) (25187/27008)\n",
      "Epoch: 58 | Batch_idx: 220 |  Loss: (0.1990) | Acc: (93.20%) (26364/28288)\n",
      "Epoch: 58 | Batch_idx: 230 |  Loss: (0.2006) | Acc: (93.14%) (27540/29568)\n",
      "Epoch: 58 | Batch_idx: 240 |  Loss: (0.2009) | Acc: (93.12%) (28727/30848)\n",
      "Epoch: 58 | Batch_idx: 250 |  Loss: (0.2006) | Acc: (93.10%) (29911/32128)\n",
      "Epoch: 58 | Batch_idx: 260 |  Loss: (0.2010) | Acc: (93.06%) (31090/33408)\n",
      "Epoch: 58 | Batch_idx: 270 |  Loss: (0.2003) | Acc: (93.07%) (32283/34688)\n",
      "Epoch: 58 | Batch_idx: 280 |  Loss: (0.2014) | Acc: (93.05%) (33469/35968)\n",
      "Epoch: 58 | Batch_idx: 290 |  Loss: (0.2015) | Acc: (93.03%) (34652/37248)\n",
      "Epoch: 58 | Batch_idx: 300 |  Loss: (0.2019) | Acc: (93.04%) (35846/38528)\n",
      "Epoch: 58 | Batch_idx: 310 |  Loss: (0.2018) | Acc: (93.04%) (37036/39808)\n",
      "Epoch: 58 | Batch_idx: 320 |  Loss: (0.2019) | Acc: (93.01%) (38218/41088)\n",
      "Epoch: 58 | Batch_idx: 330 |  Loss: (0.2019) | Acc: (93.01%) (39406/42368)\n",
      "Epoch: 58 | Batch_idx: 340 |  Loss: (0.2016) | Acc: (93.02%) (40600/43648)\n",
      "Epoch: 58 | Batch_idx: 350 |  Loss: (0.2021) | Acc: (92.98%) (41776/44928)\n",
      "Epoch: 58 | Batch_idx: 360 |  Loss: (0.2025) | Acc: (92.99%) (42970/46208)\n",
      "Epoch: 58 | Batch_idx: 370 |  Loss: (0.2027) | Acc: (92.97%) (44150/47488)\n",
      "Epoch: 58 | Batch_idx: 380 |  Loss: (0.2023) | Acc: (92.97%) (45342/48768)\n",
      "Epoch: 58 | Batch_idx: 390 |  Loss: (0.2024) | Acc: (92.97%) (46484/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4611) | Acc: (86.41%) (8641/10000)\n",
      "Epoch: 59 | Batch_idx: 0 |  Loss: (0.1265) | Acc: (96.88%) (124/128)\n",
      "Epoch: 59 | Batch_idx: 10 |  Loss: (0.2062) | Acc: (92.68%) (1305/1408)\n",
      "Epoch: 59 | Batch_idx: 20 |  Loss: (0.1958) | Acc: (93.19%) (2505/2688)\n",
      "Epoch: 59 | Batch_idx: 30 |  Loss: (0.1956) | Acc: (93.30%) (3702/3968)\n",
      "Epoch: 59 | Batch_idx: 40 |  Loss: (0.1935) | Acc: (93.25%) (4894/5248)\n",
      "Epoch: 59 | Batch_idx: 50 |  Loss: (0.1942) | Acc: (93.34%) (6093/6528)\n",
      "Epoch: 59 | Batch_idx: 60 |  Loss: (0.1950) | Acc: (93.34%) (7288/7808)\n",
      "Epoch: 59 | Batch_idx: 70 |  Loss: (0.1965) | Acc: (93.28%) (8477/9088)\n",
      "Epoch: 59 | Batch_idx: 80 |  Loss: (0.1938) | Acc: (93.37%) (9681/10368)\n",
      "Epoch: 59 | Batch_idx: 90 |  Loss: (0.1915) | Acc: (93.50%) (10891/11648)\n",
      "Epoch: 59 | Batch_idx: 100 |  Loss: (0.1904) | Acc: (93.49%) (12087/12928)\n",
      "Epoch: 59 | Batch_idx: 110 |  Loss: (0.1892) | Acc: (93.55%) (13291/14208)\n",
      "Epoch: 59 | Batch_idx: 120 |  Loss: (0.1909) | Acc: (93.49%) (14479/15488)\n",
      "Epoch: 59 | Batch_idx: 130 |  Loss: (0.1918) | Acc: (93.45%) (15669/16768)\n",
      "Epoch: 59 | Batch_idx: 140 |  Loss: (0.1907) | Acc: (93.46%) (16867/18048)\n",
      "Epoch: 59 | Batch_idx: 150 |  Loss: (0.1896) | Acc: (93.49%) (18070/19328)\n",
      "Epoch: 59 | Batch_idx: 160 |  Loss: (0.1901) | Acc: (93.49%) (19267/20608)\n",
      "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1916) | Acc: (93.40%) (20444/21888)\n",
      "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1923) | Acc: (93.38%) (21635/23168)\n",
      "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1916) | Acc: (93.44%) (22843/24448)\n",
      "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1931) | Acc: (93.37%) (24022/25728)\n",
      "Epoch: 59 | Batch_idx: 210 |  Loss: (0.1941) | Acc: (93.32%) (25204/27008)\n",
      "Epoch: 59 | Batch_idx: 220 |  Loss: (0.1941) | Acc: (93.33%) (26401/28288)\n",
      "Epoch: 59 | Batch_idx: 230 |  Loss: (0.1938) | Acc: (93.35%) (27602/29568)\n",
      "Epoch: 59 | Batch_idx: 240 |  Loss: (0.1946) | Acc: (93.30%) (28781/30848)\n",
      "Epoch: 59 | Batch_idx: 250 |  Loss: (0.1953) | Acc: (93.27%) (29966/32128)\n",
      "Epoch: 59 | Batch_idx: 260 |  Loss: (0.1951) | Acc: (93.26%) (31157/33408)\n",
      "Epoch: 59 | Batch_idx: 270 |  Loss: (0.1958) | Acc: (93.23%) (32340/34688)\n",
      "Epoch: 59 | Batch_idx: 280 |  Loss: (0.1982) | Acc: (93.15%) (33504/35968)\n",
      "Epoch: 59 | Batch_idx: 290 |  Loss: (0.1980) | Acc: (93.16%) (34700/37248)\n",
      "Epoch: 59 | Batch_idx: 300 |  Loss: (0.1976) | Acc: (93.18%) (35901/38528)\n",
      "Epoch: 59 | Batch_idx: 310 |  Loss: (0.1974) | Acc: (93.20%) (37103/39808)\n",
      "Epoch: 59 | Batch_idx: 320 |  Loss: (0.1980) | Acc: (93.18%) (38286/41088)\n",
      "Epoch: 59 | Batch_idx: 330 |  Loss: (0.1984) | Acc: (93.16%) (39471/42368)\n",
      "Epoch: 59 | Batch_idx: 340 |  Loss: (0.1979) | Acc: (93.17%) (40669/43648)\n",
      "Epoch: 59 | Batch_idx: 350 |  Loss: (0.1980) | Acc: (93.17%) (41861/44928)\n",
      "Epoch: 59 | Batch_idx: 360 |  Loss: (0.1983) | Acc: (93.17%) (43052/46208)\n",
      "Epoch: 59 | Batch_idx: 370 |  Loss: (0.1981) | Acc: (93.19%) (44255/47488)\n",
      "Epoch: 59 | Batch_idx: 380 |  Loss: (0.1984) | Acc: (93.19%) (45445/48768)\n",
      "Epoch: 59 | Batch_idx: 390 |  Loss: (0.1983) | Acc: (93.20%) (46600/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4538) | Acc: (86.80%) (8680/10000)\n",
      "Epoch: 60 | Batch_idx: 0 |  Loss: (0.1393) | Acc: (96.09%) (123/128)\n",
      "Epoch: 60 | Batch_idx: 10 |  Loss: (0.1807) | Acc: (93.39%) (1315/1408)\n",
      "Epoch: 60 | Batch_idx: 20 |  Loss: (0.1897) | Acc: (93.71%) (2519/2688)\n",
      "Epoch: 60 | Batch_idx: 30 |  Loss: (0.1940) | Acc: (93.45%) (3708/3968)\n",
      "Epoch: 60 | Batch_idx: 40 |  Loss: (0.1903) | Acc: (93.41%) (4902/5248)\n",
      "Epoch: 60 | Batch_idx: 50 |  Loss: (0.1932) | Acc: (93.26%) (6088/6528)\n",
      "Epoch: 60 | Batch_idx: 60 |  Loss: (0.1923) | Acc: (93.26%) (7282/7808)\n",
      "Epoch: 60 | Batch_idx: 70 |  Loss: (0.1911) | Acc: (93.28%) (8477/9088)\n",
      "Epoch: 60 | Batch_idx: 80 |  Loss: (0.1913) | Acc: (93.27%) (9670/10368)\n",
      "Epoch: 60 | Batch_idx: 90 |  Loss: (0.1923) | Acc: (93.29%) (10867/11648)\n",
      "Epoch: 60 | Batch_idx: 100 |  Loss: (0.1913) | Acc: (93.31%) (12063/12928)\n",
      "Epoch: 60 | Batch_idx: 110 |  Loss: (0.1925) | Acc: (93.26%) (13250/14208)\n",
      "Epoch: 60 | Batch_idx: 120 |  Loss: (0.1926) | Acc: (93.26%) (14444/15488)\n",
      "Epoch: 60 | Batch_idx: 130 |  Loss: (0.1908) | Acc: (93.30%) (15644/16768)\n",
      "Epoch: 60 | Batch_idx: 140 |  Loss: (0.1912) | Acc: (93.27%) (16833/18048)\n",
      "Epoch: 60 | Batch_idx: 150 |  Loss: (0.1903) | Acc: (93.31%) (18035/19328)\n",
      "Epoch: 60 | Batch_idx: 160 |  Loss: (0.1915) | Acc: (93.23%) (19212/20608)\n",
      "Epoch: 60 | Batch_idx: 170 |  Loss: (0.1924) | Acc: (93.17%) (20393/21888)\n",
      "Epoch: 60 | Batch_idx: 180 |  Loss: (0.1929) | Acc: (93.17%) (21585/23168)\n",
      "Epoch: 60 | Batch_idx: 190 |  Loss: (0.1927) | Acc: (93.17%) (22777/24448)\n",
      "Epoch: 60 | Batch_idx: 200 |  Loss: (0.1916) | Acc: (93.24%) (23988/25728)\n",
      "Epoch: 60 | Batch_idx: 210 |  Loss: (0.1910) | Acc: (93.26%) (25189/27008)\n",
      "Epoch: 60 | Batch_idx: 220 |  Loss: (0.1912) | Acc: (93.27%) (26383/28288)\n",
      "Epoch: 60 | Batch_idx: 230 |  Loss: (0.1914) | Acc: (93.25%) (27572/29568)\n",
      "Epoch: 60 | Batch_idx: 240 |  Loss: (0.1917) | Acc: (93.24%) (28764/30848)\n",
      "Epoch: 60 | Batch_idx: 250 |  Loss: (0.1910) | Acc: (93.24%) (29956/32128)\n",
      "Epoch: 60 | Batch_idx: 260 |  Loss: (0.1922) | Acc: (93.20%) (31136/33408)\n",
      "Epoch: 60 | Batch_idx: 270 |  Loss: (0.1926) | Acc: (93.20%) (32329/34688)\n",
      "Epoch: 60 | Batch_idx: 280 |  Loss: (0.1922) | Acc: (93.22%) (33531/35968)\n",
      "Epoch: 60 | Batch_idx: 290 |  Loss: (0.1925) | Acc: (93.22%) (34722/37248)\n",
      "Epoch: 60 | Batch_idx: 300 |  Loss: (0.1920) | Acc: (93.23%) (35920/38528)\n",
      "Epoch: 60 | Batch_idx: 310 |  Loss: (0.1923) | Acc: (93.22%) (37109/39808)\n",
      "Epoch: 60 | Batch_idx: 320 |  Loss: (0.1927) | Acc: (93.22%) (38304/41088)\n",
      "Epoch: 60 | Batch_idx: 330 |  Loss: (0.1938) | Acc: (93.20%) (39489/42368)\n",
      "Epoch: 60 | Batch_idx: 340 |  Loss: (0.1936) | Acc: (93.21%) (40685/43648)\n",
      "Epoch: 60 | Batch_idx: 350 |  Loss: (0.1936) | Acc: (93.21%) (41878/44928)\n",
      "Epoch: 60 | Batch_idx: 360 |  Loss: (0.1939) | Acc: (93.22%) (43073/46208)\n",
      "Epoch: 60 | Batch_idx: 370 |  Loss: (0.1938) | Acc: (93.21%) (44263/47488)\n",
      "Epoch: 60 | Batch_idx: 380 |  Loss: (0.1940) | Acc: (93.20%) (45453/48768)\n",
      "Epoch: 60 | Batch_idx: 390 |  Loss: (0.1937) | Acc: (93.21%) (46607/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4566) | Acc: (86.58%) (8658/10000)\n",
      "Epoch: 61 | Batch_idx: 0 |  Loss: (0.2500) | Acc: (89.06%) (114/128)\n",
      "Epoch: 61 | Batch_idx: 10 |  Loss: (0.1686) | Acc: (94.39%) (1329/1408)\n",
      "Epoch: 61 | Batch_idx: 20 |  Loss: (0.1578) | Acc: (94.79%) (2548/2688)\n",
      "Epoch: 61 | Batch_idx: 30 |  Loss: (0.1633) | Acc: (94.78%) (3761/3968)\n",
      "Epoch: 61 | Batch_idx: 40 |  Loss: (0.1658) | Acc: (94.63%) (4966/5248)\n",
      "Epoch: 61 | Batch_idx: 50 |  Loss: (0.1673) | Acc: (94.45%) (6166/6528)\n",
      "Epoch: 61 | Batch_idx: 60 |  Loss: (0.1684) | Acc: (94.38%) (7369/7808)\n",
      "Epoch: 61 | Batch_idx: 70 |  Loss: (0.1719) | Acc: (94.27%) (8567/9088)\n",
      "Epoch: 61 | Batch_idx: 80 |  Loss: (0.1741) | Acc: (94.09%) (9755/10368)\n",
      "Epoch: 61 | Batch_idx: 90 |  Loss: (0.1744) | Acc: (94.12%) (10963/11648)\n",
      "Epoch: 61 | Batch_idx: 100 |  Loss: (0.1747) | Acc: (94.10%) (12165/12928)\n",
      "Epoch: 61 | Batch_idx: 110 |  Loss: (0.1726) | Acc: (94.12%) (13372/14208)\n",
      "Epoch: 61 | Batch_idx: 120 |  Loss: (0.1754) | Acc: (93.98%) (14555/15488)\n",
      "Epoch: 61 | Batch_idx: 130 |  Loss: (0.1748) | Acc: (94.02%) (15765/16768)\n",
      "Epoch: 61 | Batch_idx: 140 |  Loss: (0.1737) | Acc: (94.02%) (16969/18048)\n",
      "Epoch: 61 | Batch_idx: 150 |  Loss: (0.1752) | Acc: (93.96%) (18161/19328)\n",
      "Epoch: 61 | Batch_idx: 160 |  Loss: (0.1752) | Acc: (93.98%) (19367/20608)\n",
      "Epoch: 61 | Batch_idx: 170 |  Loss: (0.1751) | Acc: (93.97%) (20568/21888)\n",
      "Epoch: 61 | Batch_idx: 180 |  Loss: (0.1754) | Acc: (93.96%) (21769/23168)\n",
      "Epoch: 61 | Batch_idx: 190 |  Loss: (0.1767) | Acc: (93.90%) (22956/24448)\n",
      "Epoch: 61 | Batch_idx: 200 |  Loss: (0.1778) | Acc: (93.87%) (24152/25728)\n",
      "Epoch: 61 | Batch_idx: 210 |  Loss: (0.1778) | Acc: (93.84%) (25343/27008)\n",
      "Epoch: 61 | Batch_idx: 220 |  Loss: (0.1779) | Acc: (93.82%) (26540/28288)\n",
      "Epoch: 61 | Batch_idx: 230 |  Loss: (0.1785) | Acc: (93.80%) (27736/29568)\n",
      "Epoch: 61 | Batch_idx: 240 |  Loss: (0.1787) | Acc: (93.81%) (28938/30848)\n",
      "Epoch: 61 | Batch_idx: 250 |  Loss: (0.1788) | Acc: (93.84%) (30148/32128)\n",
      "Epoch: 61 | Batch_idx: 260 |  Loss: (0.1787) | Acc: (93.83%) (31346/33408)\n",
      "Epoch: 61 | Batch_idx: 270 |  Loss: (0.1789) | Acc: (93.79%) (32535/34688)\n",
      "Epoch: 61 | Batch_idx: 280 |  Loss: (0.1799) | Acc: (93.76%) (33723/35968)\n",
      "Epoch: 61 | Batch_idx: 290 |  Loss: (0.1799) | Acc: (93.74%) (34915/37248)\n",
      "Epoch: 61 | Batch_idx: 300 |  Loss: (0.1791) | Acc: (93.77%) (36127/38528)\n",
      "Epoch: 61 | Batch_idx: 310 |  Loss: (0.1801) | Acc: (93.71%) (37305/39808)\n",
      "Epoch: 61 | Batch_idx: 320 |  Loss: (0.1812) | Acc: (93.68%) (38493/41088)\n",
      "Epoch: 61 | Batch_idx: 330 |  Loss: (0.1820) | Acc: (93.66%) (39680/42368)\n",
      "Epoch: 61 | Batch_idx: 340 |  Loss: (0.1819) | Acc: (93.66%) (40881/43648)\n",
      "Epoch: 61 | Batch_idx: 350 |  Loss: (0.1818) | Acc: (93.66%) (42081/44928)\n",
      "Epoch: 61 | Batch_idx: 360 |  Loss: (0.1827) | Acc: (93.63%) (43266/46208)\n",
      "Epoch: 61 | Batch_idx: 370 |  Loss: (0.1832) | Acc: (93.63%) (44461/47488)\n",
      "Epoch: 61 | Batch_idx: 380 |  Loss: (0.1836) | Acc: (93.62%) (45655/48768)\n",
      "Epoch: 61 | Batch_idx: 390 |  Loss: (0.1843) | Acc: (93.58%) (46792/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4427) | Acc: (86.78%) (8678/10000)\n",
      "Epoch: 62 | Batch_idx: 0 |  Loss: (0.2188) | Acc: (92.19%) (118/128)\n",
      "Epoch: 62 | Batch_idx: 10 |  Loss: (0.1875) | Acc: (93.18%) (1312/1408)\n",
      "Epoch: 62 | Batch_idx: 20 |  Loss: (0.1921) | Acc: (93.12%) (2503/2688)\n",
      "Epoch: 62 | Batch_idx: 30 |  Loss: (0.1838) | Acc: (93.47%) (3709/3968)\n",
      "Epoch: 62 | Batch_idx: 40 |  Loss: (0.1900) | Acc: (93.25%) (4894/5248)\n",
      "Epoch: 62 | Batch_idx: 50 |  Loss: (0.1925) | Acc: (93.03%) (6073/6528)\n",
      "Epoch: 62 | Batch_idx: 60 |  Loss: (0.1912) | Acc: (93.24%) (7280/7808)\n",
      "Epoch: 62 | Batch_idx: 70 |  Loss: (0.1879) | Acc: (93.39%) (8487/9088)\n",
      "Epoch: 62 | Batch_idx: 80 |  Loss: (0.1831) | Acc: (93.61%) (9705/10368)\n",
      "Epoch: 62 | Batch_idx: 90 |  Loss: (0.1806) | Acc: (93.71%) (10915/11648)\n",
      "Epoch: 62 | Batch_idx: 100 |  Loss: (0.1821) | Acc: (93.70%) (12113/12928)\n",
      "Epoch: 62 | Batch_idx: 110 |  Loss: (0.1807) | Acc: (93.81%) (13328/14208)\n",
      "Epoch: 62 | Batch_idx: 120 |  Loss: (0.1812) | Acc: (93.83%) (14533/15488)\n",
      "Epoch: 62 | Batch_idx: 130 |  Loss: (0.1804) | Acc: (93.85%) (15736/16768)\n",
      "Epoch: 62 | Batch_idx: 140 |  Loss: (0.1810) | Acc: (93.80%) (16929/18048)\n",
      "Epoch: 62 | Batch_idx: 150 |  Loss: (0.1787) | Acc: (93.87%) (18144/19328)\n",
      "Epoch: 62 | Batch_idx: 160 |  Loss: (0.1784) | Acc: (93.90%) (19351/20608)\n",
      "Epoch: 62 | Batch_idx: 170 |  Loss: (0.1795) | Acc: (93.88%) (20548/21888)\n",
      "Epoch: 62 | Batch_idx: 180 |  Loss: (0.1801) | Acc: (93.88%) (21750/23168)\n",
      "Epoch: 62 | Batch_idx: 190 |  Loss: (0.1811) | Acc: (93.86%) (22946/24448)\n",
      "Epoch: 62 | Batch_idx: 200 |  Loss: (0.1816) | Acc: (93.83%) (24140/25728)\n",
      "Epoch: 62 | Batch_idx: 210 |  Loss: (0.1816) | Acc: (93.82%) (25338/27008)\n",
      "Epoch: 62 | Batch_idx: 220 |  Loss: (0.1827) | Acc: (93.77%) (26525/28288)\n",
      "Epoch: 62 | Batch_idx: 230 |  Loss: (0.1816) | Acc: (93.82%) (27741/29568)\n",
      "Epoch: 62 | Batch_idx: 240 |  Loss: (0.1815) | Acc: (93.82%) (28942/30848)\n",
      "Epoch: 62 | Batch_idx: 250 |  Loss: (0.1813) | Acc: (93.83%) (30147/32128)\n",
      "Epoch: 62 | Batch_idx: 260 |  Loss: (0.1816) | Acc: (93.76%) (31325/33408)\n",
      "Epoch: 62 | Batch_idx: 270 |  Loss: (0.1815) | Acc: (93.76%) (32525/34688)\n",
      "Epoch: 62 | Batch_idx: 280 |  Loss: (0.1816) | Acc: (93.77%) (33726/35968)\n",
      "Epoch: 62 | Batch_idx: 290 |  Loss: (0.1813) | Acc: (93.80%) (34938/37248)\n",
      "Epoch: 62 | Batch_idx: 300 |  Loss: (0.1816) | Acc: (93.80%) (36140/38528)\n",
      "Epoch: 62 | Batch_idx: 310 |  Loss: (0.1822) | Acc: (93.80%) (37340/39808)\n",
      "Epoch: 62 | Batch_idx: 320 |  Loss: (0.1825) | Acc: (93.77%) (38529/41088)\n",
      "Epoch: 62 | Batch_idx: 330 |  Loss: (0.1826) | Acc: (93.76%) (39724/42368)\n",
      "Epoch: 62 | Batch_idx: 340 |  Loss: (0.1825) | Acc: (93.75%) (40922/43648)\n",
      "Epoch: 62 | Batch_idx: 350 |  Loss: (0.1828) | Acc: (93.75%) (42118/44928)\n",
      "Epoch: 62 | Batch_idx: 360 |  Loss: (0.1831) | Acc: (93.73%) (43309/46208)\n",
      "Epoch: 62 | Batch_idx: 370 |  Loss: (0.1838) | Acc: (93.68%) (44489/47488)\n",
      "Epoch: 62 | Batch_idx: 380 |  Loss: (0.1837) | Acc: (93.71%) (45700/48768)\n",
      "Epoch: 62 | Batch_idx: 390 |  Loss: (0.1840) | Acc: (93.69%) (46843/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4453) | Acc: (86.84%) (8684/10000)\n",
      "Epoch: 63 | Batch_idx: 0 |  Loss: (0.2326) | Acc: (94.53%) (121/128)\n",
      "Epoch: 63 | Batch_idx: 10 |  Loss: (0.1978) | Acc: (93.54%) (1317/1408)\n",
      "Epoch: 63 | Batch_idx: 20 |  Loss: (0.1857) | Acc: (93.79%) (2521/2688)\n",
      "Epoch: 63 | Batch_idx: 30 |  Loss: (0.1884) | Acc: (93.42%) (3707/3968)\n",
      "Epoch: 63 | Batch_idx: 40 |  Loss: (0.1784) | Acc: (93.88%) (4927/5248)\n",
      "Epoch: 63 | Batch_idx: 50 |  Loss: (0.1774) | Acc: (93.96%) (6134/6528)\n",
      "Epoch: 63 | Batch_idx: 60 |  Loss: (0.1805) | Acc: (94.01%) (7340/7808)\n",
      "Epoch: 63 | Batch_idx: 70 |  Loss: (0.1777) | Acc: (94.00%) (8543/9088)\n",
      "Epoch: 63 | Batch_idx: 80 |  Loss: (0.1750) | Acc: (94.14%) (9760/10368)\n",
      "Epoch: 63 | Batch_idx: 90 |  Loss: (0.1764) | Acc: (93.98%) (10947/11648)\n",
      "Epoch: 63 | Batch_idx: 100 |  Loss: (0.1773) | Acc: (93.92%) (12142/12928)\n",
      "Epoch: 63 | Batch_idx: 110 |  Loss: (0.1772) | Acc: (93.93%) (13345/14208)\n",
      "Epoch: 63 | Batch_idx: 120 |  Loss: (0.1783) | Acc: (93.91%) (14545/15488)\n",
      "Epoch: 63 | Batch_idx: 130 |  Loss: (0.1784) | Acc: (93.92%) (15748/16768)\n",
      "Epoch: 63 | Batch_idx: 140 |  Loss: (0.1780) | Acc: (93.89%) (16945/18048)\n",
      "Epoch: 63 | Batch_idx: 150 |  Loss: (0.1799) | Acc: (93.83%) (18136/19328)\n",
      "Epoch: 63 | Batch_idx: 160 |  Loss: (0.1793) | Acc: (93.83%) (19336/20608)\n",
      "Epoch: 63 | Batch_idx: 170 |  Loss: (0.1794) | Acc: (93.83%) (20538/21888)\n",
      "Epoch: 63 | Batch_idx: 180 |  Loss: (0.1798) | Acc: (93.82%) (21736/23168)\n",
      "Epoch: 63 | Batch_idx: 190 |  Loss: (0.1802) | Acc: (93.80%) (22933/24448)\n",
      "Epoch: 63 | Batch_idx: 200 |  Loss: (0.1793) | Acc: (93.84%) (24144/25728)\n",
      "Epoch: 63 | Batch_idx: 210 |  Loss: (0.1783) | Acc: (93.86%) (25350/27008)\n",
      "Epoch: 63 | Batch_idx: 220 |  Loss: (0.1786) | Acc: (93.86%) (26551/28288)\n",
      "Epoch: 63 | Batch_idx: 230 |  Loss: (0.1784) | Acc: (93.86%) (27752/29568)\n",
      "Epoch: 63 | Batch_idx: 240 |  Loss: (0.1777) | Acc: (93.87%) (28958/30848)\n",
      "Epoch: 63 | Batch_idx: 250 |  Loss: (0.1770) | Acc: (93.91%) (30173/32128)\n",
      "Epoch: 63 | Batch_idx: 260 |  Loss: (0.1768) | Acc: (93.91%) (31372/33408)\n",
      "Epoch: 63 | Batch_idx: 270 |  Loss: (0.1764) | Acc: (93.93%) (32581/34688)\n",
      "Epoch: 63 | Batch_idx: 280 |  Loss: (0.1769) | Acc: (93.90%) (33775/35968)\n",
      "Epoch: 63 | Batch_idx: 290 |  Loss: (0.1776) | Acc: (93.85%) (34958/37248)\n",
      "Epoch: 63 | Batch_idx: 300 |  Loss: (0.1775) | Acc: (93.86%) (36164/38528)\n",
      "Epoch: 63 | Batch_idx: 310 |  Loss: (0.1770) | Acc: (93.87%) (37369/39808)\n",
      "Epoch: 63 | Batch_idx: 320 |  Loss: (0.1776) | Acc: (93.86%) (38565/41088)\n",
      "Epoch: 63 | Batch_idx: 330 |  Loss: (0.1794) | Acc: (93.79%) (39735/42368)\n",
      "Epoch: 63 | Batch_idx: 340 |  Loss: (0.1794) | Acc: (93.79%) (40939/43648)\n",
      "Epoch: 63 | Batch_idx: 350 |  Loss: (0.1799) | Acc: (93.77%) (42127/44928)\n",
      "Epoch: 63 | Batch_idx: 360 |  Loss: (0.1804) | Acc: (93.73%) (43313/46208)\n",
      "Epoch: 63 | Batch_idx: 370 |  Loss: (0.1803) | Acc: (93.76%) (44526/47488)\n",
      "Epoch: 63 | Batch_idx: 380 |  Loss: (0.1806) | Acc: (93.73%) (45709/48768)\n",
      "Epoch: 63 | Batch_idx: 390 |  Loss: (0.1812) | Acc: (93.69%) (46846/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5203) | Acc: (85.01%) (8501/10000)\n",
      "Epoch: 64 | Batch_idx: 0 |  Loss: (0.1598) | Acc: (94.53%) (121/128)\n",
      "Epoch: 64 | Batch_idx: 10 |  Loss: (0.1693) | Acc: (93.39%) (1315/1408)\n",
      "Epoch: 64 | Batch_idx: 20 |  Loss: (0.1693) | Acc: (93.82%) (2522/2688)\n",
      "Epoch: 64 | Batch_idx: 30 |  Loss: (0.1668) | Acc: (93.93%) (3727/3968)\n",
      "Epoch: 64 | Batch_idx: 40 |  Loss: (0.1698) | Acc: (93.96%) (4931/5248)\n",
      "Epoch: 64 | Batch_idx: 50 |  Loss: (0.1730) | Acc: (93.83%) (6125/6528)\n",
      "Epoch: 64 | Batch_idx: 60 |  Loss: (0.1707) | Acc: (93.88%) (7330/7808)\n",
      "Epoch: 64 | Batch_idx: 70 |  Loss: (0.1693) | Acc: (93.95%) (8538/9088)\n",
      "Epoch: 64 | Batch_idx: 80 |  Loss: (0.1676) | Acc: (94.01%) (9747/10368)\n",
      "Epoch: 64 | Batch_idx: 90 |  Loss: (0.1683) | Acc: (93.97%) (10946/11648)\n",
      "Epoch: 64 | Batch_idx: 100 |  Loss: (0.1669) | Acc: (94.07%) (12161/12928)\n",
      "Epoch: 64 | Batch_idx: 110 |  Loss: (0.1668) | Acc: (94.10%) (13370/14208)\n",
      "Epoch: 64 | Batch_idx: 120 |  Loss: (0.1686) | Acc: (94.12%) (14578/15488)\n",
      "Epoch: 64 | Batch_idx: 130 |  Loss: (0.1683) | Acc: (94.16%) (15788/16768)\n",
      "Epoch: 64 | Batch_idx: 140 |  Loss: (0.1680) | Acc: (94.22%) (17005/18048)\n",
      "Epoch: 64 | Batch_idx: 150 |  Loss: (0.1677) | Acc: (94.20%) (18207/19328)\n",
      "Epoch: 64 | Batch_idx: 160 |  Loss: (0.1674) | Acc: (94.21%) (19414/20608)\n",
      "Epoch: 64 | Batch_idx: 170 |  Loss: (0.1680) | Acc: (94.23%) (20625/21888)\n",
      "Epoch: 64 | Batch_idx: 180 |  Loss: (0.1672) | Acc: (94.23%) (21832/23168)\n",
      "Epoch: 64 | Batch_idx: 190 |  Loss: (0.1678) | Acc: (94.23%) (23037/24448)\n",
      "Epoch: 64 | Batch_idx: 200 |  Loss: (0.1687) | Acc: (94.22%) (24241/25728)\n",
      "Epoch: 64 | Batch_idx: 210 |  Loss: (0.1700) | Acc: (94.18%) (25437/27008)\n",
      "Epoch: 64 | Batch_idx: 220 |  Loss: (0.1699) | Acc: (94.19%) (26644/28288)\n",
      "Epoch: 64 | Batch_idx: 230 |  Loss: (0.1705) | Acc: (94.15%) (27837/29568)\n",
      "Epoch: 64 | Batch_idx: 240 |  Loss: (0.1705) | Acc: (94.14%) (29041/30848)\n",
      "Epoch: 64 | Batch_idx: 250 |  Loss: (0.1704) | Acc: (94.13%) (30243/32128)\n",
      "Epoch: 64 | Batch_idx: 260 |  Loss: (0.1716) | Acc: (94.08%) (31430/33408)\n",
      "Epoch: 64 | Batch_idx: 270 |  Loss: (0.1724) | Acc: (94.06%) (32627/34688)\n",
      "Epoch: 64 | Batch_idx: 280 |  Loss: (0.1738) | Acc: (94.01%) (33813/35968)\n",
      "Epoch: 64 | Batch_idx: 290 |  Loss: (0.1745) | Acc: (93.96%) (34999/37248)\n",
      "Epoch: 64 | Batch_idx: 300 |  Loss: (0.1744) | Acc: (93.95%) (36196/38528)\n",
      "Epoch: 64 | Batch_idx: 310 |  Loss: (0.1750) | Acc: (93.91%) (37384/39808)\n",
      "Epoch: 64 | Batch_idx: 320 |  Loss: (0.1756) | Acc: (93.87%) (38570/41088)\n",
      "Epoch: 64 | Batch_idx: 330 |  Loss: (0.1759) | Acc: (93.87%) (39772/42368)\n",
      "Epoch: 64 | Batch_idx: 340 |  Loss: (0.1758) | Acc: (93.88%) (40977/43648)\n",
      "Epoch: 64 | Batch_idx: 350 |  Loss: (0.1766) | Acc: (93.86%) (42168/44928)\n",
      "Epoch: 64 | Batch_idx: 360 |  Loss: (0.1764) | Acc: (93.86%) (43372/46208)\n",
      "Epoch: 64 | Batch_idx: 370 |  Loss: (0.1770) | Acc: (93.85%) (44568/47488)\n",
      "Epoch: 64 | Batch_idx: 380 |  Loss: (0.1773) | Acc: (93.85%) (45769/48768)\n",
      "Epoch: 64 | Batch_idx: 390 |  Loss: (0.1777) | Acc: (93.84%) (46919/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4870) | Acc: (86.05%) (8605/10000)\n",
      "Epoch: 65 | Batch_idx: 0 |  Loss: (0.1611) | Acc: (95.31%) (122/128)\n",
      "Epoch: 65 | Batch_idx: 10 |  Loss: (0.1950) | Acc: (93.11%) (1311/1408)\n",
      "Epoch: 65 | Batch_idx: 20 |  Loss: (0.1924) | Acc: (93.23%) (2506/2688)\n",
      "Epoch: 65 | Batch_idx: 30 |  Loss: (0.1869) | Acc: (93.50%) (3710/3968)\n",
      "Epoch: 65 | Batch_idx: 40 |  Loss: (0.1866) | Acc: (93.58%) (4911/5248)\n",
      "Epoch: 65 | Batch_idx: 50 |  Loss: (0.1846) | Acc: (93.52%) (6105/6528)\n",
      "Epoch: 65 | Batch_idx: 60 |  Loss: (0.1855) | Acc: (93.57%) (7306/7808)\n",
      "Epoch: 65 | Batch_idx: 70 |  Loss: (0.1867) | Acc: (93.52%) (8499/9088)\n",
      "Epoch: 65 | Batch_idx: 80 |  Loss: (0.1871) | Acc: (93.42%) (9686/10368)\n",
      "Epoch: 65 | Batch_idx: 90 |  Loss: (0.1866) | Acc: (93.47%) (10887/11648)\n",
      "Epoch: 65 | Batch_idx: 100 |  Loss: (0.1841) | Acc: (93.56%) (12095/12928)\n",
      "Epoch: 65 | Batch_idx: 110 |  Loss: (0.1823) | Acc: (93.68%) (13310/14208)\n",
      "Epoch: 65 | Batch_idx: 120 |  Loss: (0.1830) | Acc: (93.70%) (14512/15488)\n",
      "Epoch: 65 | Batch_idx: 130 |  Loss: (0.1816) | Acc: (93.78%) (15725/16768)\n",
      "Epoch: 65 | Batch_idx: 140 |  Loss: (0.1829) | Acc: (93.71%) (16913/18048)\n",
      "Epoch: 65 | Batch_idx: 150 |  Loss: (0.1840) | Acc: (93.59%) (18090/19328)\n",
      "Epoch: 65 | Batch_idx: 160 |  Loss: (0.1840) | Acc: (93.56%) (19281/20608)\n",
      "Epoch: 65 | Batch_idx: 170 |  Loss: (0.1830) | Acc: (93.60%) (20487/21888)\n",
      "Epoch: 65 | Batch_idx: 180 |  Loss: (0.1811) | Acc: (93.67%) (21702/23168)\n",
      "Epoch: 65 | Batch_idx: 190 |  Loss: (0.1794) | Acc: (93.76%) (22922/24448)\n",
      "Epoch: 65 | Batch_idx: 200 |  Loss: (0.1792) | Acc: (93.77%) (24125/25728)\n",
      "Epoch: 65 | Batch_idx: 210 |  Loss: (0.1790) | Acc: (93.76%) (25324/27008)\n",
      "Epoch: 65 | Batch_idx: 220 |  Loss: (0.1788) | Acc: (93.75%) (26521/28288)\n",
      "Epoch: 65 | Batch_idx: 230 |  Loss: (0.1783) | Acc: (93.77%) (27725/29568)\n",
      "Epoch: 65 | Batch_idx: 240 |  Loss: (0.1769) | Acc: (93.82%) (28942/30848)\n",
      "Epoch: 65 | Batch_idx: 250 |  Loss: (0.1773) | Acc: (93.82%) (30142/32128)\n",
      "Epoch: 65 | Batch_idx: 260 |  Loss: (0.1768) | Acc: (93.85%) (31352/33408)\n",
      "Epoch: 65 | Batch_idx: 270 |  Loss: (0.1764) | Acc: (93.85%) (32554/34688)\n",
      "Epoch: 65 | Batch_idx: 280 |  Loss: (0.1772) | Acc: (93.83%) (33748/35968)\n",
      "Epoch: 65 | Batch_idx: 290 |  Loss: (0.1780) | Acc: (93.82%) (34946/37248)\n",
      "Epoch: 65 | Batch_idx: 300 |  Loss: (0.1784) | Acc: (93.81%) (36142/38528)\n",
      "Epoch: 65 | Batch_idx: 310 |  Loss: (0.1786) | Acc: (93.79%) (37334/39808)\n",
      "Epoch: 65 | Batch_idx: 320 |  Loss: (0.1780) | Acc: (93.82%) (38548/41088)\n",
      "Epoch: 65 | Batch_idx: 330 |  Loss: (0.1774) | Acc: (93.84%) (39759/42368)\n",
      "Epoch: 65 | Batch_idx: 340 |  Loss: (0.1778) | Acc: (93.82%) (40950/43648)\n",
      "Epoch: 65 | Batch_idx: 350 |  Loss: (0.1778) | Acc: (93.84%) (42159/44928)\n",
      "Epoch: 65 | Batch_idx: 360 |  Loss: (0.1771) | Acc: (93.85%) (43366/46208)\n",
      "Epoch: 65 | Batch_idx: 370 |  Loss: (0.1775) | Acc: (93.85%) (44566/47488)\n",
      "Epoch: 65 | Batch_idx: 380 |  Loss: (0.1772) | Acc: (93.85%) (45771/48768)\n",
      "Epoch: 65 | Batch_idx: 390 |  Loss: (0.1774) | Acc: (93.85%) (46925/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4695) | Acc: (86.35%) (8635/10000)\n",
      "Epoch: 66 | Batch_idx: 0 |  Loss: (0.1479) | Acc: (96.88%) (124/128)\n",
      "Epoch: 66 | Batch_idx: 10 |  Loss: (0.1649) | Acc: (94.18%) (1326/1408)\n",
      "Epoch: 66 | Batch_idx: 20 |  Loss: (0.1613) | Acc: (94.53%) (2541/2688)\n",
      "Epoch: 66 | Batch_idx: 30 |  Loss: (0.1680) | Acc: (94.20%) (3738/3968)\n",
      "Epoch: 66 | Batch_idx: 40 |  Loss: (0.1654) | Acc: (94.13%) (4940/5248)\n",
      "Epoch: 66 | Batch_idx: 50 |  Loss: (0.1637) | Acc: (94.12%) (6144/6528)\n",
      "Epoch: 66 | Batch_idx: 60 |  Loss: (0.1627) | Acc: (94.19%) (7354/7808)\n",
      "Epoch: 66 | Batch_idx: 70 |  Loss: (0.1643) | Acc: (94.15%) (8556/9088)\n",
      "Epoch: 66 | Batch_idx: 80 |  Loss: (0.1674) | Acc: (94.05%) (9751/10368)\n",
      "Epoch: 66 | Batch_idx: 90 |  Loss: (0.1657) | Acc: (94.05%) (10955/11648)\n",
      "Epoch: 66 | Batch_idx: 100 |  Loss: (0.1657) | Acc: (94.08%) (12163/12928)\n",
      "Epoch: 66 | Batch_idx: 110 |  Loss: (0.1653) | Acc: (94.16%) (13378/14208)\n",
      "Epoch: 66 | Batch_idx: 120 |  Loss: (0.1659) | Acc: (94.13%) (14579/15488)\n",
      "Epoch: 66 | Batch_idx: 130 |  Loss: (0.1650) | Acc: (94.15%) (15787/16768)\n",
      "Epoch: 66 | Batch_idx: 140 |  Loss: (0.1658) | Acc: (94.17%) (16995/18048)\n",
      "Epoch: 66 | Batch_idx: 150 |  Loss: (0.1650) | Acc: (94.16%) (18200/19328)\n",
      "Epoch: 66 | Batch_idx: 160 |  Loss: (0.1650) | Acc: (94.12%) (19396/20608)\n",
      "Epoch: 66 | Batch_idx: 170 |  Loss: (0.1658) | Acc: (94.12%) (20602/21888)\n",
      "Epoch: 66 | Batch_idx: 180 |  Loss: (0.1645) | Acc: (94.20%) (21825/23168)\n",
      "Epoch: 66 | Batch_idx: 190 |  Loss: (0.1659) | Acc: (94.14%) (23015/24448)\n",
      "Epoch: 66 | Batch_idx: 200 |  Loss: (0.1657) | Acc: (94.15%) (24222/25728)\n",
      "Epoch: 66 | Batch_idx: 210 |  Loss: (0.1654) | Acc: (94.15%) (25428/27008)\n",
      "Epoch: 66 | Batch_idx: 220 |  Loss: (0.1660) | Acc: (94.11%) (26621/28288)\n",
      "Epoch: 66 | Batch_idx: 230 |  Loss: (0.1667) | Acc: (94.10%) (27823/29568)\n",
      "Epoch: 66 | Batch_idx: 240 |  Loss: (0.1660) | Acc: (94.15%) (29042/30848)\n",
      "Epoch: 66 | Batch_idx: 250 |  Loss: (0.1661) | Acc: (94.13%) (30242/32128)\n",
      "Epoch: 66 | Batch_idx: 260 |  Loss: (0.1669) | Acc: (94.11%) (31441/33408)\n",
      "Epoch: 66 | Batch_idx: 270 |  Loss: (0.1659) | Acc: (94.14%) (32657/34688)\n",
      "Epoch: 66 | Batch_idx: 280 |  Loss: (0.1666) | Acc: (94.14%) (33860/35968)\n",
      "Epoch: 66 | Batch_idx: 290 |  Loss: (0.1659) | Acc: (94.18%) (35080/37248)\n",
      "Epoch: 66 | Batch_idx: 300 |  Loss: (0.1659) | Acc: (94.19%) (36290/38528)\n",
      "Epoch: 66 | Batch_idx: 310 |  Loss: (0.1673) | Acc: (94.16%) (37482/39808)\n",
      "Epoch: 66 | Batch_idx: 320 |  Loss: (0.1686) | Acc: (94.11%) (38669/41088)\n",
      "Epoch: 66 | Batch_idx: 330 |  Loss: (0.1687) | Acc: (94.12%) (39875/42368)\n",
      "Epoch: 66 | Batch_idx: 340 |  Loss: (0.1694) | Acc: (94.08%) (41063/43648)\n",
      "Epoch: 66 | Batch_idx: 350 |  Loss: (0.1700) | Acc: (94.05%) (42256/44928)\n",
      "Epoch: 66 | Batch_idx: 360 |  Loss: (0.1703) | Acc: (94.04%) (43454/46208)\n",
      "Epoch: 66 | Batch_idx: 370 |  Loss: (0.1699) | Acc: (94.07%) (44670/47488)\n",
      "Epoch: 66 | Batch_idx: 380 |  Loss: (0.1700) | Acc: (94.05%) (45864/48768)\n",
      "Epoch: 66 | Batch_idx: 390 |  Loss: (0.1701) | Acc: (94.03%) (47015/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4508) | Acc: (86.39%) (8639/10000)\n",
      "Epoch: 67 | Batch_idx: 0 |  Loss: (0.1929) | Acc: (92.97%) (119/128)\n",
      "Epoch: 67 | Batch_idx: 10 |  Loss: (0.1586) | Acc: (94.53%) (1331/1408)\n",
      "Epoch: 67 | Batch_idx: 20 |  Loss: (0.1548) | Acc: (94.68%) (2545/2688)\n",
      "Epoch: 67 | Batch_idx: 30 |  Loss: (0.1539) | Acc: (94.63%) (3755/3968)\n",
      "Epoch: 67 | Batch_idx: 40 |  Loss: (0.1569) | Acc: (94.57%) (4963/5248)\n",
      "Epoch: 67 | Batch_idx: 50 |  Loss: (0.1558) | Acc: (94.65%) (6179/6528)\n",
      "Epoch: 67 | Batch_idx: 60 |  Loss: (0.1585) | Acc: (94.48%) (7377/7808)\n",
      "Epoch: 67 | Batch_idx: 70 |  Loss: (0.1607) | Acc: (94.40%) (8579/9088)\n",
      "Epoch: 67 | Batch_idx: 80 |  Loss: (0.1592) | Acc: (94.44%) (9792/10368)\n",
      "Epoch: 67 | Batch_idx: 90 |  Loss: (0.1576) | Acc: (94.51%) (11008/11648)\n",
      "Epoch: 67 | Batch_idx: 100 |  Loss: (0.1592) | Acc: (94.47%) (12213/12928)\n",
      "Epoch: 67 | Batch_idx: 110 |  Loss: (0.1588) | Acc: (94.47%) (13423/14208)\n",
      "Epoch: 67 | Batch_idx: 120 |  Loss: (0.1583) | Acc: (94.50%) (14636/15488)\n",
      "Epoch: 67 | Batch_idx: 130 |  Loss: (0.1589) | Acc: (94.46%) (15839/16768)\n",
      "Epoch: 67 | Batch_idx: 140 |  Loss: (0.1592) | Acc: (94.46%) (17048/18048)\n",
      "Epoch: 67 | Batch_idx: 150 |  Loss: (0.1582) | Acc: (94.50%) (18265/19328)\n",
      "Epoch: 67 | Batch_idx: 160 |  Loss: (0.1586) | Acc: (94.51%) (19476/20608)\n",
      "Epoch: 67 | Batch_idx: 170 |  Loss: (0.1593) | Acc: (94.48%) (20680/21888)\n",
      "Epoch: 67 | Batch_idx: 180 |  Loss: (0.1600) | Acc: (94.45%) (21882/23168)\n",
      "Epoch: 67 | Batch_idx: 190 |  Loss: (0.1605) | Acc: (94.42%) (23085/24448)\n",
      "Epoch: 67 | Batch_idx: 200 |  Loss: (0.1614) | Acc: (94.37%) (24279/25728)\n",
      "Epoch: 67 | Batch_idx: 210 |  Loss: (0.1616) | Acc: (94.36%) (25486/27008)\n",
      "Epoch: 67 | Batch_idx: 220 |  Loss: (0.1621) | Acc: (94.35%) (26690/28288)\n",
      "Epoch: 67 | Batch_idx: 230 |  Loss: (0.1630) | Acc: (94.31%) (27885/29568)\n",
      "Epoch: 67 | Batch_idx: 240 |  Loss: (0.1642) | Acc: (94.27%) (29081/30848)\n",
      "Epoch: 67 | Batch_idx: 250 |  Loss: (0.1635) | Acc: (94.29%) (30292/32128)\n",
      "Epoch: 67 | Batch_idx: 260 |  Loss: (0.1633) | Acc: (94.28%) (31496/33408)\n",
      "Epoch: 67 | Batch_idx: 270 |  Loss: (0.1640) | Acc: (94.27%) (32702/34688)\n",
      "Epoch: 67 | Batch_idx: 280 |  Loss: (0.1642) | Acc: (94.28%) (33911/35968)\n",
      "Epoch: 67 | Batch_idx: 290 |  Loss: (0.1634) | Acc: (94.31%) (35129/37248)\n",
      "Epoch: 67 | Batch_idx: 300 |  Loss: (0.1638) | Acc: (94.30%) (36333/38528)\n",
      "Epoch: 67 | Batch_idx: 310 |  Loss: (0.1645) | Acc: (94.28%) (37530/39808)\n",
      "Epoch: 67 | Batch_idx: 320 |  Loss: (0.1648) | Acc: (94.26%) (38730/41088)\n",
      "Epoch: 67 | Batch_idx: 330 |  Loss: (0.1650) | Acc: (94.26%) (39938/42368)\n",
      "Epoch: 67 | Batch_idx: 340 |  Loss: (0.1650) | Acc: (94.26%) (41143/43648)\n",
      "Epoch: 67 | Batch_idx: 350 |  Loss: (0.1655) | Acc: (94.24%) (42340/44928)\n",
      "Epoch: 67 | Batch_idx: 360 |  Loss: (0.1660) | Acc: (94.21%) (43534/46208)\n",
      "Epoch: 67 | Batch_idx: 370 |  Loss: (0.1662) | Acc: (94.20%) (44736/47488)\n",
      "Epoch: 67 | Batch_idx: 380 |  Loss: (0.1662) | Acc: (94.20%) (45940/48768)\n",
      "Epoch: 67 | Batch_idx: 390 |  Loss: (0.1664) | Acc: (94.22%) (47108/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4671) | Acc: (86.55%) (8655/10000)\n",
      "Epoch: 68 | Batch_idx: 0 |  Loss: (0.1632) | Acc: (95.31%) (122/128)\n",
      "Epoch: 68 | Batch_idx: 10 |  Loss: (0.1574) | Acc: (94.89%) (1336/1408)\n",
      "Epoch: 68 | Batch_idx: 20 |  Loss: (0.1542) | Acc: (94.61%) (2543/2688)\n",
      "Epoch: 68 | Batch_idx: 30 |  Loss: (0.1610) | Acc: (94.33%) (3743/3968)\n",
      "Epoch: 68 | Batch_idx: 40 |  Loss: (0.1648) | Acc: (94.19%) (4943/5248)\n",
      "Epoch: 68 | Batch_idx: 50 |  Loss: (0.1673) | Acc: (93.93%) (6132/6528)\n",
      "Epoch: 68 | Batch_idx: 60 |  Loss: (0.1671) | Acc: (94.02%) (7341/7808)\n",
      "Epoch: 68 | Batch_idx: 70 |  Loss: (0.1652) | Acc: (94.12%) (8554/9088)\n",
      "Epoch: 68 | Batch_idx: 80 |  Loss: (0.1675) | Acc: (93.95%) (9741/10368)\n",
      "Epoch: 68 | Batch_idx: 90 |  Loss: (0.1669) | Acc: (94.01%) (10950/11648)\n",
      "Epoch: 68 | Batch_idx: 100 |  Loss: (0.1651) | Acc: (94.10%) (12165/12928)\n",
      "Epoch: 68 | Batch_idx: 110 |  Loss: (0.1622) | Acc: (94.16%) (13378/14208)\n",
      "Epoch: 68 | Batch_idx: 120 |  Loss: (0.1618) | Acc: (94.18%) (14586/15488)\n",
      "Epoch: 68 | Batch_idx: 130 |  Loss: (0.1603) | Acc: (94.23%) (15801/16768)\n",
      "Epoch: 68 | Batch_idx: 140 |  Loss: (0.1585) | Acc: (94.33%) (17024/18048)\n",
      "Epoch: 68 | Batch_idx: 150 |  Loss: (0.1585) | Acc: (94.31%) (18229/19328)\n",
      "Epoch: 68 | Batch_idx: 160 |  Loss: (0.1568) | Acc: (94.39%) (19452/20608)\n",
      "Epoch: 68 | Batch_idx: 170 |  Loss: (0.1587) | Acc: (94.33%) (20647/21888)\n",
      "Epoch: 68 | Batch_idx: 180 |  Loss: (0.1586) | Acc: (94.34%) (21857/23168)\n",
      "Epoch: 68 | Batch_idx: 190 |  Loss: (0.1583) | Acc: (94.34%) (23064/24448)\n",
      "Epoch: 68 | Batch_idx: 200 |  Loss: (0.1568) | Acc: (94.38%) (24282/25728)\n",
      "Epoch: 68 | Batch_idx: 210 |  Loss: (0.1570) | Acc: (94.37%) (25488/27008)\n",
      "Epoch: 68 | Batch_idx: 220 |  Loss: (0.1576) | Acc: (94.39%) (26701/28288)\n",
      "Epoch: 68 | Batch_idx: 230 |  Loss: (0.1585) | Acc: (94.37%) (27903/29568)\n",
      "Epoch: 68 | Batch_idx: 240 |  Loss: (0.1597) | Acc: (94.33%) (29099/30848)\n",
      "Epoch: 68 | Batch_idx: 250 |  Loss: (0.1605) | Acc: (94.30%) (30296/32128)\n",
      "Epoch: 68 | Batch_idx: 260 |  Loss: (0.1611) | Acc: (94.28%) (31498/33408)\n",
      "Epoch: 68 | Batch_idx: 270 |  Loss: (0.1605) | Acc: (94.31%) (32713/34688)\n",
      "Epoch: 68 | Batch_idx: 280 |  Loss: (0.1619) | Acc: (94.26%) (33902/35968)\n",
      "Epoch: 68 | Batch_idx: 290 |  Loss: (0.1619) | Acc: (94.27%) (35112/37248)\n",
      "Epoch: 68 | Batch_idx: 300 |  Loss: (0.1612) | Acc: (94.29%) (36327/38528)\n",
      "Epoch: 68 | Batch_idx: 310 |  Loss: (0.1615) | Acc: (94.27%) (37528/39808)\n",
      "Epoch: 68 | Batch_idx: 320 |  Loss: (0.1618) | Acc: (94.26%) (38730/41088)\n",
      "Epoch: 68 | Batch_idx: 330 |  Loss: (0.1621) | Acc: (94.26%) (39937/42368)\n",
      "Epoch: 68 | Batch_idx: 340 |  Loss: (0.1619) | Acc: (94.25%) (41139/43648)\n",
      "Epoch: 68 | Batch_idx: 350 |  Loss: (0.1617) | Acc: (94.24%) (42339/44928)\n",
      "Epoch: 68 | Batch_idx: 360 |  Loss: (0.1615) | Acc: (94.25%) (43550/46208)\n",
      "Epoch: 68 | Batch_idx: 370 |  Loss: (0.1614) | Acc: (94.25%) (44759/47488)\n",
      "Epoch: 68 | Batch_idx: 380 |  Loss: (0.1616) | Acc: (94.26%) (45971/48768)\n",
      "Epoch: 68 | Batch_idx: 390 |  Loss: (0.1615) | Acc: (94.29%) (47145/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4834) | Acc: (86.29%) (8629/10000)\n",
      "Epoch: 69 | Batch_idx: 0 |  Loss: (0.1278) | Acc: (93.75%) (120/128)\n",
      "Epoch: 69 | Batch_idx: 10 |  Loss: (0.1527) | Acc: (94.39%) (1329/1408)\n",
      "Epoch: 69 | Batch_idx: 20 |  Loss: (0.1546) | Acc: (93.97%) (2526/2688)\n",
      "Epoch: 69 | Batch_idx: 30 |  Loss: (0.1548) | Acc: (94.00%) (3730/3968)\n",
      "Epoch: 69 | Batch_idx: 40 |  Loss: (0.1631) | Acc: (93.92%) (4929/5248)\n",
      "Epoch: 69 | Batch_idx: 50 |  Loss: (0.1648) | Acc: (93.81%) (6124/6528)\n",
      "Epoch: 69 | Batch_idx: 60 |  Loss: (0.1639) | Acc: (93.95%) (7336/7808)\n",
      "Epoch: 69 | Batch_idx: 70 |  Loss: (0.1620) | Acc: (94.10%) (8552/9088)\n",
      "Epoch: 69 | Batch_idx: 80 |  Loss: (0.1626) | Acc: (94.19%) (9766/10368)\n",
      "Epoch: 69 | Batch_idx: 90 |  Loss: (0.1613) | Acc: (94.23%) (10976/11648)\n",
      "Epoch: 69 | Batch_idx: 100 |  Loss: (0.1606) | Acc: (94.25%) (12185/12928)\n",
      "Epoch: 69 | Batch_idx: 110 |  Loss: (0.1582) | Acc: (94.40%) (13412/14208)\n",
      "Epoch: 69 | Batch_idx: 120 |  Loss: (0.1590) | Acc: (94.35%) (14613/15488)\n",
      "Epoch: 69 | Batch_idx: 130 |  Loss: (0.1600) | Acc: (94.27%) (15808/16768)\n",
      "Epoch: 69 | Batch_idx: 140 |  Loss: (0.1619) | Acc: (94.23%) (17007/18048)\n",
      "Epoch: 69 | Batch_idx: 150 |  Loss: (0.1636) | Acc: (94.15%) (18197/19328)\n",
      "Epoch: 69 | Batch_idx: 160 |  Loss: (0.1633) | Acc: (94.16%) (19405/20608)\n",
      "Epoch: 69 | Batch_idx: 170 |  Loss: (0.1632) | Acc: (94.18%) (20614/21888)\n",
      "Epoch: 69 | Batch_idx: 180 |  Loss: (0.1623) | Acc: (94.20%) (21824/23168)\n",
      "Epoch: 69 | Batch_idx: 190 |  Loss: (0.1617) | Acc: (94.19%) (23028/24448)\n",
      "Epoch: 69 | Batch_idx: 200 |  Loss: (0.1607) | Acc: (94.23%) (24244/25728)\n",
      "Epoch: 69 | Batch_idx: 210 |  Loss: (0.1603) | Acc: (94.24%) (25451/27008)\n",
      "Epoch: 69 | Batch_idx: 220 |  Loss: (0.1597) | Acc: (94.28%) (26670/28288)\n",
      "Epoch: 69 | Batch_idx: 230 |  Loss: (0.1591) | Acc: (94.33%) (27891/29568)\n",
      "Epoch: 69 | Batch_idx: 240 |  Loss: (0.1595) | Acc: (94.32%) (29096/30848)\n",
      "Epoch: 69 | Batch_idx: 250 |  Loss: (0.1601) | Acc: (94.34%) (30308/32128)\n",
      "Epoch: 69 | Batch_idx: 260 |  Loss: (0.1605) | Acc: (94.31%) (31506/33408)\n",
      "Epoch: 69 | Batch_idx: 270 |  Loss: (0.1608) | Acc: (94.29%) (32706/34688)\n",
      "Epoch: 69 | Batch_idx: 280 |  Loss: (0.1603) | Acc: (94.30%) (33918/35968)\n",
      "Epoch: 69 | Batch_idx: 290 |  Loss: (0.1609) | Acc: (94.28%) (35119/37248)\n",
      "Epoch: 69 | Batch_idx: 300 |  Loss: (0.1616) | Acc: (94.28%) (36323/38528)\n",
      "Epoch: 69 | Batch_idx: 310 |  Loss: (0.1615) | Acc: (94.25%) (37519/39808)\n",
      "Epoch: 69 | Batch_idx: 320 |  Loss: (0.1622) | Acc: (94.23%) (38719/41088)\n",
      "Epoch: 69 | Batch_idx: 330 |  Loss: (0.1623) | Acc: (94.25%) (39930/42368)\n",
      "Epoch: 69 | Batch_idx: 340 |  Loss: (0.1623) | Acc: (94.25%) (41138/43648)\n",
      "Epoch: 69 | Batch_idx: 350 |  Loss: (0.1624) | Acc: (94.26%) (42349/44928)\n",
      "Epoch: 69 | Batch_idx: 360 |  Loss: (0.1626) | Acc: (94.25%) (43551/46208)\n",
      "Epoch: 69 | Batch_idx: 370 |  Loss: (0.1621) | Acc: (94.27%) (44766/47488)\n",
      "Epoch: 69 | Batch_idx: 380 |  Loss: (0.1625) | Acc: (94.24%) (45960/48768)\n",
      "Epoch: 69 | Batch_idx: 390 |  Loss: (0.1627) | Acc: (94.23%) (47115/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4418) | Acc: (87.19%) (8719/10000)\n",
      "Epoch: 70 | Batch_idx: 0 |  Loss: (0.0932) | Acc: (96.88%) (124/128)\n",
      "Epoch: 70 | Batch_idx: 10 |  Loss: (0.1603) | Acc: (93.82%) (1321/1408)\n",
      "Epoch: 70 | Batch_idx: 20 |  Loss: (0.1448) | Acc: (94.68%) (2545/2688)\n",
      "Epoch: 70 | Batch_idx: 30 |  Loss: (0.1450) | Acc: (94.76%) (3760/3968)\n",
      "Epoch: 70 | Batch_idx: 40 |  Loss: (0.1491) | Acc: (94.76%) (4973/5248)\n",
      "Epoch: 70 | Batch_idx: 50 |  Loss: (0.1526) | Acc: (94.64%) (6178/6528)\n",
      "Epoch: 70 | Batch_idx: 60 |  Loss: (0.1503) | Acc: (94.74%) (7397/7808)\n",
      "Epoch: 70 | Batch_idx: 70 |  Loss: (0.1487) | Acc: (94.78%) (8614/9088)\n",
      "Epoch: 70 | Batch_idx: 80 |  Loss: (0.1494) | Acc: (94.75%) (9824/10368)\n",
      "Epoch: 70 | Batch_idx: 90 |  Loss: (0.1504) | Acc: (94.71%) (11032/11648)\n",
      "Epoch: 70 | Batch_idx: 100 |  Loss: (0.1491) | Acc: (94.70%) (12243/12928)\n",
      "Epoch: 70 | Batch_idx: 110 |  Loss: (0.1504) | Acc: (94.66%) (13450/14208)\n",
      "Epoch: 70 | Batch_idx: 120 |  Loss: (0.1521) | Acc: (94.59%) (14650/15488)\n",
      "Epoch: 70 | Batch_idx: 130 |  Loss: (0.1510) | Acc: (94.67%) (15874/16768)\n",
      "Epoch: 70 | Batch_idx: 140 |  Loss: (0.1509) | Acc: (94.65%) (17082/18048)\n",
      "Epoch: 70 | Batch_idx: 150 |  Loss: (0.1518) | Acc: (94.68%) (18300/19328)\n",
      "Epoch: 70 | Batch_idx: 160 |  Loss: (0.1533) | Acc: (94.65%) (19506/20608)\n",
      "Epoch: 70 | Batch_idx: 170 |  Loss: (0.1535) | Acc: (94.61%) (20708/21888)\n",
      "Epoch: 70 | Batch_idx: 180 |  Loss: (0.1541) | Acc: (94.63%) (21923/23168)\n",
      "Epoch: 70 | Batch_idx: 190 |  Loss: (0.1540) | Acc: (94.61%) (23131/24448)\n",
      "Epoch: 70 | Batch_idx: 200 |  Loss: (0.1564) | Acc: (94.54%) (24324/25728)\n",
      "Epoch: 70 | Batch_idx: 210 |  Loss: (0.1554) | Acc: (94.61%) (25551/27008)\n",
      "Epoch: 70 | Batch_idx: 220 |  Loss: (0.1553) | Acc: (94.60%) (26760/28288)\n",
      "Epoch: 70 | Batch_idx: 230 |  Loss: (0.1553) | Acc: (94.61%) (27974/29568)\n",
      "Epoch: 70 | Batch_idx: 240 |  Loss: (0.1560) | Acc: (94.56%) (29169/30848)\n",
      "Epoch: 70 | Batch_idx: 250 |  Loss: (0.1578) | Acc: (94.48%) (30354/32128)\n",
      "Epoch: 70 | Batch_idx: 260 |  Loss: (0.1580) | Acc: (94.46%) (31556/33408)\n",
      "Epoch: 70 | Batch_idx: 270 |  Loss: (0.1591) | Acc: (94.40%) (32746/34688)\n",
      "Epoch: 70 | Batch_idx: 280 |  Loss: (0.1587) | Acc: (94.42%) (33960/35968)\n",
      "Epoch: 70 | Batch_idx: 290 |  Loss: (0.1587) | Acc: (94.41%) (35167/37248)\n",
      "Epoch: 70 | Batch_idx: 300 |  Loss: (0.1590) | Acc: (94.41%) (36376/38528)\n",
      "Epoch: 70 | Batch_idx: 310 |  Loss: (0.1589) | Acc: (94.43%) (37589/39808)\n",
      "Epoch: 70 | Batch_idx: 320 |  Loss: (0.1589) | Acc: (94.41%) (38792/41088)\n",
      "Epoch: 70 | Batch_idx: 330 |  Loss: (0.1582) | Acc: (94.44%) (40011/42368)\n",
      "Epoch: 70 | Batch_idx: 340 |  Loss: (0.1586) | Acc: (94.40%) (41204/43648)\n",
      "Epoch: 70 | Batch_idx: 350 |  Loss: (0.1587) | Acc: (94.38%) (42405/44928)\n",
      "Epoch: 70 | Batch_idx: 360 |  Loss: (0.1582) | Acc: (94.40%) (43621/46208)\n",
      "Epoch: 70 | Batch_idx: 370 |  Loss: (0.1589) | Acc: (94.38%) (44818/47488)\n",
      "Epoch: 70 | Batch_idx: 380 |  Loss: (0.1588) | Acc: (94.38%) (46029/48768)\n",
      "Epoch: 70 | Batch_idx: 390 |  Loss: (0.1591) | Acc: (94.37%) (47185/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4657) | Acc: (86.56%) (8656/10000)\n",
      "Epoch: 71 | Batch_idx: 0 |  Loss: (0.2160) | Acc: (92.19%) (118/128)\n",
      "Epoch: 71 | Batch_idx: 10 |  Loss: (0.1448) | Acc: (95.24%) (1341/1408)\n",
      "Epoch: 71 | Batch_idx: 20 |  Loss: (0.1554) | Acc: (94.53%) (2541/2688)\n",
      "Epoch: 71 | Batch_idx: 30 |  Loss: (0.1462) | Acc: (94.88%) (3765/3968)\n",
      "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1434) | Acc: (94.84%) (4977/5248)\n",
      "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1442) | Acc: (94.88%) (6194/6528)\n",
      "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1483) | Acc: (94.75%) (7398/7808)\n",
      "Epoch: 71 | Batch_idx: 70 |  Loss: (0.1494) | Acc: (94.75%) (8611/9088)\n",
      "Epoch: 71 | Batch_idx: 80 |  Loss: (0.1488) | Acc: (94.75%) (9824/10368)\n",
      "Epoch: 71 | Batch_idx: 90 |  Loss: (0.1488) | Acc: (94.63%) (11023/11648)\n",
      "Epoch: 71 | Batch_idx: 100 |  Loss: (0.1474) | Acc: (94.67%) (12239/12928)\n",
      "Epoch: 71 | Batch_idx: 110 |  Loss: (0.1462) | Acc: (94.76%) (13463/14208)\n",
      "Epoch: 71 | Batch_idx: 120 |  Loss: (0.1459) | Acc: (94.83%) (14687/15488)\n",
      "Epoch: 71 | Batch_idx: 130 |  Loss: (0.1465) | Acc: (94.81%) (15897/16768)\n",
      "Epoch: 71 | Batch_idx: 140 |  Loss: (0.1453) | Acc: (94.87%) (17122/18048)\n",
      "Epoch: 71 | Batch_idx: 150 |  Loss: (0.1455) | Acc: (94.83%) (18328/19328)\n",
      "Epoch: 71 | Batch_idx: 160 |  Loss: (0.1449) | Acc: (94.86%) (19548/20608)\n",
      "Epoch: 71 | Batch_idx: 170 |  Loss: (0.1454) | Acc: (94.86%) (20762/21888)\n",
      "Epoch: 71 | Batch_idx: 180 |  Loss: (0.1453) | Acc: (94.91%) (21989/23168)\n",
      "Epoch: 71 | Batch_idx: 190 |  Loss: (0.1465) | Acc: (94.85%) (23189/24448)\n",
      "Epoch: 71 | Batch_idx: 200 |  Loss: (0.1476) | Acc: (94.81%) (24393/25728)\n",
      "Epoch: 71 | Batch_idx: 210 |  Loss: (0.1468) | Acc: (94.82%) (25609/27008)\n",
      "Epoch: 71 | Batch_idx: 220 |  Loss: (0.1464) | Acc: (94.82%) (26823/28288)\n",
      "Epoch: 71 | Batch_idx: 230 |  Loss: (0.1469) | Acc: (94.80%) (28030/29568)\n",
      "Epoch: 71 | Batch_idx: 240 |  Loss: (0.1473) | Acc: (94.78%) (29239/30848)\n",
      "Epoch: 71 | Batch_idx: 250 |  Loss: (0.1478) | Acc: (94.77%) (30447/32128)\n",
      "Epoch: 71 | Batch_idx: 260 |  Loss: (0.1494) | Acc: (94.70%) (31637/33408)\n",
      "Epoch: 71 | Batch_idx: 270 |  Loss: (0.1493) | Acc: (94.72%) (32856/34688)\n",
      "Epoch: 71 | Batch_idx: 280 |  Loss: (0.1495) | Acc: (94.71%) (34066/35968)\n",
      "Epoch: 71 | Batch_idx: 290 |  Loss: (0.1494) | Acc: (94.72%) (35283/37248)\n",
      "Epoch: 71 | Batch_idx: 300 |  Loss: (0.1498) | Acc: (94.71%) (36491/38528)\n",
      "Epoch: 71 | Batch_idx: 310 |  Loss: (0.1511) | Acc: (94.67%) (37688/39808)\n",
      "Epoch: 71 | Batch_idx: 320 |  Loss: (0.1510) | Acc: (94.68%) (38904/41088)\n",
      "Epoch: 71 | Batch_idx: 330 |  Loss: (0.1516) | Acc: (94.66%) (40104/42368)\n",
      "Epoch: 71 | Batch_idx: 340 |  Loss: (0.1520) | Acc: (94.64%) (41307/43648)\n",
      "Epoch: 71 | Batch_idx: 350 |  Loss: (0.1520) | Acc: (94.63%) (42515/44928)\n",
      "Epoch: 71 | Batch_idx: 360 |  Loss: (0.1525) | Acc: (94.60%) (43714/46208)\n",
      "Epoch: 71 | Batch_idx: 370 |  Loss: (0.1532) | Acc: (94.58%) (44916/47488)\n",
      "Epoch: 71 | Batch_idx: 380 |  Loss: (0.1532) | Acc: (94.59%) (46129/48768)\n",
      "Epoch: 71 | Batch_idx: 390 |  Loss: (0.1535) | Acc: (94.57%) (47286/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4755) | Acc: (86.79%) (8679/10000)\n",
      "Epoch: 72 | Batch_idx: 0 |  Loss: (0.0686) | Acc: (98.44%) (126/128)\n",
      "Epoch: 72 | Batch_idx: 10 |  Loss: (0.1452) | Acc: (94.60%) (1332/1408)\n",
      "Epoch: 72 | Batch_idx: 20 |  Loss: (0.1392) | Acc: (94.90%) (2551/2688)\n",
      "Epoch: 72 | Batch_idx: 30 |  Loss: (0.1409) | Acc: (94.88%) (3765/3968)\n",
      "Epoch: 72 | Batch_idx: 40 |  Loss: (0.1402) | Acc: (95.12%) (4992/5248)\n",
      "Epoch: 72 | Batch_idx: 50 |  Loss: (0.1393) | Acc: (95.13%) (6210/6528)\n",
      "Epoch: 72 | Batch_idx: 60 |  Loss: (0.1395) | Acc: (95.22%) (7435/7808)\n",
      "Epoch: 72 | Batch_idx: 70 |  Loss: (0.1389) | Acc: (95.25%) (8656/9088)\n",
      "Epoch: 72 | Batch_idx: 80 |  Loss: (0.1398) | Acc: (95.22%) (9872/10368)\n",
      "Epoch: 72 | Batch_idx: 90 |  Loss: (0.1420) | Acc: (95.10%) (11077/11648)\n",
      "Epoch: 72 | Batch_idx: 100 |  Loss: (0.1442) | Acc: (95.05%) (12288/12928)\n",
      "Epoch: 72 | Batch_idx: 110 |  Loss: (0.1458) | Acc: (95.00%) (13498/14208)\n",
      "Epoch: 72 | Batch_idx: 120 |  Loss: (0.1470) | Acc: (94.96%) (14707/15488)\n",
      "Epoch: 72 | Batch_idx: 130 |  Loss: (0.1465) | Acc: (94.99%) (15928/16768)\n",
      "Epoch: 72 | Batch_idx: 140 |  Loss: (0.1476) | Acc: (94.99%) (17143/18048)\n",
      "Epoch: 72 | Batch_idx: 150 |  Loss: (0.1483) | Acc: (94.92%) (18347/19328)\n",
      "Epoch: 72 | Batch_idx: 160 |  Loss: (0.1481) | Acc: (94.91%) (19559/20608)\n",
      "Epoch: 72 | Batch_idx: 170 |  Loss: (0.1477) | Acc: (94.91%) (20774/21888)\n",
      "Epoch: 72 | Batch_idx: 180 |  Loss: (0.1479) | Acc: (94.92%) (21992/23168)\n",
      "Epoch: 72 | Batch_idx: 190 |  Loss: (0.1488) | Acc: (94.91%) (23204/24448)\n",
      "Epoch: 72 | Batch_idx: 200 |  Loss: (0.1490) | Acc: (94.90%) (24417/25728)\n",
      "Epoch: 72 | Batch_idx: 210 |  Loss: (0.1487) | Acc: (94.93%) (25638/27008)\n",
      "Epoch: 72 | Batch_idx: 220 |  Loss: (0.1482) | Acc: (94.92%) (26852/28288)\n",
      "Epoch: 72 | Batch_idx: 230 |  Loss: (0.1481) | Acc: (94.92%) (28066/29568)\n",
      "Epoch: 72 | Batch_idx: 240 |  Loss: (0.1490) | Acc: (94.88%) (29270/30848)\n",
      "Epoch: 72 | Batch_idx: 250 |  Loss: (0.1483) | Acc: (94.90%) (30488/32128)\n",
      "Epoch: 72 | Batch_idx: 260 |  Loss: (0.1488) | Acc: (94.89%) (31701/33408)\n",
      "Epoch: 72 | Batch_idx: 270 |  Loss: (0.1497) | Acc: (94.87%) (32907/34688)\n",
      "Epoch: 72 | Batch_idx: 280 |  Loss: (0.1495) | Acc: (94.89%) (34129/35968)\n",
      "Epoch: 72 | Batch_idx: 290 |  Loss: (0.1505) | Acc: (94.88%) (35341/37248)\n",
      "Epoch: 72 | Batch_idx: 300 |  Loss: (0.1509) | Acc: (94.85%) (36544/38528)\n",
      "Epoch: 72 | Batch_idx: 310 |  Loss: (0.1508) | Acc: (94.86%) (37760/39808)\n",
      "Epoch: 72 | Batch_idx: 320 |  Loss: (0.1508) | Acc: (94.85%) (38972/41088)\n",
      "Epoch: 72 | Batch_idx: 330 |  Loss: (0.1507) | Acc: (94.86%) (40190/42368)\n",
      "Epoch: 72 | Batch_idx: 340 |  Loss: (0.1511) | Acc: (94.83%) (41391/43648)\n",
      "Epoch: 72 | Batch_idx: 350 |  Loss: (0.1510) | Acc: (94.84%) (42611/44928)\n",
      "Epoch: 72 | Batch_idx: 360 |  Loss: (0.1503) | Acc: (94.86%) (43833/46208)\n",
      "Epoch: 72 | Batch_idx: 370 |  Loss: (0.1501) | Acc: (94.87%) (45053/47488)\n",
      "Epoch: 72 | Batch_idx: 380 |  Loss: (0.1500) | Acc: (94.87%) (46267/48768)\n",
      "Epoch: 72 | Batch_idx: 390 |  Loss: (0.1496) | Acc: (94.87%) (47433/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4433) | Acc: (87.25%) (8725/10000)\n",
      "Epoch: 73 | Batch_idx: 0 |  Loss: (0.0786) | Acc: (97.66%) (125/128)\n",
      "Epoch: 73 | Batch_idx: 10 |  Loss: (0.1238) | Acc: (95.67%) (1347/1408)\n",
      "Epoch: 73 | Batch_idx: 20 |  Loss: (0.1217) | Acc: (95.91%) (2578/2688)\n",
      "Epoch: 73 | Batch_idx: 30 |  Loss: (0.1249) | Acc: (95.89%) (3805/3968)\n",
      "Epoch: 73 | Batch_idx: 40 |  Loss: (0.1296) | Acc: (95.73%) (5024/5248)\n",
      "Epoch: 73 | Batch_idx: 50 |  Loss: (0.1292) | Acc: (95.74%) (6250/6528)\n",
      "Epoch: 73 | Batch_idx: 60 |  Loss: (0.1282) | Acc: (95.74%) (7475/7808)\n",
      "Epoch: 73 | Batch_idx: 70 |  Loss: (0.1313) | Acc: (95.64%) (8692/9088)\n",
      "Epoch: 73 | Batch_idx: 80 |  Loss: (0.1333) | Acc: (95.58%) (9910/10368)\n",
      "Epoch: 73 | Batch_idx: 90 |  Loss: (0.1342) | Acc: (95.54%) (11128/11648)\n",
      "Epoch: 73 | Batch_idx: 100 |  Loss: (0.1365) | Acc: (95.41%) (12335/12928)\n",
      "Epoch: 73 | Batch_idx: 110 |  Loss: (0.1365) | Acc: (95.38%) (13552/14208)\n",
      "Epoch: 73 | Batch_idx: 120 |  Loss: (0.1368) | Acc: (95.39%) (14774/15488)\n",
      "Epoch: 73 | Batch_idx: 130 |  Loss: (0.1360) | Acc: (95.41%) (15998/16768)\n",
      "Epoch: 73 | Batch_idx: 140 |  Loss: (0.1373) | Acc: (95.37%) (17212/18048)\n",
      "Epoch: 73 | Batch_idx: 150 |  Loss: (0.1388) | Acc: (95.27%) (18413/19328)\n",
      "Epoch: 73 | Batch_idx: 160 |  Loss: (0.1410) | Acc: (95.23%) (19625/20608)\n",
      "Epoch: 73 | Batch_idx: 170 |  Loss: (0.1421) | Acc: (95.19%) (20835/21888)\n",
      "Epoch: 73 | Batch_idx: 180 |  Loss: (0.1422) | Acc: (95.17%) (22049/23168)\n",
      "Epoch: 73 | Batch_idx: 190 |  Loss: (0.1429) | Acc: (95.15%) (23262/24448)\n",
      "Epoch: 73 | Batch_idx: 200 |  Loss: (0.1429) | Acc: (95.15%) (24480/25728)\n",
      "Epoch: 73 | Batch_idx: 210 |  Loss: (0.1417) | Acc: (95.17%) (25704/27008)\n",
      "Epoch: 73 | Batch_idx: 220 |  Loss: (0.1417) | Acc: (95.17%) (26923/28288)\n",
      "Epoch: 73 | Batch_idx: 230 |  Loss: (0.1427) | Acc: (95.15%) (28133/29568)\n",
      "Epoch: 73 | Batch_idx: 240 |  Loss: (0.1426) | Acc: (95.15%) (29351/30848)\n",
      "Epoch: 73 | Batch_idx: 250 |  Loss: (0.1440) | Acc: (95.08%) (30548/32128)\n",
      "Epoch: 73 | Batch_idx: 260 |  Loss: (0.1441) | Acc: (95.09%) (31768/33408)\n",
      "Epoch: 73 | Batch_idx: 270 |  Loss: (0.1444) | Acc: (95.09%) (32985/34688)\n",
      "Epoch: 73 | Batch_idx: 280 |  Loss: (0.1447) | Acc: (95.06%) (34191/35968)\n",
      "Epoch: 73 | Batch_idx: 290 |  Loss: (0.1453) | Acc: (95.03%) (35398/37248)\n",
      "Epoch: 73 | Batch_idx: 300 |  Loss: (0.1446) | Acc: (95.07%) (36627/38528)\n",
      "Epoch: 73 | Batch_idx: 310 |  Loss: (0.1457) | Acc: (95.00%) (37819/39808)\n",
      "Epoch: 73 | Batch_idx: 320 |  Loss: (0.1454) | Acc: (95.00%) (39033/41088)\n",
      "Epoch: 73 | Batch_idx: 330 |  Loss: (0.1452) | Acc: (95.02%) (40256/42368)\n",
      "Epoch: 73 | Batch_idx: 340 |  Loss: (0.1454) | Acc: (95.01%) (41471/43648)\n",
      "Epoch: 73 | Batch_idx: 350 |  Loss: (0.1462) | Acc: (94.97%) (42667/44928)\n",
      "Epoch: 73 | Batch_idx: 360 |  Loss: (0.1462) | Acc: (94.97%) (43885/46208)\n",
      "Epoch: 73 | Batch_idx: 370 |  Loss: (0.1466) | Acc: (94.97%) (45097/47488)\n",
      "Epoch: 73 | Batch_idx: 380 |  Loss: (0.1461) | Acc: (95.00%) (46330/48768)\n",
      "Epoch: 73 | Batch_idx: 390 |  Loss: (0.1462) | Acc: (95.00%) (47498/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4252) | Acc: (88.02%) (8802/10000)\n",
      "Epoch: 74 | Batch_idx: 0 |  Loss: (0.1315) | Acc: (93.75%) (120/128)\n",
      "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1355) | Acc: (95.53%) (1345/1408)\n",
      "Epoch: 74 | Batch_idx: 20 |  Loss: (0.1312) | Acc: (95.91%) (2578/2688)\n",
      "Epoch: 74 | Batch_idx: 30 |  Loss: (0.1356) | Acc: (95.64%) (3795/3968)\n",
      "Epoch: 74 | Batch_idx: 40 |  Loss: (0.1363) | Acc: (95.52%) (5013/5248)\n",
      "Epoch: 74 | Batch_idx: 50 |  Loss: (0.1429) | Acc: (95.33%) (6223/6528)\n",
      "Epoch: 74 | Batch_idx: 60 |  Loss: (0.1403) | Acc: (95.34%) (7444/7808)\n",
      "Epoch: 74 | Batch_idx: 70 |  Loss: (0.1437) | Acc: (95.25%) (8656/9088)\n",
      "Epoch: 74 | Batch_idx: 80 |  Loss: (0.1435) | Acc: (95.26%) (9877/10368)\n",
      "Epoch: 74 | Batch_idx: 90 |  Loss: (0.1425) | Acc: (95.23%) (11092/11648)\n",
      "Epoch: 74 | Batch_idx: 100 |  Loss: (0.1410) | Acc: (95.22%) (12310/12928)\n",
      "Epoch: 74 | Batch_idx: 110 |  Loss: (0.1399) | Acc: (95.23%) (13530/14208)\n",
      "Epoch: 74 | Batch_idx: 120 |  Loss: (0.1404) | Acc: (95.25%) (14752/15488)\n",
      "Epoch: 74 | Batch_idx: 130 |  Loss: (0.1384) | Acc: (95.31%) (15982/16768)\n",
      "Epoch: 74 | Batch_idx: 140 |  Loss: (0.1387) | Acc: (95.26%) (17193/18048)\n",
      "Epoch: 74 | Batch_idx: 150 |  Loss: (0.1383) | Acc: (95.27%) (18413/19328)\n",
      "Epoch: 74 | Batch_idx: 160 |  Loss: (0.1382) | Acc: (95.25%) (19630/20608)\n",
      "Epoch: 74 | Batch_idx: 170 |  Loss: (0.1378) | Acc: (95.23%) (20843/21888)\n",
      "Epoch: 74 | Batch_idx: 180 |  Loss: (0.1394) | Acc: (95.18%) (22051/23168)\n",
      "Epoch: 74 | Batch_idx: 190 |  Loss: (0.1390) | Acc: (95.20%) (23275/24448)\n",
      "Epoch: 74 | Batch_idx: 200 |  Loss: (0.1388) | Acc: (95.19%) (24491/25728)\n",
      "Epoch: 74 | Batch_idx: 210 |  Loss: (0.1396) | Acc: (95.17%) (25703/27008)\n",
      "Epoch: 74 | Batch_idx: 220 |  Loss: (0.1402) | Acc: (95.15%) (26917/28288)\n",
      "Epoch: 74 | Batch_idx: 230 |  Loss: (0.1412) | Acc: (95.08%) (28114/29568)\n",
      "Epoch: 74 | Batch_idx: 240 |  Loss: (0.1423) | Acc: (95.03%) (29316/30848)\n",
      "Epoch: 74 | Batch_idx: 250 |  Loss: (0.1430) | Acc: (95.03%) (30531/32128)\n",
      "Epoch: 74 | Batch_idx: 260 |  Loss: (0.1422) | Acc: (95.06%) (31758/33408)\n",
      "Epoch: 74 | Batch_idx: 270 |  Loss: (0.1425) | Acc: (95.06%) (32976/34688)\n",
      "Epoch: 74 | Batch_idx: 280 |  Loss: (0.1421) | Acc: (95.09%) (34202/35968)\n",
      "Epoch: 74 | Batch_idx: 290 |  Loss: (0.1427) | Acc: (95.07%) (35412/37248)\n",
      "Epoch: 74 | Batch_idx: 300 |  Loss: (0.1438) | Acc: (95.03%) (36613/38528)\n",
      "Epoch: 74 | Batch_idx: 310 |  Loss: (0.1440) | Acc: (95.00%) (37818/39808)\n",
      "Epoch: 74 | Batch_idx: 320 |  Loss: (0.1441) | Acc: (94.98%) (39025/41088)\n",
      "Epoch: 74 | Batch_idx: 330 |  Loss: (0.1450) | Acc: (94.95%) (40227/42368)\n",
      "Epoch: 74 | Batch_idx: 340 |  Loss: (0.1446) | Acc: (94.97%) (41452/43648)\n",
      "Epoch: 74 | Batch_idx: 350 |  Loss: (0.1448) | Acc: (94.97%) (42669/44928)\n",
      "Epoch: 74 | Batch_idx: 360 |  Loss: (0.1448) | Acc: (94.98%) (43887/46208)\n",
      "Epoch: 74 | Batch_idx: 370 |  Loss: (0.1451) | Acc: (94.96%) (45093/47488)\n",
      "Epoch: 74 | Batch_idx: 380 |  Loss: (0.1452) | Acc: (94.96%) (46311/48768)\n",
      "Epoch: 74 | Batch_idx: 390 |  Loss: (0.1454) | Acc: (94.94%) (47470/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4311) | Acc: (87.78%) (8778/10000)\n",
      "Epoch: 75 | Batch_idx: 0 |  Loss: (0.1599) | Acc: (92.19%) (118/128)\n",
      "Epoch: 75 | Batch_idx: 10 |  Loss: (0.1494) | Acc: (93.82%) (1321/1408)\n",
      "Epoch: 75 | Batch_idx: 20 |  Loss: (0.1416) | Acc: (94.94%) (2552/2688)\n",
      "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1380) | Acc: (95.24%) (3779/3968)\n",
      "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1335) | Acc: (95.39%) (5006/5248)\n",
      "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1278) | Acc: (95.63%) (6243/6528)\n",
      "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1281) | Acc: (95.57%) (7462/7808)\n",
      "Epoch: 75 | Batch_idx: 70 |  Loss: (0.1299) | Acc: (95.54%) (8683/9088)\n",
      "Epoch: 75 | Batch_idx: 80 |  Loss: (0.1306) | Acc: (95.55%) (9907/10368)\n",
      "Epoch: 75 | Batch_idx: 90 |  Loss: (0.1350) | Acc: (95.30%) (11101/11648)\n",
      "Epoch: 75 | Batch_idx: 100 |  Loss: (0.1351) | Acc: (95.28%) (12318/12928)\n",
      "Epoch: 75 | Batch_idx: 110 |  Loss: (0.1368) | Acc: (95.23%) (13530/14208)\n",
      "Epoch: 75 | Batch_idx: 120 |  Loss: (0.1379) | Acc: (95.17%) (14740/15488)\n",
      "Epoch: 75 | Batch_idx: 130 |  Loss: (0.1375) | Acc: (95.21%) (15964/16768)\n",
      "Epoch: 75 | Batch_idx: 140 |  Loss: (0.1390) | Acc: (95.16%) (17174/18048)\n",
      "Epoch: 75 | Batch_idx: 150 |  Loss: (0.1393) | Acc: (95.15%) (18391/19328)\n",
      "Epoch: 75 | Batch_idx: 160 |  Loss: (0.1398) | Acc: (95.13%) (19605/20608)\n",
      "Epoch: 75 | Batch_idx: 170 |  Loss: (0.1409) | Acc: (95.07%) (20808/21888)\n",
      "Epoch: 75 | Batch_idx: 180 |  Loss: (0.1416) | Acc: (95.02%) (22015/23168)\n",
      "Epoch: 75 | Batch_idx: 190 |  Loss: (0.1408) | Acc: (95.04%) (23236/24448)\n",
      "Epoch: 75 | Batch_idx: 200 |  Loss: (0.1411) | Acc: (95.00%) (24442/25728)\n",
      "Epoch: 75 | Batch_idx: 210 |  Loss: (0.1411) | Acc: (94.99%) (25656/27008)\n",
      "Epoch: 75 | Batch_idx: 220 |  Loss: (0.1403) | Acc: (95.02%) (26880/28288)\n",
      "Epoch: 75 | Batch_idx: 230 |  Loss: (0.1396) | Acc: (95.05%) (28104/29568)\n",
      "Epoch: 75 | Batch_idx: 240 |  Loss: (0.1393) | Acc: (95.08%) (29331/30848)\n",
      "Epoch: 75 | Batch_idx: 250 |  Loss: (0.1385) | Acc: (95.11%) (30557/32128)\n",
      "Epoch: 75 | Batch_idx: 260 |  Loss: (0.1389) | Acc: (95.10%) (31771/33408)\n",
      "Epoch: 75 | Batch_idx: 270 |  Loss: (0.1395) | Acc: (95.06%) (32976/34688)\n",
      "Epoch: 75 | Batch_idx: 280 |  Loss: (0.1400) | Acc: (95.04%) (34185/35968)\n",
      "Epoch: 75 | Batch_idx: 290 |  Loss: (0.1402) | Acc: (95.03%) (35395/37248)\n",
      "Epoch: 75 | Batch_idx: 300 |  Loss: (0.1402) | Acc: (95.02%) (36610/38528)\n",
      "Epoch: 75 | Batch_idx: 310 |  Loss: (0.1405) | Acc: (95.01%) (37820/39808)\n",
      "Epoch: 75 | Batch_idx: 320 |  Loss: (0.1406) | Acc: (95.01%) (39039/41088)\n",
      "Epoch: 75 | Batch_idx: 330 |  Loss: (0.1413) | Acc: (94.99%) (40247/42368)\n",
      "Epoch: 75 | Batch_idx: 340 |  Loss: (0.1421) | Acc: (94.98%) (41456/43648)\n",
      "Epoch: 75 | Batch_idx: 350 |  Loss: (0.1418) | Acc: (94.99%) (42679/44928)\n",
      "Epoch: 75 | Batch_idx: 360 |  Loss: (0.1421) | Acc: (94.98%) (43887/46208)\n",
      "Epoch: 75 | Batch_idx: 370 |  Loss: (0.1420) | Acc: (94.98%) (45103/47488)\n",
      "Epoch: 75 | Batch_idx: 380 |  Loss: (0.1420) | Acc: (94.98%) (46319/48768)\n",
      "Epoch: 75 | Batch_idx: 390 |  Loss: (0.1419) | Acc: (94.98%) (47492/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5368) | Acc: (85.61%) (8561/10000)\n",
      "Epoch: 76 | Batch_idx: 0 |  Loss: (0.1867) | Acc: (90.62%) (116/128)\n",
      "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1302) | Acc: (95.45%) (1344/1408)\n",
      "Epoch: 76 | Batch_idx: 20 |  Loss: (0.1360) | Acc: (95.24%) (2560/2688)\n",
      "Epoch: 76 | Batch_idx: 30 |  Loss: (0.1310) | Acc: (95.46%) (3788/3968)\n",
      "Epoch: 76 | Batch_idx: 40 |  Loss: (0.1277) | Acc: (95.67%) (5021/5248)\n",
      "Epoch: 76 | Batch_idx: 50 |  Loss: (0.1362) | Acc: (95.25%) (6218/6528)\n",
      "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1381) | Acc: (95.11%) (7426/7808)\n",
      "Epoch: 76 | Batch_idx: 70 |  Loss: (0.1373) | Acc: (95.11%) (8644/9088)\n",
      "Epoch: 76 | Batch_idx: 80 |  Loss: (0.1373) | Acc: (95.11%) (9861/10368)\n",
      "Epoch: 76 | Batch_idx: 90 |  Loss: (0.1381) | Acc: (95.07%) (11074/11648)\n",
      "Epoch: 76 | Batch_idx: 100 |  Loss: (0.1391) | Acc: (95.06%) (12289/12928)\n",
      "Epoch: 76 | Batch_idx: 110 |  Loss: (0.1387) | Acc: (95.08%) (13509/14208)\n",
      "Epoch: 76 | Batch_idx: 120 |  Loss: (0.1380) | Acc: (95.09%) (14728/15488)\n",
      "Epoch: 76 | Batch_idx: 130 |  Loss: (0.1374) | Acc: (95.12%) (15949/16768)\n",
      "Epoch: 76 | Batch_idx: 140 |  Loss: (0.1379) | Acc: (95.06%) (17156/18048)\n",
      "Epoch: 76 | Batch_idx: 150 |  Loss: (0.1380) | Acc: (95.08%) (18377/19328)\n",
      "Epoch: 76 | Batch_idx: 160 |  Loss: (0.1387) | Acc: (95.06%) (19589/20608)\n",
      "Epoch: 76 | Batch_idx: 170 |  Loss: (0.1381) | Acc: (95.10%) (20815/21888)\n",
      "Epoch: 76 | Batch_idx: 180 |  Loss: (0.1382) | Acc: (95.08%) (22029/23168)\n",
      "Epoch: 76 | Batch_idx: 190 |  Loss: (0.1375) | Acc: (95.09%) (23247/24448)\n",
      "Epoch: 76 | Batch_idx: 200 |  Loss: (0.1368) | Acc: (95.10%) (24467/25728)\n",
      "Epoch: 76 | Batch_idx: 210 |  Loss: (0.1372) | Acc: (95.10%) (25685/27008)\n",
      "Epoch: 76 | Batch_idx: 220 |  Loss: (0.1377) | Acc: (95.09%) (26900/28288)\n",
      "Epoch: 76 | Batch_idx: 230 |  Loss: (0.1373) | Acc: (95.10%) (28120/29568)\n",
      "Epoch: 76 | Batch_idx: 240 |  Loss: (0.1374) | Acc: (95.12%) (29342/30848)\n",
      "Epoch: 76 | Batch_idx: 250 |  Loss: (0.1378) | Acc: (95.13%) (30564/32128)\n",
      "Epoch: 76 | Batch_idx: 260 |  Loss: (0.1380) | Acc: (95.12%) (31779/33408)\n",
      "Epoch: 76 | Batch_idx: 270 |  Loss: (0.1384) | Acc: (95.13%) (32997/34688)\n",
      "Epoch: 76 | Batch_idx: 280 |  Loss: (0.1381) | Acc: (95.15%) (34222/35968)\n",
      "Epoch: 76 | Batch_idx: 290 |  Loss: (0.1385) | Acc: (95.14%) (35439/37248)\n",
      "Epoch: 76 | Batch_idx: 300 |  Loss: (0.1380) | Acc: (95.17%) (36666/38528)\n",
      "Epoch: 76 | Batch_idx: 310 |  Loss: (0.1376) | Acc: (95.19%) (37895/39808)\n",
      "Epoch: 76 | Batch_idx: 320 |  Loss: (0.1380) | Acc: (95.17%) (39105/41088)\n",
      "Epoch: 76 | Batch_idx: 330 |  Loss: (0.1379) | Acc: (95.17%) (40322/42368)\n",
      "Epoch: 76 | Batch_idx: 340 |  Loss: (0.1377) | Acc: (95.18%) (41543/43648)\n",
      "Epoch: 76 | Batch_idx: 350 |  Loss: (0.1391) | Acc: (95.13%) (42740/44928)\n",
      "Epoch: 76 | Batch_idx: 360 |  Loss: (0.1397) | Acc: (95.11%) (43947/46208)\n",
      "Epoch: 76 | Batch_idx: 370 |  Loss: (0.1396) | Acc: (95.10%) (45163/47488)\n",
      "Epoch: 76 | Batch_idx: 380 |  Loss: (0.1403) | Acc: (95.11%) (46383/48768)\n",
      "Epoch: 76 | Batch_idx: 390 |  Loss: (0.1403) | Acc: (95.09%) (47547/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4356) | Acc: (87.34%) (8734/10000)\n",
      "Epoch: 77 | Batch_idx: 0 |  Loss: (0.1163) | Acc: (96.09%) (123/128)\n",
      "Epoch: 77 | Batch_idx: 10 |  Loss: (0.1052) | Acc: (96.59%) (1360/1408)\n",
      "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1164) | Acc: (96.09%) (2583/2688)\n",
      "Epoch: 77 | Batch_idx: 30 |  Loss: (0.1279) | Acc: (95.67%) (3796/3968)\n",
      "Epoch: 77 | Batch_idx: 40 |  Loss: (0.1315) | Acc: (95.50%) (5012/5248)\n",
      "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1307) | Acc: (95.48%) (6233/6528)\n",
      "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1296) | Acc: (95.47%) (7454/7808)\n",
      "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1298) | Acc: (95.51%) (8680/9088)\n",
      "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1306) | Acc: (95.50%) (9901/10368)\n",
      "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1306) | Acc: (95.50%) (11124/11648)\n",
      "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1299) | Acc: (95.47%) (12342/12928)\n",
      "Epoch: 77 | Batch_idx: 110 |  Loss: (0.1313) | Acc: (95.37%) (13550/14208)\n",
      "Epoch: 77 | Batch_idx: 120 |  Loss: (0.1316) | Acc: (95.37%) (14771/15488)\n",
      "Epoch: 77 | Batch_idx: 130 |  Loss: (0.1308) | Acc: (95.37%) (15991/16768)\n",
      "Epoch: 77 | Batch_idx: 140 |  Loss: (0.1307) | Acc: (95.39%) (17216/18048)\n",
      "Epoch: 77 | Batch_idx: 150 |  Loss: (0.1307) | Acc: (95.42%) (18442/19328)\n",
      "Epoch: 77 | Batch_idx: 160 |  Loss: (0.1298) | Acc: (95.45%) (19670/20608)\n",
      "Epoch: 77 | Batch_idx: 170 |  Loss: (0.1303) | Acc: (95.43%) (20887/21888)\n",
      "Epoch: 77 | Batch_idx: 180 |  Loss: (0.1303) | Acc: (95.46%) (22117/23168)\n",
      "Epoch: 77 | Batch_idx: 190 |  Loss: (0.1299) | Acc: (95.48%) (23344/24448)\n",
      "Epoch: 77 | Batch_idx: 200 |  Loss: (0.1298) | Acc: (95.46%) (24561/25728)\n",
      "Epoch: 77 | Batch_idx: 210 |  Loss: (0.1294) | Acc: (95.48%) (25787/27008)\n",
      "Epoch: 77 | Batch_idx: 220 |  Loss: (0.1319) | Acc: (95.36%) (26975/28288)\n",
      "Epoch: 77 | Batch_idx: 230 |  Loss: (0.1321) | Acc: (95.36%) (28196/29568)\n",
      "Epoch: 77 | Batch_idx: 240 |  Loss: (0.1325) | Acc: (95.38%) (29424/30848)\n",
      "Epoch: 77 | Batch_idx: 250 |  Loss: (0.1324) | Acc: (95.37%) (30641/32128)\n",
      "Epoch: 77 | Batch_idx: 260 |  Loss: (0.1328) | Acc: (95.35%) (31856/33408)\n",
      "Epoch: 77 | Batch_idx: 270 |  Loss: (0.1329) | Acc: (95.36%) (33080/34688)\n",
      "Epoch: 77 | Batch_idx: 280 |  Loss: (0.1328) | Acc: (95.38%) (34306/35968)\n",
      "Epoch: 77 | Batch_idx: 290 |  Loss: (0.1330) | Acc: (95.36%) (35520/37248)\n",
      "Epoch: 77 | Batch_idx: 300 |  Loss: (0.1328) | Acc: (95.39%) (36751/38528)\n",
      "Epoch: 77 | Batch_idx: 310 |  Loss: (0.1330) | Acc: (95.39%) (37973/39808)\n",
      "Epoch: 77 | Batch_idx: 320 |  Loss: (0.1337) | Acc: (95.38%) (39190/41088)\n",
      "Epoch: 77 | Batch_idx: 330 |  Loss: (0.1341) | Acc: (95.36%) (40403/42368)\n",
      "Epoch: 77 | Batch_idx: 340 |  Loss: (0.1345) | Acc: (95.34%) (41616/43648)\n",
      "Epoch: 77 | Batch_idx: 350 |  Loss: (0.1345) | Acc: (95.33%) (42830/44928)\n",
      "Epoch: 77 | Batch_idx: 360 |  Loss: (0.1344) | Acc: (95.32%) (44047/46208)\n",
      "Epoch: 77 | Batch_idx: 370 |  Loss: (0.1344) | Acc: (95.32%) (45267/47488)\n",
      "Epoch: 77 | Batch_idx: 380 |  Loss: (0.1347) | Acc: (95.32%) (46484/48768)\n",
      "Epoch: 77 | Batch_idx: 390 |  Loss: (0.1351) | Acc: (95.29%) (47647/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4446) | Acc: (87.70%) (8770/10000)\n",
      "Epoch: 78 | Batch_idx: 0 |  Loss: (0.1207) | Acc: (96.88%) (124/128)\n",
      "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1394) | Acc: (95.24%) (1341/1408)\n",
      "Epoch: 78 | Batch_idx: 20 |  Loss: (0.1416) | Acc: (95.09%) (2556/2688)\n",
      "Epoch: 78 | Batch_idx: 30 |  Loss: (0.1399) | Acc: (95.34%) (3783/3968)\n",
      "Epoch: 78 | Batch_idx: 40 |  Loss: (0.1366) | Acc: (95.43%) (5008/5248)\n",
      "Epoch: 78 | Batch_idx: 50 |  Loss: (0.1371) | Acc: (95.31%) (6222/6528)\n",
      "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1367) | Acc: (95.35%) (7445/7808)\n",
      "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1335) | Acc: (95.44%) (8674/9088)\n",
      "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1326) | Acc: (95.48%) (9899/10368)\n",
      "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1333) | Acc: (95.42%) (11115/11648)\n",
      "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1303) | Acc: (95.51%) (12347/12928)\n",
      "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1312) | Acc: (95.43%) (13558/14208)\n",
      "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1308) | Acc: (95.44%) (14782/15488)\n",
      "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1314) | Acc: (95.43%) (16002/16768)\n",
      "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1316) | Acc: (95.41%) (17220/18048)\n",
      "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1318) | Acc: (95.40%) (18438/19328)\n",
      "Epoch: 78 | Batch_idx: 160 |  Loss: (0.1317) | Acc: (95.38%) (19655/20608)\n",
      "Epoch: 78 | Batch_idx: 170 |  Loss: (0.1322) | Acc: (95.36%) (20873/21888)\n",
      "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1321) | Acc: (95.37%) (22095/23168)\n",
      "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1316) | Acc: (95.39%) (23322/24448)\n",
      "Epoch: 78 | Batch_idx: 200 |  Loss: (0.1318) | Acc: (95.41%) (24546/25728)\n",
      "Epoch: 78 | Batch_idx: 210 |  Loss: (0.1311) | Acc: (95.42%) (25772/27008)\n",
      "Epoch: 78 | Batch_idx: 220 |  Loss: (0.1315) | Acc: (95.41%) (26990/28288)\n",
      "Epoch: 78 | Batch_idx: 230 |  Loss: (0.1311) | Acc: (95.40%) (28208/29568)\n",
      "Epoch: 78 | Batch_idx: 240 |  Loss: (0.1312) | Acc: (95.39%) (29426/30848)\n",
      "Epoch: 78 | Batch_idx: 250 |  Loss: (0.1320) | Acc: (95.39%) (30646/32128)\n",
      "Epoch: 78 | Batch_idx: 260 |  Loss: (0.1322) | Acc: (95.39%) (31867/33408)\n",
      "Epoch: 78 | Batch_idx: 270 |  Loss: (0.1323) | Acc: (95.38%) (33086/34688)\n",
      "Epoch: 78 | Batch_idx: 280 |  Loss: (0.1331) | Acc: (95.35%) (34296/35968)\n",
      "Epoch: 78 | Batch_idx: 290 |  Loss: (0.1326) | Acc: (95.34%) (35513/37248)\n",
      "Epoch: 78 | Batch_idx: 300 |  Loss: (0.1325) | Acc: (95.34%) (36732/38528)\n",
      "Epoch: 78 | Batch_idx: 310 |  Loss: (0.1328) | Acc: (95.32%) (37946/39808)\n",
      "Epoch: 78 | Batch_idx: 320 |  Loss: (0.1329) | Acc: (95.31%) (39162/41088)\n",
      "Epoch: 78 | Batch_idx: 330 |  Loss: (0.1328) | Acc: (95.31%) (40382/42368)\n",
      "Epoch: 78 | Batch_idx: 340 |  Loss: (0.1325) | Acc: (95.33%) (41611/43648)\n",
      "Epoch: 78 | Batch_idx: 350 |  Loss: (0.1327) | Acc: (95.34%) (42835/44928)\n",
      "Epoch: 78 | Batch_idx: 360 |  Loss: (0.1331) | Acc: (95.31%) (44043/46208)\n",
      "Epoch: 78 | Batch_idx: 370 |  Loss: (0.1331) | Acc: (95.33%) (45269/47488)\n",
      "Epoch: 78 | Batch_idx: 380 |  Loss: (0.1327) | Acc: (95.34%) (46495/48768)\n",
      "Epoch: 78 | Batch_idx: 390 |  Loss: (0.1326) | Acc: (95.36%) (47682/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4340) | Acc: (87.76%) (8776/10000)\n",
      "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1552) | Acc: (92.19%) (118/128)\n",
      "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1217) | Acc: (95.88%) (1350/1408)\n",
      "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1230) | Acc: (95.94%) (2579/2688)\n",
      "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1287) | Acc: (95.79%) (3801/3968)\n",
      "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1250) | Acc: (95.96%) (5036/5248)\n",
      "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1235) | Acc: (96.02%) (6268/6528)\n",
      "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1238) | Acc: (95.91%) (7489/7808)\n",
      "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1262) | Acc: (95.80%) (8706/9088)\n",
      "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1257) | Acc: (95.79%) (9932/10368)\n",
      "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1260) | Acc: (95.73%) (11151/11648)\n",
      "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1323) | Acc: (95.47%) (12342/12928)\n",
      "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1319) | Acc: (95.46%) (13563/14208)\n",
      "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1320) | Acc: (95.47%) (14786/15488)\n",
      "Epoch: 79 | Batch_idx: 130 |  Loss: (0.1323) | Acc: (95.46%) (16006/16768)\n",
      "Epoch: 79 | Batch_idx: 140 |  Loss: (0.1327) | Acc: (95.45%) (17226/18048)\n",
      "Epoch: 79 | Batch_idx: 150 |  Loss: (0.1306) | Acc: (95.55%) (18468/19328)\n",
      "Epoch: 79 | Batch_idx: 160 |  Loss: (0.1309) | Acc: (95.50%) (19681/20608)\n",
      "Epoch: 79 | Batch_idx: 170 |  Loss: (0.1302) | Acc: (95.54%) (20911/21888)\n",
      "Epoch: 79 | Batch_idx: 180 |  Loss: (0.1293) | Acc: (95.58%) (22145/23168)\n",
      "Epoch: 79 | Batch_idx: 190 |  Loss: (0.1308) | Acc: (95.50%) (23348/24448)\n",
      "Epoch: 79 | Batch_idx: 200 |  Loss: (0.1295) | Acc: (95.57%) (24587/25728)\n",
      "Epoch: 79 | Batch_idx: 210 |  Loss: (0.1291) | Acc: (95.55%) (25807/27008)\n",
      "Epoch: 79 | Batch_idx: 220 |  Loss: (0.1295) | Acc: (95.54%) (27027/28288)\n",
      "Epoch: 79 | Batch_idx: 230 |  Loss: (0.1292) | Acc: (95.55%) (28252/29568)\n",
      "Epoch: 79 | Batch_idx: 240 |  Loss: (0.1290) | Acc: (95.56%) (29477/30848)\n",
      "Epoch: 79 | Batch_idx: 250 |  Loss: (0.1295) | Acc: (95.55%) (30697/32128)\n",
      "Epoch: 79 | Batch_idx: 260 |  Loss: (0.1295) | Acc: (95.55%) (31923/33408)\n",
      "Epoch: 79 | Batch_idx: 270 |  Loss: (0.1295) | Acc: (95.57%) (33150/34688)\n",
      "Epoch: 79 | Batch_idx: 280 |  Loss: (0.1303) | Acc: (95.55%) (34366/35968)\n",
      "Epoch: 79 | Batch_idx: 290 |  Loss: (0.1302) | Acc: (95.53%) (35583/37248)\n",
      "Epoch: 79 | Batch_idx: 300 |  Loss: (0.1300) | Acc: (95.54%) (36811/38528)\n",
      "Epoch: 79 | Batch_idx: 310 |  Loss: (0.1303) | Acc: (95.52%) (38024/39808)\n",
      "Epoch: 79 | Batch_idx: 320 |  Loss: (0.1314) | Acc: (95.47%) (39225/41088)\n",
      "Epoch: 79 | Batch_idx: 330 |  Loss: (0.1312) | Acc: (95.46%) (40444/42368)\n",
      "Epoch: 79 | Batch_idx: 340 |  Loss: (0.1310) | Acc: (95.46%) (41665/43648)\n",
      "Epoch: 79 | Batch_idx: 350 |  Loss: (0.1311) | Acc: (95.44%) (42878/44928)\n",
      "Epoch: 79 | Batch_idx: 360 |  Loss: (0.1314) | Acc: (95.42%) (44092/46208)\n",
      "Epoch: 79 | Batch_idx: 370 |  Loss: (0.1318) | Acc: (95.41%) (45307/47488)\n",
      "Epoch: 79 | Batch_idx: 380 |  Loss: (0.1319) | Acc: (95.40%) (46526/48768)\n",
      "Epoch: 79 | Batch_idx: 390 |  Loss: (0.1324) | Acc: (95.38%) (47689/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4391) | Acc: (87.62%) (8762/10000)\n",
      "Epoch: 80 | Batch_idx: 0 |  Loss: (0.0685) | Acc: (98.44%) (126/128)\n",
      "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1168) | Acc: (96.24%) (1355/1408)\n",
      "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1189) | Acc: (96.02%) (2581/2688)\n",
      "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1157) | Acc: (96.04%) (3811/3968)\n",
      "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1142) | Acc: (96.21%) (5049/5248)\n",
      "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1110) | Acc: (96.42%) (6294/6528)\n",
      "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1066) | Acc: (96.55%) (7539/7808)\n",
      "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1048) | Acc: (96.65%) (8784/9088)\n",
      "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1039) | Acc: (96.65%) (10021/10368)\n",
      "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1022) | Acc: (96.73%) (11267/11648)\n",
      "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1006) | Acc: (96.79%) (12513/12928)\n",
      "Epoch: 80 | Batch_idx: 110 |  Loss: (0.0997) | Acc: (96.85%) (13760/14208)\n",
      "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1002) | Acc: (96.79%) (14991/15488)\n",
      "Epoch: 80 | Batch_idx: 130 |  Loss: (0.0996) | Acc: (96.84%) (16238/16768)\n",
      "Epoch: 80 | Batch_idx: 140 |  Loss: (0.0988) | Acc: (96.88%) (17485/18048)\n",
      "Epoch: 80 | Batch_idx: 150 |  Loss: (0.0984) | Acc: (96.86%) (18721/19328)\n",
      "Epoch: 80 | Batch_idx: 160 |  Loss: (0.0983) | Acc: (96.87%) (19962/20608)\n",
      "Epoch: 80 | Batch_idx: 170 |  Loss: (0.0984) | Acc: (96.88%) (21206/21888)\n",
      "Epoch: 80 | Batch_idx: 180 |  Loss: (0.0978) | Acc: (96.90%) (22450/23168)\n",
      "Epoch: 80 | Batch_idx: 190 |  Loss: (0.0979) | Acc: (96.90%) (23689/24448)\n",
      "Epoch: 80 | Batch_idx: 200 |  Loss: (0.0973) | Acc: (96.94%) (24942/25728)\n",
      "Epoch: 80 | Batch_idx: 210 |  Loss: (0.0969) | Acc: (96.95%) (26183/27008)\n",
      "Epoch: 80 | Batch_idx: 220 |  Loss: (0.0962) | Acc: (96.95%) (27425/28288)\n",
      "Epoch: 80 | Batch_idx: 230 |  Loss: (0.0966) | Acc: (96.93%) (28660/29568)\n",
      "Epoch: 80 | Batch_idx: 240 |  Loss: (0.0964) | Acc: (96.92%) (29899/30848)\n",
      "Epoch: 80 | Batch_idx: 250 |  Loss: (0.0963) | Acc: (96.92%) (31138/32128)\n",
      "Epoch: 80 | Batch_idx: 260 |  Loss: (0.0959) | Acc: (96.94%) (32387/33408)\n",
      "Epoch: 80 | Batch_idx: 270 |  Loss: (0.0955) | Acc: (96.94%) (33628/34688)\n",
      "Epoch: 80 | Batch_idx: 280 |  Loss: (0.0951) | Acc: (96.95%) (34872/35968)\n",
      "Epoch: 80 | Batch_idx: 290 |  Loss: (0.0947) | Acc: (96.97%) (36118/37248)\n",
      "Epoch: 80 | Batch_idx: 300 |  Loss: (0.0951) | Acc: (96.93%) (37347/38528)\n",
      "Epoch: 80 | Batch_idx: 310 |  Loss: (0.0949) | Acc: (96.96%) (38598/39808)\n",
      "Epoch: 80 | Batch_idx: 320 |  Loss: (0.0947) | Acc: (96.97%) (39843/41088)\n",
      "Epoch: 80 | Batch_idx: 330 |  Loss: (0.0940) | Acc: (97.01%) (41103/42368)\n",
      "Epoch: 80 | Batch_idx: 340 |  Loss: (0.0941) | Acc: (97.01%) (42344/43648)\n",
      "Epoch: 80 | Batch_idx: 350 |  Loss: (0.0942) | Acc: (97.02%) (43587/44928)\n",
      "Epoch: 80 | Batch_idx: 360 |  Loss: (0.0942) | Acc: (97.00%) (44821/46208)\n",
      "Epoch: 80 | Batch_idx: 370 |  Loss: (0.0944) | Acc: (96.99%) (46058/47488)\n",
      "Epoch: 80 | Batch_idx: 380 |  Loss: (0.0945) | Acc: (96.99%) (47300/48768)\n",
      "Epoch: 80 | Batch_idx: 390 |  Loss: (0.0942) | Acc: (97.00%) (48502/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3798) | Acc: (89.31%) (8931/10000)\n",
      "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0477) | Acc: (99.22%) (127/128)\n",
      "Epoch: 81 | Batch_idx: 10 |  Loss: (0.0758) | Acc: (97.44%) (1372/1408)\n",
      "Epoch: 81 | Batch_idx: 20 |  Loss: (0.0848) | Acc: (97.06%) (2609/2688)\n",
      "Epoch: 81 | Batch_idx: 30 |  Loss: (0.0864) | Acc: (97.03%) (3850/3968)\n",
      "Epoch: 81 | Batch_idx: 40 |  Loss: (0.0846) | Acc: (97.22%) (5102/5248)\n",
      "Epoch: 81 | Batch_idx: 50 |  Loss: (0.0836) | Acc: (97.30%) (6352/6528)\n",
      "Epoch: 81 | Batch_idx: 60 |  Loss: (0.0854) | Acc: (97.21%) (7590/7808)\n",
      "Epoch: 81 | Batch_idx: 70 |  Loss: (0.0862) | Acc: (97.17%) (8831/9088)\n",
      "Epoch: 81 | Batch_idx: 80 |  Loss: (0.0867) | Acc: (97.23%) (10081/10368)\n",
      "Epoch: 81 | Batch_idx: 90 |  Loss: (0.0849) | Acc: (97.30%) (11333/11648)\n",
      "Epoch: 81 | Batch_idx: 100 |  Loss: (0.0847) | Acc: (97.29%) (12578/12928)\n",
      "Epoch: 81 | Batch_idx: 110 |  Loss: (0.0845) | Acc: (97.36%) (13833/14208)\n",
      "Epoch: 81 | Batch_idx: 120 |  Loss: (0.0854) | Acc: (97.33%) (15074/15488)\n",
      "Epoch: 81 | Batch_idx: 130 |  Loss: (0.0852) | Acc: (97.33%) (16320/16768)\n",
      "Epoch: 81 | Batch_idx: 140 |  Loss: (0.0855) | Acc: (97.33%) (17567/18048)\n",
      "Epoch: 81 | Batch_idx: 150 |  Loss: (0.0851) | Acc: (97.33%) (18811/19328)\n",
      "Epoch: 81 | Batch_idx: 160 |  Loss: (0.0858) | Acc: (97.28%) (20048/20608)\n",
      "Epoch: 81 | Batch_idx: 170 |  Loss: (0.0850) | Acc: (97.34%) (21305/21888)\n",
      "Epoch: 81 | Batch_idx: 180 |  Loss: (0.0854) | Acc: (97.31%) (22545/23168)\n",
      "Epoch: 81 | Batch_idx: 190 |  Loss: (0.0852) | Acc: (97.34%) (23797/24448)\n",
      "Epoch: 81 | Batch_idx: 200 |  Loss: (0.0847) | Acc: (97.36%) (25049/25728)\n",
      "Epoch: 81 | Batch_idx: 210 |  Loss: (0.0852) | Acc: (97.32%) (26285/27008)\n",
      "Epoch: 81 | Batch_idx: 220 |  Loss: (0.0845) | Acc: (97.35%) (27537/28288)\n",
      "Epoch: 81 | Batch_idx: 230 |  Loss: (0.0845) | Acc: (97.35%) (28785/29568)\n",
      "Epoch: 81 | Batch_idx: 240 |  Loss: (0.0842) | Acc: (97.37%) (30036/30848)\n",
      "Epoch: 81 | Batch_idx: 250 |  Loss: (0.0840) | Acc: (97.39%) (31289/32128)\n",
      "Epoch: 81 | Batch_idx: 260 |  Loss: (0.0841) | Acc: (97.38%) (32532/33408)\n",
      "Epoch: 81 | Batch_idx: 270 |  Loss: (0.0841) | Acc: (97.38%) (33779/34688)\n",
      "Epoch: 81 | Batch_idx: 280 |  Loss: (0.0837) | Acc: (97.39%) (35028/35968)\n",
      "Epoch: 81 | Batch_idx: 290 |  Loss: (0.0833) | Acc: (97.39%) (36277/37248)\n",
      "Epoch: 81 | Batch_idx: 300 |  Loss: (0.0832) | Acc: (97.40%) (37528/38528)\n",
      "Epoch: 81 | Batch_idx: 310 |  Loss: (0.0834) | Acc: (97.39%) (38769/39808)\n",
      "Epoch: 81 | Batch_idx: 320 |  Loss: (0.0833) | Acc: (97.41%) (40022/41088)\n",
      "Epoch: 81 | Batch_idx: 330 |  Loss: (0.0835) | Acc: (97.41%) (41270/42368)\n",
      "Epoch: 81 | Batch_idx: 340 |  Loss: (0.0836) | Acc: (97.41%) (42517/43648)\n",
      "Epoch: 81 | Batch_idx: 350 |  Loss: (0.0836) | Acc: (97.41%) (43766/44928)\n",
      "Epoch: 81 | Batch_idx: 360 |  Loss: (0.0836) | Acc: (97.42%) (45017/46208)\n",
      "Epoch: 81 | Batch_idx: 370 |  Loss: (0.0833) | Acc: (97.44%) (46270/47488)\n",
      "Epoch: 81 | Batch_idx: 380 |  Loss: (0.0836) | Acc: (97.43%) (47514/48768)\n",
      "Epoch: 81 | Batch_idx: 390 |  Loss: (0.0838) | Acc: (97.42%) (48712/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3780) | Acc: (89.37%) (8937/10000)\n",
      "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0655) | Acc: (99.22%) (127/128)\n",
      "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0705) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 82 | Batch_idx: 20 |  Loss: (0.0800) | Acc: (97.43%) (2619/2688)\n",
      "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0828) | Acc: (97.33%) (3862/3968)\n",
      "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0817) | Acc: (97.45%) (5114/5248)\n",
      "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0817) | Acc: (97.43%) (6360/6528)\n",
      "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0799) | Acc: (97.48%) (7611/7808)\n",
      "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0781) | Acc: (97.60%) (8870/9088)\n",
      "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0790) | Acc: (97.58%) (10117/10368)\n",
      "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0786) | Acc: (97.57%) (11365/11648)\n",
      "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0777) | Acc: (97.60%) (12618/12928)\n",
      "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0793) | Acc: (97.54%) (13859/14208)\n",
      "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0784) | Acc: (97.59%) (15115/15488)\n",
      "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0783) | Acc: (97.60%) (16366/16768)\n",
      "Epoch: 82 | Batch_idx: 140 |  Loss: (0.0795) | Acc: (97.57%) (17610/18048)\n",
      "Epoch: 82 | Batch_idx: 150 |  Loss: (0.0798) | Acc: (97.58%) (18861/19328)\n",
      "Epoch: 82 | Batch_idx: 160 |  Loss: (0.0792) | Acc: (97.65%) (20123/20608)\n",
      "Epoch: 82 | Batch_idx: 170 |  Loss: (0.0793) | Acc: (97.66%) (21375/21888)\n",
      "Epoch: 82 | Batch_idx: 180 |  Loss: (0.0795) | Acc: (97.65%) (22624/23168)\n",
      "Epoch: 82 | Batch_idx: 190 |  Loss: (0.0799) | Acc: (97.63%) (23869/24448)\n",
      "Epoch: 82 | Batch_idx: 200 |  Loss: (0.0802) | Acc: (97.60%) (25110/25728)\n",
      "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0802) | Acc: (97.59%) (26356/27008)\n",
      "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0797) | Acc: (97.59%) (27606/28288)\n",
      "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0797) | Acc: (97.58%) (28852/29568)\n",
      "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0799) | Acc: (97.59%) (30105/30848)\n",
      "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0799) | Acc: (97.57%) (31348/32128)\n",
      "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0798) | Acc: (97.59%) (32604/33408)\n",
      "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0805) | Acc: (97.55%) (33837/34688)\n",
      "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0805) | Acc: (97.55%) (35086/35968)\n",
      "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0809) | Acc: (97.52%) (36324/37248)\n",
      "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0811) | Acc: (97.51%) (37568/38528)\n",
      "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0805) | Acc: (97.54%) (38827/39808)\n",
      "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0802) | Acc: (97.54%) (40079/41088)\n",
      "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0802) | Acc: (97.55%) (41332/42368)\n",
      "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0800) | Acc: (97.56%) (42584/43648)\n",
      "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0799) | Acc: (97.56%) (43833/44928)\n",
      "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0799) | Acc: (97.55%) (45078/46208)\n",
      "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0803) | Acc: (97.54%) (46318/47488)\n",
      "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0803) | Acc: (97.54%) (47569/48768)\n",
      "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0806) | Acc: (97.53%) (48764/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3767) | Acc: (89.52%) (8952/10000)\n",
      "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0409) | Acc: (100.00%) (128/128)\n",
      "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0733) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0750) | Acc: (97.92%) (2632/2688)\n",
      "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0755) | Acc: (97.71%) (3877/3968)\n",
      "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0742) | Acc: (97.71%) (5128/5248)\n",
      "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0739) | Acc: (97.64%) (6374/6528)\n",
      "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0723) | Acc: (97.75%) (7632/7808)\n",
      "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0744) | Acc: (97.63%) (8873/9088)\n",
      "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0753) | Acc: (97.61%) (10120/10368)\n",
      "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0769) | Acc: (97.51%) (11358/11648)\n",
      "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0767) | Acc: (97.56%) (12613/12928)\n",
      "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0759) | Acc: (97.62%) (13870/14208)\n",
      "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0762) | Acc: (97.60%) (15117/15488)\n",
      "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0759) | Acc: (97.63%) (16371/16768)\n",
      "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0761) | Acc: (97.61%) (17616/18048)\n",
      "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0754) | Acc: (97.64%) (18871/19328)\n",
      "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0764) | Acc: (97.61%) (20116/20608)\n",
      "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0774) | Acc: (97.57%) (21356/21888)\n",
      "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0778) | Acc: (97.56%) (22602/23168)\n",
      "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0778) | Acc: (97.57%) (23854/24448)\n",
      "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0775) | Acc: (97.59%) (25107/25728)\n",
      "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0770) | Acc: (97.59%) (26358/27008)\n",
      "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0772) | Acc: (97.61%) (27611/28288)\n",
      "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0773) | Acc: (97.60%) (28858/29568)\n",
      "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0778) | Acc: (97.60%) (30109/30848)\n",
      "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0781) | Acc: (97.59%) (31355/32128)\n",
      "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0779) | Acc: (97.62%) (32613/33408)\n",
      "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0782) | Acc: (97.60%) (33856/34688)\n",
      "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0783) | Acc: (97.59%) (35102/35968)\n",
      "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0783) | Acc: (97.59%) (36350/37248)\n",
      "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0783) | Acc: (97.60%) (37602/38528)\n",
      "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0784) | Acc: (97.60%) (38854/39808)\n",
      "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0787) | Acc: (97.58%) (40093/41088)\n",
      "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0788) | Acc: (97.57%) (41338/42368)\n",
      "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0790) | Acc: (97.57%) (42586/43648)\n",
      "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0788) | Acc: (97.58%) (43841/44928)\n",
      "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0790) | Acc: (97.57%) (45086/46208)\n",
      "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0789) | Acc: (97.57%) (46336/47488)\n",
      "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0789) | Acc: (97.58%) (47587/48768)\n",
      "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0790) | Acc: (97.58%) (48789/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3751) | Acc: (89.53%) (8953/10000)\n",
      "Epoch: 84 | Batch_idx: 0 |  Loss: (0.1016) | Acc: (96.88%) (124/128)\n",
      "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0870) | Acc: (97.51%) (1373/1408)\n",
      "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0802) | Acc: (97.69%) (2626/2688)\n",
      "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0794) | Acc: (97.73%) (3878/3968)\n",
      "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0775) | Acc: (97.81%) (5133/5248)\n",
      "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0762) | Acc: (97.84%) (6387/6528)\n",
      "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0796) | Acc: (97.75%) (7632/7808)\n",
      "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0795) | Acc: (97.73%) (8882/9088)\n",
      "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0803) | Acc: (97.63%) (10122/10368)\n",
      "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0814) | Acc: (97.58%) (11366/11648)\n",
      "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0817) | Acc: (97.60%) (12618/12928)\n",
      "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0822) | Acc: (97.56%) (13862/14208)\n",
      "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0806) | Acc: (97.60%) (15117/15488)\n",
      "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0808) | Acc: (97.58%) (16362/16768)\n",
      "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0799) | Acc: (97.61%) (17617/18048)\n",
      "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0806) | Acc: (97.59%) (18862/19328)\n",
      "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0798) | Acc: (97.65%) (20123/20608)\n",
      "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0798) | Acc: (97.67%) (21378/21888)\n",
      "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0790) | Acc: (97.70%) (22635/23168)\n",
      "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0786) | Acc: (97.72%) (23891/24448)\n",
      "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0782) | Acc: (97.74%) (25146/25728)\n",
      "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0784) | Acc: (97.71%) (26390/27008)\n",
      "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0791) | Acc: (97.68%) (27632/28288)\n",
      "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0786) | Acc: (97.70%) (28889/29568)\n",
      "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0782) | Acc: (97.70%) (30139/30848)\n",
      "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0778) | Acc: (97.71%) (31391/32128)\n",
      "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0777) | Acc: (97.71%) (32644/33408)\n",
      "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0778) | Acc: (97.72%) (33896/34688)\n",
      "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0778) | Acc: (97.71%) (35144/35968)\n",
      "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0772) | Acc: (97.74%) (36405/37248)\n",
      "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0769) | Acc: (97.75%) (37662/38528)\n",
      "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0776) | Acc: (97.73%) (38904/39808)\n",
      "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0777) | Acc: (97.72%) (40153/41088)\n",
      "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0775) | Acc: (97.74%) (41410/42368)\n",
      "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0773) | Acc: (97.75%) (42666/43648)\n",
      "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0769) | Acc: (97.77%) (43924/44928)\n",
      "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0770) | Acc: (97.76%) (45172/46208)\n",
      "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0771) | Acc: (97.75%) (46418/47488)\n",
      "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0771) | Acc: (97.74%) (47667/48768)\n",
      "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0770) | Acc: (97.74%) (48869/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3802) | Acc: (89.35%) (8935/10000)\n",
      "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0814) | Acc: (97.66%) (125/128)\n",
      "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0710) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0785) | Acc: (97.58%) (2623/2688)\n",
      "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0797) | Acc: (97.48%) (3868/3968)\n",
      "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0762) | Acc: (97.62%) (5123/5248)\n",
      "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0781) | Acc: (97.56%) (6369/6528)\n",
      "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0782) | Acc: (97.62%) (7622/7808)\n",
      "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0786) | Acc: (97.59%) (8869/9088)\n",
      "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0794) | Acc: (97.54%) (10113/10368)\n",
      "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0787) | Acc: (97.57%) (11365/11648)\n",
      "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0776) | Acc: (97.59%) (12616/12928)\n",
      "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0769) | Acc: (97.60%) (13867/14208)\n",
      "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0772) | Acc: (97.57%) (15111/15488)\n",
      "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0779) | Acc: (97.54%) (16355/16768)\n",
      "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0777) | Acc: (97.56%) (17607/18048)\n",
      "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0771) | Acc: (97.60%) (18865/19328)\n",
      "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0771) | Acc: (97.60%) (20114/20608)\n",
      "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0770) | Acc: (97.60%) (21363/21888)\n",
      "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0771) | Acc: (97.60%) (22612/23168)\n",
      "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0766) | Acc: (97.63%) (23868/24448)\n",
      "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0763) | Acc: (97.63%) (25118/25728)\n",
      "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0775) | Acc: (97.56%) (26349/27008)\n",
      "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0769) | Acc: (97.59%) (27606/28288)\n",
      "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0768) | Acc: (97.61%) (28860/29568)\n",
      "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0767) | Acc: (97.63%) (30117/30848)\n",
      "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0760) | Acc: (97.67%) (31378/32128)\n",
      "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0761) | Acc: (97.68%) (32632/33408)\n",
      "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0767) | Acc: (97.66%) (33875/34688)\n",
      "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0762) | Acc: (97.67%) (35130/35968)\n",
      "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0767) | Acc: (97.66%) (36375/37248)\n",
      "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0766) | Acc: (97.66%) (37626/38528)\n",
      "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0764) | Acc: (97.67%) (38880/39808)\n",
      "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0761) | Acc: (97.68%) (40136/41088)\n",
      "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0760) | Acc: (97.68%) (41386/42368)\n",
      "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0764) | Acc: (97.66%) (42627/43648)\n",
      "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0763) | Acc: (97.65%) (43872/44928)\n",
      "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0761) | Acc: (97.65%) (45124/46208)\n",
      "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0760) | Acc: (97.66%) (46378/47488)\n",
      "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0757) | Acc: (97.68%) (47639/48768)\n",
      "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0757) | Acc: (97.69%) (48845/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3746) | Acc: (89.44%) (8944/10000)\n",
      "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0461) | Acc: (100.00%) (128/128)\n",
      "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0766) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0731) | Acc: (98.25%) (2641/2688)\n",
      "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0752) | Acc: (98.16%) (3895/3968)\n",
      "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0722) | Acc: (98.17%) (5152/5248)\n",
      "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0725) | Acc: (98.07%) (6402/6528)\n",
      "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0742) | Acc: (97.98%) (7650/7808)\n",
      "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0725) | Acc: (98.03%) (8909/9088)\n",
      "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0733) | Acc: (97.98%) (10159/10368)\n",
      "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0733) | Acc: (97.97%) (11411/11648)\n",
      "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0721) | Acc: (98.00%) (12670/12928)\n",
      "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0721) | Acc: (97.98%) (13921/14208)\n",
      "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0723) | Acc: (97.97%) (15174/15488)\n",
      "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0726) | Acc: (97.94%) (16422/16768)\n",
      "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0732) | Acc: (97.87%) (17664/18048)\n",
      "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0741) | Acc: (97.87%) (18917/19328)\n",
      "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0742) | Acc: (97.86%) (20167/20608)\n",
      "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0745) | Acc: (97.85%) (21418/21888)\n",
      "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0746) | Acc: (97.85%) (22671/23168)\n",
      "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0747) | Acc: (97.86%) (23925/24448)\n",
      "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0742) | Acc: (97.89%) (25186/25728)\n",
      "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0749) | Acc: (97.83%) (26423/27008)\n",
      "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0748) | Acc: (97.84%) (27678/28288)\n",
      "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0745) | Acc: (97.85%) (28933/29568)\n",
      "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0744) | Acc: (97.86%) (30187/30848)\n",
      "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0741) | Acc: (97.88%) (31446/32128)\n",
      "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0744) | Acc: (97.86%) (32693/33408)\n",
      "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0744) | Acc: (97.85%) (33943/34688)\n",
      "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0743) | Acc: (97.84%) (35190/35968)\n",
      "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0753) | Acc: (97.79%) (36424/37248)\n",
      "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0754) | Acc: (97.78%) (37672/38528)\n",
      "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0751) | Acc: (97.79%) (38927/39808)\n",
      "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0751) | Acc: (97.79%) (40178/41088)\n",
      "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0753) | Acc: (97.77%) (41425/42368)\n",
      "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0755) | Acc: (97.76%) (42670/43648)\n",
      "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0755) | Acc: (97.75%) (43917/44928)\n",
      "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0757) | Acc: (97.75%) (45169/46208)\n",
      "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0757) | Acc: (97.75%) (46420/47488)\n",
      "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0759) | Acc: (97.74%) (47665/48768)\n",
      "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0760) | Acc: (97.73%) (48866/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3748) | Acc: (89.40%) (8940/10000)\n",
      "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0501) | Acc: (99.22%) (127/128)\n",
      "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0654) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0664) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0673) | Acc: (98.34%) (3902/3968)\n",
      "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0705) | Acc: (98.00%) (5143/5248)\n",
      "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0730) | Acc: (97.78%) (6383/6528)\n",
      "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0712) | Acc: (97.84%) (7639/7808)\n",
      "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0716) | Acc: (97.79%) (8887/9088)\n",
      "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0716) | Acc: (97.79%) (10139/10368)\n",
      "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0713) | Acc: (97.79%) (11390/11648)\n",
      "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0701) | Acc: (97.83%) (12648/12928)\n",
      "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0708) | Acc: (97.81%) (13897/14208)\n",
      "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0710) | Acc: (97.82%) (15150/15488)\n",
      "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0711) | Acc: (97.83%) (16404/16768)\n",
      "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0714) | Acc: (97.80%) (17651/18048)\n",
      "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0712) | Acc: (97.83%) (18908/19328)\n",
      "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0717) | Acc: (97.80%) (20154/20608)\n",
      "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0719) | Acc: (97.80%) (21406/21888)\n",
      "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0723) | Acc: (97.77%) (22652/23168)\n",
      "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0726) | Acc: (97.75%) (23898/24448)\n",
      "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0718) | Acc: (97.78%) (25158/25728)\n",
      "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0723) | Acc: (97.78%) (26409/27008)\n",
      "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0723) | Acc: (97.80%) (27665/28288)\n",
      "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0724) | Acc: (97.81%) (28919/29568)\n",
      "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0720) | Acc: (97.83%) (30179/30848)\n",
      "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0720) | Acc: (97.84%) (31434/32128)\n",
      "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0724) | Acc: (97.81%) (32678/33408)\n",
      "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0723) | Acc: (97.83%) (33934/34688)\n",
      "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0729) | Acc: (97.81%) (35180/35968)\n",
      "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0734) | Acc: (97.77%) (36418/37248)\n",
      "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0733) | Acc: (97.77%) (37670/38528)\n",
      "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0733) | Acc: (97.77%) (38920/39808)\n",
      "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0730) | Acc: (97.77%) (40172/41088)\n",
      "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0729) | Acc: (97.77%) (41424/42368)\n",
      "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0729) | Acc: (97.75%) (42668/43648)\n",
      "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0729) | Acc: (97.76%) (43923/44928)\n",
      "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0732) | Acc: (97.75%) (45168/46208)\n",
      "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0734) | Acc: (97.74%) (46413/47488)\n",
      "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0735) | Acc: (97.74%) (47664/48768)\n",
      "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0736) | Acc: (97.74%) (48872/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3766) | Acc: (89.42%) (8942/10000)\n",
      "Epoch: 88 | Batch_idx: 0 |  Loss: (0.1111) | Acc: (94.53%) (121/128)\n",
      "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0757) | Acc: (97.59%) (1374/1408)\n",
      "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0753) | Acc: (97.43%) (2619/2688)\n",
      "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0728) | Acc: (97.61%) (3873/3968)\n",
      "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0731) | Acc: (97.73%) (5129/5248)\n",
      "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0741) | Acc: (97.72%) (6379/6528)\n",
      "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0743) | Acc: (97.73%) (7631/7808)\n",
      "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0722) | Acc: (97.82%) (8890/9088)\n",
      "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0727) | Acc: (97.81%) (10141/10368)\n",
      "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0735) | Acc: (97.78%) (11389/11648)\n",
      "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0728) | Acc: (97.79%) (12642/12928)\n",
      "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0728) | Acc: (97.76%) (13890/14208)\n",
      "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0718) | Acc: (97.83%) (15152/15488)\n",
      "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0725) | Acc: (97.79%) (16398/16768)\n",
      "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0723) | Acc: (97.77%) (17646/18048)\n",
      "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0722) | Acc: (97.79%) (18901/19328)\n",
      "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0719) | Acc: (97.80%) (20155/20608)\n",
      "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0716) | Acc: (97.85%) (21417/21888)\n",
      "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0716) | Acc: (97.86%) (22672/23168)\n",
      "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0716) | Acc: (97.86%) (23924/24448)\n",
      "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0714) | Acc: (97.87%) (25180/25728)\n",
      "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0718) | Acc: (97.84%) (26425/27008)\n",
      "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0721) | Acc: (97.84%) (27676/28288)\n",
      "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0728) | Acc: (97.79%) (28915/29568)\n",
      "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0727) | Acc: (97.82%) (30177/30848)\n",
      "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0725) | Acc: (97.85%) (31436/32128)\n",
      "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0720) | Acc: (97.86%) (32694/33408)\n",
      "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0718) | Acc: (97.88%) (33952/34688)\n",
      "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0725) | Acc: (97.86%) (35198/35968)\n",
      "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0728) | Acc: (97.85%) (36446/37248)\n",
      "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0727) | Acc: (97.85%) (37701/38528)\n",
      "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0731) | Acc: (97.82%) (38939/39808)\n",
      "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0726) | Acc: (97.84%) (40202/41088)\n",
      "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0720) | Acc: (97.87%) (41465/42368)\n",
      "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0724) | Acc: (97.86%) (42714/43648)\n",
      "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0720) | Acc: (97.88%) (43976/44928)\n",
      "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0716) | Acc: (97.90%) (45236/46208)\n",
      "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0713) | Acc: (97.90%) (46492/47488)\n",
      "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0715) | Acc: (97.89%) (47738/48768)\n",
      "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0718) | Acc: (97.88%) (48939/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3772) | Acc: (89.46%) (8946/10000)\n",
      "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0567) | Acc: (98.44%) (126/128)\n",
      "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0679) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0743) | Acc: (97.77%) (2628/2688)\n",
      "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0694) | Acc: (97.96%) (3887/3968)\n",
      "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0689) | Acc: (98.00%) (5143/5248)\n",
      "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0725) | Acc: (97.79%) (6384/6528)\n",
      "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0712) | Acc: (97.89%) (7643/7808)\n",
      "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0710) | Acc: (97.90%) (8897/9088)\n",
      "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0697) | Acc: (97.95%) (10155/10368)\n",
      "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0698) | Acc: (97.94%) (11408/11648)\n",
      "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0692) | Acc: (98.00%) (12670/12928)\n",
      "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0691) | Acc: (97.97%) (13920/14208)\n",
      "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0690) | Acc: (98.00%) (15179/15488)\n",
      "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0685) | Acc: (98.02%) (16436/16768)\n",
      "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0673) | Acc: (98.06%) (17698/18048)\n",
      "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0680) | Acc: (98.03%) (18947/19328)\n",
      "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0681) | Acc: (98.01%) (20197/20608)\n",
      "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0682) | Acc: (97.99%) (21447/21888)\n",
      "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0688) | Acc: (97.98%) (22701/23168)\n",
      "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0693) | Acc: (97.94%) (23945/24448)\n",
      "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0695) | Acc: (97.94%) (25197/25728)\n",
      "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0699) | Acc: (97.92%) (26447/27008)\n",
      "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0695) | Acc: (97.92%) (27699/28288)\n",
      "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0695) | Acc: (97.89%) (28945/29568)\n",
      "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0692) | Acc: (97.91%) (30203/30848)\n",
      "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0690) | Acc: (97.91%) (31458/32128)\n",
      "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0690) | Acc: (97.92%) (32712/33408)\n",
      "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0690) | Acc: (97.93%) (33971/34688)\n",
      "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0691) | Acc: (97.94%) (35227/35968)\n",
      "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0688) | Acc: (97.95%) (36486/37248)\n",
      "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0689) | Acc: (97.95%) (37739/38528)\n",
      "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0688) | Acc: (97.95%) (38993/39808)\n",
      "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0690) | Acc: (97.95%) (40244/41088)\n",
      "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0692) | Acc: (97.94%) (41495/42368)\n",
      "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0694) | Acc: (97.93%) (42745/43648)\n",
      "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0693) | Acc: (97.94%) (44003/44928)\n",
      "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0696) | Acc: (97.93%) (45253/46208)\n",
      "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0695) | Acc: (97.94%) (46508/47488)\n",
      "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0698) | Acc: (97.93%) (47759/48768)\n",
      "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0702) | Acc: (97.93%) (48963/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3809) | Acc: (89.57%) (8957/10000)\n",
      "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0753) | Acc: (98.44%) (126/128)\n",
      "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0628) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0668) | Acc: (98.03%) (2635/2688)\n",
      "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0704) | Acc: (97.91%) (3885/3968)\n",
      "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0696) | Acc: (98.02%) (5144/5248)\n",
      "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0680) | Acc: (98.05%) (6401/6528)\n",
      "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0672) | Acc: (98.14%) (7663/7808)\n",
      "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0695) | Acc: (98.01%) (8907/9088)\n",
      "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0680) | Acc: (98.03%) (10164/10368)\n",
      "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0682) | Acc: (97.99%) (11414/11648)\n",
      "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0685) | Acc: (97.99%) (12668/12928)\n",
      "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0679) | Acc: (98.00%) (13924/14208)\n",
      "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0690) | Acc: (97.97%) (15174/15488)\n",
      "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0689) | Acc: (97.95%) (16425/16768)\n",
      "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0696) | Acc: (97.94%) (17677/18048)\n",
      "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0691) | Acc: (97.96%) (18934/19328)\n",
      "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0688) | Acc: (97.95%) (20186/20608)\n",
      "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0691) | Acc: (97.94%) (21438/21888)\n",
      "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0691) | Acc: (97.93%) (22688/23168)\n",
      "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0688) | Acc: (97.94%) (23944/24448)\n",
      "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0690) | Acc: (97.93%) (25195/25728)\n",
      "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0694) | Acc: (97.93%) (26449/27008)\n",
      "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0704) | Acc: (97.86%) (27684/28288)\n",
      "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0704) | Acc: (97.87%) (28937/29568)\n",
      "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0705) | Acc: (97.86%) (30189/30848)\n",
      "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0704) | Acc: (97.88%) (31446/32128)\n",
      "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0707) | Acc: (97.87%) (32696/33408)\n",
      "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0707) | Acc: (97.88%) (33953/34688)\n",
      "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0706) | Acc: (97.90%) (35212/35968)\n",
      "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0704) | Acc: (97.90%) (36464/37248)\n",
      "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0702) | Acc: (97.90%) (37720/38528)\n",
      "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0702) | Acc: (97.92%) (38981/39808)\n",
      "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0706) | Acc: (97.91%) (40228/41088)\n",
      "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0707) | Acc: (97.90%) (41477/42368)\n",
      "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0704) | Acc: (97.91%) (42736/43648)\n",
      "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0706) | Acc: (97.91%) (43988/44928)\n",
      "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0705) | Acc: (97.93%) (45251/46208)\n",
      "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0707) | Acc: (97.92%) (46500/47488)\n",
      "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0709) | Acc: (97.91%) (47748/48768)\n",
      "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0706) | Acc: (97.92%) (48959/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3835) | Acc: (89.46%) (8946/10000)\n",
      "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0659) | Acc: (96.88%) (124/128)\n",
      "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0658) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0711) | Acc: (98.10%) (2637/2688)\n",
      "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0709) | Acc: (98.03%) (3890/3968)\n",
      "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0700) | Acc: (98.09%) (5148/5248)\n",
      "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0712) | Acc: (98.01%) (6398/6528)\n",
      "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0724) | Acc: (97.95%) (7648/7808)\n",
      "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0704) | Acc: (98.03%) (8909/9088)\n",
      "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0698) | Acc: (98.04%) (10165/10368)\n",
      "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0698) | Acc: (98.03%) (11419/11648)\n",
      "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0709) | Acc: (97.92%) (12659/12928)\n",
      "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0707) | Acc: (97.90%) (13910/14208)\n",
      "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0721) | Acc: (97.86%) (15156/15488)\n",
      "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0717) | Acc: (97.88%) (16413/16768)\n",
      "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0714) | Acc: (97.93%) (17674/18048)\n",
      "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0703) | Acc: (97.99%) (18939/19328)\n",
      "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0699) | Acc: (97.98%) (20192/20608)\n",
      "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0701) | Acc: (97.96%) (21442/21888)\n",
      "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0699) | Acc: (97.98%) (22701/23168)\n",
      "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0702) | Acc: (97.95%) (23946/24448)\n",
      "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0705) | Acc: (97.93%) (25195/25728)\n",
      "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0711) | Acc: (97.92%) (26447/27008)\n",
      "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0711) | Acc: (97.91%) (27697/28288)\n",
      "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0713) | Acc: (97.91%) (28949/29568)\n",
      "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0708) | Acc: (97.92%) (30206/30848)\n",
      "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0708) | Acc: (97.92%) (31460/32128)\n",
      "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0707) | Acc: (97.93%) (32716/33408)\n",
      "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0706) | Acc: (97.93%) (33969/34688)\n",
      "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0703) | Acc: (97.93%) (35222/35968)\n",
      "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0702) | Acc: (97.94%) (36479/37248)\n",
      "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0707) | Acc: (97.92%) (37728/38528)\n",
      "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0705) | Acc: (97.94%) (38987/39808)\n",
      "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0702) | Acc: (97.95%) (40244/41088)\n",
      "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0700) | Acc: (97.95%) (41499/42368)\n",
      "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0696) | Acc: (97.96%) (42758/43648)\n",
      "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0697) | Acc: (97.96%) (44012/44928)\n",
      "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0699) | Acc: (97.96%) (45265/46208)\n",
      "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0696) | Acc: (97.96%) (46521/47488)\n",
      "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0698) | Acc: (97.96%) (47771/48768)\n",
      "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0697) | Acc: (97.95%) (48977/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3832) | Acc: (89.29%) (8929/10000)\n",
      "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0589) | Acc: (96.88%) (124/128)\n",
      "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0663) | Acc: (97.80%) (1377/1408)\n",
      "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0656) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0675) | Acc: (97.76%) (3879/3968)\n",
      "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0686) | Acc: (97.77%) (5131/5248)\n",
      "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0682) | Acc: (97.82%) (6386/6528)\n",
      "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0684) | Acc: (97.80%) (7636/7808)\n",
      "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0681) | Acc: (97.80%) (8888/9088)\n",
      "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0688) | Acc: (97.72%) (10132/10368)\n",
      "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0685) | Acc: (97.79%) (11390/11648)\n",
      "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0684) | Acc: (97.75%) (12637/12928)\n",
      "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0682) | Acc: (97.77%) (13891/14208)\n",
      "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0685) | Acc: (97.80%) (15147/15488)\n",
      "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0684) | Acc: (97.83%) (16404/16768)\n",
      "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0681) | Acc: (97.86%) (17662/18048)\n",
      "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0675) | Acc: (97.89%) (18921/19328)\n",
      "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0683) | Acc: (97.85%) (20165/20608)\n",
      "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0687) | Acc: (97.84%) (21415/21888)\n",
      "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0691) | Acc: (97.85%) (22670/23168)\n",
      "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0688) | Acc: (97.86%) (23926/24448)\n",
      "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0687) | Acc: (97.89%) (25186/25728)\n",
      "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0688) | Acc: (97.89%) (26438/27008)\n",
      "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0686) | Acc: (97.90%) (27695/28288)\n",
      "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0684) | Acc: (97.91%) (28950/29568)\n",
      "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0679) | Acc: (97.93%) (30209/30848)\n",
      "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0674) | Acc: (97.96%) (31471/32128)\n",
      "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0675) | Acc: (97.97%) (32729/33408)\n",
      "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0677) | Acc: (97.96%) (33981/34688)\n",
      "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0678) | Acc: (97.95%) (35230/35968)\n",
      "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0678) | Acc: (97.95%) (36485/37248)\n",
      "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0675) | Acc: (97.97%) (37746/38528)\n",
      "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0673) | Acc: (97.99%) (39009/39808)\n",
      "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0674) | Acc: (97.98%) (40260/41088)\n",
      "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0674) | Acc: (97.97%) (41510/42368)\n",
      "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0671) | Acc: (97.99%) (42772/43648)\n",
      "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0673) | Acc: (97.99%) (44024/44928)\n",
      "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0677) | Acc: (97.97%) (45270/46208)\n",
      "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0677) | Acc: (97.98%) (46527/47488)\n",
      "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0677) | Acc: (97.97%) (47778/48768)\n",
      "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0677) | Acc: (97.98%) (48991/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3851) | Acc: (89.30%) (8930/10000)\n",
      "Epoch: 93 | Batch_idx: 0 |  Loss: (0.1068) | Acc: (96.88%) (124/128)\n",
      "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0705) | Acc: (97.87%) (1378/1408)\n",
      "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0740) | Acc: (97.66%) (2625/2688)\n",
      "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0742) | Acc: (97.56%) (3871/3968)\n",
      "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0720) | Acc: (97.60%) (5122/5248)\n",
      "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0730) | Acc: (97.59%) (6371/6528)\n",
      "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0720) | Acc: (97.59%) (7620/7808)\n",
      "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0716) | Acc: (97.60%) (8870/9088)\n",
      "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0701) | Acc: (97.73%) (10133/10368)\n",
      "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0692) | Acc: (97.79%) (11391/11648)\n",
      "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0683) | Acc: (97.85%) (12650/12928)\n",
      "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0684) | Acc: (97.88%) (13907/14208)\n",
      "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0674) | Acc: (97.92%) (15166/15488)\n",
      "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0665) | Acc: (97.96%) (16426/16768)\n",
      "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0663) | Acc: (97.99%) (17685/18048)\n",
      "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0677) | Acc: (97.96%) (18933/19328)\n",
      "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0679) | Acc: (97.96%) (20187/20608)\n",
      "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0678) | Acc: (97.97%) (21443/21888)\n",
      "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0674) | Acc: (97.98%) (22701/23168)\n",
      "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0669) | Acc: (98.01%) (23962/24448)\n",
      "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0670) | Acc: (98.00%) (25213/25728)\n",
      "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0668) | Acc: (98.02%) (26474/27008)\n",
      "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0671) | Acc: (98.01%) (27725/28288)\n",
      "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0670) | Acc: (98.04%) (28988/29568)\n",
      "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0661) | Acc: (98.07%) (30254/30848)\n",
      "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0661) | Acc: (98.07%) (31509/32128)\n",
      "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0661) | Acc: (98.09%) (32771/33408)\n",
      "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0663) | Acc: (98.08%) (34021/34688)\n",
      "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0666) | Acc: (98.06%) (35270/35968)\n",
      "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0669) | Acc: (98.05%) (36521/37248)\n",
      "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0669) | Acc: (98.06%) (37779/38528)\n",
      "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0669) | Acc: (98.04%) (39029/39808)\n",
      "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0671) | Acc: (98.05%) (40285/41088)\n",
      "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0671) | Acc: (98.05%) (41542/42368)\n",
      "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0670) | Acc: (98.05%) (42799/43648)\n",
      "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0670) | Acc: (98.05%) (44052/44928)\n",
      "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0670) | Acc: (98.06%) (45311/46208)\n",
      "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0667) | Acc: (98.07%) (46573/47488)\n",
      "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0667) | Acc: (98.06%) (47823/48768)\n",
      "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0670) | Acc: (98.06%) (49029/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3851) | Acc: (89.33%) (8933/10000)\n",
      "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0496) | Acc: (97.66%) (125/128)\n",
      "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0684) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0753) | Acc: (97.81%) (2629/2688)\n",
      "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0701) | Acc: (97.98%) (3888/3968)\n",
      "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0684) | Acc: (98.15%) (5151/5248)\n",
      "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0677) | Acc: (98.07%) (6402/6528)\n",
      "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0690) | Acc: (98.00%) (7652/7808)\n",
      "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0697) | Acc: (97.91%) (8898/9088)\n",
      "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0674) | Acc: (98.01%) (10162/10368)\n",
      "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0699) | Acc: (97.91%) (11404/11648)\n",
      "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0695) | Acc: (97.91%) (12658/12928)\n",
      "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0686) | Acc: (97.96%) (13918/14208)\n",
      "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0681) | Acc: (97.98%) (15175/15488)\n",
      "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0687) | Acc: (97.96%) (16426/16768)\n",
      "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0681) | Acc: (97.97%) (17681/18048)\n",
      "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0681) | Acc: (97.94%) (18930/19328)\n",
      "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0683) | Acc: (97.92%) (20180/20608)\n",
      "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0681) | Acc: (97.93%) (21434/21888)\n",
      "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0682) | Acc: (97.94%) (22691/23168)\n",
      "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0684) | Acc: (97.95%) (23946/24448)\n",
      "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0691) | Acc: (97.91%) (25190/25728)\n",
      "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0692) | Acc: (97.91%) (26443/27008)\n",
      "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0695) | Acc: (97.91%) (27697/28288)\n",
      "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0690) | Acc: (97.94%) (28960/29568)\n",
      "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0688) | Acc: (97.94%) (30211/30848)\n",
      "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0687) | Acc: (97.95%) (31469/32128)\n",
      "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0686) | Acc: (97.96%) (32726/33408)\n",
      "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0687) | Acc: (97.95%) (33978/34688)\n",
      "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0687) | Acc: (97.95%) (35231/35968)\n",
      "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0687) | Acc: (97.95%) (36486/37248)\n",
      "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0685) | Acc: (97.97%) (37745/38528)\n",
      "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0685) | Acc: (97.96%) (38996/39808)\n",
      "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0687) | Acc: (97.94%) (40243/41088)\n",
      "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0684) | Acc: (97.95%) (41498/42368)\n",
      "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0681) | Acc: (97.96%) (42757/43648)\n",
      "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0684) | Acc: (97.95%) (44007/44928)\n",
      "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0687) | Acc: (97.95%) (45263/46208)\n",
      "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0685) | Acc: (97.96%) (46520/47488)\n",
      "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0688) | Acc: (97.95%) (47769/48768)\n",
      "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0689) | Acc: (97.96%) (48979/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3860) | Acc: (89.31%) (8931/10000)\n",
      "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0562) | Acc: (98.44%) (126/128)\n",
      "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0673) | Acc: (97.94%) (1379/1408)\n",
      "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0596) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0597) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0619) | Acc: (98.25%) (5156/5248)\n",
      "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0596) | Acc: (98.36%) (6421/6528)\n",
      "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0645) | Acc: (98.16%) (7664/7808)\n",
      "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0657) | Acc: (98.10%) (8915/9088)\n",
      "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0645) | Acc: (98.13%) (10174/10368)\n",
      "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0652) | Acc: (98.13%) (11430/11648)\n",
      "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0668) | Acc: (98.01%) (12671/12928)\n",
      "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0678) | Acc: (98.00%) (13924/14208)\n",
      "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0679) | Acc: (97.97%) (15173/15488)\n",
      "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0671) | Acc: (98.01%) (16434/16768)\n",
      "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0675) | Acc: (98.01%) (17688/18048)\n",
      "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0671) | Acc: (98.00%) (18942/19328)\n",
      "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0672) | Acc: (98.01%) (20198/20608)\n",
      "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0672) | Acc: (98.02%) (21454/21888)\n",
      "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0670) | Acc: (98.03%) (22712/23168)\n",
      "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0674) | Acc: (98.00%) (23960/24448)\n",
      "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0674) | Acc: (98.00%) (25214/25728)\n",
      "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0674) | Acc: (98.00%) (26469/27008)\n",
      "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0672) | Acc: (98.01%) (27725/28288)\n",
      "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0675) | Acc: (97.98%) (28971/29568)\n",
      "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0670) | Acc: (97.99%) (30228/30848)\n",
      "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0671) | Acc: (97.98%) (31479/32128)\n",
      "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0667) | Acc: (97.98%) (32732/33408)\n",
      "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0669) | Acc: (97.96%) (33981/34688)\n",
      "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0669) | Acc: (97.97%) (35239/35968)\n",
      "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0670) | Acc: (97.98%) (36494/37248)\n",
      "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0666) | Acc: (97.99%) (37754/38528)\n",
      "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0668) | Acc: (98.00%) (39011/39808)\n",
      "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0670) | Acc: (98.01%) (40270/41088)\n",
      "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0669) | Acc: (98.01%) (41524/42368)\n",
      "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0671) | Acc: (98.00%) (42775/43648)\n",
      "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0668) | Acc: (98.02%) (44040/44928)\n",
      "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0665) | Acc: (98.03%) (45298/46208)\n",
      "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0667) | Acc: (98.03%) (46552/47488)\n",
      "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0667) | Acc: (98.03%) (47806/48768)\n",
      "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0668) | Acc: (98.02%) (49010/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3869) | Acc: (89.34%) (8934/10000)\n",
      "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0317) | Acc: (100.00%) (128/128)\n",
      "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0627) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0622) | Acc: (98.44%) (2646/2688)\n",
      "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0644) | Acc: (98.16%) (3895/3968)\n",
      "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0675) | Acc: (97.96%) (5141/5248)\n",
      "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0652) | Acc: (98.04%) (6400/6528)\n",
      "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0658) | Acc: (98.08%) (7658/7808)\n",
      "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0672) | Acc: (98.06%) (8912/9088)\n",
      "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0661) | Acc: (98.11%) (10172/10368)\n",
      "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0672) | Acc: (98.08%) (11424/11648)\n",
      "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0665) | Acc: (98.10%) (12683/12928)\n",
      "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0673) | Acc: (98.02%) (13927/14208)\n",
      "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0672) | Acc: (98.00%) (15179/15488)\n",
      "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0672) | Acc: (97.98%) (16430/16768)\n",
      "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0664) | Acc: (98.02%) (17691/18048)\n",
      "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0660) | Acc: (98.04%) (18949/19328)\n",
      "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0661) | Acc: (98.02%) (20199/20608)\n",
      "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0661) | Acc: (98.03%) (21457/21888)\n",
      "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0663) | Acc: (98.03%) (22712/23168)\n",
      "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0662) | Acc: (98.04%) (23970/24448)\n",
      "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0662) | Acc: (98.04%) (25223/25728)\n",
      "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0666) | Acc: (98.04%) (26478/27008)\n",
      "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0663) | Acc: (98.05%) (27736/28288)\n",
      "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0659) | Acc: (98.06%) (28993/29568)\n",
      "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0657) | Acc: (98.09%) (30258/30848)\n",
      "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0655) | Acc: (98.12%) (31523/32128)\n",
      "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0656) | Acc: (98.10%) (32774/33408)\n",
      "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0655) | Acc: (98.11%) (34031/34688)\n",
      "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0659) | Acc: (98.08%) (35278/35968)\n",
      "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0656) | Acc: (98.10%) (36540/37248)\n",
      "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0656) | Acc: (98.10%) (37797/38528)\n",
      "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0657) | Acc: (98.09%) (39049/39808)\n",
      "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0659) | Acc: (98.08%) (40298/41088)\n",
      "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0656) | Acc: (98.09%) (41559/42368)\n",
      "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0656) | Acc: (98.10%) (42820/43648)\n",
      "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0658) | Acc: (98.09%) (44071/44928)\n",
      "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0660) | Acc: (98.09%) (45326/46208)\n",
      "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0661) | Acc: (98.09%) (46581/47488)\n",
      "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0662) | Acc: (98.08%) (47834/48768)\n",
      "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0665) | Acc: (98.07%) (49035/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3826) | Acc: (89.44%) (8944/10000)\n",
      "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0626) | Acc: (99.22%) (127/128)\n",
      "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0718) | Acc: (97.87%) (1378/1408)\n",
      "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0691) | Acc: (97.92%) (2632/2688)\n",
      "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0697) | Acc: (97.86%) (3883/3968)\n",
      "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0744) | Acc: (97.68%) (5126/5248)\n",
      "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0711) | Acc: (97.82%) (6386/6528)\n",
      "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0691) | Acc: (97.85%) (7640/7808)\n",
      "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0718) | Acc: (97.72%) (8881/9088)\n",
      "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0717) | Acc: (97.75%) (10135/10368)\n",
      "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0703) | Acc: (97.83%) (11395/11648)\n",
      "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0698) | Acc: (97.85%) (12650/12928)\n",
      "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0700) | Acc: (97.83%) (13900/14208)\n",
      "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0701) | Acc: (97.84%) (15153/15488)\n",
      "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0695) | Acc: (97.86%) (16409/16768)\n",
      "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0699) | Acc: (97.83%) (17657/18048)\n",
      "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0702) | Acc: (97.83%) (18908/19328)\n",
      "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0695) | Acc: (97.88%) (20171/20608)\n",
      "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0697) | Acc: (97.85%) (21417/21888)\n",
      "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0697) | Acc: (97.85%) (22671/23168)\n",
      "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0697) | Acc: (97.86%) (23924/24448)\n",
      "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0694) | Acc: (97.89%) (25186/25728)\n",
      "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0693) | Acc: (97.87%) (26434/27008)\n",
      "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0689) | Acc: (97.90%) (27695/28288)\n",
      "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0696) | Acc: (97.87%) (28939/29568)\n",
      "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0697) | Acc: (97.87%) (30192/30848)\n",
      "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0693) | Acc: (97.89%) (31450/32128)\n",
      "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0691) | Acc: (97.90%) (32707/33408)\n",
      "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0689) | Acc: (97.90%) (33961/34688)\n",
      "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0690) | Acc: (97.90%) (35214/35968)\n",
      "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0686) | Acc: (97.93%) (36477/37248)\n",
      "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0685) | Acc: (97.94%) (37734/38528)\n",
      "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0678) | Acc: (97.98%) (39003/39808)\n",
      "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0680) | Acc: (97.97%) (40254/41088)\n",
      "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0680) | Acc: (97.96%) (41504/42368)\n",
      "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0681) | Acc: (97.94%) (42748/43648)\n",
      "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0681) | Acc: (97.94%) (44001/44928)\n",
      "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0683) | Acc: (97.92%) (45247/46208)\n",
      "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0683) | Acc: (97.92%) (46501/47488)\n",
      "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0680) | Acc: (97.94%) (47761/48768)\n",
      "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0679) | Acc: (97.95%) (48973/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3847) | Acc: (89.33%) (8933/10000)\n",
      "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0816) | Acc: (97.66%) (125/128)\n",
      "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0647) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0631) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0618) | Acc: (98.51%) (3909/3968)\n",
      "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0618) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0648) | Acc: (98.28%) (6416/6528)\n",
      "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0646) | Acc: (98.23%) (7670/7808)\n",
      "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0638) | Acc: (98.27%) (8931/9088)\n",
      "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0643) | Acc: (98.26%) (10188/10368)\n",
      "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0631) | Acc: (98.30%) (11450/11648)\n",
      "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0637) | Acc: (98.28%) (12706/12928)\n",
      "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0633) | Acc: (98.27%) (13962/14208)\n",
      "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0634) | Acc: (98.24%) (15215/15488)\n",
      "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0638) | Acc: (98.22%) (16470/16768)\n",
      "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0633) | Acc: (98.25%) (17733/18048)\n",
      "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0637) | Acc: (98.22%) (18983/19328)\n",
      "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0633) | Acc: (98.22%) (20242/20608)\n",
      "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0629) | Acc: (98.23%) (21500/21888)\n",
      "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0630) | Acc: (98.23%) (22757/23168)\n",
      "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0634) | Acc: (98.19%) (24006/24448)\n",
      "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0638) | Acc: (98.17%) (25258/25728)\n",
      "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0639) | Acc: (98.18%) (26517/27008)\n",
      "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0635) | Acc: (98.21%) (27783/28288)\n",
      "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0636) | Acc: (98.20%) (29035/29568)\n",
      "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0635) | Acc: (98.21%) (30295/30848)\n",
      "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0640) | Acc: (98.18%) (31542/32128)\n",
      "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0639) | Acc: (98.18%) (32801/33408)\n",
      "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0644) | Acc: (98.15%) (34048/34688)\n",
      "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0644) | Acc: (98.17%) (35308/35968)\n",
      "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0643) | Acc: (98.17%) (36568/37248)\n",
      "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0642) | Acc: (98.18%) (37825/38528)\n",
      "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0644) | Acc: (98.16%) (39074/39808)\n",
      "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0643) | Acc: (98.14%) (40325/41088)\n",
      "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0647) | Acc: (98.13%) (41574/42368)\n",
      "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0646) | Acc: (98.14%) (42838/43648)\n",
      "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0642) | Acc: (98.16%) (44103/44928)\n",
      "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0640) | Acc: (98.18%) (45365/46208)\n",
      "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0641) | Acc: (98.16%) (46616/47488)\n",
      "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0641) | Acc: (98.16%) (47869/48768)\n",
      "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0640) | Acc: (98.15%) (49076/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3849) | Acc: (89.55%) (8955/10000)\n",
      "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0728) | Acc: (97.66%) (125/128)\n",
      "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0712) | Acc: (97.80%) (1377/1408)\n",
      "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0708) | Acc: (97.69%) (2626/2688)\n",
      "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0677) | Acc: (97.86%) (3883/3968)\n",
      "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0635) | Acc: (98.08%) (5147/5248)\n",
      "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0616) | Acc: (98.13%) (6406/6528)\n",
      "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0614) | Acc: (98.17%) (7665/7808)\n",
      "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0627) | Acc: (98.16%) (8921/9088)\n",
      "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0622) | Acc: (98.20%) (10181/10368)\n",
      "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0621) | Acc: (98.21%) (11440/11648)\n",
      "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0619) | Acc: (98.26%) (12703/12928)\n",
      "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0627) | Acc: (98.24%) (13958/14208)\n",
      "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0630) | Acc: (98.21%) (15211/15488)\n",
      "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0636) | Acc: (98.17%) (16461/16768)\n",
      "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0630) | Acc: (98.19%) (17721/18048)\n",
      "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0635) | Acc: (98.16%) (18972/19328)\n",
      "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0640) | Acc: (98.15%) (20226/20608)\n",
      "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0639) | Acc: (98.14%) (21481/21888)\n",
      "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0643) | Acc: (98.14%) (22736/23168)\n",
      "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0638) | Acc: (98.16%) (23997/24448)\n",
      "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0635) | Acc: (98.19%) (25263/25728)\n",
      "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0636) | Acc: (98.18%) (26516/27008)\n",
      "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0638) | Acc: (98.15%) (27766/28288)\n",
      "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0638) | Acc: (98.15%) (29022/29568)\n",
      "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0636) | Acc: (98.18%) (30286/30848)\n",
      "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0638) | Acc: (98.16%) (31538/32128)\n",
      "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0636) | Acc: (98.19%) (32803/33408)\n",
      "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0637) | Acc: (98.19%) (34060/34688)\n",
      "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0639) | Acc: (98.18%) (35314/35968)\n",
      "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0638) | Acc: (98.19%) (36574/37248)\n",
      "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0640) | Acc: (98.19%) (37830/38528)\n",
      "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0640) | Acc: (98.18%) (39083/39808)\n",
      "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0643) | Acc: (98.16%) (40333/41088)\n",
      "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0646) | Acc: (98.15%) (41584/42368)\n",
      "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0648) | Acc: (98.13%) (42832/43648)\n",
      "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0646) | Acc: (98.14%) (44091/44928)\n",
      "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0648) | Acc: (98.13%) (45343/46208)\n",
      "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0649) | Acc: (98.12%) (46595/47488)\n",
      "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0649) | Acc: (98.11%) (47847/48768)\n",
      "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0654) | Acc: (98.09%) (49044/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3871) | Acc: (89.42%) (8942/10000)\n",
      "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0546) | Acc: (98.44%) (126/128)\n",
      "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0624) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0686) | Acc: (97.81%) (2629/2688)\n",
      "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0700) | Acc: (97.88%) (3884/3968)\n",
      "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0723) | Acc: (97.69%) (5127/5248)\n",
      "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0700) | Acc: (97.81%) (6385/6528)\n",
      "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0694) | Acc: (97.85%) (7640/7808)\n",
      "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0689) | Acc: (97.85%) (8893/9088)\n",
      "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0682) | Acc: (97.90%) (10150/10368)\n",
      "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0684) | Acc: (97.89%) (11402/11648)\n",
      "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0679) | Acc: (97.92%) (12659/12928)\n",
      "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0675) | Acc: (97.97%) (13920/14208)\n",
      "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0687) | Acc: (97.92%) (15166/15488)\n",
      "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0686) | Acc: (97.95%) (16424/16768)\n",
      "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0683) | Acc: (97.97%) (17682/18048)\n",
      "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0678) | Acc: (98.03%) (18947/19328)\n",
      "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0682) | Acc: (98.02%) (20199/20608)\n",
      "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0677) | Acc: (98.03%) (21456/21888)\n",
      "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0674) | Acc: (98.03%) (22711/23168)\n",
      "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0669) | Acc: (98.05%) (23972/24448)\n",
      "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0670) | Acc: (98.03%) (25221/25728)\n",
      "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0669) | Acc: (98.05%) (26481/27008)\n",
      "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0669) | Acc: (98.06%) (27739/28288)\n",
      "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0671) | Acc: (98.06%) (28994/29568)\n",
      "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0668) | Acc: (98.07%) (30253/30848)\n",
      "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0664) | Acc: (98.09%) (31513/32128)\n",
      "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0665) | Acc: (98.09%) (32771/33408)\n",
      "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0665) | Acc: (98.09%) (34026/34688)\n",
      "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0663) | Acc: (98.10%) (35283/35968)\n",
      "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0660) | Acc: (98.11%) (36544/37248)\n",
      "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0659) | Acc: (98.11%) (37799/38528)\n",
      "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0663) | Acc: (98.09%) (39048/39808)\n",
      "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0663) | Acc: (98.08%) (40299/41088)\n",
      "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0660) | Acc: (98.08%) (41556/42368)\n",
      "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0661) | Acc: (98.07%) (42806/43648)\n",
      "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0659) | Acc: (98.08%) (44065/44928)\n",
      "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0659) | Acc: (98.08%) (45319/46208)\n",
      "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0658) | Acc: (98.08%) (46577/47488)\n",
      "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0658) | Acc: (98.08%) (47834/48768)\n",
      "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0654) | Acc: (98.10%) (49050/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3867) | Acc: (89.32%) (8932/10000)\n",
      "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0226) | Acc: (100.00%) (128/128)\n",
      "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0618) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0681) | Acc: (97.84%) (2630/2688)\n",
      "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0661) | Acc: (98.03%) (3890/3968)\n",
      "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0643) | Acc: (98.09%) (5148/5248)\n",
      "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0626) | Acc: (98.19%) (6410/6528)\n",
      "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0607) | Acc: (98.30%) (7675/7808)\n",
      "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0638) | Acc: (98.15%) (8920/9088)\n",
      "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0644) | Acc: (98.14%) (10175/10368)\n",
      "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0638) | Acc: (98.15%) (11433/11648)\n",
      "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0646) | Acc: (98.13%) (12686/12928)\n",
      "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0639) | Acc: (98.16%) (13947/14208)\n",
      "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0645) | Acc: (98.10%) (15193/15488)\n",
      "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0649) | Acc: (98.07%) (16445/16768)\n",
      "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0648) | Acc: (98.05%) (17696/18048)\n",
      "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0655) | Acc: (98.04%) (18950/19328)\n",
      "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0655) | Acc: (98.05%) (20206/20608)\n",
      "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0649) | Acc: (98.09%) (21469/21888)\n",
      "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0644) | Acc: (98.09%) (22726/23168)\n",
      "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0647) | Acc: (98.08%) (23978/24448)\n",
      "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0637) | Acc: (98.11%) (25243/25728)\n",
      "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0638) | Acc: (98.13%) (26502/27008)\n",
      "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0637) | Acc: (98.13%) (27760/28288)\n",
      "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0643) | Acc: (98.11%) (29010/29568)\n",
      "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0649) | Acc: (98.09%) (30258/30848)\n",
      "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0645) | Acc: (98.10%) (31516/32128)\n",
      "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0647) | Acc: (98.09%) (32771/33408)\n",
      "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0646) | Acc: (98.11%) (34034/34688)\n",
      "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0649) | Acc: (98.10%) (35283/35968)\n",
      "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0652) | Acc: (98.08%) (36534/37248)\n",
      "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0651) | Acc: (98.08%) (37787/38528)\n",
      "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0648) | Acc: (98.09%) (39047/39808)\n",
      "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0648) | Acc: (98.10%) (40306/41088)\n",
      "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0649) | Acc: (98.08%) (41554/42368)\n",
      "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0652) | Acc: (98.08%) (42808/43648)\n",
      "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0650) | Acc: (98.08%) (44067/44928)\n",
      "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0651) | Acc: (98.08%) (45320/46208)\n",
      "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0650) | Acc: (98.08%) (46576/47488)\n",
      "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0653) | Acc: (98.06%) (47821/48768)\n",
      "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0651) | Acc: (98.07%) (49033/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3851) | Acc: (89.48%) (8948/10000)\n",
      "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0557) | Acc: (97.66%) (125/128)\n",
      "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0627) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0668) | Acc: (97.77%) (2628/2688)\n",
      "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0652) | Acc: (97.83%) (3882/3968)\n",
      "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0645) | Acc: (97.87%) (5136/5248)\n",
      "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0641) | Acc: (97.96%) (6395/6528)\n",
      "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0629) | Acc: (98.00%) (7652/7808)\n",
      "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0617) | Acc: (98.03%) (8909/9088)\n",
      "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0623) | Acc: (98.02%) (10163/10368)\n",
      "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0636) | Acc: (97.99%) (11414/11648)\n",
      "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0641) | Acc: (98.01%) (12671/12928)\n",
      "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0643) | Acc: (98.06%) (13933/14208)\n",
      "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0645) | Acc: (98.06%) (15188/15488)\n",
      "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0638) | Acc: (98.10%) (16449/16768)\n",
      "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0642) | Acc: (98.09%) (17704/18048)\n",
      "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0646) | Acc: (98.11%) (18963/19328)\n",
      "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0648) | Acc: (98.11%) (20218/20608)\n",
      "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0644) | Acc: (98.14%) (21480/21888)\n",
      "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0649) | Acc: (98.14%) (22737/23168)\n",
      "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0646) | Acc: (98.16%) (23998/24448)\n",
      "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0649) | Acc: (98.12%) (25245/25728)\n",
      "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0645) | Acc: (98.13%) (26504/27008)\n",
      "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0641) | Acc: (98.15%) (27765/28288)\n",
      "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0641) | Acc: (98.15%) (29020/29568)\n",
      "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0639) | Acc: (98.17%) (30282/30848)\n",
      "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0647) | Acc: (98.15%) (31533/32128)\n",
      "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0651) | Acc: (98.12%) (32780/33408)\n",
      "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0647) | Acc: (98.14%) (34043/34688)\n",
      "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0644) | Acc: (98.15%) (35304/35968)\n",
      "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0646) | Acc: (98.15%) (36560/37248)\n",
      "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0640) | Acc: (98.19%) (37830/38528)\n",
      "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0640) | Acc: (98.20%) (39090/39808)\n",
      "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0640) | Acc: (98.19%) (40344/41088)\n",
      "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0640) | Acc: (98.17%) (41594/42368)\n",
      "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0637) | Acc: (98.18%) (42854/43648)\n",
      "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0638) | Acc: (98.18%) (44110/44928)\n",
      "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0639) | Acc: (98.17%) (45363/46208)\n",
      "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0637) | Acc: (98.18%) (46623/47488)\n",
      "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0641) | Acc: (98.15%) (47868/48768)\n",
      "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0643) | Acc: (98.15%) (49073/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3885) | Acc: (89.52%) (8952/10000)\n",
      "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0541) | Acc: (98.44%) (126/128)\n",
      "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0576) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0567) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0578) | Acc: (98.26%) (3899/3968)\n",
      "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0555) | Acc: (98.40%) (5164/5248)\n",
      "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0571) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0565) | Acc: (98.44%) (7686/7808)\n",
      "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0571) | Acc: (98.45%) (8947/9088)\n",
      "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0581) | Acc: (98.42%) (10204/10368)\n",
      "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0587) | Acc: (98.36%) (11457/11648)\n",
      "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0581) | Acc: (98.40%) (12721/12928)\n",
      "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0580) | Acc: (98.39%) (13979/14208)\n",
      "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0592) | Acc: (98.35%) (15233/15488)\n",
      "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0593) | Acc: (98.36%) (16493/16768)\n",
      "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0594) | Acc: (98.35%) (17751/18048)\n",
      "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0597) | Acc: (98.33%) (19006/19328)\n",
      "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0601) | Acc: (98.33%) (20264/20608)\n",
      "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0603) | Acc: (98.32%) (21521/21888)\n",
      "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0600) | Acc: (98.32%) (22778/23168)\n",
      "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0602) | Acc: (98.31%) (24035/24448)\n",
      "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0604) | Acc: (98.31%) (25292/25728)\n",
      "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0604) | Acc: (98.30%) (26548/27008)\n",
      "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0605) | Acc: (98.29%) (27804/28288)\n",
      "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0600) | Acc: (98.31%) (29067/29568)\n",
      "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0604) | Acc: (98.27%) (30315/30848)\n",
      "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0614) | Acc: (98.24%) (31563/32128)\n",
      "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0614) | Acc: (98.25%) (32824/33408)\n",
      "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0616) | Acc: (98.24%) (34077/34688)\n",
      "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0614) | Acc: (98.23%) (35333/35968)\n",
      "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0617) | Acc: (98.22%) (36584/37248)\n",
      "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0616) | Acc: (98.23%) (37847/38528)\n",
      "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0614) | Acc: (98.24%) (39108/39808)\n",
      "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0617) | Acc: (98.23%) (40361/41088)\n",
      "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0621) | Acc: (98.21%) (41611/42368)\n",
      "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0627) | Acc: (98.18%) (42854/43648)\n",
      "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0626) | Acc: (98.19%) (44114/44928)\n",
      "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0624) | Acc: (98.20%) (45378/46208)\n",
      "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0625) | Acc: (98.20%) (46631/47488)\n",
      "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0626) | Acc: (98.19%) (47883/48768)\n",
      "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0625) | Acc: (98.19%) (49095/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3906) | Acc: (89.41%) (8941/10000)\n",
      "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0747) | Acc: (95.31%) (122/128)\n",
      "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0792) | Acc: (97.16%) (1368/1408)\n",
      "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0690) | Acc: (97.84%) (2630/2688)\n",
      "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0693) | Acc: (97.96%) (3887/3968)\n",
      "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0678) | Acc: (98.02%) (5144/5248)\n",
      "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0669) | Acc: (98.09%) (6403/6528)\n",
      "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0656) | Acc: (98.14%) (7663/7808)\n",
      "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0644) | Acc: (98.20%) (8924/9088)\n",
      "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0635) | Acc: (98.19%) (10180/10368)\n",
      "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0638) | Acc: (98.18%) (11436/11648)\n",
      "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0630) | Acc: (98.24%) (12700/12928)\n",
      "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0624) | Acc: (98.28%) (13963/14208)\n",
      "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0631) | Acc: (98.19%) (15207/15488)\n",
      "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0638) | Acc: (98.18%) (16463/16768)\n",
      "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0636) | Acc: (98.18%) (17720/18048)\n",
      "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0629) | Acc: (98.22%) (18984/19328)\n",
      "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0622) | Acc: (98.25%) (20248/20608)\n",
      "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0616) | Acc: (98.26%) (21508/21888)\n",
      "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0619) | Acc: (98.24%) (22761/23168)\n",
      "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0621) | Acc: (98.22%) (24012/24448)\n",
      "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0627) | Acc: (98.18%) (25260/25728)\n",
      "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0628) | Acc: (98.19%) (26518/27008)\n",
      "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0630) | Acc: (98.16%) (27767/28288)\n",
      "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0626) | Acc: (98.18%) (29030/29568)\n",
      "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0627) | Acc: (98.18%) (30288/30848)\n",
      "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0625) | Acc: (98.19%) (31548/32128)\n",
      "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0624) | Acc: (98.18%) (32801/33408)\n",
      "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0624) | Acc: (98.19%) (34059/34688)\n",
      "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0624) | Acc: (98.18%) (35313/35968)\n",
      "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0624) | Acc: (98.18%) (36571/37248)\n",
      "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0623) | Acc: (98.18%) (37827/38528)\n",
      "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0626) | Acc: (98.17%) (39078/39808)\n",
      "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0625) | Acc: (98.18%) (40339/41088)\n",
      "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0626) | Acc: (98.17%) (41594/42368)\n",
      "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0623) | Acc: (98.19%) (42857/43648)\n",
      "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0619) | Acc: (98.21%) (44122/44928)\n",
      "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0620) | Acc: (98.20%) (45376/46208)\n",
      "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0622) | Acc: (98.18%) (46624/47488)\n",
      "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0623) | Acc: (98.18%) (47878/48768)\n",
      "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0627) | Acc: (98.16%) (49082/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3885) | Acc: (89.35%) (8935/10000)\n",
      "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0778) | Acc: (98.44%) (126/128)\n",
      "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0635) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0658) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0671) | Acc: (97.88%) (3884/3968)\n",
      "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0663) | Acc: (97.87%) (5136/5248)\n",
      "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0634) | Acc: (98.07%) (6402/6528)\n",
      "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0642) | Acc: (98.08%) (7658/7808)\n",
      "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0644) | Acc: (98.14%) (8919/9088)\n",
      "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0645) | Acc: (98.13%) (10174/10368)\n",
      "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0635) | Acc: (98.16%) (11434/11648)\n",
      "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0633) | Acc: (98.17%) (12692/12928)\n",
      "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0632) | Acc: (98.14%) (13944/14208)\n",
      "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0629) | Acc: (98.13%) (15199/15488)\n",
      "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0631) | Acc: (98.12%) (16453/16768)\n",
      "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0641) | Acc: (98.09%) (17704/18048)\n",
      "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0639) | Acc: (98.10%) (18960/19328)\n",
      "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0638) | Acc: (98.12%) (20220/20608)\n",
      "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0636) | Acc: (98.15%) (21482/21888)\n",
      "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0634) | Acc: (98.17%) (22743/23168)\n",
      "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0636) | Acc: (98.15%) (23996/24448)\n",
      "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0639) | Acc: (98.13%) (25248/25728)\n",
      "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0633) | Acc: (98.16%) (26512/27008)\n",
      "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0637) | Acc: (98.14%) (27761/28288)\n",
      "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0640) | Acc: (98.11%) (29008/29568)\n",
      "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0644) | Acc: (98.11%) (30266/30848)\n",
      "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0642) | Acc: (98.12%) (31525/32128)\n",
      "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0643) | Acc: (98.12%) (32780/33408)\n",
      "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0640) | Acc: (98.12%) (34037/34688)\n",
      "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0638) | Acc: (98.13%) (35297/35968)\n",
      "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0641) | Acc: (98.11%) (36544/37248)\n",
      "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0643) | Acc: (98.10%) (37796/38528)\n",
      "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0640) | Acc: (98.11%) (39054/39808)\n",
      "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0637) | Acc: (98.11%) (40312/41088)\n",
      "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0636) | Acc: (98.13%) (41574/42368)\n",
      "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0639) | Acc: (98.12%) (42827/43648)\n",
      "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0638) | Acc: (98.12%) (44085/44928)\n",
      "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0635) | Acc: (98.13%) (45343/46208)\n",
      "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0634) | Acc: (98.14%) (46604/47488)\n",
      "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0632) | Acc: (98.15%) (47864/48768)\n",
      "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0630) | Acc: (98.15%) (49074/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3908) | Acc: (89.43%) (8943/10000)\n",
      "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0795) | Acc: (99.22%) (127/128)\n",
      "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0580) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0551) | Acc: (98.77%) (2655/2688)\n",
      "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0562) | Acc: (98.61%) (3913/3968)\n",
      "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0576) | Acc: (98.55%) (5172/5248)\n",
      "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0597) | Acc: (98.44%) (6426/6528)\n",
      "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0618) | Acc: (98.30%) (7675/7808)\n",
      "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0622) | Acc: (98.24%) (8928/9088)\n",
      "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0619) | Acc: (98.20%) (10181/10368)\n",
      "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0629) | Acc: (98.21%) (11439/11648)\n",
      "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0631) | Acc: (98.19%) (12694/12928)\n",
      "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0627) | Acc: (98.22%) (13955/14208)\n",
      "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0638) | Acc: (98.19%) (15207/15488)\n",
      "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0633) | Acc: (98.18%) (16463/16768)\n",
      "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0634) | Acc: (98.18%) (17719/18048)\n",
      "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0630) | Acc: (98.19%) (18979/19328)\n",
      "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0629) | Acc: (98.19%) (20235/20608)\n",
      "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0625) | Acc: (98.22%) (21498/21888)\n",
      "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0626) | Acc: (98.20%) (22751/23168)\n",
      "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0624) | Acc: (98.20%) (24009/24448)\n",
      "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0623) | Acc: (98.22%) (25269/25728)\n",
      "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0618) | Acc: (98.24%) (26534/27008)\n",
      "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0620) | Acc: (98.23%) (27786/28288)\n",
      "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0624) | Acc: (98.21%) (29038/29568)\n",
      "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0621) | Acc: (98.22%) (30299/30848)\n",
      "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0622) | Acc: (98.21%) (31553/32128)\n",
      "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0620) | Acc: (98.20%) (32808/33408)\n",
      "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0624) | Acc: (98.19%) (34059/34688)\n",
      "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0625) | Acc: (98.17%) (35310/35968)\n",
      "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0628) | Acc: (98.16%) (36564/37248)\n",
      "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0629) | Acc: (98.15%) (37815/38528)\n",
      "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0628) | Acc: (98.16%) (39074/39808)\n",
      "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0626) | Acc: (98.16%) (40333/41088)\n",
      "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0625) | Acc: (98.17%) (41592/42368)\n",
      "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0625) | Acc: (98.17%) (42848/43648)\n",
      "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0627) | Acc: (98.17%) (44105/44928)\n",
      "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0622) | Acc: (98.19%) (45371/46208)\n",
      "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0624) | Acc: (98.18%) (46626/47488)\n",
      "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0624) | Acc: (98.18%) (47879/48768)\n",
      "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0624) | Acc: (98.17%) (49087/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3938) | Acc: (89.44%) (8944/10000)\n",
      "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0649) | Acc: (98.44%) (126/128)\n",
      "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0503) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0528) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0569) | Acc: (98.34%) (3902/3968)\n",
      "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0576) | Acc: (98.32%) (5160/5248)\n",
      "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0584) | Acc: (98.28%) (6416/6528)\n",
      "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0589) | Acc: (98.31%) (7676/7808)\n",
      "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0598) | Acc: (98.26%) (8930/9088)\n",
      "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0616) | Acc: (98.19%) (10180/10368)\n",
      "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0623) | Acc: (98.11%) (11428/11648)\n",
      "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0611) | Acc: (98.17%) (12692/12928)\n",
      "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0602) | Acc: (98.23%) (13956/14208)\n",
      "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0623) | Acc: (98.11%) (15196/15488)\n",
      "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0614) | Acc: (98.15%) (16457/16768)\n",
      "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0612) | Acc: (98.16%) (17716/18048)\n",
      "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0614) | Acc: (98.17%) (18974/19328)\n",
      "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0612) | Acc: (98.18%) (20232/20608)\n",
      "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0615) | Acc: (98.15%) (21484/21888)\n",
      "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0609) | Acc: (98.19%) (22749/23168)\n",
      "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0608) | Acc: (98.21%) (24010/24448)\n",
      "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0609) | Acc: (98.19%) (25263/25728)\n",
      "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0610) | Acc: (98.19%) (26518/27008)\n",
      "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0609) | Acc: (98.18%) (27772/28288)\n",
      "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0611) | Acc: (98.18%) (29029/29568)\n",
      "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0613) | Acc: (98.17%) (30285/30848)\n",
      "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0612) | Acc: (98.18%) (31543/32128)\n",
      "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0620) | Acc: (98.16%) (32792/33408)\n",
      "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0621) | Acc: (98.15%) (34048/34688)\n",
      "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0616) | Acc: (98.17%) (35311/35968)\n",
      "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0619) | Acc: (98.17%) (36568/37248)\n",
      "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0620) | Acc: (98.17%) (37822/38528)\n",
      "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0622) | Acc: (98.17%) (39079/39808)\n",
      "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0621) | Acc: (98.18%) (40339/41088)\n",
      "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0622) | Acc: (98.17%) (41592/42368)\n",
      "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0623) | Acc: (98.17%) (42848/43648)\n",
      "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0622) | Acc: (98.17%) (44106/44928)\n",
      "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0620) | Acc: (98.18%) (45368/46208)\n",
      "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0623) | Acc: (98.18%) (46623/47488)\n",
      "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0622) | Acc: (98.20%) (47890/48768)\n",
      "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0621) | Acc: (98.20%) (49100/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3886) | Acc: (89.50%) (8950/10000)\n",
      "Epoch: 108 | Batch_idx: 0 |  Loss: (0.0822) | Acc: (96.88%) (124/128)\n",
      "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0534) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0588) | Acc: (98.07%) (2636/2688)\n",
      "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0628) | Acc: (98.03%) (3890/3968)\n",
      "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0601) | Acc: (98.21%) (5154/5248)\n",
      "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0598) | Acc: (98.19%) (6410/6528)\n",
      "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0597) | Acc: (98.18%) (7666/7808)\n",
      "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0592) | Acc: (98.20%) (8924/9088)\n",
      "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0598) | Acc: (98.16%) (10177/10368)\n",
      "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0598) | Acc: (98.15%) (11433/11648)\n",
      "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0594) | Acc: (98.21%) (12697/12928)\n",
      "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0604) | Acc: (98.15%) (13945/14208)\n",
      "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0617) | Acc: (98.08%) (15191/15488)\n",
      "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0615) | Acc: (98.09%) (16447/16768)\n",
      "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0611) | Acc: (98.09%) (17704/18048)\n",
      "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0612) | Acc: (98.11%) (18962/19328)\n",
      "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0616) | Acc: (98.10%) (20216/20608)\n",
      "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0612) | Acc: (98.12%) (21476/21888)\n",
      "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0625) | Acc: (98.06%) (22719/23168)\n",
      "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0620) | Acc: (98.08%) (23979/24448)\n",
      "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0621) | Acc: (98.08%) (25234/25728)\n",
      "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0614) | Acc: (98.13%) (26502/27008)\n",
      "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0619) | Acc: (98.11%) (27752/28288)\n",
      "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0620) | Acc: (98.11%) (29009/29568)\n",
      "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0620) | Acc: (98.10%) (30261/30848)\n",
      "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0620) | Acc: (98.10%) (31517/32128)\n",
      "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0621) | Acc: (98.10%) (32773/33408)\n",
      "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0623) | Acc: (98.08%) (34022/34688)\n",
      "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0624) | Acc: (98.08%) (35276/35968)\n",
      "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0623) | Acc: (98.09%) (36535/37248)\n",
      "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0622) | Acc: (98.10%) (37795/38528)\n",
      "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0620) | Acc: (98.11%) (39056/39808)\n",
      "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0617) | Acc: (98.12%) (40317/41088)\n",
      "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0618) | Acc: (98.11%) (41569/42368)\n",
      "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0617) | Acc: (98.12%) (42827/43648)\n",
      "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0624) | Acc: (98.10%) (44074/44928)\n",
      "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0623) | Acc: (98.11%) (45333/46208)\n",
      "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0625) | Acc: (98.10%) (46585/47488)\n",
      "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0624) | Acc: (98.10%) (47842/48768)\n",
      "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0625) | Acc: (98.10%) (49049/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3893) | Acc: (89.36%) (8936/10000)\n",
      "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0878) | Acc: (96.88%) (124/128)\n",
      "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0562) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0584) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0604) | Acc: (98.31%) (3901/3968)\n",
      "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0630) | Acc: (98.23%) (5155/5248)\n",
      "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0614) | Acc: (98.28%) (6416/6528)\n",
      "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0600) | Acc: (98.35%) (7679/7808)\n",
      "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0619) | Acc: (98.25%) (8929/9088)\n",
      "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0608) | Acc: (98.29%) (10191/10368)\n",
      "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0609) | Acc: (98.27%) (11446/11648)\n",
      "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0612) | Acc: (98.23%) (12699/12928)\n",
      "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0597) | Acc: (98.29%) (13965/14208)\n",
      "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0591) | Acc: (98.28%) (15222/15488)\n",
      "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0594) | Acc: (98.28%) (16479/16768)\n",
      "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0599) | Acc: (98.25%) (17732/18048)\n",
      "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0598) | Acc: (98.27%) (18993/19328)\n",
      "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0590) | Acc: (98.31%) (20260/20608)\n",
      "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0592) | Acc: (98.31%) (21519/21888)\n",
      "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0585) | Acc: (98.32%) (22779/23168)\n",
      "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0580) | Acc: (98.32%) (24038/24448)\n",
      "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0586) | Acc: (98.31%) (25292/25728)\n",
      "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0592) | Acc: (98.30%) (26549/27008)\n",
      "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0593) | Acc: (98.27%) (27800/28288)\n",
      "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0596) | Acc: (98.26%) (29054/29568)\n",
      "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0597) | Acc: (98.27%) (30314/30848)\n",
      "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0596) | Acc: (98.25%) (31567/32128)\n",
      "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0595) | Acc: (98.27%) (32829/33408)\n",
      "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0595) | Acc: (98.26%) (34084/34688)\n",
      "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0596) | Acc: (98.25%) (35338/35968)\n",
      "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0597) | Acc: (98.25%) (36597/37248)\n",
      "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0594) | Acc: (98.27%) (37863/38528)\n",
      "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0596) | Acc: (98.26%) (39117/39808)\n",
      "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0596) | Acc: (98.27%) (40376/41088)\n",
      "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0593) | Acc: (98.28%) (41641/42368)\n",
      "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0594) | Acc: (98.28%) (42897/43648)\n",
      "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0596) | Acc: (98.27%) (44151/44928)\n",
      "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0594) | Acc: (98.27%) (45410/46208)\n",
      "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0593) | Acc: (98.29%) (46674/47488)\n",
      "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0595) | Acc: (98.27%) (47924/48768)\n",
      "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0596) | Acc: (98.27%) (49135/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3945) | Acc: (89.52%) (8952/10000)\n",
      "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0654) | Acc: (98.44%) (126/128)\n",
      "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0658) | Acc: (98.01%) (1380/1408)\n",
      "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0579) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0568) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0571) | Acc: (98.48%) (5168/5248)\n",
      "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0578) | Acc: (98.41%) (6424/6528)\n",
      "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0598) | Acc: (98.37%) (7681/7808)\n",
      "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0594) | Acc: (98.33%) (8936/9088)\n",
      "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0595) | Acc: (98.28%) (10190/10368)\n",
      "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0585) | Acc: (98.33%) (11454/11648)\n",
      "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0596) | Acc: (98.29%) (12707/12928)\n",
      "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0588) | Acc: (98.34%) (13972/14208)\n",
      "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0587) | Acc: (98.33%) (15229/15488)\n",
      "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0581) | Acc: (98.38%) (16497/16768)\n",
      "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0585) | Acc: (98.35%) (17750/18048)\n",
      "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0585) | Acc: (98.37%) (19012/19328)\n",
      "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0582) | Acc: (98.38%) (20274/20608)\n",
      "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0590) | Acc: (98.33%) (21522/21888)\n",
      "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0589) | Acc: (98.32%) (22778/23168)\n",
      "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0586) | Acc: (98.32%) (24037/24448)\n",
      "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0588) | Acc: (98.31%) (25293/25728)\n",
      "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0591) | Acc: (98.29%) (26547/27008)\n",
      "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0591) | Acc: (98.31%) (27809/28288)\n",
      "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0593) | Acc: (98.31%) (29069/29568)\n",
      "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0594) | Acc: (98.31%) (30328/30848)\n",
      "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0598) | Acc: (98.29%) (31578/32128)\n",
      "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0601) | Acc: (98.28%) (32834/33408)\n",
      "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0599) | Acc: (98.30%) (34097/34688)\n",
      "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0601) | Acc: (98.29%) (35352/35968)\n",
      "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0604) | Acc: (98.26%) (36599/37248)\n",
      "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0604) | Acc: (98.25%) (37855/38528)\n",
      "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0606) | Acc: (98.24%) (39109/39808)\n",
      "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0607) | Acc: (98.24%) (40364/41088)\n",
      "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0609) | Acc: (98.23%) (41618/42368)\n",
      "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0612) | Acc: (98.23%) (42874/43648)\n",
      "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0613) | Acc: (98.22%) (44128/44928)\n",
      "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0613) | Acc: (98.21%) (45381/46208)\n",
      "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0613) | Acc: (98.21%) (46638/47488)\n",
      "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0613) | Acc: (98.21%) (47894/48768)\n",
      "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0613) | Acc: (98.21%) (49106/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3940) | Acc: (89.32%) (8932/10000)\n",
      "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0369) | Acc: (99.22%) (127/128)\n",
      "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0535) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0537) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0582) | Acc: (98.24%) (3898/3968)\n",
      "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0555) | Acc: (98.38%) (5163/5248)\n",
      "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0578) | Acc: (98.22%) (6412/6528)\n",
      "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0569) | Acc: (98.32%) (7677/7808)\n",
      "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0555) | Acc: (98.39%) (8942/9088)\n",
      "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0555) | Acc: (98.40%) (10202/10368)\n",
      "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0558) | Acc: (98.37%) (11458/11648)\n",
      "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0561) | Acc: (98.38%) (12718/12928)\n",
      "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0565) | Acc: (98.32%) (13969/14208)\n",
      "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0565) | Acc: (98.31%) (15226/15488)\n",
      "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0572) | Acc: (98.30%) (16483/16768)\n",
      "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0576) | Acc: (98.32%) (17744/18048)\n",
      "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0567) | Acc: (98.38%) (19015/19328)\n",
      "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0573) | Acc: (98.35%) (20268/20608)\n",
      "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0575) | Acc: (98.35%) (21526/21888)\n",
      "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0576) | Acc: (98.36%) (22787/23168)\n",
      "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0580) | Acc: (98.34%) (24043/24448)\n",
      "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0576) | Acc: (98.36%) (25307/25728)\n",
      "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0580) | Acc: (98.36%) (26564/27008)\n",
      "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0579) | Acc: (98.34%) (27818/28288)\n",
      "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0578) | Acc: (98.35%) (29079/29568)\n",
      "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0578) | Acc: (98.36%) (30341/30848)\n",
      "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0576) | Acc: (98.36%) (31601/32128)\n",
      "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0575) | Acc: (98.37%) (32863/33408)\n",
      "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0575) | Acc: (98.36%) (34120/34688)\n",
      "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0576) | Acc: (98.36%) (35377/35968)\n",
      "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0579) | Acc: (98.34%) (36628/37248)\n",
      "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0583) | Acc: (98.32%) (37880/38528)\n",
      "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0581) | Acc: (98.32%) (39140/39808)\n",
      "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0584) | Acc: (98.32%) (40397/41088)\n",
      "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0581) | Acc: (98.34%) (41663/42368)\n",
      "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0579) | Acc: (98.34%) (42925/43648)\n",
      "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0579) | Acc: (98.34%) (44184/44928)\n",
      "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0578) | Acc: (98.34%) (45442/46208)\n",
      "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0583) | Acc: (98.33%) (46693/47488)\n",
      "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0582) | Acc: (98.33%) (47956/48768)\n",
      "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0586) | Acc: (98.32%) (49160/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3932) | Acc: (89.58%) (8958/10000)\n",
      "Epoch: 112 | Batch_idx: 0 |  Loss: (0.1024) | Acc: (96.88%) (124/128)\n",
      "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0590) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0602) | Acc: (98.14%) (2638/2688)\n",
      "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0583) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0574) | Acc: (98.36%) (5162/5248)\n",
      "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0566) | Acc: (98.36%) (6421/6528)\n",
      "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0563) | Acc: (98.39%) (7682/7808)\n",
      "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0573) | Acc: (98.35%) (8938/9088)\n",
      "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0562) | Acc: (98.37%) (10199/10368)\n",
      "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0561) | Acc: (98.35%) (11456/11648)\n",
      "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0571) | Acc: (98.30%) (12708/12928)\n",
      "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0580) | Acc: (98.25%) (13959/14208)\n",
      "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0589) | Acc: (98.22%) (15212/15488)\n",
      "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0578) | Acc: (98.27%) (16478/16768)\n",
      "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0584) | Acc: (98.24%) (17730/18048)\n",
      "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0584) | Acc: (98.25%) (18989/19328)\n",
      "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0584) | Acc: (98.27%) (20252/20608)\n",
      "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0586) | Acc: (98.25%) (21506/21888)\n",
      "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0586) | Acc: (98.26%) (22766/23168)\n",
      "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0586) | Acc: (98.26%) (24022/24448)\n",
      "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0583) | Acc: (98.27%) (25283/25728)\n",
      "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0583) | Acc: (98.27%) (26541/27008)\n",
      "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0581) | Acc: (98.27%) (27798/28288)\n",
      "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0582) | Acc: (98.27%) (29056/29568)\n",
      "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0582) | Acc: (98.27%) (30315/30848)\n",
      "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0582) | Acc: (98.28%) (31574/32128)\n",
      "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0582) | Acc: (98.28%) (32834/33408)\n",
      "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0583) | Acc: (98.28%) (34092/34688)\n",
      "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0582) | Acc: (98.28%) (35351/35968)\n",
      "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0585) | Acc: (98.26%) (36601/37248)\n",
      "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0583) | Acc: (98.27%) (37863/38528)\n",
      "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0582) | Acc: (98.28%) (39124/39808)\n",
      "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0586) | Acc: (98.26%) (40374/41088)\n",
      "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0587) | Acc: (98.25%) (41628/42368)\n",
      "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0586) | Acc: (98.26%) (42890/43648)\n",
      "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0586) | Acc: (98.25%) (44144/44928)\n",
      "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0587) | Acc: (98.25%) (45398/46208)\n",
      "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0585) | Acc: (98.25%) (46657/47488)\n",
      "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0586) | Acc: (98.25%) (47913/48768)\n",
      "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0587) | Acc: (98.25%) (49123/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3949) | Acc: (89.55%) (8955/10000)\n",
      "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0383) | Acc: (99.22%) (127/128)\n",
      "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0525) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0563) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0599) | Acc: (98.16%) (3895/3968)\n",
      "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0588) | Acc: (98.23%) (5155/5248)\n",
      "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0564) | Acc: (98.30%) (6417/6528)\n",
      "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0588) | Acc: (98.25%) (7671/7808)\n",
      "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0612) | Acc: (98.05%) (8911/9088)\n",
      "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0613) | Acc: (98.11%) (10172/10368)\n",
      "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0616) | Acc: (98.09%) (11426/11648)\n",
      "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0621) | Acc: (98.10%) (12682/12928)\n",
      "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0616) | Acc: (98.14%) (13944/14208)\n",
      "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0617) | Acc: (98.10%) (15193/15488)\n",
      "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0625) | Acc: (98.05%) (16441/16768)\n",
      "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0617) | Acc: (98.07%) (17699/18048)\n",
      "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0612) | Acc: (98.11%) (18963/19328)\n",
      "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0608) | Acc: (98.13%) (20223/20608)\n",
      "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0606) | Acc: (98.15%) (21484/21888)\n",
      "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0605) | Acc: (98.18%) (22746/23168)\n",
      "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0604) | Acc: (98.18%) (24004/24448)\n",
      "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0601) | Acc: (98.20%) (25264/25728)\n",
      "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0602) | Acc: (98.21%) (26524/27008)\n",
      "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0602) | Acc: (98.18%) (27774/28288)\n",
      "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0600) | Acc: (98.18%) (29031/29568)\n",
      "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0598) | Acc: (98.21%) (30296/30848)\n",
      "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0599) | Acc: (98.21%) (31554/32128)\n",
      "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0597) | Acc: (98.22%) (32815/33408)\n",
      "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0597) | Acc: (98.22%) (34071/34688)\n",
      "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0597) | Acc: (98.22%) (35327/35968)\n",
      "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0594) | Acc: (98.22%) (36585/37248)\n",
      "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0598) | Acc: (98.21%) (37838/38528)\n",
      "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0597) | Acc: (98.22%) (39098/39808)\n",
      "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0596) | Acc: (98.22%) (40355/41088)\n",
      "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0598) | Acc: (98.20%) (41606/42368)\n",
      "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0598) | Acc: (98.19%) (42856/43648)\n",
      "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0599) | Acc: (98.19%) (44113/44928)\n",
      "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0599) | Acc: (98.19%) (45373/46208)\n",
      "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0598) | Acc: (98.19%) (46629/47488)\n",
      "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0598) | Acc: (98.20%) (47889/48768)\n",
      "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0598) | Acc: (98.19%) (49097/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3903) | Acc: (89.36%) (8936/10000)\n",
      "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0304) | Acc: (99.22%) (127/128)\n",
      "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0498) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0555) | Acc: (98.10%) (2637/2688)\n",
      "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0582) | Acc: (98.08%) (3892/3968)\n",
      "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0607) | Acc: (97.98%) (5142/5248)\n",
      "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0600) | Acc: (98.01%) (6398/6528)\n",
      "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0592) | Acc: (98.05%) (7656/7808)\n",
      "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0590) | Acc: (98.11%) (8916/9088)\n",
      "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0595) | Acc: (98.12%) (10173/10368)\n",
      "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0589) | Acc: (98.19%) (11437/11648)\n",
      "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0592) | Acc: (98.21%) (12696/12928)\n",
      "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0584) | Acc: (98.25%) (13959/14208)\n",
      "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0579) | Acc: (98.26%) (15219/15488)\n",
      "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0575) | Acc: (98.28%) (16479/16768)\n",
      "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0582) | Acc: (98.22%) (17727/18048)\n",
      "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0580) | Acc: (98.24%) (18987/19328)\n",
      "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0576) | Acc: (98.25%) (20247/20608)\n",
      "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0575) | Acc: (98.26%) (21507/21888)\n",
      "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0575) | Acc: (98.25%) (22763/23168)\n",
      "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0576) | Acc: (98.25%) (24020/24448)\n",
      "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0581) | Acc: (98.22%) (25271/25728)\n",
      "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0580) | Acc: (98.22%) (26527/27008)\n",
      "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0579) | Acc: (98.24%) (27789/28288)\n",
      "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0577) | Acc: (98.25%) (29051/29568)\n",
      "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0577) | Acc: (98.26%) (30310/30848)\n",
      "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0579) | Acc: (98.25%) (31565/32128)\n",
      "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0584) | Acc: (98.24%) (32820/33408)\n",
      "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0585) | Acc: (98.23%) (34074/34688)\n",
      "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0588) | Acc: (98.23%) (35331/35968)\n",
      "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0587) | Acc: (98.24%) (36591/37248)\n",
      "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0585) | Acc: (98.25%) (37853/38528)\n",
      "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0589) | Acc: (98.24%) (39109/39808)\n",
      "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0592) | Acc: (98.24%) (40363/41088)\n",
      "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0590) | Acc: (98.25%) (41628/42368)\n",
      "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0588) | Acc: (98.26%) (42890/43648)\n",
      "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0586) | Acc: (98.27%) (44151/44928)\n",
      "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0588) | Acc: (98.28%) (45411/46208)\n",
      "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0590) | Acc: (98.27%) (46666/47488)\n",
      "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0592) | Acc: (98.27%) (47925/48768)\n",
      "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0593) | Acc: (98.27%) (49133/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3940) | Acc: (89.54%) (8954/10000)\n",
      "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0318) | Acc: (99.22%) (127/128)\n",
      "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0527) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0551) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0587) | Acc: (98.21%) (3897/3968)\n",
      "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0588) | Acc: (98.23%) (5155/5248)\n",
      "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0614) | Acc: (98.09%) (6403/6528)\n",
      "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0598) | Acc: (98.21%) (7668/7808)\n",
      "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0599) | Acc: (98.20%) (8924/9088)\n",
      "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0595) | Acc: (98.23%) (10184/10368)\n",
      "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0582) | Acc: (98.28%) (11448/11648)\n",
      "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0576) | Acc: (98.32%) (12711/12928)\n",
      "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0585) | Acc: (98.31%) (13968/14208)\n",
      "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0574) | Acc: (98.33%) (15229/15488)\n",
      "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0586) | Acc: (98.28%) (16479/16768)\n",
      "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0587) | Acc: (98.23%) (17728/18048)\n",
      "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0582) | Acc: (98.27%) (18993/19328)\n",
      "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0585) | Acc: (98.25%) (20248/20608)\n",
      "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0584) | Acc: (98.25%) (21506/21888)\n",
      "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0582) | Acc: (98.26%) (22766/23168)\n",
      "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0580) | Acc: (98.28%) (24028/24448)\n",
      "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0577) | Acc: (98.31%) (25292/25728)\n",
      "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0577) | Acc: (98.30%) (26548/27008)\n",
      "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0579) | Acc: (98.27%) (27799/28288)\n",
      "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0578) | Acc: (98.29%) (29062/29568)\n",
      "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0577) | Acc: (98.30%) (30324/30848)\n",
      "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0581) | Acc: (98.29%) (31579/32128)\n",
      "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0583) | Acc: (98.28%) (32833/33408)\n",
      "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0582) | Acc: (98.27%) (34089/34688)\n",
      "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0584) | Acc: (98.27%) (35344/35968)\n",
      "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0581) | Acc: (98.27%) (36605/37248)\n",
      "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0581) | Acc: (98.27%) (37861/38528)\n",
      "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0580) | Acc: (98.27%) (39118/39808)\n",
      "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0578) | Acc: (98.28%) (40380/41088)\n",
      "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0579) | Acc: (98.28%) (41640/42368)\n",
      "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0579) | Acc: (98.28%) (42899/43648)\n",
      "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0579) | Acc: (98.29%) (44159/44928)\n",
      "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0581) | Acc: (98.28%) (45414/46208)\n",
      "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0579) | Acc: (98.29%) (46675/47488)\n",
      "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0579) | Acc: (98.28%) (47930/48768)\n",
      "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0580) | Acc: (98.27%) (49134/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3924) | Acc: (89.51%) (8951/10000)\n",
      "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0678) | Acc: (98.44%) (126/128)\n",
      "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0543) | Acc: (98.58%) (1388/1408)\n",
      "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0544) | Acc: (98.51%) (2648/2688)\n",
      "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0559) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0537) | Acc: (98.57%) (5173/5248)\n",
      "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0556) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0554) | Acc: (98.44%) (7686/7808)\n",
      "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0547) | Acc: (98.49%) (8951/9088)\n",
      "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0542) | Acc: (98.52%) (10215/10368)\n",
      "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0541) | Acc: (98.45%) (11468/11648)\n",
      "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0553) | Acc: (98.38%) (12719/12928)\n",
      "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0551) | Acc: (98.40%) (13980/14208)\n",
      "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0564) | Acc: (98.31%) (15227/15488)\n",
      "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0572) | Acc: (98.26%) (16476/16768)\n",
      "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0576) | Acc: (98.27%) (17736/18048)\n",
      "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0581) | Acc: (98.22%) (18984/19328)\n",
      "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0581) | Acc: (98.22%) (20242/20608)\n",
      "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0587) | Acc: (98.21%) (21497/21888)\n",
      "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0585) | Acc: (98.23%) (22757/23168)\n",
      "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0579) | Acc: (98.27%) (24024/24448)\n",
      "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0581) | Acc: (98.25%) (25279/25728)\n",
      "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0579) | Acc: (98.27%) (26540/27008)\n",
      "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0579) | Acc: (98.29%) (27803/28288)\n",
      "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0577) | Acc: (98.27%) (29057/29568)\n",
      "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0578) | Acc: (98.25%) (30307/30848)\n",
      "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0579) | Acc: (98.24%) (31563/32128)\n",
      "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0576) | Acc: (98.28%) (32833/33408)\n",
      "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0572) | Acc: (98.30%) (34100/34688)\n",
      "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0572) | Acc: (98.32%) (35362/35968)\n",
      "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0574) | Acc: (98.31%) (36620/37248)\n",
      "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0575) | Acc: (98.32%) (37882/38528)\n",
      "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0574) | Acc: (98.34%) (39147/39808)\n",
      "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0573) | Acc: (98.34%) (40405/41088)\n",
      "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0571) | Acc: (98.34%) (41663/42368)\n",
      "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0573) | Acc: (98.32%) (42916/43648)\n",
      "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0576) | Acc: (98.32%) (44173/44928)\n",
      "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0574) | Acc: (98.33%) (45435/46208)\n",
      "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0575) | Acc: (98.33%) (46696/47488)\n",
      "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0577) | Acc: (98.32%) (47950/48768)\n",
      "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0577) | Acc: (98.33%) (49163/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3937) | Acc: (89.52%) (8952/10000)\n",
      "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0670) | Acc: (97.66%) (125/128)\n",
      "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0497) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0570) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0574) | Acc: (98.39%) (3904/3968)\n",
      "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0579) | Acc: (98.32%) (5160/5248)\n",
      "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0595) | Acc: (98.24%) (6413/6528)\n",
      "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0602) | Acc: (98.26%) (7672/7808)\n",
      "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0599) | Acc: (98.29%) (8933/9088)\n",
      "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0590) | Acc: (98.32%) (10194/10368)\n",
      "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0585) | Acc: (98.34%) (11455/11648)\n",
      "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0588) | Acc: (98.33%) (12712/12928)\n",
      "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0582) | Acc: (98.35%) (13974/14208)\n",
      "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0580) | Acc: (98.37%) (15235/15488)\n",
      "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0579) | Acc: (98.38%) (16497/16768)\n",
      "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0583) | Acc: (98.37%) (17754/18048)\n",
      "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0582) | Acc: (98.34%) (19007/19328)\n",
      "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0576) | Acc: (98.36%) (20269/20608)\n",
      "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0587) | Acc: (98.30%) (21516/21888)\n",
      "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0583) | Acc: (98.32%) (22778/23168)\n",
      "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0581) | Acc: (98.34%) (24041/24448)\n",
      "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0580) | Acc: (98.34%) (25301/25728)\n",
      "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0579) | Acc: (98.35%) (26563/27008)\n",
      "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0579) | Acc: (98.34%) (27818/28288)\n",
      "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0583) | Acc: (98.31%) (29069/29568)\n",
      "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0582) | Acc: (98.29%) (30321/30848)\n",
      "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0582) | Acc: (98.29%) (31579/32128)\n",
      "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0583) | Acc: (98.29%) (32837/33408)\n",
      "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0582) | Acc: (98.28%) (34093/34688)\n",
      "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0581) | Acc: (98.30%) (35356/35968)\n",
      "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0581) | Acc: (98.30%) (36614/37248)\n",
      "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0583) | Acc: (98.29%) (37871/38528)\n",
      "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0583) | Acc: (98.29%) (39129/39808)\n",
      "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0580) | Acc: (98.31%) (40394/41088)\n",
      "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0581) | Acc: (98.31%) (41654/42368)\n",
      "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0580) | Acc: (98.32%) (42914/43648)\n",
      "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0581) | Acc: (98.32%) (44171/44928)\n",
      "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0581) | Acc: (98.31%) (45429/46208)\n",
      "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0582) | Acc: (98.31%) (46687/47488)\n",
      "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0581) | Acc: (98.32%) (47949/48768)\n",
      "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0583) | Acc: (98.31%) (49153/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3964) | Acc: (89.47%) (8947/10000)\n",
      "Epoch: 118 | Batch_idx: 0 |  Loss: (0.1209) | Acc: (96.88%) (124/128)\n",
      "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0589) | Acc: (98.22%) (1383/1408)\n",
      "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0574) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0617) | Acc: (98.21%) (3897/3968)\n",
      "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0595) | Acc: (98.29%) (5158/5248)\n",
      "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0592) | Acc: (98.25%) (6414/6528)\n",
      "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0587) | Acc: (98.31%) (7676/7808)\n",
      "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0591) | Acc: (98.33%) (8936/9088)\n",
      "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0587) | Acc: (98.32%) (10194/10368)\n",
      "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0594) | Acc: (98.33%) (11454/11648)\n",
      "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0588) | Acc: (98.36%) (12716/12928)\n",
      "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0585) | Acc: (98.37%) (13977/14208)\n",
      "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0584) | Acc: (98.35%) (15233/15488)\n",
      "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0576) | Acc: (98.38%) (16497/16768)\n",
      "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0572) | Acc: (98.35%) (17750/18048)\n",
      "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0563) | Acc: (98.38%) (19015/19328)\n",
      "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0566) | Acc: (98.36%) (20269/20608)\n",
      "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0566) | Acc: (98.36%) (21528/21888)\n",
      "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0563) | Acc: (98.38%) (22792/23168)\n",
      "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0565) | Acc: (98.36%) (24048/24448)\n",
      "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0569) | Acc: (98.34%) (25300/25728)\n",
      "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0569) | Acc: (98.34%) (26561/27008)\n",
      "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0567) | Acc: (98.35%) (27821/28288)\n",
      "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0566) | Acc: (98.33%) (29075/29568)\n",
      "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0573) | Acc: (98.29%) (30322/30848)\n",
      "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0569) | Acc: (98.31%) (31585/32128)\n",
      "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0568) | Acc: (98.30%) (32841/33408)\n",
      "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0568) | Acc: (98.30%) (34097/34688)\n",
      "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0565) | Acc: (98.31%) (35360/35968)\n",
      "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0569) | Acc: (98.29%) (36612/37248)\n",
      "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0569) | Acc: (98.28%) (37867/38528)\n",
      "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0570) | Acc: (98.28%) (39123/39808)\n",
      "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0572) | Acc: (98.27%) (40376/41088)\n",
      "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0573) | Acc: (98.28%) (41638/42368)\n",
      "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0573) | Acc: (98.27%) (42895/43648)\n",
      "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0570) | Acc: (98.30%) (44162/44928)\n",
      "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0570) | Acc: (98.28%) (45415/46208)\n",
      "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0569) | Acc: (98.29%) (46677/47488)\n",
      "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0569) | Acc: (98.29%) (47935/48768)\n",
      "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0571) | Acc: (98.28%) (49142/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3982) | Acc: (89.56%) (8956/10000)\n",
      "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0608) | Acc: (97.66%) (125/128)\n",
      "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0571) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0511) | Acc: (98.55%) (2649/2688)\n",
      "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0513) | Acc: (98.54%) (3910/3968)\n",
      "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0529) | Acc: (98.42%) (5165/5248)\n",
      "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0532) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0544) | Acc: (98.48%) (7689/7808)\n",
      "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0552) | Acc: (98.47%) (8949/9088)\n",
      "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0559) | Acc: (98.39%) (10201/10368)\n",
      "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0567) | Acc: (98.37%) (11458/11648)\n",
      "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0570) | Acc: (98.33%) (12712/12928)\n",
      "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0562) | Acc: (98.40%) (13981/14208)\n",
      "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0566) | Acc: (98.38%) (15237/15488)\n",
      "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0566) | Acc: (98.37%) (16495/16768)\n",
      "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0567) | Acc: (98.37%) (17753/18048)\n",
      "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0563) | Acc: (98.39%) (19016/19328)\n",
      "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0560) | Acc: (98.40%) (20278/20608)\n",
      "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0555) | Acc: (98.41%) (21540/21888)\n",
      "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0557) | Acc: (98.40%) (22798/23168)\n",
      "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0553) | Acc: (98.40%) (24057/24448)\n",
      "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0550) | Acc: (98.41%) (25318/25728)\n",
      "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0549) | Acc: (98.42%) (26580/27008)\n",
      "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0553) | Acc: (98.42%) (27840/28288)\n",
      "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0553) | Acc: (98.42%) (29100/29568)\n",
      "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0554) | Acc: (98.41%) (30358/30848)\n",
      "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0552) | Acc: (98.41%) (31617/32128)\n",
      "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0552) | Acc: (98.42%) (32880/33408)\n",
      "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0552) | Acc: (98.42%) (34140/34688)\n",
      "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0554) | Acc: (98.40%) (35393/35968)\n",
      "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0556) | Acc: (98.39%) (36649/37248)\n",
      "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0556) | Acc: (98.39%) (37909/38528)\n",
      "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0558) | Acc: (98.38%) (39164/39808)\n",
      "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0561) | Acc: (98.37%) (40418/41088)\n",
      "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0563) | Acc: (98.36%) (41672/42368)\n",
      "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0564) | Acc: (98.36%) (42931/43648)\n",
      "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0567) | Acc: (98.34%) (44184/44928)\n",
      "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0566) | Acc: (98.35%) (45446/46208)\n",
      "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0565) | Acc: (98.36%) (46709/47488)\n",
      "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0565) | Acc: (98.36%) (47966/48768)\n",
      "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0564) | Acc: (98.35%) (49177/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3959) | Acc: (89.48%) (8948/10000)\n",
      "Epoch: 120 | Batch_idx: 0 |  Loss: (0.0449) | Acc: (99.22%) (127/128)\n",
      "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0443) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0475) | Acc: (98.66%) (2652/2688)\n",
      "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0483) | Acc: (98.51%) (3909/3968)\n",
      "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0541) | Acc: (98.27%) (5157/5248)\n",
      "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0544) | Acc: (98.24%) (6413/6528)\n",
      "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0558) | Acc: (98.13%) (7662/7808)\n",
      "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0566) | Acc: (98.22%) (8926/9088)\n",
      "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0570) | Acc: (98.17%) (10178/10368)\n",
      "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0557) | Acc: (98.26%) (11445/11648)\n",
      "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0559) | Acc: (98.24%) (12700/12928)\n",
      "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0551) | Acc: (98.28%) (13964/14208)\n",
      "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0553) | Acc: (98.28%) (15221/15488)\n",
      "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0557) | Acc: (98.25%) (16475/16768)\n",
      "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0552) | Acc: (98.30%) (17741/18048)\n",
      "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0560) | Acc: (98.26%) (18991/19328)\n",
      "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0554) | Acc: (98.28%) (20253/20608)\n",
      "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0552) | Acc: (98.30%) (21516/21888)\n",
      "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0554) | Acc: (98.30%) (22775/23168)\n",
      "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0548) | Acc: (98.33%) (24040/24448)\n",
      "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0556) | Acc: (98.31%) (25294/25728)\n",
      "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0556) | Acc: (98.33%) (26556/27008)\n",
      "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0557) | Acc: (98.35%) (27820/28288)\n",
      "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0556) | Acc: (98.35%) (29079/29568)\n",
      "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0555) | Acc: (98.34%) (30335/30848)\n",
      "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0553) | Acc: (98.34%) (31596/32128)\n",
      "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0551) | Acc: (98.35%) (32857/33408)\n",
      "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0550) | Acc: (98.35%) (34117/34688)\n",
      "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0553) | Acc: (98.34%) (35372/35968)\n",
      "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0552) | Acc: (98.35%) (36634/37248)\n",
      "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0550) | Acc: (98.36%) (37898/38528)\n",
      "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0555) | Acc: (98.35%) (39152/39808)\n",
      "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0554) | Acc: (98.35%) (40411/41088)\n",
      "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0556) | Acc: (98.36%) (41672/42368)\n",
      "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0555) | Acc: (98.36%) (42932/43648)\n",
      "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0558) | Acc: (98.34%) (44181/44928)\n",
      "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0556) | Acc: (98.35%) (45446/46208)\n",
      "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0554) | Acc: (98.37%) (46712/47488)\n",
      "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0553) | Acc: (98.38%) (47976/48768)\n",
      "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0556) | Acc: (98.37%) (49186/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3926) | Acc: (89.59%) (8959/10000)\n",
      "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0299) | Acc: (99.22%) (127/128)\n",
      "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0567) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0580) | Acc: (98.03%) (2635/2688)\n",
      "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0609) | Acc: (98.08%) (3892/3968)\n",
      "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0611) | Acc: (98.17%) (5152/5248)\n",
      "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0600) | Acc: (98.21%) (6411/6528)\n",
      "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0575) | Acc: (98.30%) (7675/7808)\n",
      "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0566) | Acc: (98.33%) (8936/9088)\n",
      "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0555) | Acc: (98.39%) (10201/10368)\n",
      "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0559) | Acc: (98.37%) (11458/11648)\n",
      "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0561) | Acc: (98.38%) (12718/12928)\n",
      "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0566) | Acc: (98.32%) (13970/14208)\n",
      "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0568) | Acc: (98.33%) (15229/15488)\n",
      "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0561) | Acc: (98.35%) (16492/16768)\n",
      "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0555) | Acc: (98.40%) (17760/18048)\n",
      "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0556) | Acc: (98.41%) (19020/19328)\n",
      "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0548) | Acc: (98.44%) (20287/20608)\n",
      "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0548) | Acc: (98.43%) (21544/21888)\n",
      "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0548) | Acc: (98.42%) (22801/23168)\n",
      "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0546) | Acc: (98.43%) (24065/24448)\n",
      "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0545) | Acc: (98.46%) (25332/25728)\n",
      "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0543) | Acc: (98.47%) (26594/27008)\n",
      "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0543) | Acc: (98.47%) (27855/28288)\n",
      "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0544) | Acc: (98.45%) (29111/29568)\n",
      "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0541) | Acc: (98.48%) (30378/30848)\n",
      "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0540) | Acc: (98.48%) (31639/32128)\n",
      "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0537) | Acc: (98.49%) (32904/33408)\n",
      "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0537) | Acc: (98.49%) (34164/34688)\n",
      "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0535) | Acc: (98.50%) (35429/35968)\n",
      "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0534) | Acc: (98.52%) (36695/37248)\n",
      "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0534) | Acc: (98.50%) (37952/38528)\n",
      "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0535) | Acc: (98.50%) (39210/39808)\n",
      "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0531) | Acc: (98.51%) (40477/41088)\n",
      "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0530) | Acc: (98.52%) (41741/42368)\n",
      "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0530) | Acc: (98.52%) (43004/43648)\n",
      "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0531) | Acc: (98.52%) (44265/44928)\n",
      "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0529) | Acc: (98.53%) (45528/46208)\n",
      "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0529) | Acc: (98.53%) (46792/47488)\n",
      "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0527) | Acc: (98.53%) (48052/48768)\n",
      "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0528) | Acc: (98.53%) (49267/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3941) | Acc: (89.65%) (8965/10000)\n",
      "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0531) | Acc: (97.66%) (125/128)\n",
      "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0498) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0532) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0561) | Acc: (98.26%) (3899/3968)\n",
      "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0543) | Acc: (98.40%) (5164/5248)\n",
      "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0539) | Acc: (98.42%) (6425/6528)\n",
      "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0519) | Acc: (98.54%) (7694/7808)\n",
      "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0538) | Acc: (98.47%) (8949/9088)\n",
      "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0547) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0546) | Acc: (98.45%) (11467/11648)\n",
      "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0552) | Acc: (98.43%) (12725/12928)\n",
      "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0545) | Acc: (98.44%) (13987/14208)\n",
      "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0542) | Acc: (98.48%) (15252/15488)\n",
      "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0539) | Acc: (98.50%) (16516/16768)\n",
      "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0532) | Acc: (98.52%) (17780/18048)\n",
      "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0529) | Acc: (98.53%) (19043/19328)\n",
      "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0531) | Acc: (98.52%) (20304/20608)\n",
      "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0533) | Acc: (98.52%) (21564/21888)\n",
      "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0532) | Acc: (98.52%) (22826/23168)\n",
      "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0530) | Acc: (98.55%) (24093/24448)\n",
      "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0529) | Acc: (98.56%) (25357/25728)\n",
      "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0531) | Acc: (98.55%) (26617/27008)\n",
      "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0528) | Acc: (98.54%) (27875/28288)\n",
      "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0532) | Acc: (98.51%) (29126/29568)\n",
      "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0531) | Acc: (98.52%) (30391/30848)\n",
      "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0529) | Acc: (98.53%) (31656/32128)\n",
      "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0529) | Acc: (98.52%) (32913/33408)\n",
      "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0528) | Acc: (98.53%) (34177/34688)\n",
      "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0529) | Acc: (98.52%) (35437/35968)\n",
      "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0530) | Acc: (98.53%) (36700/37248)\n",
      "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0532) | Acc: (98.51%) (37954/38528)\n",
      "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0531) | Acc: (98.51%) (39216/39808)\n",
      "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0534) | Acc: (98.51%) (40476/41088)\n",
      "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0533) | Acc: (98.51%) (41738/42368)\n",
      "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0534) | Acc: (98.50%) (42993/43648)\n",
      "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0531) | Acc: (98.52%) (44263/44928)\n",
      "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0532) | Acc: (98.52%) (45522/46208)\n",
      "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0529) | Acc: (98.53%) (46790/47488)\n",
      "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0531) | Acc: (98.52%) (48044/48768)\n",
      "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0533) | Acc: (98.51%) (49255/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3949) | Acc: (89.51%) (8951/10000)\n",
      "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0523) | Acc: (98.44%) (126/128)\n",
      "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0642) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0552) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0537) | Acc: (98.36%) (3903/3968)\n",
      "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0522) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0538) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0535) | Acc: (98.48%) (7689/7808)\n",
      "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0531) | Acc: (98.50%) (8952/9088)\n",
      "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0533) | Acc: (98.52%) (10215/10368)\n",
      "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0520) | Acc: (98.52%) (11476/11648)\n",
      "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0523) | Acc: (98.51%) (12736/12928)\n",
      "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0530) | Acc: (98.54%) (14000/14208)\n",
      "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0528) | Acc: (98.53%) (15261/15488)\n",
      "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0527) | Acc: (98.56%) (16526/16768)\n",
      "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0526) | Acc: (98.58%) (17791/18048)\n",
      "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0525) | Acc: (98.56%) (19049/19328)\n",
      "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0524) | Acc: (98.56%) (20311/20608)\n",
      "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0524) | Acc: (98.53%) (21567/21888)\n",
      "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0523) | Acc: (98.54%) (22830/23168)\n",
      "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0529) | Acc: (98.52%) (24086/24448)\n",
      "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0529) | Acc: (98.54%) (25352/25728)\n",
      "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0531) | Acc: (98.53%) (26612/27008)\n",
      "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0533) | Acc: (98.52%) (27870/28288)\n",
      "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0536) | Acc: (98.50%) (29124/29568)\n",
      "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0537) | Acc: (98.49%) (30382/30848)\n",
      "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0535) | Acc: (98.50%) (31645/32128)\n",
      "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0539) | Acc: (98.48%) (32901/33408)\n",
      "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0538) | Acc: (98.48%) (34162/34688)\n",
      "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0538) | Acc: (98.48%) (35423/35968)\n",
      "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0540) | Acc: (98.48%) (36680/37248)\n",
      "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.48%) (37941/38528)\n",
      "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0539) | Acc: (98.48%) (39201/39808)\n",
      "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.48%) (40464/41088)\n",
      "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0536) | Acc: (98.49%) (41730/42368)\n",
      "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0534) | Acc: (98.51%) (42996/43648)\n",
      "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0533) | Acc: (98.51%) (44257/44928)\n",
      "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0531) | Acc: (98.51%) (45521/46208)\n",
      "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0530) | Acc: (98.51%) (46779/47488)\n",
      "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.51%) (48041/48768)\n",
      "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0530) | Acc: (98.51%) (49257/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3930) | Acc: (89.55%) (8955/10000)\n",
      "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0289) | Acc: (100.00%) (128/128)\n",
      "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0456) | Acc: (99.36%) (1399/1408)\n",
      "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0470) | Acc: (99.11%) (2664/2688)\n",
      "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0468) | Acc: (98.97%) (3927/3968)\n",
      "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0487) | Acc: (98.86%) (5188/5248)\n",
      "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0507) | Acc: (98.73%) (6445/6528)\n",
      "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0509) | Acc: (98.71%) (7707/7808)\n",
      "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0516) | Acc: (98.65%) (8965/9088)\n",
      "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0533) | Acc: (98.53%) (10216/10368)\n",
      "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0532) | Acc: (98.52%) (11476/11648)\n",
      "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0534) | Acc: (98.52%) (12737/12928)\n",
      "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0532) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0528) | Acc: (98.56%) (15265/15488)\n",
      "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0531) | Acc: (98.57%) (16528/16768)\n",
      "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0537) | Acc: (98.54%) (17784/18048)\n",
      "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0534) | Acc: (98.54%) (19046/19328)\n",
      "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0535) | Acc: (98.54%) (20307/20608)\n",
      "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0537) | Acc: (98.52%) (21564/21888)\n",
      "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0538) | Acc: (98.53%) (22827/23168)\n",
      "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0538) | Acc: (98.54%) (24090/24448)\n",
      "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0535) | Acc: (98.52%) (25348/25728)\n",
      "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0534) | Acc: (98.53%) (26611/27008)\n",
      "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0530) | Acc: (98.53%) (27871/28288)\n",
      "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0534) | Acc: (98.52%) (29130/29568)\n",
      "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0534) | Acc: (98.51%) (30389/30848)\n",
      "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0535) | Acc: (98.51%) (31648/32128)\n",
      "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0542) | Acc: (98.46%) (32894/33408)\n",
      "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0538) | Acc: (98.48%) (34160/34688)\n",
      "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0540) | Acc: (98.47%) (35417/35968)\n",
      "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0542) | Acc: (98.46%) (36676/37248)\n",
      "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.47%) (37939/38528)\n",
      "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0543) | Acc: (98.45%) (39192/39808)\n",
      "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0542) | Acc: (98.46%) (40456/41088)\n",
      "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0545) | Acc: (98.45%) (41710/42368)\n",
      "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0545) | Acc: (98.44%) (42968/43648)\n",
      "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0547) | Acc: (98.44%) (44226/44928)\n",
      "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0545) | Acc: (98.44%) (45489/46208)\n",
      "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0544) | Acc: (98.44%) (46749/47488)\n",
      "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0540) | Acc: (98.46%) (48015/48768)\n",
      "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0540) | Acc: (98.46%) (49229/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3917) | Acc: (89.63%) (8963/10000)\n",
      "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0710) | Acc: (97.66%) (125/128)\n",
      "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0572) | Acc: (98.30%) (1384/1408)\n",
      "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0559) | Acc: (98.44%) (2646/2688)\n",
      "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0550) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0544) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0525) | Acc: (98.59%) (6436/6528)\n",
      "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0517) | Acc: (98.62%) (7700/7808)\n",
      "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0508) | Acc: (98.61%) (8962/9088)\n",
      "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0506) | Acc: (98.61%) (10224/10368)\n",
      "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0525) | Acc: (98.51%) (11475/11648)\n",
      "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0538) | Acc: (98.48%) (12731/12928)\n",
      "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0542) | Acc: (98.49%) (13993/14208)\n",
      "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0539) | Acc: (98.50%) (15255/15488)\n",
      "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0523) | Acc: (98.57%) (16528/16768)\n",
      "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0521) | Acc: (98.56%) (17788/18048)\n",
      "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0517) | Acc: (98.58%) (19054/19328)\n",
      "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0517) | Acc: (98.59%) (20317/20608)\n",
      "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0525) | Acc: (98.55%) (21571/21888)\n",
      "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0525) | Acc: (98.54%) (22830/23168)\n",
      "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0527) | Acc: (98.54%) (24092/24448)\n",
      "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0524) | Acc: (98.56%) (25358/25728)\n",
      "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0525) | Acc: (98.56%) (26619/27008)\n",
      "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0527) | Acc: (98.55%) (27878/28288)\n",
      "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0527) | Acc: (98.55%) (29140/29568)\n",
      "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0527) | Acc: (98.55%) (30400/30848)\n",
      "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0525) | Acc: (98.56%) (31666/32128)\n",
      "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0525) | Acc: (98.55%) (32925/33408)\n",
      "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0527) | Acc: (98.56%) (34187/34688)\n",
      "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0532) | Acc: (98.53%) (35441/35968)\n",
      "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0536) | Acc: (98.50%) (36691/37248)\n",
      "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.49%) (37948/38528)\n",
      "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.48%) (39201/39808)\n",
      "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0541) | Acc: (98.48%) (40464/41088)\n",
      "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0540) | Acc: (98.49%) (41727/42368)\n",
      "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0543) | Acc: (98.47%) (42980/43648)\n",
      "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0544) | Acc: (98.48%) (44245/44928)\n",
      "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0541) | Acc: (98.49%) (45512/46208)\n",
      "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0542) | Acc: (98.48%) (46768/47488)\n",
      "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0541) | Acc: (98.49%) (48031/48768)\n",
      "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0540) | Acc: (98.49%) (49247/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3928) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0563) | Acc: (97.66%) (125/128)\n",
      "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0571) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0600) | Acc: (98.18%) (2639/2688)\n",
      "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0604) | Acc: (98.24%) (3898/3968)\n",
      "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0586) | Acc: (98.29%) (5158/5248)\n",
      "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0588) | Acc: (98.18%) (6409/6528)\n",
      "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0572) | Acc: (98.22%) (7669/7808)\n",
      "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0571) | Acc: (98.28%) (8932/9088)\n",
      "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0567) | Acc: (98.28%) (10190/10368)\n",
      "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0568) | Acc: (98.27%) (11446/11648)\n",
      "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0564) | Acc: (98.32%) (12711/12928)\n",
      "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0565) | Acc: (98.29%) (13965/14208)\n",
      "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0565) | Acc: (98.26%) (15219/15488)\n",
      "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0561) | Acc: (98.30%) (16483/16768)\n",
      "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0561) | Acc: (98.32%) (17745/18048)\n",
      "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0557) | Acc: (98.33%) (19005/19328)\n",
      "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0553) | Acc: (98.34%) (20266/20608)\n",
      "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0548) | Acc: (98.36%) (21530/21888)\n",
      "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0545) | Acc: (98.38%) (22792/23168)\n",
      "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0544) | Acc: (98.37%) (24049/24448)\n",
      "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0541) | Acc: (98.37%) (25309/25728)\n",
      "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0543) | Acc: (98.38%) (26571/27008)\n",
      "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0541) | Acc: (98.40%) (27836/28288)\n",
      "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0539) | Acc: (98.42%) (29101/29568)\n",
      "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0540) | Acc: (98.41%) (30359/30848)\n",
      "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0537) | Acc: (98.42%) (31620/32128)\n",
      "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0536) | Acc: (98.43%) (32885/33408)\n",
      "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0534) | Acc: (98.44%) (34147/34688)\n",
      "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0533) | Acc: (98.44%) (35407/35968)\n",
      "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0531) | Acc: (98.45%) (36669/37248)\n",
      "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0532) | Acc: (98.43%) (37924/38528)\n",
      "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0531) | Acc: (98.43%) (39185/39808)\n",
      "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0533) | Acc: (98.42%) (40439/41088)\n",
      "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0535) | Acc: (98.41%) (41693/42368)\n",
      "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0533) | Acc: (98.43%) (42961/43648)\n",
      "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0535) | Acc: (98.43%) (44221/44928)\n",
      "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0536) | Acc: (98.42%) (45477/46208)\n",
      "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0535) | Acc: (98.42%) (46738/47488)\n",
      "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0538) | Acc: (98.42%) (47996/48768)\n",
      "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0537) | Acc: (98.42%) (49212/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3939) | Acc: (89.73%) (8973/10000)\n",
      "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0529) | Acc: (99.22%) (127/128)\n",
      "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0604) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0569) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0539) | Acc: (98.56%) (3911/3968)\n",
      "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0534) | Acc: (98.59%) (5174/5248)\n",
      "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0534) | Acc: (98.59%) (6436/6528)\n",
      "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0543) | Acc: (98.57%) (7696/7808)\n",
      "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0542) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0553) | Acc: (98.45%) (10207/10368)\n",
      "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0559) | Acc: (98.40%) (11462/11648)\n",
      "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0547) | Acc: (98.47%) (12730/12928)\n",
      "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0548) | Acc: (98.47%) (13990/14208)\n",
      "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0538) | Acc: (98.51%) (15257/15488)\n",
      "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0538) | Acc: (98.50%) (16517/16768)\n",
      "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0538) | Acc: (98.50%) (17777/18048)\n",
      "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0532) | Acc: (98.54%) (19045/19328)\n",
      "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0534) | Acc: (98.53%) (20305/20608)\n",
      "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0533) | Acc: (98.55%) (21571/21888)\n",
      "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0538) | Acc: (98.54%) (22830/23168)\n",
      "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0540) | Acc: (98.52%) (24087/24448)\n",
      "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0541) | Acc: (98.51%) (25344/25728)\n",
      "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0540) | Acc: (98.51%) (26606/27008)\n",
      "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0538) | Acc: (98.50%) (27864/28288)\n",
      "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0534) | Acc: (98.53%) (29133/29568)\n",
      "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0536) | Acc: (98.53%) (30395/30848)\n",
      "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0539) | Acc: (98.52%) (31654/32128)\n",
      "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0538) | Acc: (98.53%) (32916/33408)\n",
      "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0537) | Acc: (98.54%) (34183/34688)\n",
      "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0535) | Acc: (98.54%) (35442/35968)\n",
      "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0533) | Acc: (98.53%) (36702/37248)\n",
      "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0534) | Acc: (98.52%) (37959/38528)\n",
      "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0536) | Acc: (98.52%) (39218/39808)\n",
      "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0536) | Acc: (98.52%) (40479/41088)\n",
      "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0533) | Acc: (98.53%) (41746/42368)\n",
      "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0533) | Acc: (98.53%) (43008/43648)\n",
      "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0533) | Acc: (98.53%) (44268/44928)\n",
      "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0532) | Acc: (98.54%) (45533/46208)\n",
      "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0530) | Acc: (98.54%) (46797/47488)\n",
      "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0530) | Acc: (98.55%) (48059/48768)\n",
      "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0529) | Acc: (98.55%) (49275/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3930) | Acc: (89.73%) (8973/10000)\n",
      "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0689) | Acc: (96.88%) (124/128)\n",
      "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0617) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0602) | Acc: (97.92%) (2632/2688)\n",
      "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0577) | Acc: (98.11%) (3893/3968)\n",
      "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0562) | Acc: (98.23%) (5155/5248)\n",
      "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0563) | Acc: (98.25%) (6414/6528)\n",
      "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0550) | Acc: (98.34%) (7678/7808)\n",
      "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0557) | Acc: (98.29%) (8933/9088)\n",
      "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.32%) (10194/10368)\n",
      "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0544) | Acc: (98.35%) (11456/11648)\n",
      "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0539) | Acc: (98.38%) (12718/12928)\n",
      "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0545) | Acc: (98.37%) (13977/14208)\n",
      "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0549) | Acc: (98.39%) (15239/15488)\n",
      "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0555) | Acc: (98.35%) (16492/16768)\n",
      "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0549) | Acc: (98.39%) (17758/18048)\n",
      "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0544) | Acc: (98.42%) (19023/19328)\n",
      "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0544) | Acc: (98.44%) (20286/20608)\n",
      "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0541) | Acc: (98.46%) (21551/21888)\n",
      "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0539) | Acc: (98.47%) (22814/23168)\n",
      "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0536) | Acc: (98.50%) (24081/24448)\n",
      "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0531) | Acc: (98.52%) (25348/25728)\n",
      "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0532) | Acc: (98.51%) (26605/27008)\n",
      "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0534) | Acc: (98.50%) (27864/28288)\n",
      "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0536) | Acc: (98.48%) (29120/29568)\n",
      "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0534) | Acc: (98.51%) (30387/30848)\n",
      "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0534) | Acc: (98.51%) (31650/32128)\n",
      "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0529) | Acc: (98.53%) (32918/33408)\n",
      "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.53%) (34179/34688)\n",
      "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0530) | Acc: (98.53%) (35440/35968)\n",
      "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0534) | Acc: (98.52%) (36698/37248)\n",
      "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0533) | Acc: (98.52%) (37957/38528)\n",
      "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0535) | Acc: (98.52%) (39217/39808)\n",
      "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0533) | Acc: (98.53%) (40482/41088)\n",
      "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0532) | Acc: (98.52%) (41740/42368)\n",
      "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0532) | Acc: (98.53%) (43005/43648)\n",
      "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0531) | Acc: (98.53%) (44269/44928)\n",
      "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0530) | Acc: (98.53%) (45528/46208)\n",
      "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0531) | Acc: (98.52%) (46783/47488)\n",
      "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.52%) (48045/48768)\n",
      "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0532) | Acc: (98.50%) (49251/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3922) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0696) | Acc: (98.44%) (126/128)\n",
      "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0505) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0498) | Acc: (98.74%) (2654/2688)\n",
      "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0547) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0516) | Acc: (98.65%) (5177/5248)\n",
      "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0521) | Acc: (98.71%) (6444/6528)\n",
      "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0523) | Acc: (98.62%) (7700/7808)\n",
      "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0529) | Acc: (98.60%) (8961/9088)\n",
      "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0540) | Acc: (98.57%) (10220/10368)\n",
      "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0545) | Acc: (98.56%) (11480/11648)\n",
      "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0537) | Acc: (98.58%) (12745/12928)\n",
      "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0538) | Acc: (98.58%) (14006/14208)\n",
      "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0544) | Acc: (98.55%) (15264/15488)\n",
      "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0541) | Acc: (98.56%) (16526/16768)\n",
      "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0531) | Acc: (98.59%) (17794/18048)\n",
      "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0535) | Acc: (98.55%) (19048/19328)\n",
      "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0542) | Acc: (98.51%) (20300/20608)\n",
      "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0538) | Acc: (98.53%) (21567/21888)\n",
      "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0537) | Acc: (98.53%) (22827/23168)\n",
      "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0537) | Acc: (98.54%) (24091/24448)\n",
      "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0533) | Acc: (98.56%) (25357/25728)\n",
      "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0532) | Acc: (98.56%) (26618/27008)\n",
      "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0530) | Acc: (98.55%) (27879/28288)\n",
      "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0531) | Acc: (98.55%) (29138/29568)\n",
      "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0528) | Acc: (98.56%) (30405/30848)\n",
      "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0531) | Acc: (98.57%) (31668/32128)\n",
      "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0531) | Acc: (98.57%) (32929/33408)\n",
      "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0528) | Acc: (98.58%) (34195/34688)\n",
      "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0526) | Acc: (98.58%) (35459/35968)\n",
      "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0529) | Acc: (98.58%) (36718/37248)\n",
      "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0528) | Acc: (98.60%) (37987/38528)\n",
      "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0526) | Acc: (98.60%) (39251/39808)\n",
      "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0530) | Acc: (98.59%) (40508/41088)\n",
      "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0526) | Acc: (98.61%) (41779/42368)\n",
      "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0528) | Acc: (98.60%) (43037/43648)\n",
      "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0531) | Acc: (98.59%) (44294/44928)\n",
      "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0536) | Acc: (98.56%) (45544/46208)\n",
      "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0535) | Acc: (98.56%) (46802/47488)\n",
      "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0533) | Acc: (98.55%) (48063/48768)\n",
      "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0536) | Acc: (98.54%) (49269/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3924) | Acc: (89.67%) (8967/10000)\n",
      "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0593) | Acc: (97.66%) (125/128)\n",
      "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0584) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0570) | Acc: (98.07%) (2636/2688)\n",
      "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0544) | Acc: (98.16%) (3895/3968)\n",
      "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0523) | Acc: (98.27%) (5157/5248)\n",
      "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0520) | Acc: (98.30%) (6417/6528)\n",
      "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0503) | Acc: (98.48%) (7689/7808)\n",
      "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0518) | Acc: (98.34%) (8937/9088)\n",
      "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0518) | Acc: (98.36%) (10198/10368)\n",
      "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0515) | Acc: (98.38%) (11459/11648)\n",
      "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0510) | Acc: (98.41%) (12722/12928)\n",
      "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0513) | Acc: (98.42%) (13984/14208)\n",
      "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0508) | Acc: (98.44%) (15247/15488)\n",
      "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0509) | Acc: (98.45%) (16508/16768)\n",
      "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0499) | Acc: (98.50%) (17777/18048)\n",
      "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0502) | Acc: (98.49%) (19037/19328)\n",
      "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0504) | Acc: (98.51%) (20301/20608)\n",
      "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0513) | Acc: (98.47%) (21554/21888)\n",
      "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0509) | Acc: (98.51%) (22823/23168)\n",
      "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0507) | Acc: (98.54%) (24090/24448)\n",
      "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0507) | Acc: (98.55%) (25355/25728)\n",
      "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0509) | Acc: (98.54%) (26613/27008)\n",
      "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0512) | Acc: (98.53%) (27871/28288)\n",
      "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0511) | Acc: (98.54%) (29137/29568)\n",
      "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0516) | Acc: (98.52%) (30391/30848)\n",
      "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0515) | Acc: (98.53%) (31655/32128)\n",
      "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0516) | Acc: (98.53%) (32918/33408)\n",
      "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0516) | Acc: (98.54%) (34180/34688)\n",
      "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0519) | Acc: (98.53%) (35438/35968)\n",
      "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0521) | Acc: (98.53%) (36699/37248)\n",
      "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0520) | Acc: (98.53%) (37963/38528)\n",
      "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0520) | Acc: (98.53%) (39222/39808)\n",
      "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0519) | Acc: (98.53%) (40486/41088)\n",
      "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0518) | Acc: (98.54%) (41750/42368)\n",
      "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0517) | Acc: (98.54%) (43012/43648)\n",
      "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0514) | Acc: (98.55%) (44277/44928)\n",
      "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0520) | Acc: (98.52%) (45526/46208)\n",
      "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0520) | Acc: (98.53%) (46791/47488)\n",
      "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0519) | Acc: (98.53%) (48052/48768)\n",
      "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0519) | Acc: (98.53%) (49266/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3949) | Acc: (89.62%) (8962/10000)\n",
      "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0634) | Acc: (97.66%) (125/128)\n",
      "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0563) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0538) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0557) | Acc: (98.34%) (3902/3968)\n",
      "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0529) | Acc: (98.48%) (5168/5248)\n",
      "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0510) | Acc: (98.58%) (6435/6528)\n",
      "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0531) | Acc: (98.53%) (7693/7808)\n",
      "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0521) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0503) | Acc: (98.64%) (10227/10368)\n",
      "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0512) | Acc: (98.57%) (11482/11648)\n",
      "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0522) | Acc: (98.55%) (12741/12928)\n",
      "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0521) | Acc: (98.57%) (14005/14208)\n",
      "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0526) | Acc: (98.55%) (15263/15488)\n",
      "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0530) | Acc: (98.53%) (16522/16768)\n",
      "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0528) | Acc: (98.58%) (17791/18048)\n",
      "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0523) | Acc: (98.61%) (19059/19328)\n",
      "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0521) | Acc: (98.62%) (20324/20608)\n",
      "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0521) | Acc: (98.61%) (21584/21888)\n",
      "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0519) | Acc: (98.61%) (22847/23168)\n",
      "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0522) | Acc: (98.61%) (24109/24448)\n",
      "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0523) | Acc: (98.62%) (25373/25728)\n",
      "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0521) | Acc: (98.63%) (26639/27008)\n",
      "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0522) | Acc: (98.63%) (27900/28288)\n",
      "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0522) | Acc: (98.63%) (29162/29568)\n",
      "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0522) | Acc: (98.62%) (30421/30848)\n",
      "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0525) | Acc: (98.60%) (31677/32128)\n",
      "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0521) | Acc: (98.61%) (32945/33408)\n",
      "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0518) | Acc: (98.61%) (34206/34688)\n",
      "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0517) | Acc: (98.62%) (35472/35968)\n",
      "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0520) | Acc: (98.60%) (36727/37248)\n",
      "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0519) | Acc: (98.61%) (37991/38528)\n",
      "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0520) | Acc: (98.60%) (39252/39808)\n",
      "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0518) | Acc: (98.61%) (40518/41088)\n",
      "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0522) | Acc: (98.61%) (41777/42368)\n",
      "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0520) | Acc: (98.61%) (43041/43648)\n",
      "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0518) | Acc: (98.62%) (44308/44928)\n",
      "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0518) | Acc: (98.62%) (45572/46208)\n",
      "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0519) | Acc: (98.62%) (46835/47488)\n",
      "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0518) | Acc: (98.63%) (48100/48768)\n",
      "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0521) | Acc: (98.62%) (49312/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3925) | Acc: (89.62%) (8962/10000)\n",
      "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0801) | Acc: (96.88%) (124/128)\n",
      "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0555) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0561) | Acc: (98.55%) (2649/2688)\n",
      "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0547) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0561) | Acc: (98.48%) (5168/5248)\n",
      "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0567) | Acc: (98.48%) (6429/6528)\n",
      "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0557) | Acc: (98.53%) (7693/7808)\n",
      "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0558) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0549) | Acc: (98.50%) (10212/10368)\n",
      "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0549) | Acc: (98.51%) (11474/11648)\n",
      "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0545) | Acc: (98.53%) (12738/12928)\n",
      "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0544) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0538) | Acc: (98.55%) (15263/15488)\n",
      "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0533) | Acc: (98.56%) (16527/16768)\n",
      "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0534) | Acc: (98.56%) (17788/18048)\n",
      "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0528) | Acc: (98.60%) (19058/19328)\n",
      "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0526) | Acc: (98.60%) (20320/20608)\n",
      "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0524) | Acc: (98.62%) (21586/21888)\n",
      "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0526) | Acc: (98.60%) (22844/23168)\n",
      "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0526) | Acc: (98.61%) (24107/24448)\n",
      "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0522) | Acc: (98.63%) (25375/25728)\n",
      "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0525) | Acc: (98.63%) (26637/27008)\n",
      "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0522) | Acc: (98.64%) (27903/28288)\n",
      "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0523) | Acc: (98.63%) (29162/29568)\n",
      "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0528) | Acc: (98.60%) (30417/30848)\n",
      "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0527) | Acc: (98.61%) (31681/32128)\n",
      "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0525) | Acc: (98.63%) (32949/33408)\n",
      "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0520) | Acc: (98.66%) (34222/34688)\n",
      "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0523) | Acc: (98.64%) (35479/35968)\n",
      "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0522) | Acc: (98.65%) (36746/37248)\n",
      "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0528) | Acc: (98.62%) (37996/38528)\n",
      "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0529) | Acc: (98.61%) (39253/39808)\n",
      "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0527) | Acc: (98.61%) (40515/41088)\n",
      "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0527) | Acc: (98.61%) (41778/42368)\n",
      "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0527) | Acc: (98.61%) (43040/43648)\n",
      "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0527) | Acc: (98.60%) (44300/44928)\n",
      "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0526) | Acc: (98.61%) (45564/46208)\n",
      "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0528) | Acc: (98.61%) (46826/47488)\n",
      "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0531) | Acc: (98.59%) (48081/48768)\n",
      "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0529) | Acc: (98.60%) (49298/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3919) | Acc: (89.50%) (8950/10000)\n",
      "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0507) | Acc: (99.22%) (127/128)\n",
      "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0510) | Acc: (98.86%) (1392/1408)\n",
      "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0576) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0615) | Acc: (98.36%) (3903/3968)\n",
      "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0629) | Acc: (98.15%) (5151/5248)\n",
      "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0603) | Acc: (98.24%) (6413/6528)\n",
      "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0597) | Acc: (98.25%) (7671/7808)\n",
      "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0592) | Acc: (98.26%) (8930/9088)\n",
      "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0591) | Acc: (98.27%) (10189/10368)\n",
      "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0583) | Acc: (98.27%) (11446/11648)\n",
      "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0570) | Acc: (98.31%) (12709/12928)\n",
      "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0562) | Acc: (98.36%) (13975/14208)\n",
      "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0570) | Acc: (98.35%) (15232/15488)\n",
      "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0561) | Acc: (98.39%) (16498/16768)\n",
      "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0561) | Acc: (98.39%) (17758/18048)\n",
      "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0559) | Acc: (98.40%) (19019/19328)\n",
      "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0559) | Acc: (98.41%) (20281/20608)\n",
      "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0555) | Acc: (98.44%) (21547/21888)\n",
      "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0552) | Acc: (98.45%) (22809/23168)\n",
      "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0551) | Acc: (98.45%) (24070/24448)\n",
      "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0554) | Acc: (98.45%) (25329/25728)\n",
      "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0549) | Acc: (98.46%) (26591/27008)\n",
      "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0549) | Acc: (98.46%) (27852/28288)\n",
      "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0550) | Acc: (98.45%) (29111/29568)\n",
      "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0547) | Acc: (98.48%) (30379/30848)\n",
      "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0544) | Acc: (98.50%) (31645/32128)\n",
      "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0539) | Acc: (98.51%) (32909/33408)\n",
      "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0539) | Acc: (98.50%) (34166/34688)\n",
      "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0540) | Acc: (98.49%) (35424/35968)\n",
      "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0543) | Acc: (98.49%) (36684/37248)\n",
      "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0539) | Acc: (98.51%) (37953/38528)\n",
      "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0535) | Acc: (98.53%) (39223/39808)\n",
      "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0533) | Acc: (98.53%) (40486/41088)\n",
      "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0534) | Acc: (98.52%) (41741/42368)\n",
      "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0533) | Acc: (98.53%) (43005/43648)\n",
      "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0533) | Acc: (98.52%) (44264/44928)\n",
      "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0531) | Acc: (98.53%) (45530/46208)\n",
      "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0532) | Acc: (98.53%) (46790/47488)\n",
      "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0533) | Acc: (98.53%) (48049/48768)\n",
      "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0531) | Acc: (98.54%) (49270/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3923) | Acc: (89.59%) (8959/10000)\n",
      "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0234) | Acc: (99.22%) (127/128)\n",
      "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0510) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0516) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0539) | Acc: (98.36%) (3903/3968)\n",
      "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0544) | Acc: (98.36%) (5162/5248)\n",
      "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0534) | Acc: (98.39%) (6423/6528)\n",
      "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0546) | Acc: (98.37%) (7681/7808)\n",
      "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0543) | Acc: (98.37%) (8940/9088)\n",
      "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0532) | Acc: (98.42%) (10204/10368)\n",
      "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0529) | Acc: (98.47%) (11470/11648)\n",
      "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0533) | Acc: (98.42%) (12724/12928)\n",
      "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0528) | Acc: (98.47%) (13990/14208)\n",
      "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0523) | Acc: (98.49%) (15254/15488)\n",
      "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0529) | Acc: (98.47%) (16511/16768)\n",
      "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0530) | Acc: (98.47%) (17771/18048)\n",
      "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0530) | Acc: (98.45%) (19028/19328)\n",
      "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0526) | Acc: (98.47%) (20292/20608)\n",
      "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0525) | Acc: (98.48%) (21556/21888)\n",
      "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0528) | Acc: (98.47%) (22814/23168)\n",
      "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0531) | Acc: (98.48%) (24077/24448)\n",
      "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0532) | Acc: (98.47%) (25335/25728)\n",
      "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0530) | Acc: (98.49%) (26599/27008)\n",
      "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0531) | Acc: (98.48%) (27858/28288)\n",
      "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0532) | Acc: (98.48%) (29118/29568)\n",
      "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0533) | Acc: (98.48%) (30379/30848)\n",
      "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0536) | Acc: (98.47%) (31638/32128)\n",
      "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0538) | Acc: (98.46%) (32893/33408)\n",
      "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0537) | Acc: (98.47%) (34156/34688)\n",
      "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0535) | Acc: (98.47%) (35416/35968)\n",
      "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0533) | Acc: (98.48%) (36683/37248)\n",
      "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0531) | Acc: (98.50%) (37949/38528)\n",
      "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0528) | Acc: (98.50%) (39212/39808)\n",
      "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0525) | Acc: (98.52%) (40478/41088)\n",
      "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0523) | Acc: (98.52%) (41743/42368)\n",
      "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0522) | Acc: (98.54%) (43010/43648)\n",
      "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0523) | Acc: (98.53%) (44268/44928)\n",
      "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0520) | Acc: (98.53%) (45531/46208)\n",
      "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0518) | Acc: (98.55%) (46799/47488)\n",
      "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0517) | Acc: (98.56%) (48066/48768)\n",
      "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0515) | Acc: (98.57%) (49286/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3926) | Acc: (89.66%) (8966/10000)\n",
      "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0848) | Acc: (97.66%) (125/128)\n",
      "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0585) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0541) | Acc: (98.51%) (2648/2688)\n",
      "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0503) | Acc: (98.74%) (3918/3968)\n",
      "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0490) | Acc: (98.74%) (5182/5248)\n",
      "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0507) | Acc: (98.70%) (6443/6528)\n",
      "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0504) | Acc: (98.68%) (7705/7808)\n",
      "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0509) | Acc: (98.64%) (8964/9088)\n",
      "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0506) | Acc: (98.63%) (10226/10368)\n",
      "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0507) | Acc: (98.63%) (11489/11648)\n",
      "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0518) | Acc: (98.62%) (12749/12928)\n",
      "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0523) | Acc: (98.59%) (14007/14208)\n",
      "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0521) | Acc: (98.59%) (15269/15488)\n",
      "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0518) | Acc: (98.59%) (16531/16768)\n",
      "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0519) | Acc: (98.59%) (17793/18048)\n",
      "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0516) | Acc: (98.60%) (19058/19328)\n",
      "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0517) | Acc: (98.59%) (20317/20608)\n",
      "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0518) | Acc: (98.59%) (21579/21888)\n",
      "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0521) | Acc: (98.59%) (22841/23168)\n",
      "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0518) | Acc: (98.59%) (24104/24448)\n",
      "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0524) | Acc: (98.56%) (25357/25728)\n",
      "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0517) | Acc: (98.59%) (26627/27008)\n",
      "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0518) | Acc: (98.58%) (27885/28288)\n",
      "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0520) | Acc: (98.57%) (29144/29568)\n",
      "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0524) | Acc: (98.53%) (30395/30848)\n",
      "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0522) | Acc: (98.53%) (31657/32128)\n",
      "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0520) | Acc: (98.55%) (32922/33408)\n",
      "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0517) | Acc: (98.56%) (34188/34688)\n",
      "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0519) | Acc: (98.56%) (35451/35968)\n",
      "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0520) | Acc: (98.55%) (36709/37248)\n",
      "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0518) | Acc: (98.56%) (37974/38528)\n",
      "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0520) | Acc: (98.56%) (39234/39808)\n",
      "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0519) | Acc: (98.56%) (40496/41088)\n",
      "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0517) | Acc: (98.57%) (41761/42368)\n",
      "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0519) | Acc: (98.56%) (43018/43648)\n",
      "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0518) | Acc: (98.56%) (44281/44928)\n",
      "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0516) | Acc: (98.57%) (45548/46208)\n",
      "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0518) | Acc: (98.57%) (46809/47488)\n",
      "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0518) | Acc: (98.56%) (48067/48768)\n",
      "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0519) | Acc: (98.56%) (49280/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3965) | Acc: (89.71%) (8971/10000)\n",
      "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0178) | Acc: (100.00%) (128/128)\n",
      "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0539) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0507) | Acc: (98.62%) (2651/2688)\n",
      "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0501) | Acc: (98.59%) (3912/3968)\n",
      "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0520) | Acc: (98.53%) (5171/5248)\n",
      "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0525) | Acc: (98.59%) (6436/6528)\n",
      "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0503) | Acc: (98.64%) (7702/7808)\n",
      "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0509) | Acc: (98.62%) (8963/9088)\n",
      "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0516) | Acc: (98.58%) (10221/10368)\n",
      "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0511) | Acc: (98.63%) (11488/11648)\n",
      "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0503) | Acc: (98.63%) (12751/12928)\n",
      "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0500) | Acc: (98.67%) (14019/14208)\n",
      "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0497) | Acc: (98.68%) (15284/15488)\n",
      "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0499) | Acc: (98.66%) (16544/16768)\n",
      "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0503) | Acc: (98.66%) (17807/18048)\n",
      "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0501) | Acc: (98.69%) (19075/19328)\n",
      "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0502) | Acc: (98.68%) (20335/20608)\n",
      "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0497) | Acc: (98.70%) (21604/21888)\n",
      "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0500) | Acc: (98.70%) (22866/23168)\n",
      "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0508) | Acc: (98.66%) (24120/24448)\n",
      "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0513) | Acc: (98.64%) (25378/25728)\n",
      "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0520) | Acc: (98.60%) (26631/27008)\n",
      "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0520) | Acc: (98.58%) (27887/28288)\n",
      "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0525) | Acc: (98.57%) (29144/29568)\n",
      "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0524) | Acc: (98.58%) (30409/30848)\n",
      "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0524) | Acc: (98.57%) (31668/32128)\n",
      "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0521) | Acc: (98.59%) (32937/33408)\n",
      "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0519) | Acc: (98.59%) (34200/34688)\n",
      "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0518) | Acc: (98.60%) (35464/35968)\n",
      "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0518) | Acc: (98.59%) (36722/37248)\n",
      "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0517) | Acc: (98.59%) (37983/38528)\n",
      "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0515) | Acc: (98.60%) (39249/39808)\n",
      "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0516) | Acc: (98.60%) (40512/41088)\n",
      "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0517) | Acc: (98.60%) (41776/42368)\n",
      "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0518) | Acc: (98.59%) (43034/43648)\n",
      "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0519) | Acc: (98.60%) (44298/44928)\n",
      "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0520) | Acc: (98.59%) (45556/46208)\n",
      "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0519) | Acc: (98.59%) (46819/47488)\n",
      "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0520) | Acc: (98.58%) (48077/48768)\n",
      "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0520) | Acc: (98.59%) (49294/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3926) | Acc: (89.64%) (8964/10000)\n",
      "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0404) | Acc: (99.22%) (127/128)\n",
      "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0481) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0496) | Acc: (98.59%) (2650/2688)\n",
      "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0536) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0524) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0535) | Acc: (98.47%) (6428/6528)\n",
      "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0551) | Acc: (98.40%) (7683/7808)\n",
      "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0552) | Acc: (98.40%) (8943/9088)\n",
      "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0544) | Acc: (98.46%) (10208/10368)\n",
      "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0547) | Acc: (98.45%) (11467/11648)\n",
      "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0546) | Acc: (98.45%) (12727/12928)\n",
      "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0553) | Acc: (98.43%) (13985/14208)\n",
      "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0554) | Acc: (98.45%) (15248/15488)\n",
      "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0557) | Acc: (98.46%) (16509/16768)\n",
      "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0559) | Acc: (98.45%) (17769/18048)\n",
      "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0554) | Acc: (98.47%) (19033/19328)\n",
      "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0548) | Acc: (98.49%) (20296/20608)\n",
      "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0541) | Acc: (98.52%) (21563/21888)\n",
      "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0543) | Acc: (98.51%) (22822/23168)\n",
      "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0538) | Acc: (98.52%) (24086/24448)\n",
      "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0537) | Acc: (98.52%) (25348/25728)\n",
      "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0535) | Acc: (98.52%) (26607/27008)\n",
      "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0535) | Acc: (98.51%) (27867/28288)\n",
      "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0533) | Acc: (98.54%) (29135/29568)\n",
      "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0530) | Acc: (98.54%) (30399/30848)\n",
      "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0528) | Acc: (98.55%) (31662/32128)\n",
      "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0528) | Acc: (98.56%) (32926/33408)\n",
      "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0524) | Acc: (98.57%) (34193/34688)\n",
      "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0524) | Acc: (98.58%) (35456/35968)\n",
      "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0525) | Acc: (98.56%) (36710/37248)\n",
      "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0529) | Acc: (98.54%) (37966/38528)\n",
      "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0531) | Acc: (98.54%) (39227/39808)\n",
      "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0532) | Acc: (98.53%) (40483/41088)\n",
      "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0530) | Acc: (98.54%) (41749/42368)\n",
      "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0531) | Acc: (98.55%) (43013/43648)\n",
      "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0532) | Acc: (98.54%) (44273/44928)\n",
      "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0535) | Acc: (98.53%) (45527/46208)\n",
      "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0534) | Acc: (98.53%) (46788/47488)\n",
      "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0536) | Acc: (98.52%) (48044/48768)\n",
      "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0532) | Acc: (98.53%) (49265/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3933) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0510) | Acc: (98.44%) (126/128)\n",
      "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0596) | Acc: (98.08%) (1381/1408)\n",
      "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0532) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0527) | Acc: (98.44%) (3906/3968)\n",
      "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0548) | Acc: (98.36%) (5162/5248)\n",
      "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0545) | Acc: (98.38%) (6422/6528)\n",
      "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0534) | Acc: (98.44%) (7686/7808)\n",
      "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0535) | Acc: (98.49%) (8951/9088)\n",
      "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0526) | Acc: (98.56%) (10219/10368)\n",
      "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0526) | Acc: (98.56%) (11480/11648)\n",
      "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0526) | Acc: (98.52%) (12737/12928)\n",
      "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0520) | Acc: (98.59%) (14007/14208)\n",
      "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0528) | Acc: (98.55%) (15264/15488)\n",
      "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0525) | Acc: (98.57%) (16529/16768)\n",
      "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0529) | Acc: (98.54%) (17785/18048)\n",
      "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0522) | Acc: (98.57%) (19051/19328)\n",
      "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0528) | Acc: (98.53%) (20305/20608)\n",
      "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0527) | Acc: (98.54%) (21568/21888)\n",
      "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0529) | Acc: (98.53%) (22828/23168)\n",
      "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0529) | Acc: (98.53%) (24088/24448)\n",
      "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0525) | Acc: (98.56%) (25357/25728)\n",
      "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0523) | Acc: (98.56%) (26620/27008)\n",
      "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0525) | Acc: (98.55%) (27879/28288)\n",
      "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0529) | Acc: (98.54%) (29136/29568)\n",
      "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0524) | Acc: (98.56%) (30403/30848)\n",
      "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0521) | Acc: (98.58%) (31673/32128)\n",
      "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0522) | Acc: (98.60%) (32940/33408)\n",
      "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0522) | Acc: (98.61%) (34206/34688)\n",
      "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0520) | Acc: (98.61%) (35469/35968)\n",
      "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0527) | Acc: (98.59%) (36722/37248)\n",
      "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0528) | Acc: (98.58%) (37980/38528)\n",
      "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0531) | Acc: (98.55%) (39232/39808)\n",
      "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0529) | Acc: (98.56%) (40496/41088)\n",
      "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0528) | Acc: (98.57%) (41762/42368)\n",
      "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0526) | Acc: (98.57%) (43025/43648)\n",
      "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0525) | Acc: (98.58%) (44288/44928)\n",
      "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0526) | Acc: (98.57%) (45549/46208)\n",
      "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0526) | Acc: (98.58%) (46813/47488)\n",
      "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0523) | Acc: (98.58%) (48077/48768)\n",
      "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0526) | Acc: (98.57%) (49286/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3919) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0251) | Acc: (100.00%) (128/128)\n",
      "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0478) | Acc: (98.93%) (1393/1408)\n",
      "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0488) | Acc: (98.74%) (2654/2688)\n",
      "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0503) | Acc: (98.56%) (3911/3968)\n",
      "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0488) | Acc: (98.63%) (5176/5248)\n",
      "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0489) | Acc: (98.61%) (6437/6528)\n",
      "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0513) | Acc: (98.55%) (7695/7808)\n",
      "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0513) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0526) | Acc: (98.49%) (10211/10368)\n",
      "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0535) | Acc: (98.44%) (11466/11648)\n",
      "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0532) | Acc: (98.45%) (12728/12928)\n",
      "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0530) | Acc: (98.48%) (13992/14208)\n",
      "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0527) | Acc: (98.50%) (15255/15488)\n",
      "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0532) | Acc: (98.47%) (16511/16768)\n",
      "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0536) | Acc: (98.46%) (17770/18048)\n",
      "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0534) | Acc: (98.47%) (19033/19328)\n",
      "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0528) | Acc: (98.49%) (20296/20608)\n",
      "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0534) | Acc: (98.46%) (21550/21888)\n",
      "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0534) | Acc: (98.46%) (22811/23168)\n",
      "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0538) | Acc: (98.44%) (24066/24448)\n",
      "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0533) | Acc: (98.48%) (25336/25728)\n",
      "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0527) | Acc: (98.50%) (26602/27008)\n",
      "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0525) | Acc: (98.51%) (27867/28288)\n",
      "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0529) | Acc: (98.51%) (29126/29568)\n",
      "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0526) | Acc: (98.52%) (30391/30848)\n",
      "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0529) | Acc: (98.50%) (31647/32128)\n",
      "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0535) | Acc: (98.48%) (32901/33408)\n",
      "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0534) | Acc: (98.49%) (34163/34688)\n",
      "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0537) | Acc: (98.48%) (35421/35968)\n",
      "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0534) | Acc: (98.49%) (36684/37248)\n",
      "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0535) | Acc: (98.48%) (37943/38528)\n",
      "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0533) | Acc: (98.50%) (39210/39808)\n",
      "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0534) | Acc: (98.49%) (40469/41088)\n",
      "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0533) | Acc: (98.50%) (41732/42368)\n",
      "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0535) | Acc: (98.50%) (42993/43648)\n",
      "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0533) | Acc: (98.50%) (44256/44928)\n",
      "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0533) | Acc: (98.50%) (45514/46208)\n",
      "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0531) | Acc: (98.50%) (46776/47488)\n",
      "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.51%) (48040/48768)\n",
      "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0530) | Acc: (98.50%) (49252/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3934) | Acc: (89.61%) (8961/10000)\n",
      "Epoch: 140 | Batch_idx: 0 |  Loss: (0.1095) | Acc: (95.31%) (122/128)\n",
      "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0561) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0572) | Acc: (98.14%) (2638/2688)\n",
      "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0546) | Acc: (98.36%) (3903/3968)\n",
      "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0533) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0523) | Acc: (98.54%) (6433/6528)\n",
      "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0524) | Acc: (98.57%) (7696/7808)\n",
      "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0526) | Acc: (98.64%) (8964/9088)\n",
      "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0528) | Acc: (98.59%) (10222/10368)\n",
      "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0537) | Acc: (98.55%) (11479/11648)\n",
      "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0537) | Acc: (98.56%) (12742/12928)\n",
      "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0538) | Acc: (98.54%) (14000/14208)\n",
      "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0534) | Acc: (98.55%) (15264/15488)\n",
      "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0529) | Acc: (98.59%) (16532/16768)\n",
      "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0528) | Acc: (98.58%) (17791/18048)\n",
      "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0526) | Acc: (98.58%) (19053/19328)\n",
      "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0523) | Acc: (98.58%) (20315/20608)\n",
      "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0527) | Acc: (98.56%) (21572/21888)\n",
      "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0530) | Acc: (98.56%) (22835/23168)\n",
      "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0528) | Acc: (98.57%) (24099/24448)\n",
      "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0530) | Acc: (98.56%) (25358/25728)\n",
      "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0530) | Acc: (98.54%) (26615/27008)\n",
      "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0531) | Acc: (98.55%) (27877/28288)\n",
      "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0530) | Acc: (98.55%) (29140/29568)\n",
      "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0531) | Acc: (98.53%) (30396/30848)\n",
      "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0528) | Acc: (98.55%) (31662/32128)\n",
      "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0528) | Acc: (98.55%) (32923/33408)\n",
      "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.54%) (34181/34688)\n",
      "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0528) | Acc: (98.54%) (35444/35968)\n",
      "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0524) | Acc: (98.56%) (36711/37248)\n",
      "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0527) | Acc: (98.55%) (37970/38528)\n",
      "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0523) | Acc: (98.57%) (39237/39808)\n",
      "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0520) | Acc: (98.59%) (40507/41088)\n",
      "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0517) | Acc: (98.60%) (41776/42368)\n",
      "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0518) | Acc: (98.59%) (43031/43648)\n",
      "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0522) | Acc: (98.58%) (44288/44928)\n",
      "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0520) | Acc: (98.59%) (45557/46208)\n",
      "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0519) | Acc: (98.60%) (46821/47488)\n",
      "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0521) | Acc: (98.59%) (48078/48768)\n",
      "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0520) | Acc: (98.59%) (49293/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3956) | Acc: (89.48%) (8948/10000)\n",
      "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0574) | Acc: (98.44%) (126/128)\n",
      "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0537) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0536) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0521) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0532) | Acc: (98.32%) (5160/5248)\n",
      "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0525) | Acc: (98.41%) (6424/6528)\n",
      "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0529) | Acc: (98.41%) (7684/7808)\n",
      "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0542) | Acc: (98.39%) (8942/9088)\n",
      "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0546) | Acc: (98.31%) (10193/10368)\n",
      "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0551) | Acc: (98.30%) (11450/11648)\n",
      "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0559) | Acc: (98.28%) (12705/12928)\n",
      "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0554) | Acc: (98.28%) (13964/14208)\n",
      "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0549) | Acc: (98.31%) (15226/15488)\n",
      "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0553) | Acc: (98.33%) (16488/16768)\n",
      "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0548) | Acc: (98.38%) (17755/18048)\n",
      "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0547) | Acc: (98.40%) (19019/19328)\n",
      "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0546) | Acc: (98.39%) (20277/20608)\n",
      "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0542) | Acc: (98.41%) (21540/21888)\n",
      "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0539) | Acc: (98.44%) (22807/23168)\n",
      "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0537) | Acc: (98.44%) (24067/24448)\n",
      "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0532) | Acc: (98.47%) (25334/25728)\n",
      "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0530) | Acc: (98.47%) (26595/27008)\n",
      "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0531) | Acc: (98.48%) (27859/28288)\n",
      "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0529) | Acc: (98.48%) (29119/29568)\n",
      "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0533) | Acc: (98.47%) (30377/30848)\n",
      "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0532) | Acc: (98.46%) (31634/32128)\n",
      "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0531) | Acc: (98.47%) (32898/33408)\n",
      "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.47%) (34156/34688)\n",
      "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0526) | Acc: (98.47%) (35419/35968)\n",
      "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0530) | Acc: (98.46%) (36675/37248)\n",
      "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0529) | Acc: (98.46%) (37936/38528)\n",
      "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0530) | Acc: (98.46%) (39195/39808)\n",
      "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0531) | Acc: (98.46%) (40455/41088)\n",
      "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0528) | Acc: (98.47%) (41720/42368)\n",
      "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0528) | Acc: (98.47%) (42982/43648)\n",
      "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0526) | Acc: (98.49%) (44249/44928)\n",
      "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0524) | Acc: (98.50%) (45516/46208)\n",
      "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0524) | Acc: (98.50%) (46776/47488)\n",
      "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0525) | Acc: (98.50%) (48036/48768)\n",
      "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0525) | Acc: (98.51%) (49254/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3950) | Acc: (89.55%) (8955/10000)\n",
      "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0283) | Acc: (100.00%) (128/128)\n",
      "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0512) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0512) | Acc: (98.70%) (2653/2688)\n",
      "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0554) | Acc: (98.46%) (3907/3968)\n",
      "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0550) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0591) | Acc: (98.38%) (6422/6528)\n",
      "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0597) | Acc: (98.35%) (7679/7808)\n",
      "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0591) | Acc: (98.34%) (8937/9088)\n",
      "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0583) | Acc: (98.35%) (10197/10368)\n",
      "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0585) | Acc: (98.34%) (11455/11648)\n",
      "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0583) | Acc: (98.36%) (12716/12928)\n",
      "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0588) | Acc: (98.34%) (13972/14208)\n",
      "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0580) | Acc: (98.35%) (15233/15488)\n",
      "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0571) | Acc: (98.38%) (16496/16768)\n",
      "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0563) | Acc: (98.39%) (17757/18048)\n",
      "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0559) | Acc: (98.41%) (19020/19328)\n",
      "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0559) | Acc: (98.40%) (20279/20608)\n",
      "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0557) | Acc: (98.40%) (21537/21888)\n",
      "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0558) | Acc: (98.39%) (22796/23168)\n",
      "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0552) | Acc: (98.43%) (24063/24448)\n",
      "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0550) | Acc: (98.42%) (25322/25728)\n",
      "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0562) | Acc: (98.40%) (26577/27008)\n",
      "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0562) | Acc: (98.41%) (27839/28288)\n",
      "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0558) | Acc: (98.43%) (29104/29568)\n",
      "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0553) | Acc: (98.45%) (30369/30848)\n",
      "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0556) | Acc: (98.43%) (31624/32128)\n",
      "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0556) | Acc: (98.41%) (32878/33408)\n",
      "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0555) | Acc: (98.41%) (34137/34688)\n",
      "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0552) | Acc: (98.43%) (35405/35968)\n",
      "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0548) | Acc: (98.44%) (36666/37248)\n",
      "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0547) | Acc: (98.43%) (37923/38528)\n",
      "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0545) | Acc: (98.44%) (39187/39808)\n",
      "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0540) | Acc: (98.47%) (40460/41088)\n",
      "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0538) | Acc: (98.49%) (41729/42368)\n",
      "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0537) | Acc: (98.49%) (42989/43648)\n",
      "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0537) | Acc: (98.50%) (44252/44928)\n",
      "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0539) | Acc: (98.50%) (45514/46208)\n",
      "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0541) | Acc: (98.48%) (46768/47488)\n",
      "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0541) | Acc: (98.48%) (48028/48768)\n",
      "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0539) | Acc: (98.49%) (49247/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3949) | Acc: (89.64%) (8964/10000)\n",
      "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0463) | Acc: (99.22%) (127/128)\n",
      "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0474) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0468) | Acc: (98.77%) (2655/2688)\n",
      "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0485) | Acc: (98.61%) (3913/3968)\n",
      "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0477) | Acc: (98.72%) (5181/5248)\n",
      "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0492) | Acc: (98.68%) (6442/6528)\n",
      "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0501) | Acc: (98.62%) (7700/7808)\n",
      "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0495) | Acc: (98.64%) (8964/9088)\n",
      "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0495) | Acc: (98.66%) (10229/10368)\n",
      "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0498) | Acc: (98.63%) (11489/11648)\n",
      "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0493) | Acc: (98.65%) (12754/12928)\n",
      "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0500) | Acc: (98.61%) (14011/14208)\n",
      "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0510) | Acc: (98.54%) (15262/15488)\n",
      "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0513) | Acc: (98.56%) (16527/16768)\n",
      "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0517) | Acc: (98.57%) (17790/18048)\n",
      "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0515) | Acc: (98.55%) (19047/19328)\n",
      "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0518) | Acc: (98.54%) (20308/20608)\n",
      "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0522) | Acc: (98.52%) (21564/21888)\n",
      "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0523) | Acc: (98.53%) (22828/23168)\n",
      "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0524) | Acc: (98.53%) (24089/24448)\n",
      "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0521) | Acc: (98.55%) (25355/25728)\n",
      "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0519) | Acc: (98.55%) (26617/27008)\n",
      "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0516) | Acc: (98.56%) (27882/28288)\n",
      "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0517) | Acc: (98.55%) (29139/29568)\n",
      "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0516) | Acc: (98.55%) (30402/30848)\n",
      "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0519) | Acc: (98.54%) (31658/32128)\n",
      "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0521) | Acc: (98.53%) (32916/33408)\n",
      "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0522) | Acc: (98.52%) (34174/34688)\n",
      "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0525) | Acc: (98.50%) (35427/35968)\n",
      "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0526) | Acc: (98.50%) (36690/37248)\n",
      "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0525) | Acc: (98.51%) (37953/38528)\n",
      "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0523) | Acc: (98.53%) (39221/39808)\n",
      "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0524) | Acc: (98.53%) (40483/41088)\n",
      "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0523) | Acc: (98.53%) (41745/42368)\n",
      "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0525) | Acc: (98.53%) (43007/43648)\n",
      "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0524) | Acc: (98.53%) (44269/44928)\n",
      "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0523) | Acc: (98.53%) (45531/46208)\n",
      "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0524) | Acc: (98.52%) (46785/47488)\n",
      "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0522) | Acc: (98.53%) (48052/48768)\n",
      "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0523) | Acc: (98.53%) (49266/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3945) | Acc: (89.55%) (8955/10000)\n",
      "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0558) | Acc: (97.66%) (125/128)\n",
      "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0601) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0567) | Acc: (98.25%) (2641/2688)\n",
      "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0559) | Acc: (98.31%) (3901/3968)\n",
      "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0520) | Acc: (98.55%) (5172/5248)\n",
      "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0518) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0525) | Acc: (98.50%) (7691/7808)\n",
      "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0531) | Acc: (98.46%) (8948/9088)\n",
      "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0529) | Acc: (98.45%) (10207/10368)\n",
      "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0527) | Acc: (98.48%) (11471/11648)\n",
      "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0530) | Acc: (98.45%) (12728/12928)\n",
      "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0541) | Acc: (98.42%) (13984/14208)\n",
      "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0539) | Acc: (98.41%) (15241/15488)\n",
      "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0544) | Acc: (98.38%) (16497/16768)\n",
      "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0545) | Acc: (98.40%) (17759/18048)\n",
      "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0543) | Acc: (98.41%) (19020/19328)\n",
      "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0542) | Acc: (98.41%) (20280/20608)\n",
      "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0537) | Acc: (98.41%) (21541/21888)\n",
      "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0534) | Acc: (98.43%) (22804/23168)\n",
      "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0536) | Acc: (98.43%) (24064/24448)\n",
      "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0537) | Acc: (98.41%) (25320/25728)\n",
      "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0538) | Acc: (98.42%) (26581/27008)\n",
      "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0542) | Acc: (98.40%) (27835/28288)\n",
      "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0540) | Acc: (98.40%) (29094/29568)\n",
      "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0536) | Acc: (98.41%) (30358/30848)\n",
      "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0531) | Acc: (98.44%) (31627/32128)\n",
      "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0529) | Acc: (98.44%) (32887/33408)\n",
      "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.44%) (34146/34688)\n",
      "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0524) | Acc: (98.47%) (35419/35968)\n",
      "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0523) | Acc: (98.48%) (36680/37248)\n",
      "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0522) | Acc: (98.49%) (37946/38528)\n",
      "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0521) | Acc: (98.50%) (39211/39808)\n",
      "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0518) | Acc: (98.51%) (40477/41088)\n",
      "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0517) | Acc: (98.52%) (41743/42368)\n",
      "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0521) | Acc: (98.51%) (42996/43648)\n",
      "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0522) | Acc: (98.50%) (44255/44928)\n",
      "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0522) | Acc: (98.51%) (45519/46208)\n",
      "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0521) | Acc: (98.51%) (46782/47488)\n",
      "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0519) | Acc: (98.52%) (48046/48768)\n",
      "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0520) | Acc: (98.51%) (49255/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3939) | Acc: (89.65%) (8965/10000)\n",
      "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0366) | Acc: (100.00%) (128/128)\n",
      "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0477) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0511) | Acc: (98.59%) (2650/2688)\n",
      "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0493) | Acc: (98.74%) (3918/3968)\n",
      "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0471) | Acc: (98.88%) (5189/5248)\n",
      "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0473) | Acc: (98.91%) (6457/6528)\n",
      "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0471) | Acc: (98.91%) (7723/7808)\n",
      "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0485) | Acc: (98.82%) (8981/9088)\n",
      "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0490) | Acc: (98.80%) (10244/10368)\n",
      "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0508) | Acc: (98.76%) (11504/11648)\n",
      "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0520) | Acc: (98.69%) (12759/12928)\n",
      "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0513) | Acc: (98.76%) (14032/14208)\n",
      "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0509) | Acc: (98.79%) (15300/15488)\n",
      "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0512) | Acc: (98.73%) (16555/16768)\n",
      "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0519) | Acc: (98.70%) (17814/18048)\n",
      "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0514) | Acc: (98.72%) (19081/19328)\n",
      "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0513) | Acc: (98.70%) (20341/20608)\n",
      "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0517) | Acc: (98.68%) (21600/21888)\n",
      "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0518) | Acc: (98.66%) (22858/23168)\n",
      "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0517) | Acc: (98.67%) (24122/24448)\n",
      "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0519) | Acc: (98.66%) (25383/25728)\n",
      "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0516) | Acc: (98.67%) (26649/27008)\n",
      "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0517) | Acc: (98.66%) (27910/28288)\n",
      "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0521) | Acc: (98.63%) (29163/29568)\n",
      "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0524) | Acc: (98.63%) (30424/30848)\n",
      "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0521) | Acc: (98.64%) (31691/32128)\n",
      "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0522) | Acc: (98.62%) (32947/33408)\n",
      "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0519) | Acc: (98.62%) (34209/34688)\n",
      "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0518) | Acc: (98.63%) (35475/35968)\n",
      "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0518) | Acc: (98.63%) (36736/37248)\n",
      "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0515) | Acc: (98.65%) (38007/38528)\n",
      "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0517) | Acc: (98.65%) (39269/39808)\n",
      "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0517) | Acc: (98.64%) (40530/41088)\n",
      "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0519) | Acc: (98.64%) (41791/42368)\n",
      "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0519) | Acc: (98.63%) (43050/43648)\n",
      "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0522) | Acc: (98.62%) (44308/44928)\n",
      "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0523) | Acc: (98.61%) (45568/46208)\n",
      "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0521) | Acc: (98.62%) (46833/47488)\n",
      "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0522) | Acc: (98.61%) (48090/48768)\n",
      "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0519) | Acc: (98.62%) (49312/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3966) | Acc: (89.54%) (8954/10000)\n",
      "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0401) | Acc: (99.22%) (127/128)\n",
      "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0580) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0569) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0568) | Acc: (98.34%) (3902/3968)\n",
      "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0530) | Acc: (98.49%) (5169/5248)\n",
      "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0525) | Acc: (98.58%) (6435/6528)\n",
      "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0533) | Acc: (98.53%) (7693/7808)\n",
      "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0539) | Acc: (98.49%) (8951/9088)\n",
      "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0535) | Acc: (98.51%) (10214/10368)\n",
      "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0533) | Acc: (98.53%) (11477/11648)\n",
      "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0529) | Acc: (98.54%) (12739/12928)\n",
      "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0519) | Acc: (98.56%) (14003/14208)\n",
      "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0520) | Acc: (98.58%) (15268/15488)\n",
      "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0520) | Acc: (98.59%) (16532/16768)\n",
      "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0522) | Acc: (98.59%) (17794/18048)\n",
      "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0522) | Acc: (98.56%) (19050/19328)\n",
      "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0522) | Acc: (98.57%) (20313/20608)\n",
      "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0522) | Acc: (98.57%) (21575/21888)\n",
      "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0524) | Acc: (98.55%) (22833/23168)\n",
      "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0527) | Acc: (98.54%) (24092/24448)\n",
      "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0527) | Acc: (98.55%) (25356/25728)\n",
      "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0526) | Acc: (98.56%) (26618/27008)\n",
      "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0524) | Acc: (98.57%) (27884/28288)\n",
      "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0524) | Acc: (98.58%) (29147/29568)\n",
      "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0523) | Acc: (98.57%) (30406/30848)\n",
      "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0523) | Acc: (98.56%) (31664/32128)\n",
      "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0518) | Acc: (98.58%) (32934/33408)\n",
      "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0516) | Acc: (98.60%) (34203/34688)\n",
      "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0516) | Acc: (98.61%) (35468/35968)\n",
      "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0519) | Acc: (98.60%) (36726/37248)\n",
      "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0520) | Acc: (98.60%) (37987/38528)\n",
      "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0522) | Acc: (98.59%) (39246/39808)\n",
      "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0523) | Acc: (98.59%) (40509/41088)\n",
      "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0525) | Acc: (98.59%) (41770/42368)\n",
      "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0524) | Acc: (98.60%) (43035/43648)\n",
      "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0525) | Acc: (98.59%) (44295/44928)\n",
      "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0522) | Acc: (98.60%) (45560/46208)\n",
      "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0521) | Acc: (98.60%) (46824/47488)\n",
      "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0520) | Acc: (98.61%) (48088/48768)\n",
      "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0518) | Acc: (98.60%) (49302/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3957) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 147 | Batch_idx: 0 |  Loss: (0.1169) | Acc: (96.09%) (123/128)\n",
      "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0457) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0474) | Acc: (98.66%) (2652/2688)\n",
      "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0478) | Acc: (98.82%) (3921/3968)\n",
      "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0490) | Acc: (98.82%) (5186/5248)\n",
      "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0481) | Acc: (98.85%) (6453/6528)\n",
      "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0506) | Acc: (98.64%) (7702/7808)\n",
      "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0508) | Acc: (98.64%) (8964/9088)\n",
      "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0501) | Acc: (98.69%) (10232/10368)\n",
      "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0505) | Acc: (98.63%) (11489/11648)\n",
      "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0501) | Acc: (98.66%) (12755/12928)\n",
      "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0505) | Acc: (98.68%) (14021/14208)\n",
      "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0503) | Acc: (98.68%) (15283/15488)\n",
      "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0507) | Acc: (98.68%) (16546/16768)\n",
      "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0511) | Acc: (98.64%) (17802/18048)\n",
      "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0508) | Acc: (98.65%) (19067/19328)\n",
      "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0508) | Acc: (98.66%) (20331/20608)\n",
      "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0508) | Acc: (98.66%) (21595/21888)\n",
      "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0511) | Acc: (98.64%) (22853/23168)\n",
      "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0512) | Acc: (98.62%) (24111/24448)\n",
      "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0513) | Acc: (98.62%) (25372/25728)\n",
      "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0513) | Acc: (98.61%) (26633/27008)\n",
      "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0514) | Acc: (98.62%) (27897/28288)\n",
      "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0511) | Acc: (98.63%) (29162/29568)\n",
      "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0512) | Acc: (98.62%) (30423/30848)\n",
      "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0514) | Acc: (98.60%) (31679/32128)\n",
      "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0515) | Acc: (98.59%) (32936/33408)\n",
      "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0524) | Acc: (98.54%) (34180/34688)\n",
      "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0525) | Acc: (98.54%) (35443/35968)\n",
      "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0521) | Acc: (98.57%) (36715/37248)\n",
      "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0518) | Acc: (98.58%) (37982/38528)\n",
      "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0516) | Acc: (98.59%) (39247/39808)\n",
      "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0515) | Acc: (98.58%) (40506/41088)\n",
      "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0519) | Acc: (98.57%) (41761/42368)\n",
      "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0517) | Acc: (98.57%) (43026/43648)\n",
      "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0519) | Acc: (98.56%) (44282/44928)\n",
      "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0521) | Acc: (98.56%) (45541/46208)\n",
      "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0520) | Acc: (98.57%) (46807/47488)\n",
      "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0523) | Acc: (98.56%) (48065/48768)\n",
      "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0522) | Acc: (98.56%) (49282/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3944) | Acc: (89.58%) (8958/10000)\n",
      "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0166) | Acc: (100.00%) (128/128)\n",
      "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0473) | Acc: (99.01%) (1394/1408)\n",
      "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0524) | Acc: (98.74%) (2654/2688)\n",
      "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0529) | Acc: (98.74%) (3918/3968)\n",
      "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0522) | Acc: (98.78%) (5184/5248)\n",
      "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0518) | Acc: (98.68%) (6442/6528)\n",
      "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0512) | Acc: (98.69%) (7706/7808)\n",
      "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0513) | Acc: (98.67%) (8967/9088)\n",
      "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0516) | Acc: (98.62%) (10225/10368)\n",
      "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0506) | Acc: (98.63%) (11488/11648)\n",
      "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0502) | Acc: (98.64%) (12752/12928)\n",
      "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0503) | Acc: (98.62%) (14012/14208)\n",
      "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0505) | Acc: (98.59%) (15270/15488)\n",
      "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0509) | Acc: (98.59%) (16531/16768)\n",
      "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0506) | Acc: (98.59%) (17793/18048)\n",
      "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0509) | Acc: (98.60%) (19057/19328)\n",
      "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0508) | Acc: (98.61%) (20321/20608)\n",
      "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0509) | Acc: (98.60%) (21581/21888)\n",
      "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0507) | Acc: (98.60%) (22843/23168)\n",
      "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0505) | Acc: (98.61%) (24109/24448)\n",
      "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0505) | Acc: (98.62%) (25373/25728)\n",
      "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0503) | Acc: (98.62%) (26636/27008)\n",
      "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0506) | Acc: (98.61%) (27895/28288)\n",
      "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0516) | Acc: (98.56%) (29143/29568)\n",
      "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0512) | Acc: (98.57%) (30407/30848)\n",
      "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0510) | Acc: (98.57%) (31668/32128)\n",
      "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0512) | Acc: (98.56%) (32927/33408)\n",
      "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0512) | Acc: (98.57%) (34192/34688)\n",
      "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0515) | Acc: (98.55%) (35445/35968)\n",
      "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0514) | Acc: (98.55%) (36707/37248)\n",
      "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0516) | Acc: (98.54%) (37966/38528)\n",
      "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0517) | Acc: (98.54%) (39227/39808)\n",
      "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0517) | Acc: (98.53%) (40483/41088)\n",
      "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0519) | Acc: (98.52%) (41741/42368)\n",
      "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0519) | Acc: (98.51%) (42997/43648)\n",
      "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0515) | Acc: (98.53%) (44268/44928)\n",
      "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0514) | Acc: (98.54%) (45534/46208)\n",
      "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0516) | Acc: (98.53%) (46790/47488)\n",
      "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0518) | Acc: (98.52%) (48047/48768)\n",
      "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0515) | Acc: (98.54%) (49271/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3974) | Acc: (89.51%) (8951/10000)\n",
      "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0646) | Acc: (99.22%) (127/128)\n",
      "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0563) | Acc: (98.79%) (1391/1408)\n",
      "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0506) | Acc: (98.85%) (2657/2688)\n",
      "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0498) | Acc: (98.94%) (3926/3968)\n",
      "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0474) | Acc: (98.99%) (5195/5248)\n",
      "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0492) | Acc: (98.87%) (6454/6528)\n",
      "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0492) | Acc: (98.90%) (7722/7808)\n",
      "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0479) | Acc: (98.97%) (8994/9088)\n",
      "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0480) | Acc: (98.91%) (10255/10368)\n",
      "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0480) | Acc: (98.90%) (11520/11648)\n",
      "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0488) | Acc: (98.80%) (12773/12928)\n",
      "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0493) | Acc: (98.76%) (14032/14208)\n",
      "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0499) | Acc: (98.70%) (15286/15488)\n",
      "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0501) | Acc: (98.68%) (16546/16768)\n",
      "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0498) | Acc: (98.71%) (17815/18048)\n",
      "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0503) | Acc: (98.72%) (19081/19328)\n",
      "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0501) | Acc: (98.73%) (20346/20608)\n",
      "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0500) | Acc: (98.73%) (21609/21888)\n",
      "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0498) | Acc: (98.74%) (22875/23168)\n",
      "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0498) | Acc: (98.72%) (24136/24448)\n",
      "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0498) | Acc: (98.69%) (25392/25728)\n",
      "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0499) | Acc: (98.70%) (26658/27008)\n",
      "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0499) | Acc: (98.71%) (27924/28288)\n",
      "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0499) | Acc: (98.71%) (29186/29568)\n",
      "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0503) | Acc: (98.68%) (30440/30848)\n",
      "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0502) | Acc: (98.69%) (31707/32128)\n",
      "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0499) | Acc: (98.70%) (32974/33408)\n",
      "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0497) | Acc: (98.71%) (34242/34688)\n",
      "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0498) | Acc: (98.72%) (35506/35968)\n",
      "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0496) | Acc: (98.73%) (36775/37248)\n",
      "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0494) | Acc: (98.75%) (38045/38528)\n",
      "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0492) | Acc: (98.74%) (39308/39808)\n",
      "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0497) | Acc: (98.72%) (40561/41088)\n",
      "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0498) | Acc: (98.69%) (41815/42368)\n",
      "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0499) | Acc: (98.70%) (43080/43648)\n",
      "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0500) | Acc: (98.69%) (44340/44928)\n",
      "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0500) | Acc: (98.68%) (45600/46208)\n",
      "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0501) | Acc: (98.68%) (46861/47488)\n",
      "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0505) | Acc: (98.66%) (48113/48768)\n",
      "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0505) | Acc: (98.66%) (49330/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3925) | Acc: (89.67%) (8967/10000)\n",
      "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0264) | Acc: (100.00%) (128/128)\n",
      "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0552) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0548) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0537) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0536) | Acc: (98.53%) (5171/5248)\n",
      "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0531) | Acc: (98.58%) (6435/6528)\n",
      "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0531) | Acc: (98.58%) (7697/7808)\n",
      "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0551) | Acc: (98.53%) (8954/9088)\n",
      "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0552) | Acc: (98.51%) (10214/10368)\n",
      "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0542) | Acc: (98.57%) (11481/11648)\n",
      "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0535) | Acc: (98.58%) (12745/12928)\n",
      "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0524) | Acc: (98.61%) (14011/14208)\n",
      "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0522) | Acc: (98.62%) (15275/15488)\n",
      "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0527) | Acc: (98.60%) (16533/16768)\n",
      "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0526) | Acc: (98.58%) (17792/18048)\n",
      "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0521) | Acc: (98.60%) (19057/19328)\n",
      "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0519) | Acc: (98.59%) (20317/20608)\n",
      "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0523) | Acc: (98.57%) (21575/21888)\n",
      "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0520) | Acc: (98.58%) (22840/23168)\n",
      "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0516) | Acc: (98.59%) (24104/24448)\n",
      "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0517) | Acc: (98.60%) (25368/25728)\n",
      "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0514) | Acc: (98.62%) (26635/27008)\n",
      "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0516) | Acc: (98.61%) (27895/28288)\n",
      "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0516) | Acc: (98.61%) (29158/29568)\n",
      "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0516) | Acc: (98.61%) (30419/30848)\n",
      "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0517) | Acc: (98.60%) (31679/32128)\n",
      "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0518) | Acc: (98.60%) (32939/33408)\n",
      "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0518) | Acc: (98.60%) (34201/34688)\n",
      "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0520) | Acc: (98.59%) (35461/35968)\n",
      "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0522) | Acc: (98.58%) (36718/37248)\n",
      "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0520) | Acc: (98.59%) (37983/38528)\n",
      "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0520) | Acc: (98.59%) (39246/39808)\n",
      "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0517) | Acc: (98.60%) (40514/41088)\n",
      "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0518) | Acc: (98.58%) (41768/42368)\n",
      "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0519) | Acc: (98.58%) (43028/43648)\n",
      "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0522) | Acc: (98.57%) (44287/44928)\n",
      "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0522) | Acc: (98.57%) (45548/46208)\n",
      "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0523) | Acc: (98.56%) (46805/47488)\n",
      "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0524) | Acc: (98.56%) (48064/48768)\n",
      "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0524) | Acc: (98.55%) (49274/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3950) | Acc: (89.56%) (8956/10000)\n",
      "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0474) | Acc: (98.44%) (126/128)\n",
      "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0495) | Acc: (98.86%) (1392/1408)\n",
      "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0502) | Acc: (98.70%) (2653/2688)\n",
      "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0520) | Acc: (98.59%) (3912/3968)\n",
      "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0508) | Acc: (98.57%) (5173/5248)\n",
      "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0502) | Acc: (98.59%) (6436/6528)\n",
      "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0505) | Acc: (98.55%) (7695/7808)\n",
      "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0500) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0495) | Acc: (98.57%) (10220/10368)\n",
      "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0493) | Acc: (98.60%) (11485/11648)\n",
      "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0495) | Acc: (98.62%) (12750/12928)\n",
      "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0509) | Acc: (98.54%) (14000/14208)\n",
      "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0510) | Acc: (98.52%) (15259/15488)\n",
      "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0503) | Acc: (98.54%) (16523/16768)\n",
      "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0502) | Acc: (98.56%) (17789/18048)\n",
      "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0506) | Acc: (98.57%) (19051/19328)\n",
      "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0500) | Acc: (98.61%) (20322/20608)\n",
      "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0504) | Acc: (98.59%) (21579/21888)\n",
      "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0512) | Acc: (98.54%) (22830/23168)\n",
      "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0508) | Acc: (98.56%) (24095/24448)\n",
      "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0510) | Acc: (98.56%) (25358/25728)\n",
      "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0513) | Acc: (98.55%) (26617/27008)\n",
      "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0512) | Acc: (98.55%) (27879/28288)\n",
      "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0511) | Acc: (98.56%) (29143/29568)\n",
      "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0507) | Acc: (98.57%) (30407/30848)\n",
      "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0507) | Acc: (98.57%) (31669/32128)\n",
      "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0504) | Acc: (98.57%) (32931/33408)\n",
      "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0505) | Acc: (98.58%) (34196/34688)\n",
      "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0506) | Acc: (98.59%) (35460/35968)\n",
      "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0509) | Acc: (98.59%) (36721/37248)\n",
      "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0511) | Acc: (98.58%) (37979/38528)\n",
      "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0515) | Acc: (98.56%) (39233/39808)\n",
      "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0520) | Acc: (98.53%) (40486/41088)\n",
      "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0520) | Acc: (98.54%) (41750/42368)\n",
      "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0520) | Acc: (98.55%) (43015/43648)\n",
      "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0523) | Acc: (98.54%) (44270/44928)\n",
      "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0522) | Acc: (98.54%) (45535/46208)\n",
      "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0523) | Acc: (98.54%) (46794/47488)\n",
      "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0520) | Acc: (98.55%) (48059/48768)\n",
      "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0518) | Acc: (98.56%) (49279/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3946) | Acc: (89.43%) (8943/10000)\n",
      "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0452) | Acc: (98.44%) (126/128)\n",
      "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0497) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0516) | Acc: (98.55%) (2649/2688)\n",
      "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0524) | Acc: (98.56%) (3911/3968)\n",
      "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0545) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0534) | Acc: (98.54%) (6433/6528)\n",
      "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0523) | Acc: (98.58%) (7697/7808)\n",
      "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0537) | Acc: (98.46%) (8948/9088)\n",
      "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0533) | Acc: (98.46%) (10208/10368)\n",
      "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0533) | Acc: (98.48%) (11471/11648)\n",
      "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0525) | Acc: (98.47%) (12730/12928)\n",
      "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0533) | Acc: (98.45%) (13988/14208)\n",
      "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0536) | Acc: (98.44%) (15246/15488)\n",
      "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0536) | Acc: (98.44%) (16507/16768)\n",
      "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0537) | Acc: (98.42%) (17762/18048)\n",
      "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0533) | Acc: (98.43%) (19024/19328)\n",
      "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0530) | Acc: (98.44%) (20286/20608)\n",
      "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0525) | Acc: (98.46%) (21550/21888)\n",
      "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0525) | Acc: (98.46%) (22812/23168)\n",
      "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0534) | Acc: (98.43%) (24063/24448)\n",
      "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0530) | Acc: (98.44%) (25326/25728)\n",
      "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0532) | Acc: (98.43%) (26585/27008)\n",
      "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0531) | Acc: (98.43%) (27845/28288)\n",
      "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0529) | Acc: (98.43%) (29103/29568)\n",
      "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0528) | Acc: (98.43%) (30365/30848)\n",
      "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0523) | Acc: (98.46%) (31633/32128)\n",
      "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0524) | Acc: (98.47%) (32896/33408)\n",
      "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0524) | Acc: (98.48%) (34160/34688)\n",
      "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0524) | Acc: (98.48%) (35421/35968)\n",
      "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0528) | Acc: (98.46%) (36676/37248)\n",
      "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0528) | Acc: (98.47%) (37938/38528)\n",
      "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0529) | Acc: (98.47%) (39200/39808)\n",
      "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0528) | Acc: (98.47%) (40461/41088)\n",
      "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0531) | Acc: (98.46%) (41717/42368)\n",
      "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0530) | Acc: (98.47%) (42980/43648)\n",
      "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0529) | Acc: (98.47%) (44241/44928)\n",
      "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0527) | Acc: (98.48%) (45507/46208)\n",
      "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0522) | Acc: (98.50%) (46776/47488)\n",
      "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0523) | Acc: (98.49%) (48034/48768)\n",
      "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0523) | Acc: (98.50%) (49248/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3921) | Acc: (89.66%) (8966/10000)\n",
      "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0220) | Acc: (99.22%) (127/128)\n",
      "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0509) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0514) | Acc: (98.62%) (2651/2688)\n",
      "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0515) | Acc: (98.59%) (3912/3968)\n",
      "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0501) | Acc: (98.65%) (5177/5248)\n",
      "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0489) | Acc: (98.67%) (6441/6528)\n",
      "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0484) | Acc: (98.72%) (7708/7808)\n",
      "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0472) | Acc: (98.76%) (8975/9088)\n",
      "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0485) | Acc: (98.75%) (10238/10368)\n",
      "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0482) | Acc: (98.73%) (11500/11648)\n",
      "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0489) | Acc: (98.72%) (12762/12928)\n",
      "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0504) | Acc: (98.66%) (14017/14208)\n",
      "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0504) | Acc: (98.69%) (15285/15488)\n",
      "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0501) | Acc: (98.70%) (16550/16768)\n",
      "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0505) | Acc: (98.68%) (17810/18048)\n",
      "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0499) | Acc: (98.72%) (19081/19328)\n",
      "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0499) | Acc: (98.72%) (20344/20608)\n",
      "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0495) | Acc: (98.73%) (21609/21888)\n",
      "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0494) | Acc: (98.71%) (22868/23168)\n",
      "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0496) | Acc: (98.70%) (24130/24448)\n",
      "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0502) | Acc: (98.66%) (25384/25728)\n",
      "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0499) | Acc: (98.67%) (26650/27008)\n",
      "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0503) | Acc: (98.66%) (27910/28288)\n",
      "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0503) | Acc: (98.66%) (29173/29568)\n",
      "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0505) | Acc: (98.65%) (30432/30848)\n",
      "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0508) | Acc: (98.64%) (31690/32128)\n",
      "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0510) | Acc: (98.62%) (32947/33408)\n",
      "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0511) | Acc: (98.62%) (34208/34688)\n",
      "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0510) | Acc: (98.62%) (35471/35968)\n",
      "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0507) | Acc: (98.64%) (36741/37248)\n",
      "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0508) | Acc: (98.63%) (38000/38528)\n",
      "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0509) | Acc: (98.62%) (39259/39808)\n",
      "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0512) | Acc: (98.60%) (40514/41088)\n",
      "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0510) | Acc: (98.61%) (41779/42368)\n",
      "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0510) | Acc: (98.60%) (43038/43648)\n",
      "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0510) | Acc: (98.62%) (44306/44928)\n",
      "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0514) | Acc: (98.58%) (45553/46208)\n",
      "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0513) | Acc: (98.58%) (46816/47488)\n",
      "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0514) | Acc: (98.57%) (48073/48768)\n",
      "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0514) | Acc: (98.57%) (49287/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3942) | Acc: (89.51%) (8951/10000)\n",
      "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0495) | Acc: (97.66%) (125/128)\n",
      "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0503) | Acc: (98.51%) (1387/1408)\n",
      "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0467) | Acc: (98.70%) (2653/2688)\n",
      "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0487) | Acc: (98.51%) (3909/3968)\n",
      "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0512) | Acc: (98.44%) (5166/5248)\n",
      "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0523) | Acc: (98.39%) (6423/6528)\n",
      "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0512) | Acc: (98.44%) (7686/7808)\n",
      "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0517) | Acc: (98.49%) (8951/9088)\n",
      "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0516) | Acc: (98.52%) (10215/10368)\n",
      "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0515) | Acc: (98.51%) (11474/11648)\n",
      "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0512) | Acc: (98.54%) (12739/12928)\n",
      "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0506) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0512) | Acc: (98.51%) (15257/15488)\n",
      "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0512) | Acc: (98.50%) (16517/16768)\n",
      "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0512) | Acc: (98.53%) (17783/18048)\n",
      "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0509) | Acc: (98.55%) (19047/19328)\n",
      "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0507) | Acc: (98.55%) (20309/20608)\n",
      "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0504) | Acc: (98.57%) (21576/21888)\n",
      "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0509) | Acc: (98.56%) (22834/23168)\n",
      "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0506) | Acc: (98.57%) (24099/24448)\n",
      "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0508) | Acc: (98.57%) (25360/25728)\n",
      "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0511) | Acc: (98.54%) (26614/27008)\n",
      "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0510) | Acc: (98.54%) (27876/28288)\n",
      "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0512) | Acc: (98.55%) (29139/29568)\n",
      "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0517) | Acc: (98.52%) (30392/30848)\n",
      "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0519) | Acc: (98.50%) (31645/32128)\n",
      "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0518) | Acc: (98.50%) (32907/33408)\n",
      "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0517) | Acc: (98.50%) (34166/34688)\n",
      "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0518) | Acc: (98.49%) (35426/35968)\n",
      "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0516) | Acc: (98.52%) (36695/37248)\n",
      "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0513) | Acc: (98.54%) (37964/38528)\n",
      "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0513) | Acc: (98.54%) (39225/39808)\n",
      "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0515) | Acc: (98.53%) (40485/41088)\n",
      "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0515) | Acc: (98.54%) (41750/42368)\n",
      "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0515) | Acc: (98.53%) (43008/43648)\n",
      "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0515) | Acc: (98.53%) (44266/44928)\n",
      "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0512) | Acc: (98.55%) (45540/46208)\n",
      "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0514) | Acc: (98.54%) (46796/47488)\n",
      "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0512) | Acc: (98.55%) (48061/48768)\n",
      "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0512) | Acc: (98.55%) (49275/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3950) | Acc: (89.59%) (8959/10000)\n",
      "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0651) | Acc: (98.44%) (126/128)\n",
      "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0552) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0551) | Acc: (98.33%) (2643/2688)\n",
      "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0544) | Acc: (98.34%) (3902/3968)\n",
      "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0531) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0545) | Acc: (98.39%) (6423/6528)\n",
      "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0526) | Acc: (98.51%) (7692/7808)\n",
      "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0532) | Acc: (98.51%) (8953/9088)\n",
      "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0525) | Acc: (98.54%) (10217/10368)\n",
      "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0514) | Acc: (98.59%) (11484/11648)\n",
      "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0516) | Acc: (98.60%) (12747/12928)\n",
      "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0513) | Acc: (98.61%) (14010/14208)\n",
      "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0512) | Acc: (98.64%) (15277/15488)\n",
      "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0521) | Acc: (98.56%) (16526/16768)\n",
      "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0522) | Acc: (98.56%) (17788/18048)\n",
      "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0524) | Acc: (98.51%) (19040/19328)\n",
      "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0527) | Acc: (98.52%) (20304/20608)\n",
      "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0526) | Acc: (98.52%) (21565/21888)\n",
      "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0524) | Acc: (98.52%) (22826/23168)\n",
      "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0525) | Acc: (98.51%) (24083/24448)\n",
      "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0523) | Acc: (98.52%) (25348/25728)\n",
      "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0528) | Acc: (98.48%) (26597/27008)\n",
      "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0528) | Acc: (98.47%) (27855/28288)\n",
      "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0528) | Acc: (98.48%) (29120/29568)\n",
      "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0527) | Acc: (98.49%) (30381/30848)\n",
      "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0529) | Acc: (98.48%) (31640/32128)\n",
      "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0531) | Acc: (98.49%) (32903/33408)\n",
      "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0529) | Acc: (98.50%) (34168/34688)\n",
      "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0528) | Acc: (98.50%) (35427/35968)\n",
      "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0527) | Acc: (98.50%) (36690/37248)\n",
      "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0527) | Acc: (98.51%) (37953/38528)\n",
      "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0529) | Acc: (98.51%) (39213/39808)\n",
      "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0527) | Acc: (98.51%) (40474/41088)\n",
      "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0531) | Acc: (98.49%) (41729/42368)\n",
      "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0529) | Acc: (98.49%) (42990/43648)\n",
      "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0527) | Acc: (98.50%) (44256/44928)\n",
      "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0528) | Acc: (98.50%) (45517/46208)\n",
      "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0531) | Acc: (98.49%) (46773/47488)\n",
      "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0529) | Acc: (98.51%) (48039/48768)\n",
      "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0529) | Acc: (98.50%) (49252/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3955) | Acc: (89.62%) (8962/10000)\n",
      "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0405) | Acc: (99.22%) (127/128)\n",
      "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0527) | Acc: (98.79%) (1391/1408)\n",
      "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0487) | Acc: (98.77%) (2655/2688)\n",
      "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0482) | Acc: (98.71%) (3917/3968)\n",
      "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0506) | Acc: (98.67%) (5178/5248)\n",
      "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0487) | Acc: (98.70%) (6443/6528)\n",
      "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0487) | Acc: (98.64%) (7702/7808)\n",
      "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0486) | Acc: (98.60%) (8961/9088)\n",
      "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0493) | Acc: (98.61%) (10224/10368)\n",
      "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0494) | Acc: (98.62%) (11487/11648)\n",
      "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0493) | Acc: (98.62%) (12750/12928)\n",
      "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0491) | Acc: (98.63%) (14013/14208)\n",
      "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0491) | Acc: (98.64%) (15277/15488)\n",
      "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0496) | Acc: (98.65%) (16541/16768)\n",
      "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0500) | Acc: (98.63%) (17800/18048)\n",
      "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0504) | Acc: (98.61%) (19060/19328)\n",
      "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0504) | Acc: (98.62%) (20323/20608)\n",
      "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0506) | Acc: (98.62%) (21586/21888)\n",
      "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0509) | Acc: (98.60%) (22844/23168)\n",
      "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0503) | Acc: (98.63%) (24114/24448)\n",
      "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0506) | Acc: (98.62%) (25373/25728)\n",
      "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0509) | Acc: (98.59%) (26628/27008)\n",
      "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0506) | Acc: (98.61%) (27896/28288)\n",
      "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0506) | Acc: (98.60%) (29153/29568)\n",
      "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0507) | Acc: (98.59%) (30414/30848)\n",
      "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0507) | Acc: (98.59%) (31676/32128)\n",
      "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0508) | Acc: (98.60%) (32940/33408)\n",
      "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0506) | Acc: (98.61%) (34206/34688)\n",
      "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0510) | Acc: (98.60%) (35464/35968)\n",
      "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0513) | Acc: (98.59%) (36722/37248)\n",
      "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0512) | Acc: (98.60%) (37989/38528)\n",
      "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0511) | Acc: (98.62%) (39258/39808)\n",
      "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0513) | Acc: (98.61%) (40516/41088)\n",
      "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0514) | Acc: (98.59%) (41772/42368)\n",
      "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0514) | Acc: (98.59%) (43034/43648)\n",
      "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0516) | Acc: (98.58%) (44291/44928)\n",
      "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0515) | Acc: (98.59%) (45556/46208)\n",
      "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0516) | Acc: (98.58%) (46816/47488)\n",
      "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0514) | Acc: (98.60%) (48083/48768)\n",
      "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0512) | Acc: (98.60%) (49301/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3942) | Acc: (89.61%) (8961/10000)\n",
      "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0620) | Acc: (98.44%) (126/128)\n",
      "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0535) | Acc: (98.65%) (1389/1408)\n",
      "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0555) | Acc: (98.44%) (2646/2688)\n",
      "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0530) | Acc: (98.54%) (3910/3968)\n",
      "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0524) | Acc: (98.53%) (5171/5248)\n",
      "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0524) | Acc: (98.62%) (6438/6528)\n",
      "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0523) | Acc: (98.59%) (7698/7808)\n",
      "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0524) | Acc: (98.59%) (8960/9088)\n",
      "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0519) | Acc: (98.60%) (10223/10368)\n",
      "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0524) | Acc: (98.57%) (11482/11648)\n",
      "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0530) | Acc: (98.53%) (12738/12928)\n",
      "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0536) | Acc: (98.48%) (13992/14208)\n",
      "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0534) | Acc: (98.50%) (15255/15488)\n",
      "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0533) | Acc: (98.50%) (16516/16768)\n",
      "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0525) | Acc: (98.52%) (17781/18048)\n",
      "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0527) | Acc: (98.53%) (19043/19328)\n",
      "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0523) | Acc: (98.55%) (20309/20608)\n",
      "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0523) | Acc: (98.52%) (21565/21888)\n",
      "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0520) | Acc: (98.53%) (22827/23168)\n",
      "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0518) | Acc: (98.55%) (24093/24448)\n",
      "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0518) | Acc: (98.54%) (25353/25728)\n",
      "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0519) | Acc: (98.53%) (26612/27008)\n",
      "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0522) | Acc: (98.51%) (27866/28288)\n",
      "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0519) | Acc: (98.53%) (29133/29568)\n",
      "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0518) | Acc: (98.53%) (30396/30848)\n",
      "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0516) | Acc: (98.56%) (31664/32128)\n",
      "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0515) | Acc: (98.56%) (32926/33408)\n",
      "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0516) | Acc: (98.56%) (34190/34688)\n",
      "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0516) | Acc: (98.57%) (35452/35968)\n",
      "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0517) | Acc: (98.56%) (36711/37248)\n",
      "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0521) | Acc: (98.54%) (37967/38528)\n",
      "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0522) | Acc: (98.54%) (39226/39808)\n",
      "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0524) | Acc: (98.54%) (40489/41088)\n",
      "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0522) | Acc: (98.56%) (41756/42368)\n",
      "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0523) | Acc: (98.55%) (43017/43648)\n",
      "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0524) | Acc: (98.56%) (44282/44928)\n",
      "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0524) | Acc: (98.55%) (45540/46208)\n",
      "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0523) | Acc: (98.55%) (46800/47488)\n",
      "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0524) | Acc: (98.54%) (48055/48768)\n",
      "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0523) | Acc: (98.54%) (49270/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3939) | Acc: (89.63%) (8963/10000)\n",
      "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0359) | Acc: (99.22%) (127/128)\n",
      "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0572) | Acc: (98.15%) (1382/1408)\n",
      "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0622) | Acc: (97.99%) (2634/2688)\n",
      "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0594) | Acc: (98.16%) (3895/3968)\n",
      "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0570) | Acc: (98.27%) (5157/5248)\n",
      "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0556) | Acc: (98.36%) (6421/6528)\n",
      "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0544) | Acc: (98.44%) (7686/7808)\n",
      "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0535) | Acc: (98.48%) (8950/9088)\n",
      "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0531) | Acc: (98.51%) (10214/10368)\n",
      "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0532) | Acc: (98.50%) (11473/11648)\n",
      "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0537) | Acc: (98.48%) (12731/12928)\n",
      "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0526) | Acc: (98.52%) (13998/14208)\n",
      "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0520) | Acc: (98.57%) (15266/15488)\n",
      "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0519) | Acc: (98.59%) (16531/16768)\n",
      "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0513) | Acc: (98.63%) (17801/18048)\n",
      "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0516) | Acc: (98.63%) (19064/19328)\n",
      "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0517) | Acc: (98.65%) (20329/20608)\n",
      "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0515) | Acc: (98.65%) (21593/21888)\n",
      "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0513) | Acc: (98.63%) (22851/23168)\n",
      "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0518) | Acc: (98.63%) (24112/24448)\n",
      "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0519) | Acc: (98.62%) (25372/25728)\n",
      "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0517) | Acc: (98.63%) (26639/27008)\n",
      "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0517) | Acc: (98.63%) (27900/28288)\n",
      "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0517) | Acc: (98.63%) (29163/29568)\n",
      "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0520) | Acc: (98.60%) (30417/30848)\n",
      "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0520) | Acc: (98.60%) (31679/32128)\n",
      "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0518) | Acc: (98.63%) (32949/33408)\n",
      "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0515) | Acc: (98.63%) (34213/34688)\n",
      "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0514) | Acc: (98.62%) (35472/35968)\n",
      "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0518) | Acc: (98.60%) (36725/37248)\n",
      "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0518) | Acc: (98.60%) (37987/38528)\n",
      "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0516) | Acc: (98.60%) (39252/39808)\n",
      "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0516) | Acc: (98.60%) (40513/41088)\n",
      "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0514) | Acc: (98.61%) (41778/42368)\n",
      "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0514) | Acc: (98.62%) (43044/43648)\n",
      "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0512) | Acc: (98.62%) (44310/44928)\n",
      "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0511) | Acc: (98.63%) (45577/46208)\n",
      "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0509) | Acc: (98.64%) (46840/47488)\n",
      "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0510) | Acc: (98.63%) (48098/48768)\n",
      "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0511) | Acc: (98.61%) (49307/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3959) | Acc: (89.57%) (8957/10000)\n",
      "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0716) | Acc: (95.31%) (122/128)\n",
      "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0625) | Acc: (97.87%) (1378/1408)\n",
      "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0528) | Acc: (98.40%) (2645/2688)\n",
      "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0515) | Acc: (98.41%) (3905/3968)\n",
      "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0511) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0515) | Acc: (98.41%) (6424/6528)\n",
      "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0528) | Acc: (98.32%) (7677/7808)\n",
      "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0531) | Acc: (98.35%) (8938/9088)\n",
      "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0515) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0523) | Acc: (98.43%) (11465/11648)\n",
      "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0542) | Acc: (98.38%) (12718/12928)\n",
      "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0535) | Acc: (98.41%) (13982/14208)\n",
      "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0533) | Acc: (98.44%) (15246/15488)\n",
      "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0527) | Acc: (98.47%) (16511/16768)\n",
      "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0530) | Acc: (98.44%) (17766/18048)\n",
      "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0525) | Acc: (98.45%) (19028/19328)\n",
      "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0522) | Acc: (98.48%) (20294/20608)\n",
      "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0516) | Acc: (98.51%) (21561/21888)\n",
      "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0514) | Acc: (98.54%) (22829/23168)\n",
      "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0519) | Acc: (98.53%) (24088/24448)\n",
      "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0525) | Acc: (98.50%) (25343/25728)\n",
      "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0519) | Acc: (98.52%) (26609/27008)\n",
      "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0525) | Acc: (98.49%) (27862/28288)\n",
      "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0526) | Acc: (98.48%) (29118/29568)\n",
      "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0526) | Acc: (98.46%) (30374/30848)\n",
      "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0525) | Acc: (98.46%) (31634/32128)\n",
      "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0523) | Acc: (98.47%) (32896/33408)\n",
      "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0520) | Acc: (98.50%) (34166/34688)\n",
      "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0518) | Acc: (98.50%) (35429/35968)\n",
      "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0516) | Acc: (98.50%) (36691/37248)\n",
      "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0516) | Acc: (98.50%) (37951/38528)\n",
      "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0516) | Acc: (98.50%) (39209/39808)\n",
      "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0520) | Acc: (98.48%) (40463/41088)\n",
      "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0519) | Acc: (98.49%) (41729/42368)\n",
      "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0517) | Acc: (98.50%) (42995/43648)\n",
      "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0516) | Acc: (98.51%) (44258/44928)\n",
      "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0514) | Acc: (98.53%) (45528/46208)\n",
      "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0514) | Acc: (98.54%) (46793/47488)\n",
      "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0516) | Acc: (98.53%) (48049/48768)\n",
      "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0519) | Acc: (98.51%) (49256/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3979) | Acc: (89.42%) (8942/10000)\n",
      "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0332) | Acc: (100.00%) (128/128)\n",
      "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0439) | Acc: (99.08%) (1395/1408)\n",
      "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0433) | Acc: (99.14%) (2665/2688)\n",
      "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0455) | Acc: (98.99%) (3928/3968)\n",
      "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0507) | Acc: (98.78%) (5184/5248)\n",
      "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0503) | Acc: (98.71%) (6444/6528)\n",
      "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0508) | Acc: (98.71%) (7707/7808)\n",
      "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0521) | Acc: (98.65%) (8965/9088)\n",
      "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0518) | Acc: (98.65%) (10228/10368)\n",
      "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0522) | Acc: (98.60%) (11485/11648)\n",
      "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0510) | Acc: (98.62%) (12750/12928)\n",
      "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0508) | Acc: (98.64%) (14015/14208)\n",
      "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0515) | Acc: (98.60%) (15271/15488)\n",
      "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0512) | Acc: (98.62%) (16536/16768)\n",
      "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0509) | Acc: (98.63%) (17800/18048)\n",
      "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0510) | Acc: (98.61%) (19059/19328)\n",
      "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0510) | Acc: (98.61%) (20321/20608)\n",
      "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0511) | Acc: (98.58%) (21578/21888)\n",
      "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0509) | Acc: (98.59%) (22841/23168)\n",
      "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0510) | Acc: (98.58%) (24102/24448)\n",
      "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0507) | Acc: (98.61%) (25370/25728)\n",
      "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0509) | Acc: (98.60%) (26629/27008)\n",
      "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0507) | Acc: (98.61%) (27896/28288)\n",
      "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0508) | Acc: (98.60%) (29155/29568)\n",
      "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0508) | Acc: (98.60%) (30417/30848)\n",
      "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0509) | Acc: (98.61%) (31682/32128)\n",
      "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0512) | Acc: (98.59%) (32937/33408)\n",
      "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0514) | Acc: (98.58%) (34194/34688)\n",
      "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0519) | Acc: (98.55%) (35447/35968)\n",
      "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0519) | Acc: (98.53%) (36701/37248)\n",
      "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0522) | Acc: (98.51%) (37954/38528)\n",
      "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0526) | Acc: (98.50%) (39210/39808)\n",
      "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0525) | Acc: (98.51%) (40475/41088)\n",
      "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0524) | Acc: (98.52%) (41740/42368)\n",
      "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0525) | Acc: (98.51%) (42996/43648)\n",
      "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0524) | Acc: (98.52%) (44263/44928)\n",
      "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0524) | Acc: (98.52%) (45526/46208)\n",
      "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0526) | Acc: (98.52%) (46785/47488)\n",
      "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0523) | Acc: (98.54%) (48056/48768)\n",
      "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0521) | Acc: (98.55%) (49277/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3940) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0562) | Acc: (99.22%) (127/128)\n",
      "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0575) | Acc: (98.44%) (1386/1408)\n",
      "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0553) | Acc: (98.29%) (2642/2688)\n",
      "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0528) | Acc: (98.54%) (3910/3968)\n",
      "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0534) | Acc: (98.51%) (5170/5248)\n",
      "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0532) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0524) | Acc: (98.57%) (7696/7808)\n",
      "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0524) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0533) | Acc: (98.47%) (10209/10368)\n",
      "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0531) | Acc: (98.47%) (11470/11648)\n",
      "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0529) | Acc: (98.50%) (12734/12928)\n",
      "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0522) | Acc: (98.54%) (14001/14208)\n",
      "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0521) | Acc: (98.55%) (15264/15488)\n",
      "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0525) | Acc: (98.55%) (16525/16768)\n",
      "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0522) | Acc: (98.57%) (17790/18048)\n",
      "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0525) | Acc: (98.55%) (19047/19328)\n",
      "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0527) | Acc: (98.53%) (20306/20608)\n",
      "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0524) | Acc: (98.56%) (21573/21888)\n",
      "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0526) | Acc: (98.54%) (22829/23168)\n",
      "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0522) | Acc: (98.56%) (24095/24448)\n",
      "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0525) | Acc: (98.55%) (25354/25728)\n",
      "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0522) | Acc: (98.55%) (26616/27008)\n",
      "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0521) | Acc: (98.56%) (27882/28288)\n",
      "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0521) | Acc: (98.56%) (29141/29568)\n",
      "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0517) | Acc: (98.57%) (30407/30848)\n",
      "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0518) | Acc: (98.58%) (31672/32128)\n",
      "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0517) | Acc: (98.59%) (32936/33408)\n",
      "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0517) | Acc: (98.60%) (34204/34688)\n",
      "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0514) | Acc: (98.62%) (35471/35968)\n",
      "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0514) | Acc: (98.62%) (36734/37248)\n",
      "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0514) | Acc: (98.62%) (37995/38528)\n",
      "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0510) | Acc: (98.64%) (39267/39808)\n",
      "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0511) | Acc: (98.65%) (40532/41088)\n",
      "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0509) | Acc: (98.65%) (41794/42368)\n",
      "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0507) | Acc: (98.66%) (43063/43648)\n",
      "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0511) | Acc: (98.65%) (44320/44928)\n",
      "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0512) | Acc: (98.65%) (45582/46208)\n",
      "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0513) | Acc: (98.63%) (46839/47488)\n",
      "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0511) | Acc: (98.63%) (48102/48768)\n",
      "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0509) | Acc: (98.64%) (49319/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3964) | Acc: (89.53%) (8953/10000)\n",
      "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0845) | Acc: (96.88%) (124/128)\n",
      "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0520) | Acc: (98.37%) (1385/1408)\n",
      "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0503) | Acc: (98.44%) (2646/2688)\n",
      "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0516) | Acc: (98.49%) (3908/3968)\n",
      "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0530) | Acc: (98.46%) (5167/5248)\n",
      "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0527) | Acc: (98.48%) (6429/6528)\n",
      "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0550) | Acc: (98.34%) (7678/7808)\n",
      "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0536) | Acc: (98.46%) (8948/9088)\n",
      "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0541) | Acc: (98.42%) (10204/10368)\n",
      "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0545) | Acc: (98.39%) (11461/11648)\n",
      "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0536) | Acc: (98.45%) (12728/12928)\n",
      "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0527) | Acc: (98.49%) (13993/14208)\n",
      "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0528) | Acc: (98.50%) (15255/15488)\n",
      "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0521) | Acc: (98.53%) (16522/16768)\n",
      "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0515) | Acc: (98.54%) (17785/18048)\n",
      "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0515) | Acc: (98.56%) (19049/19328)\n",
      "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0513) | Acc: (98.55%) (20309/20608)\n",
      "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0513) | Acc: (98.57%) (21575/21888)\n",
      "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0514) | Acc: (98.57%) (22836/23168)\n",
      "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0514) | Acc: (98.58%) (24100/24448)\n",
      "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0516) | Acc: (98.57%) (25360/25728)\n",
      "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0513) | Acc: (98.59%) (26627/27008)\n",
      "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0509) | Acc: (98.60%) (27892/28288)\n",
      "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0505) | Acc: (98.62%) (29160/29568)\n",
      "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0505) | Acc: (98.62%) (30422/30848)\n",
      "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0503) | Acc: (98.63%) (31688/32128)\n",
      "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0503) | Acc: (98.62%) (32948/33408)\n",
      "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0500) | Acc: (98.63%) (34213/34688)\n",
      "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0502) | Acc: (98.62%) (35471/35968)\n",
      "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0502) | Acc: (98.63%) (36736/37248)\n",
      "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0506) | Acc: (98.61%) (37991/38528)\n",
      "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0507) | Acc: (98.60%) (39252/39808)\n",
      "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0509) | Acc: (98.60%) (40512/41088)\n",
      "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0510) | Acc: (98.59%) (41771/42368)\n",
      "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0511) | Acc: (98.59%) (43032/43648)\n",
      "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0511) | Acc: (98.59%) (44293/44928)\n",
      "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0509) | Acc: (98.60%) (45559/46208)\n",
      "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0513) | Acc: (98.58%) (46814/47488)\n",
      "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0514) | Acc: (98.57%) (48070/48768)\n",
      "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0515) | Acc: (98.56%) (49282/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3953) | Acc: (89.60%) (8960/10000)\n",
      "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0395) | Acc: (99.22%) (127/128)\n",
      "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0487) | Acc: (98.58%) (1388/1408)\n",
      "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0541) | Acc: (98.36%) (2644/2688)\n",
      "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0509) | Acc: (98.56%) (3911/3968)\n",
      "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0501) | Acc: (98.59%) (5174/5248)\n",
      "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0512) | Acc: (98.56%) (6434/6528)\n",
      "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0512) | Acc: (98.49%) (7690/7808)\n",
      "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0496) | Acc: (98.58%) (8959/9088)\n",
      "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0485) | Acc: (98.64%) (10227/10368)\n",
      "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0504) | Acc: (98.59%) (11484/11648)\n",
      "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0508) | Acc: (98.58%) (12744/12928)\n",
      "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0505) | Acc: (98.58%) (14006/14208)\n",
      "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0511) | Acc: (98.54%) (15262/15488)\n",
      "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0513) | Acc: (98.54%) (16524/16768)\n",
      "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0509) | Acc: (98.59%) (17793/18048)\n",
      "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0506) | Acc: (98.62%) (19061/19328)\n",
      "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0501) | Acc: (98.62%) (20323/20608)\n",
      "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0502) | Acc: (98.61%) (21584/21888)\n",
      "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0509) | Acc: (98.58%) (22840/23168)\n",
      "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0509) | Acc: (98.57%) (24098/24448)\n",
      "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0513) | Acc: (98.55%) (25356/25728)\n",
      "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0509) | Acc: (98.57%) (26623/27008)\n",
      "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0511) | Acc: (98.57%) (27883/28288)\n",
      "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0514) | Acc: (98.57%) (29144/29568)\n",
      "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0512) | Acc: (98.57%) (30407/30848)\n",
      "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0508) | Acc: (98.57%) (31670/32128)\n",
      "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0509) | Acc: (98.58%) (32935/33408)\n",
      "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0510) | Acc: (98.60%) (34203/34688)\n",
      "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0510) | Acc: (98.61%) (35469/35968)\n",
      "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0506) | Acc: (98.63%) (36736/37248)\n",
      "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0505) | Acc: (98.63%) (38001/38528)\n",
      "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0508) | Acc: (98.62%) (39260/39808)\n",
      "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0505) | Acc: (98.64%) (40529/41088)\n",
      "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0508) | Acc: (98.63%) (41789/42368)\n",
      "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0507) | Acc: (98.64%) (43054/43648)\n",
      "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0506) | Acc: (98.65%) (44322/44928)\n",
      "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0507) | Acc: (98.64%) (45581/46208)\n",
      "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0508) | Acc: (98.63%) (46839/47488)\n",
      "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0506) | Acc: (98.63%) (48100/48768)\n",
      "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0507) | Acc: (98.63%) (49314/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3956) | Acc: (89.71%) (8971/10000)\n",
      "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0586) | Acc: (98.44%) (126/128)\n",
      "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0442) | Acc: (98.72%) (1390/1408)\n",
      "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0495) | Acc: (98.47%) (2647/2688)\n",
      "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0500) | Acc: (98.51%) (3909/3968)\n",
      "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0504) | Acc: (98.49%) (5169/5248)\n",
      "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0506) | Acc: (98.51%) (6431/6528)\n",
      "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0497) | Acc: (98.57%) (7696/7808)\n",
      "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0519) | Acc: (98.48%) (8950/9088)\n",
      "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0520) | Acc: (98.50%) (10212/10368)\n",
      "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0512) | Acc: (98.56%) (11480/11648)\n",
      "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0503) | Acc: (98.56%) (12742/12928)\n",
      "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0503) | Acc: (98.59%) (14008/14208)\n",
      "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0495) | Acc: (98.63%) (15276/15488)\n",
      "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0497) | Acc: (98.57%) (16529/16768)\n",
      "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0495) | Acc: (98.59%) (17793/18048)\n",
      "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0494) | Acc: (98.57%) (19052/19328)\n",
      "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0495) | Acc: (98.59%) (20317/20608)\n",
      "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0498) | Acc: (98.59%) (21579/21888)\n",
      "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0492) | Acc: (98.63%) (22850/23168)\n",
      "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0497) | Acc: (98.62%) (24110/24448)\n",
      "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0496) | Acc: (98.64%) (25377/25728)\n",
      "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0502) | Acc: (98.62%) (26635/27008)\n",
      "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0505) | Acc: (98.61%) (27896/28288)\n",
      "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0508) | Acc: (98.60%) (29155/29568)\n",
      "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0508) | Acc: (98.60%) (30417/30848)\n",
      "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0509) | Acc: (98.60%) (31678/32128)\n",
      "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0506) | Acc: (98.62%) (32947/33408)\n",
      "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0508) | Acc: (98.62%) (34209/34688)\n",
      "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0507) | Acc: (98.63%) (35475/35968)\n",
      "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0508) | Acc: (98.63%) (36739/37248)\n",
      "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0505) | Acc: (98.64%) (38005/38528)\n",
      "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0503) | Acc: (98.65%) (39269/39808)\n",
      "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0501) | Acc: (98.65%) (40533/41088)\n",
      "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0501) | Acc: (98.65%) (41796/42368)\n",
      "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0499) | Acc: (98.66%) (43063/43648)\n",
      "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0499) | Acc: (98.65%) (44323/44928)\n",
      "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0500) | Acc: (98.65%) (45585/46208)\n",
      "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0496) | Acc: (98.67%) (46856/47488)\n",
      "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0495) | Acc: (98.67%) (48121/48768)\n",
      "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0494) | Acc: (98.67%) (49337/50000)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3958) | Acc: (89.58%) (8958/10000)\n",
      "4 hours 1 mins 7 secs for training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "root_dir = 'drive/app/cifar10/'\n",
    "default_directory = 'drive/app/torch/save_modelsResnet'\n",
    "\n",
    "# Data Augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
    "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "# automatically download\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
    "                                           num_workers=4)           # CPU loader number\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
    "                                          num_workers=4)            # CPU loader number\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4,\n",
    "                                nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")\n",
    "\n",
    "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "for epoch in range(start_epoch, 165):\n",
    "\n",
    "    if epoch < 80:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 120:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d7f0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
