{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8Ld93C0ZzKb",
    "outputId": "f2e321ac-2c40-4dab-d370-dfd46006f96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
    "start_time = time.time()\n",
    "batch_size = 30\n",
    "learning_rate = 0.001\n",
    "root_dir = 'drive/app/cifar10/'\n",
    "default_directory = 'drive/app/torch/save_modelsdensenet201'\n",
    "\n",
    "# Data Augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
    "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "# automatically download\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
    "                                           num_workers=4)           # CPU loader number\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
    "                                          num_workers=4)            # CPU loader number\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SzrJQw5AbQOz"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([out,x], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_planes)\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_planes = 2*growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n",
    "        num_planes += nblocks[0]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans1 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n",
    "        num_planes += nblocks[1]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans2 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n",
    "        num_planes += nblocks[2]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans3 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n",
    "        num_planes += nblocks[3]*growth_rate\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_planes)\n",
    "        self.linear = nn.Linear(num_planes, num_classes)\n",
    "\n",
    "    def _make_dense_layers(self, block, in_planes, nblock):\n",
    "        layers = []\n",
    "        for i in range(nblock):\n",
    "            layers.append(block(in_planes, self.growth_rate))\n",
    "            in_planes += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        out = self.dense4(out)\n",
    "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "#model = DenseNet() \n",
    "#def DenseNet201():\n",
    " #   return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\n",
    "\n",
    "model= DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNAdGYhQa_D0",
    "outputId": "ab413829-1a36-4bf7-8652-bb2d42bd301b"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE 1 GPUs!\n",
      "=> loading checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Batch_idx: 0 |  Loss: (1.1382) | Acc: (60.00%) (18/30)\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (1.1649) | Acc: (58.48%) (193/330)\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (1.1636) | Acc: (58.73%) (370/630)\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (1.1982) | Acc: (57.31%) (533/930)\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (1.2033) | Acc: (57.40%) (706/1230)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (1.2249) | Acc: (56.67%) (867/1530)\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (1.2239) | Acc: (56.99%) (1043/1830)\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (1.2422) | Acc: (56.34%) (1200/2130)\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (1.2362) | Acc: (56.34%) (1369/2430)\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (1.2407) | Acc: (56.04%) (1530/2730)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (1.2542) | Acc: (55.31%) (1676/3030)\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (1.2580) | Acc: (55.23%) (1839/3330)\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (1.2610) | Acc: (54.99%) (1996/3630)\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (1.2571) | Acc: (55.09%) (2165/3930)\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (1.2567) | Acc: (55.25%) (2337/4230)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (1.2561) | Acc: (55.23%) (2502/4530)\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (1.2535) | Acc: (55.32%) (2672/4830)\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (1.2544) | Acc: (55.15%) (2829/5130)\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (1.2528) | Acc: (55.08%) (2991/5430)\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (1.2524) | Acc: (55.13%) (3159/5730)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (1.2506) | Acc: (55.19%) (3328/6030)\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (1.2508) | Acc: (55.15%) (3491/6330)\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (1.2498) | Acc: (55.13%) (3655/6630)\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (1.2516) | Acc: (54.95%) (3808/6930)\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (1.2475) | Acc: (55.12%) (3985/7230)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (1.2416) | Acc: (55.30%) (4164/7530)\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (1.2429) | Acc: (55.21%) (4323/7830)\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (1.2458) | Acc: (55.12%) (4481/8130)\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (1.2442) | Acc: (55.20%) (4653/8430)\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (1.2446) | Acc: (55.23%) (4822/8730)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (1.2412) | Acc: (55.32%) (4995/9030)\n",
      "Epoch: 2 | Batch_idx: 310 |  Loss: (1.2419) | Acc: (55.27%) (5157/9330)\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (1.2429) | Acc: (55.29%) (5324/9630)\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (1.2413) | Acc: (55.45%) (5506/9930)\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (1.2412) | Acc: (55.45%) (5673/10230)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (1.2392) | Acc: (55.56%) (5850/10530)\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (1.2384) | Acc: (55.61%) (6023/10830)\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (1.2377) | Acc: (55.59%) (6187/11130)\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (1.2354) | Acc: (55.66%) (6362/11430)\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (1.2334) | Acc: (55.80%) (6545/11730)\n",
      "Epoch: 2 | Batch_idx: 400 |  Loss: (1.2311) | Acc: (55.93%) (6728/12030)\n",
      "Epoch: 2 | Batch_idx: 410 |  Loss: (1.2273) | Acc: (56.05%) (6911/12330)\n",
      "Epoch: 2 | Batch_idx: 420 |  Loss: (1.2276) | Acc: (56.06%) (7080/12630)\n",
      "Epoch: 2 | Batch_idx: 430 |  Loss: (1.2245) | Acc: (56.17%) (7263/12930)\n",
      "Epoch: 2 | Batch_idx: 440 |  Loss: (1.2224) | Acc: (56.24%) (7440/13230)\n",
      "Epoch: 2 | Batch_idx: 450 |  Loss: (1.2206) | Acc: (56.28%) (7615/13530)\n",
      "Epoch: 2 | Batch_idx: 460 |  Loss: (1.2179) | Acc: (56.33%) (7791/13830)\n",
      "Epoch: 2 | Batch_idx: 470 |  Loss: (1.2156) | Acc: (56.39%) (7968/14130)\n",
      "Epoch: 2 | Batch_idx: 480 |  Loss: (1.2144) | Acc: (56.42%) (8142/14430)\n",
      "Epoch: 2 | Batch_idx: 490 |  Loss: (1.2123) | Acc: (56.48%) (8320/14730)\n",
      "Epoch: 2 | Batch_idx: 500 |  Loss: (1.2116) | Acc: (56.49%) (8490/15030)\n",
      "Epoch: 2 | Batch_idx: 510 |  Loss: (1.2101) | Acc: (56.52%) (8664/15330)\n",
      "Epoch: 2 | Batch_idx: 520 |  Loss: (1.2077) | Acc: (56.60%) (8846/15630)\n",
      "Epoch: 2 | Batch_idx: 530 |  Loss: (1.2062) | Acc: (56.68%) (9029/15930)\n",
      "Epoch: 2 | Batch_idx: 540 |  Loss: (1.2040) | Acc: (56.78%) (9216/16230)\n",
      "Epoch: 2 | Batch_idx: 550 |  Loss: (1.2032) | Acc: (56.82%) (9393/16530)\n",
      "Epoch: 2 | Batch_idx: 560 |  Loss: (1.2004) | Acc: (56.98%) (9589/16830)\n",
      "Epoch: 2 | Batch_idx: 570 |  Loss: (1.1996) | Acc: (57.00%) (9764/17130)\n",
      "Epoch: 2 | Batch_idx: 580 |  Loss: (1.1984) | Acc: (57.10%) (9952/17430)\n",
      "Epoch: 2 | Batch_idx: 590 |  Loss: (1.1976) | Acc: (57.12%) (10128/17730)\n",
      "Epoch: 2 | Batch_idx: 600 |  Loss: (1.1952) | Acc: (57.19%) (10311/18030)\n",
      "Epoch: 2 | Batch_idx: 610 |  Loss: (1.1932) | Acc: (57.26%) (10495/18330)\n",
      "Epoch: 2 | Batch_idx: 620 |  Loss: (1.1907) | Acc: (57.34%) (10683/18630)\n",
      "Epoch: 2 | Batch_idx: 630 |  Loss: (1.1886) | Acc: (57.41%) (10867/18930)\n",
      "Epoch: 2 | Batch_idx: 640 |  Loss: (1.1858) | Acc: (57.55%) (11066/19230)\n",
      "Epoch: 2 | Batch_idx: 650 |  Loss: (1.1842) | Acc: (57.58%) (11245/19530)\n",
      "Epoch: 2 | Batch_idx: 660 |  Loss: (1.1834) | Acc: (57.57%) (11417/19830)\n",
      "Epoch: 2 | Batch_idx: 670 |  Loss: (1.1817) | Acc: (57.63%) (11601/20130)\n",
      "Epoch: 2 | Batch_idx: 680 |  Loss: (1.1802) | Acc: (57.68%) (11784/20430)\n",
      "Epoch: 2 | Batch_idx: 690 |  Loss: (1.1796) | Acc: (57.72%) (11965/20730)\n",
      "Epoch: 2 | Batch_idx: 700 |  Loss: (1.1790) | Acc: (57.76%) (12146/21030)\n",
      "Epoch: 2 | Batch_idx: 710 |  Loss: (1.1777) | Acc: (57.80%) (12328/21330)\n",
      "Epoch: 2 | Batch_idx: 720 |  Loss: (1.1760) | Acc: (57.86%) (12515/21630)\n",
      "Epoch: 2 | Batch_idx: 730 |  Loss: (1.1743) | Acc: (57.95%) (12708/21930)\n",
      "Epoch: 2 | Batch_idx: 740 |  Loss: (1.1728) | Acc: (57.98%) (12888/22230)\n",
      "Epoch: 2 | Batch_idx: 750 |  Loss: (1.1707) | Acc: (58.04%) (13077/22530)\n",
      "Epoch: 2 | Batch_idx: 760 |  Loss: (1.1704) | Acc: (58.04%) (13251/22830)\n",
      "Epoch: 2 | Batch_idx: 770 |  Loss: (1.1685) | Acc: (58.12%) (13442/23130)\n",
      "Epoch: 2 | Batch_idx: 780 |  Loss: (1.1668) | Acc: (58.22%) (13640/23430)\n",
      "Epoch: 2 | Batch_idx: 790 |  Loss: (1.1660) | Acc: (58.27%) (13828/23730)\n",
      "Epoch: 2 | Batch_idx: 800 |  Loss: (1.1641) | Acc: (58.34%) (14018/24030)\n",
      "Epoch: 2 | Batch_idx: 810 |  Loss: (1.1639) | Acc: (58.33%) (14191/24330)\n",
      "Epoch: 2 | Batch_idx: 820 |  Loss: (1.1632) | Acc: (58.36%) (14373/24630)\n",
      "Epoch: 2 | Batch_idx: 830 |  Loss: (1.1617) | Acc: (58.39%) (14556/24930)\n",
      "Epoch: 2 | Batch_idx: 840 |  Loss: (1.1599) | Acc: (58.48%) (14754/25230)\n",
      "Epoch: 2 | Batch_idx: 850 |  Loss: (1.1579) | Acc: (58.56%) (14950/25530)\n",
      "Epoch: 2 | Batch_idx: 860 |  Loss: (1.1558) | Acc: (58.62%) (15142/25830)\n",
      "Epoch: 2 | Batch_idx: 870 |  Loss: (1.1534) | Acc: (58.67%) (15330/26130)\n",
      "Epoch: 2 | Batch_idx: 880 |  Loss: (1.1527) | Acc: (58.71%) (15517/26430)\n",
      "Epoch: 2 | Batch_idx: 890 |  Loss: (1.1513) | Acc: (58.75%) (15704/26730)\n",
      "Epoch: 2 | Batch_idx: 900 |  Loss: (1.1493) | Acc: (58.83%) (15902/27030)\n",
      "Epoch: 2 | Batch_idx: 910 |  Loss: (1.1478) | Acc: (58.86%) (16087/27330)\n",
      "Epoch: 2 | Batch_idx: 920 |  Loss: (1.1464) | Acc: (58.89%) (16270/27630)\n",
      "Epoch: 2 | Batch_idx: 930 |  Loss: (1.1453) | Acc: (58.92%) (16457/27930)\n",
      "Epoch: 2 | Batch_idx: 940 |  Loss: (1.1436) | Acc: (58.98%) (16651/28230)\n",
      "Epoch: 2 | Batch_idx: 950 |  Loss: (1.1432) | Acc: (59.00%) (16833/28530)\n",
      "Epoch: 2 | Batch_idx: 960 |  Loss: (1.1419) | Acc: (59.05%) (17023/28830)\n",
      "Epoch: 2 | Batch_idx: 970 |  Loss: (1.1396) | Acc: (59.15%) (17230/29130)\n",
      "Epoch: 2 | Batch_idx: 980 |  Loss: (1.1390) | Acc: (59.15%) (17408/29430)\n",
      "Epoch: 2 | Batch_idx: 990 |  Loss: (1.1384) | Acc: (59.18%) (17595/29730)\n",
      "Epoch: 2 | Batch_idx: 1000 |  Loss: (1.1367) | Acc: (59.23%) (17786/30030)\n",
      "Epoch: 2 | Batch_idx: 1010 |  Loss: (1.1354) | Acc: (59.28%) (17979/30330)\n",
      "Epoch: 2 | Batch_idx: 1020 |  Loss: (1.1328) | Acc: (59.38%) (18188/30630)\n",
      "Epoch: 2 | Batch_idx: 1030 |  Loss: (1.1309) | Acc: (59.44%) (18386/30930)\n",
      "Epoch: 2 | Batch_idx: 1040 |  Loss: (1.1288) | Acc: (59.54%) (18595/31230)\n",
      "Epoch: 2 | Batch_idx: 1050 |  Loss: (1.1279) | Acc: (59.60%) (18793/31530)\n",
      "Epoch: 2 | Batch_idx: 1060 |  Loss: (1.1273) | Acc: (59.64%) (18984/31830)\n",
      "Epoch: 2 | Batch_idx: 1070 |  Loss: (1.1264) | Acc: (59.66%) (19170/32130)\n",
      "Epoch: 2 | Batch_idx: 1080 |  Loss: (1.1258) | Acc: (59.69%) (19356/32430)\n",
      "Epoch: 2 | Batch_idx: 1090 |  Loss: (1.1238) | Acc: (59.77%) (19564/32730)\n",
      "Epoch: 2 | Batch_idx: 1100 |  Loss: (1.1236) | Acc: (59.77%) (19743/33030)\n",
      "Epoch: 2 | Batch_idx: 1110 |  Loss: (1.1232) | Acc: (59.76%) (19918/33330)\n",
      "Epoch: 2 | Batch_idx: 1120 |  Loss: (1.1221) | Acc: (59.81%) (20113/33630)\n",
      "Epoch: 2 | Batch_idx: 1130 |  Loss: (1.1213) | Acc: (59.84%) (20305/33930)\n",
      "Epoch: 2 | Batch_idx: 1140 |  Loss: (1.1207) | Acc: (59.89%) (20502/34230)\n",
      "Epoch: 2 | Batch_idx: 1150 |  Loss: (1.1194) | Acc: (59.95%) (20702/34530)\n",
      "Epoch: 2 | Batch_idx: 1160 |  Loss: (1.1180) | Acc: (60.02%) (20906/34830)\n",
      "Epoch: 2 | Batch_idx: 1170 |  Loss: (1.1173) | Acc: (60.06%) (21098/35130)\n",
      "Epoch: 2 | Batch_idx: 1180 |  Loss: (1.1149) | Acc: (60.14%) (21307/35430)\n",
      "Epoch: 2 | Batch_idx: 1190 |  Loss: (1.1131) | Acc: (60.22%) (21515/35730)\n",
      "Epoch: 2 | Batch_idx: 1200 |  Loss: (1.1117) | Acc: (60.26%) (21711/36030)\n",
      "Epoch: 2 | Batch_idx: 1210 |  Loss: (1.1098) | Acc: (60.33%) (21918/36330)\n",
      "Epoch: 2 | Batch_idx: 1220 |  Loss: (1.1085) | Acc: (60.38%) (22118/36630)\n",
      "Epoch: 2 | Batch_idx: 1230 |  Loss: (1.1072) | Acc: (60.42%) (22312/36930)\n",
      "Epoch: 2 | Batch_idx: 1240 |  Loss: (1.1060) | Acc: (60.45%) (22504/37230)\n",
      "Epoch: 2 | Batch_idx: 1250 |  Loss: (1.1043) | Acc: (60.51%) (22709/37530)\n",
      "Epoch: 2 | Batch_idx: 1260 |  Loss: (1.1033) | Acc: (60.55%) (22905/37830)\n",
      "Epoch: 2 | Batch_idx: 1270 |  Loss: (1.1014) | Acc: (60.61%) (23112/38130)\n",
      "Epoch: 2 | Batch_idx: 1280 |  Loss: (1.1005) | Acc: (60.68%) (23319/38430)\n",
      "Epoch: 2 | Batch_idx: 1290 |  Loss: (1.0995) | Acc: (60.71%) (23513/38730)\n",
      "Epoch: 2 | Batch_idx: 1300 |  Loss: (1.0991) | Acc: (60.72%) (23699/39030)\n",
      "Epoch: 2 | Batch_idx: 1310 |  Loss: (1.0976) | Acc: (60.75%) (23893/39330)\n",
      "Epoch: 2 | Batch_idx: 1320 |  Loss: (1.0976) | Acc: (60.74%) (24073/39630)\n",
      "Epoch: 2 | Batch_idx: 1330 |  Loss: (1.0961) | Acc: (60.81%) (24281/39930)\n",
      "Epoch: 2 | Batch_idx: 1340 |  Loss: (1.0949) | Acc: (60.85%) (24481/40230)\n",
      "Epoch: 2 | Batch_idx: 1350 |  Loss: (1.0937) | Acc: (60.88%) (24675/40530)\n",
      "Epoch: 2 | Batch_idx: 1360 |  Loss: (1.0929) | Acc: (60.90%) (24866/40830)\n",
      "Epoch: 2 | Batch_idx: 1370 |  Loss: (1.0920) | Acc: (60.93%) (25062/41130)\n",
      "Epoch: 2 | Batch_idx: 1380 |  Loss: (1.0905) | Acc: (61.00%) (25273/41430)\n",
      "Epoch: 2 | Batch_idx: 1390 |  Loss: (1.0892) | Acc: (61.10%) (25495/41730)\n",
      "Epoch: 2 | Batch_idx: 1400 |  Loss: (1.0872) | Acc: (61.17%) (25709/42030)\n",
      "Epoch: 2 | Batch_idx: 1410 |  Loss: (1.0857) | Acc: (61.21%) (25911/42330)\n",
      "Epoch: 2 | Batch_idx: 1420 |  Loss: (1.0849) | Acc: (61.24%) (26107/42630)\n",
      "Epoch: 2 | Batch_idx: 1430 |  Loss: (1.0842) | Acc: (61.25%) (26296/42930)\n",
      "Epoch: 2 | Batch_idx: 1440 |  Loss: (1.0828) | Acc: (61.29%) (26497/43230)\n",
      "Epoch: 2 | Batch_idx: 1450 |  Loss: (1.0814) | Acc: (61.35%) (26707/43530)\n",
      "Epoch: 2 | Batch_idx: 1460 |  Loss: (1.0801) | Acc: (61.39%) (26907/43830)\n",
      "Epoch: 2 | Batch_idx: 1470 |  Loss: (1.0789) | Acc: (61.43%) (27111/44130)\n",
      "Epoch: 2 | Batch_idx: 1480 |  Loss: (1.0786) | Acc: (61.45%) (27302/44430)\n",
      "Epoch: 2 | Batch_idx: 1490 |  Loss: (1.0782) | Acc: (61.48%) (27498/44730)\n",
      "Epoch: 2 | Batch_idx: 1500 |  Loss: (1.0773) | Acc: (61.52%) (27703/45030)\n",
      "Epoch: 2 | Batch_idx: 1510 |  Loss: (1.0773) | Acc: (61.53%) (27892/45330)\n",
      "Epoch: 2 | Batch_idx: 1520 |  Loss: (1.0759) | Acc: (61.57%) (28094/45630)\n",
      "Epoch: 2 | Batch_idx: 1530 |  Loss: (1.0738) | Acc: (61.64%) (28311/45930)\n",
      "Epoch: 2 | Batch_idx: 1540 |  Loss: (1.0731) | Acc: (61.67%) (28508/46230)\n",
      "Epoch: 2 | Batch_idx: 1550 |  Loss: (1.0727) | Acc: (61.69%) (28704/46530)\n",
      "Epoch: 2 | Batch_idx: 1560 |  Loss: (1.0717) | Acc: (61.73%) (28910/46830)\n",
      "Epoch: 2 | Batch_idx: 1570 |  Loss: (1.0701) | Acc: (61.79%) (29121/47130)\n",
      "Epoch: 2 | Batch_idx: 1580 |  Loss: (1.0683) | Acc: (61.87%) (29346/47430)\n",
      "Epoch: 2 | Batch_idx: 1590 |  Loss: (1.0669) | Acc: (61.92%) (29553/47730)\n",
      "Epoch: 2 | Batch_idx: 1600 |  Loss: (1.0662) | Acc: (61.96%) (29758/48030)\n",
      "Epoch: 2 | Batch_idx: 1610 |  Loss: (1.0652) | Acc: (62.00%) (29965/48330)\n",
      "Epoch: 2 | Batch_idx: 1620 |  Loss: (1.0641) | Acc: (62.03%) (30163/48630)\n",
      "Epoch: 2 | Batch_idx: 1630 |  Loss: (1.0634) | Acc: (62.06%) (30368/48930)\n",
      "Epoch: 2 | Batch_idx: 1640 |  Loss: (1.0622) | Acc: (62.11%) (30577/49230)\n",
      "Epoch: 2 | Batch_idx: 1650 |  Loss: (1.0620) | Acc: (62.14%) (30776/49530)\n",
      "Epoch: 2 | Batch_idx: 1660 |  Loss: (1.0611) | Acc: (62.17%) (30980/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.8219) | Acc: (70.94%) (7094/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (0.6918) | Acc: (76.67%) (23/30)\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (0.9203) | Acc: (68.48%) (226/330)\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (0.9094) | Acc: (68.73%) (433/630)\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (0.8680) | Acc: (71.51%) (665/930)\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (0.8612) | Acc: (71.22%) (876/1230)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (0.8471) | Acc: (71.44%) (1093/1530)\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (0.8549) | Acc: (70.82%) (1296/1830)\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (0.8398) | Acc: (71.22%) (1517/2130)\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (0.8313) | Acc: (71.60%) (1740/2430)\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (0.8324) | Acc: (71.36%) (1948/2730)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (0.8330) | Acc: (71.49%) (2166/3030)\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (0.8278) | Acc: (71.53%) (2382/3330)\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (0.8296) | Acc: (71.54%) (2597/3630)\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (0.8367) | Acc: (71.27%) (2801/3930)\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (0.8473) | Acc: (70.97%) (3002/4230)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (0.8500) | Acc: (70.75%) (3205/4530)\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (0.8533) | Acc: (70.54%) (3407/4830)\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (0.8513) | Acc: (70.62%) (3623/5130)\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (0.8514) | Acc: (70.64%) (3836/5430)\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (0.8523) | Acc: (70.49%) (4039/5730)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (0.8484) | Acc: (70.75%) (4266/6030)\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (0.8466) | Acc: (70.82%) (4483/6330)\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (0.8429) | Acc: (70.90%) (4701/6630)\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (0.8418) | Acc: (70.89%) (4913/6930)\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (0.8408) | Acc: (70.77%) (5117/7230)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (0.8386) | Acc: (70.78%) (5330/7530)\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (0.8396) | Acc: (70.68%) (5534/7830)\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (0.8429) | Acc: (70.65%) (5744/8130)\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (0.8427) | Acc: (70.60%) (5952/8430)\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (0.8426) | Acc: (70.54%) (6158/8730)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (0.8427) | Acc: (70.49%) (6365/9030)\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (0.8376) | Acc: (70.70%) (6596/9330)\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (0.8361) | Acc: (70.67%) (6806/9630)\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (0.8374) | Acc: (70.74%) (7024/9930)\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (0.8375) | Acc: (70.79%) (7242/10230)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (0.8356) | Acc: (70.79%) (7454/10530)\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (0.8345) | Acc: (70.87%) (7675/10830)\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (0.8338) | Acc: (70.93%) (7895/11130)\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (0.8313) | Acc: (70.99%) (8114/11430)\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (0.8307) | Acc: (71.02%) (8331/11730)\n",
      "Epoch: 3 | Batch_idx: 400 |  Loss: (0.8332) | Acc: (70.84%) (8522/12030)\n",
      "Epoch: 3 | Batch_idx: 410 |  Loss: (0.8381) | Acc: (70.70%) (8717/12330)\n",
      "Epoch: 3 | Batch_idx: 420 |  Loss: (0.8375) | Acc: (70.65%) (8923/12630)\n",
      "Epoch: 3 | Batch_idx: 430 |  Loss: (0.8378) | Acc: (70.67%) (9137/12930)\n",
      "Epoch: 3 | Batch_idx: 440 |  Loss: (0.8360) | Acc: (70.70%) (9354/13230)\n",
      "Epoch: 3 | Batch_idx: 450 |  Loss: (0.8383) | Acc: (70.58%) (9549/13530)\n",
      "Epoch: 3 | Batch_idx: 460 |  Loss: (0.8387) | Acc: (70.56%) (9758/13830)\n",
      "Epoch: 3 | Batch_idx: 470 |  Loss: (0.8382) | Acc: (70.56%) (9970/14130)\n",
      "Epoch: 3 | Batch_idx: 480 |  Loss: (0.8385) | Acc: (70.57%) (10183/14430)\n",
      "Epoch: 3 | Batch_idx: 490 |  Loss: (0.8355) | Acc: (70.71%) (10416/14730)\n",
      "Epoch: 3 | Batch_idx: 500 |  Loss: (0.8340) | Acc: (70.77%) (10637/15030)\n",
      "Epoch: 3 | Batch_idx: 510 |  Loss: (0.8323) | Acc: (70.86%) (10863/15330)\n",
      "Epoch: 3 | Batch_idx: 520 |  Loss: (0.8300) | Acc: (70.91%) (11084/15630)\n",
      "Epoch: 3 | Batch_idx: 530 |  Loss: (0.8311) | Acc: (70.87%) (11289/15930)\n",
      "Epoch: 3 | Batch_idx: 540 |  Loss: (0.8293) | Acc: (70.89%) (11506/16230)\n",
      "Epoch: 3 | Batch_idx: 550 |  Loss: (0.8277) | Acc: (70.97%) (11731/16530)\n",
      "Epoch: 3 | Batch_idx: 560 |  Loss: (0.8270) | Acc: (70.94%) (11939/16830)\n",
      "Epoch: 3 | Batch_idx: 570 |  Loss: (0.8260) | Acc: (71.00%) (12162/17130)\n",
      "Epoch: 3 | Batch_idx: 580 |  Loss: (0.8257) | Acc: (70.95%) (12367/17430)\n",
      "Epoch: 3 | Batch_idx: 590 |  Loss: (0.8257) | Acc: (70.95%) (12579/17730)\n",
      "Epoch: 3 | Batch_idx: 600 |  Loss: (0.8249) | Acc: (70.95%) (12793/18030)\n",
      "Epoch: 3 | Batch_idx: 610 |  Loss: (0.8255) | Acc: (70.95%) (13006/18330)\n",
      "Epoch: 3 | Batch_idx: 620 |  Loss: (0.8265) | Acc: (70.90%) (13208/18630)\n",
      "Epoch: 3 | Batch_idx: 630 |  Loss: (0.8264) | Acc: (70.88%) (13418/18930)\n",
      "Epoch: 3 | Batch_idx: 640 |  Loss: (0.8271) | Acc: (70.88%) (13631/19230)\n",
      "Epoch: 3 | Batch_idx: 650 |  Loss: (0.8267) | Acc: (70.87%) (13840/19530)\n",
      "Epoch: 3 | Batch_idx: 660 |  Loss: (0.8266) | Acc: (70.88%) (14055/19830)\n",
      "Epoch: 3 | Batch_idx: 670 |  Loss: (0.8272) | Acc: (70.89%) (14271/20130)\n",
      "Epoch: 3 | Batch_idx: 680 |  Loss: (0.8264) | Acc: (70.92%) (14488/20430)\n",
      "Epoch: 3 | Batch_idx: 690 |  Loss: (0.8256) | Acc: (70.96%) (14711/20730)\n",
      "Epoch: 3 | Batch_idx: 700 |  Loss: (0.8249) | Acc: (71.03%) (14938/21030)\n",
      "Epoch: 3 | Batch_idx: 710 |  Loss: (0.8250) | Acc: (71.07%) (15160/21330)\n",
      "Epoch: 3 | Batch_idx: 720 |  Loss: (0.8237) | Acc: (71.11%) (15381/21630)\n",
      "Epoch: 3 | Batch_idx: 730 |  Loss: (0.8225) | Acc: (71.13%) (15598/21930)\n",
      "Epoch: 3 | Batch_idx: 740 |  Loss: (0.8232) | Acc: (71.08%) (15800/22230)\n",
      "Epoch: 3 | Batch_idx: 750 |  Loss: (0.8222) | Acc: (71.13%) (16026/22530)\n",
      "Epoch: 3 | Batch_idx: 760 |  Loss: (0.8228) | Acc: (71.14%) (16241/22830)\n",
      "Epoch: 3 | Batch_idx: 770 |  Loss: (0.8222) | Acc: (71.12%) (16450/23130)\n",
      "Epoch: 3 | Batch_idx: 780 |  Loss: (0.8222) | Acc: (71.12%) (16664/23430)\n",
      "Epoch: 3 | Batch_idx: 790 |  Loss: (0.8214) | Acc: (71.16%) (16887/23730)\n",
      "Epoch: 3 | Batch_idx: 800 |  Loss: (0.8199) | Acc: (71.21%) (17111/24030)\n",
      "Epoch: 3 | Batch_idx: 810 |  Loss: (0.8196) | Acc: (71.23%) (17331/24330)\n",
      "Epoch: 3 | Batch_idx: 820 |  Loss: (0.8184) | Acc: (71.26%) (17552/24630)\n",
      "Epoch: 3 | Batch_idx: 830 |  Loss: (0.8175) | Acc: (71.32%) (17781/24930)\n",
      "Epoch: 3 | Batch_idx: 840 |  Loss: (0.8162) | Acc: (71.35%) (18001/25230)\n",
      "Epoch: 3 | Batch_idx: 850 |  Loss: (0.8152) | Acc: (71.39%) (18226/25530)\n",
      "Epoch: 3 | Batch_idx: 860 |  Loss: (0.8139) | Acc: (71.43%) (18451/25830)\n",
      "Epoch: 3 | Batch_idx: 870 |  Loss: (0.8133) | Acc: (71.43%) (18664/26130)\n",
      "Epoch: 3 | Batch_idx: 880 |  Loss: (0.8135) | Acc: (71.40%) (18871/26430)\n",
      "Epoch: 3 | Batch_idx: 890 |  Loss: (0.8118) | Acc: (71.48%) (19107/26730)\n",
      "Epoch: 3 | Batch_idx: 900 |  Loss: (0.8113) | Acc: (71.53%) (19334/27030)\n",
      "Epoch: 3 | Batch_idx: 910 |  Loss: (0.8105) | Acc: (71.57%) (19560/27330)\n",
      "Epoch: 3 | Batch_idx: 920 |  Loss: (0.8092) | Acc: (71.60%) (19782/27630)\n",
      "Epoch: 3 | Batch_idx: 930 |  Loss: (0.8081) | Acc: (71.66%) (20015/27930)\n",
      "Epoch: 3 | Batch_idx: 940 |  Loss: (0.8070) | Acc: (71.71%) (20243/28230)\n",
      "Epoch: 3 | Batch_idx: 950 |  Loss: (0.8072) | Acc: (71.73%) (20465/28530)\n",
      "Epoch: 3 | Batch_idx: 960 |  Loss: (0.8064) | Acc: (71.73%) (20680/28830)\n",
      "Epoch: 3 | Batch_idx: 970 |  Loss: (0.8068) | Acc: (71.72%) (20892/29130)\n",
      "Epoch: 3 | Batch_idx: 980 |  Loss: (0.8049) | Acc: (71.78%) (21124/29430)\n",
      "Epoch: 3 | Batch_idx: 990 |  Loss: (0.8042) | Acc: (71.81%) (21350/29730)\n",
      "Epoch: 3 | Batch_idx: 1000 |  Loss: (0.8046) | Acc: (71.80%) (21563/30030)\n",
      "Epoch: 3 | Batch_idx: 1010 |  Loss: (0.8034) | Acc: (71.86%) (21795/30330)\n",
      "Epoch: 3 | Batch_idx: 1020 |  Loss: (0.8031) | Acc: (71.87%) (22013/30630)\n",
      "Epoch: 3 | Batch_idx: 1030 |  Loss: (0.8013) | Acc: (71.94%) (22252/30930)\n",
      "Epoch: 3 | Batch_idx: 1040 |  Loss: (0.8002) | Acc: (71.99%) (22481/31230)\n",
      "Epoch: 3 | Batch_idx: 1050 |  Loss: (0.8000) | Acc: (71.98%) (22696/31530)\n",
      "Epoch: 3 | Batch_idx: 1060 |  Loss: (0.7993) | Acc: (72.00%) (22917/31830)\n",
      "Epoch: 3 | Batch_idx: 1070 |  Loss: (0.7979) | Acc: (72.06%) (23152/32130)\n",
      "Epoch: 3 | Batch_idx: 1080 |  Loss: (0.7963) | Acc: (72.12%) (23387/32430)\n",
      "Epoch: 3 | Batch_idx: 1090 |  Loss: (0.7964) | Acc: (72.13%) (23608/32730)\n",
      "Epoch: 3 | Batch_idx: 1100 |  Loss: (0.7958) | Acc: (72.15%) (23830/33030)\n",
      "Epoch: 3 | Batch_idx: 1110 |  Loss: (0.7948) | Acc: (72.19%) (24062/33330)\n",
      "Epoch: 3 | Batch_idx: 1120 |  Loss: (0.7935) | Acc: (72.22%) (24287/33630)\n",
      "Epoch: 3 | Batch_idx: 1130 |  Loss: (0.7924) | Acc: (72.24%) (24512/33930)\n",
      "Epoch: 3 | Batch_idx: 1140 |  Loss: (0.7916) | Acc: (72.26%) (24735/34230)\n",
      "Epoch: 3 | Batch_idx: 1150 |  Loss: (0.7917) | Acc: (72.24%) (24944/34530)\n",
      "Epoch: 3 | Batch_idx: 1160 |  Loss: (0.7913) | Acc: (72.25%) (25166/34830)\n",
      "Epoch: 3 | Batch_idx: 1170 |  Loss: (0.7907) | Acc: (72.28%) (25393/35130)\n",
      "Epoch: 3 | Batch_idx: 1180 |  Loss: (0.7903) | Acc: (72.28%) (25609/35430)\n",
      "Epoch: 3 | Batch_idx: 1190 |  Loss: (0.7887) | Acc: (72.35%) (25851/35730)\n",
      "Epoch: 3 | Batch_idx: 1200 |  Loss: (0.7875) | Acc: (72.40%) (26084/36030)\n",
      "Epoch: 3 | Batch_idx: 1210 |  Loss: (0.7876) | Acc: (72.41%) (26308/36330)\n",
      "Epoch: 3 | Batch_idx: 1220 |  Loss: (0.7870) | Acc: (72.45%) (26539/36630)\n",
      "Epoch: 3 | Batch_idx: 1230 |  Loss: (0.7859) | Acc: (72.48%) (26767/36930)\n",
      "Epoch: 3 | Batch_idx: 1240 |  Loss: (0.7849) | Acc: (72.51%) (26997/37230)\n",
      "Epoch: 3 | Batch_idx: 1250 |  Loss: (0.7848) | Acc: (72.50%) (27211/37530)\n",
      "Epoch: 3 | Batch_idx: 1260 |  Loss: (0.7844) | Acc: (72.53%) (27437/37830)\n",
      "Epoch: 3 | Batch_idx: 1270 |  Loss: (0.7837) | Acc: (72.54%) (27660/38130)\n",
      "Epoch: 3 | Batch_idx: 1280 |  Loss: (0.7835) | Acc: (72.54%) (27878/38430)\n",
      "Epoch: 3 | Batch_idx: 1290 |  Loss: (0.7831) | Acc: (72.58%) (28110/38730)\n",
      "Epoch: 3 | Batch_idx: 1300 |  Loss: (0.7822) | Acc: (72.63%) (28347/39030)\n",
      "Epoch: 3 | Batch_idx: 1310 |  Loss: (0.7818) | Acc: (72.64%) (28568/39330)\n",
      "Epoch: 3 | Batch_idx: 1320 |  Loss: (0.7817) | Acc: (72.64%) (28788/39630)\n",
      "Epoch: 3 | Batch_idx: 1330 |  Loss: (0.7810) | Acc: (72.65%) (29010/39930)\n",
      "Epoch: 3 | Batch_idx: 1340 |  Loss: (0.7807) | Acc: (72.66%) (29233/40230)\n",
      "Epoch: 3 | Batch_idx: 1350 |  Loss: (0.7800) | Acc: (72.70%) (29466/40530)\n",
      "Epoch: 3 | Batch_idx: 1360 |  Loss: (0.7798) | Acc: (72.71%) (29687/40830)\n",
      "Epoch: 3 | Batch_idx: 1370 |  Loss: (0.7789) | Acc: (72.76%) (29925/41130)\n",
      "Epoch: 3 | Batch_idx: 1380 |  Loss: (0.7784) | Acc: (72.78%) (30151/41430)\n",
      "Epoch: 3 | Batch_idx: 1390 |  Loss: (0.7781) | Acc: (72.80%) (30378/41730)\n",
      "Epoch: 3 | Batch_idx: 1400 |  Loss: (0.7784) | Acc: (72.80%) (30597/42030)\n",
      "Epoch: 3 | Batch_idx: 1410 |  Loss: (0.7777) | Acc: (72.81%) (30819/42330)\n",
      "Epoch: 3 | Batch_idx: 1420 |  Loss: (0.7775) | Acc: (72.81%) (31041/42630)\n",
      "Epoch: 3 | Batch_idx: 1430 |  Loss: (0.7783) | Acc: (72.81%) (31257/42930)\n",
      "Epoch: 3 | Batch_idx: 1440 |  Loss: (0.7781) | Acc: (72.82%) (31481/43230)\n",
      "Epoch: 3 | Batch_idx: 1450 |  Loss: (0.7773) | Acc: (72.86%) (31716/43530)\n",
      "Epoch: 3 | Batch_idx: 1460 |  Loss: (0.7764) | Acc: (72.89%) (31949/43830)\n",
      "Epoch: 3 | Batch_idx: 1470 |  Loss: (0.7760) | Acc: (72.91%) (32175/44130)\n",
      "Epoch: 3 | Batch_idx: 1480 |  Loss: (0.7752) | Acc: (72.94%) (32407/44430)\n",
      "Epoch: 3 | Batch_idx: 1490 |  Loss: (0.7746) | Acc: (72.96%) (32636/44730)\n",
      "Epoch: 3 | Batch_idx: 1500 |  Loss: (0.7740) | Acc: (72.98%) (32863/45030)\n",
      "Epoch: 3 | Batch_idx: 1510 |  Loss: (0.7733) | Acc: (72.99%) (33088/45330)\n",
      "Epoch: 3 | Batch_idx: 1520 |  Loss: (0.7736) | Acc: (73.00%) (33309/45630)\n",
      "Epoch: 3 | Batch_idx: 1530 |  Loss: (0.7732) | Acc: (73.03%) (33541/45930)\n",
      "Epoch: 3 | Batch_idx: 1540 |  Loss: (0.7728) | Acc: (73.05%) (33770/46230)\n",
      "Epoch: 3 | Batch_idx: 1550 |  Loss: (0.7726) | Acc: (73.05%) (33992/46530)\n",
      "Epoch: 3 | Batch_idx: 1560 |  Loss: (0.7725) | Acc: (73.06%) (34215/46830)\n",
      "Epoch: 3 | Batch_idx: 1570 |  Loss: (0.7716) | Acc: (73.09%) (34445/47130)\n",
      "Epoch: 3 | Batch_idx: 1580 |  Loss: (0.7713) | Acc: (73.10%) (34673/47430)\n",
      "Epoch: 3 | Batch_idx: 1590 |  Loss: (0.7709) | Acc: (73.13%) (34903/47730)\n",
      "Epoch: 3 | Batch_idx: 1600 |  Loss: (0.7699) | Acc: (73.16%) (35138/48030)\n",
      "Epoch: 3 | Batch_idx: 1610 |  Loss: (0.7694) | Acc: (73.19%) (35373/48330)\n",
      "Epoch: 3 | Batch_idx: 1620 |  Loss: (0.7692) | Acc: (73.20%) (35596/48630)\n",
      "Epoch: 3 | Batch_idx: 1630 |  Loss: (0.7684) | Acc: (73.23%) (35829/48930)\n",
      "Epoch: 3 | Batch_idx: 1640 |  Loss: (0.7679) | Acc: (73.25%) (36062/49230)\n",
      "Epoch: 3 | Batch_idx: 1650 |  Loss: (0.7676) | Acc: (73.26%) (36288/49530)\n",
      "Epoch: 3 | Batch_idx: 1660 |  Loss: (0.7672) | Acc: (73.29%) (36522/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.6470) | Acc: (77.83%) (7783/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (0.5538) | Acc: (76.67%) (23/30)\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (0.6910) | Acc: (76.97%) (254/330)\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (0.6765) | Acc: (76.67%) (483/630)\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (0.7072) | Acc: (75.38%) (701/930)\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (0.7189) | Acc: (75.45%) (928/1230)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (0.6936) | Acc: (76.21%) (1166/1530)\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (0.6913) | Acc: (76.17%) (1394/1830)\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (0.6946) | Acc: (75.68%) (1612/2130)\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (0.6948) | Acc: (75.84%) (1843/2430)\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (0.6841) | Acc: (76.01%) (2075/2730)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (0.6781) | Acc: (76.20%) (2309/3030)\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (0.6725) | Acc: (76.49%) (2547/3330)\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (0.6707) | Acc: (76.72%) (2785/3630)\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (0.6674) | Acc: (76.90%) (3022/3930)\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (0.6689) | Acc: (76.62%) (3241/4230)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (0.6740) | Acc: (76.53%) (3467/4530)\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (0.6677) | Acc: (76.67%) (3703/4830)\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (0.6620) | Acc: (76.90%) (3945/5130)\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (0.6588) | Acc: (77.03%) (4183/5430)\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (0.6584) | Acc: (77.16%) (4421/5730)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (0.6538) | Acc: (77.26%) (4659/6030)\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (0.6501) | Acc: (77.31%) (4894/6330)\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (0.6497) | Acc: (77.35%) (5128/6630)\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (0.6498) | Acc: (77.34%) (5360/6930)\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (0.6514) | Acc: (77.39%) (5595/7230)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (0.6525) | Acc: (77.22%) (5815/7530)\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (0.6488) | Acc: (77.33%) (6055/7830)\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (0.6494) | Acc: (77.20%) (6276/8130)\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (0.6471) | Acc: (77.28%) (6515/8430)\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (0.6462) | Acc: (77.33%) (6751/8730)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (0.6404) | Acc: (77.49%) (6997/9030)\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (0.6424) | Acc: (77.41%) (7222/9330)\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (0.6438) | Acc: (77.31%) (7445/9630)\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (0.6443) | Acc: (77.38%) (7684/9930)\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (0.6461) | Acc: (77.36%) (7914/10230)\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (0.6455) | Acc: (77.41%) (8151/10530)\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (0.6455) | Acc: (77.46%) (8389/10830)\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (0.6453) | Acc: (77.44%) (8619/11130)\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (0.6463) | Acc: (77.43%) (8850/11430)\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (0.6465) | Acc: (77.38%) (9077/11730)\n",
      "Epoch: 4 | Batch_idx: 400 |  Loss: (0.6449) | Acc: (77.46%) (9319/12030)\n",
      "Epoch: 4 | Batch_idx: 410 |  Loss: (0.6442) | Acc: (77.49%) (9555/12330)\n",
      "Epoch: 4 | Batch_idx: 420 |  Loss: (0.6432) | Acc: (77.49%) (9787/12630)\n",
      "Epoch: 4 | Batch_idx: 430 |  Loss: (0.6448) | Acc: (77.42%) (10011/12930)\n",
      "Epoch: 4 | Batch_idx: 440 |  Loss: (0.6434) | Acc: (77.41%) (10242/13230)\n",
      "Epoch: 4 | Batch_idx: 450 |  Loss: (0.6432) | Acc: (77.40%) (10472/13530)\n",
      "Epoch: 4 | Batch_idx: 460 |  Loss: (0.6425) | Acc: (77.38%) (10702/13830)\n",
      "Epoch: 4 | Batch_idx: 470 |  Loss: (0.6423) | Acc: (77.37%) (10932/14130)\n",
      "Epoch: 4 | Batch_idx: 480 |  Loss: (0.6414) | Acc: (77.42%) (11172/14430)\n",
      "Epoch: 4 | Batch_idx: 490 |  Loss: (0.6414) | Acc: (77.45%) (11409/14730)\n",
      "Epoch: 4 | Batch_idx: 500 |  Loss: (0.6394) | Acc: (77.49%) (11647/15030)\n",
      "Epoch: 4 | Batch_idx: 510 |  Loss: (0.6380) | Acc: (77.52%) (11884/15330)\n",
      "Epoch: 4 | Batch_idx: 520 |  Loss: (0.6362) | Acc: (77.58%) (12126/15630)\n",
      "Epoch: 4 | Batch_idx: 530 |  Loss: (0.6363) | Acc: (77.62%) (12365/15930)\n",
      "Epoch: 4 | Batch_idx: 540 |  Loss: (0.6359) | Acc: (77.64%) (12601/16230)\n",
      "Epoch: 4 | Batch_idx: 550 |  Loss: (0.6347) | Acc: (77.66%) (12837/16530)\n",
      "Epoch: 4 | Batch_idx: 560 |  Loss: (0.6342) | Acc: (77.67%) (13072/16830)\n",
      "Epoch: 4 | Batch_idx: 570 |  Loss: (0.6344) | Acc: (77.69%) (13309/17130)\n",
      "Epoch: 4 | Batch_idx: 580 |  Loss: (0.6334) | Acc: (77.73%) (13549/17430)\n",
      "Epoch: 4 | Batch_idx: 590 |  Loss: (0.6322) | Acc: (77.81%) (13795/17730)\n",
      "Epoch: 4 | Batch_idx: 600 |  Loss: (0.6315) | Acc: (77.83%) (14032/18030)\n",
      "Epoch: 4 | Batch_idx: 610 |  Loss: (0.6310) | Acc: (77.86%) (14271/18330)\n",
      "Epoch: 4 | Batch_idx: 620 |  Loss: (0.6330) | Acc: (77.80%) (14494/18630)\n",
      "Epoch: 4 | Batch_idx: 630 |  Loss: (0.6333) | Acc: (77.81%) (14729/18930)\n",
      "Epoch: 4 | Batch_idx: 640 |  Loss: (0.6339) | Acc: (77.79%) (14959/19230)\n",
      "Epoch: 4 | Batch_idx: 650 |  Loss: (0.6327) | Acc: (77.79%) (15193/19530)\n",
      "Epoch: 4 | Batch_idx: 660 |  Loss: (0.6328) | Acc: (77.82%) (15431/19830)\n",
      "Epoch: 4 | Batch_idx: 670 |  Loss: (0.6321) | Acc: (77.84%) (15669/20130)\n",
      "Epoch: 4 | Batch_idx: 680 |  Loss: (0.6320) | Acc: (77.85%) (15904/20430)\n",
      "Epoch: 4 | Batch_idx: 690 |  Loss: (0.6315) | Acc: (77.87%) (16142/20730)\n",
      "Epoch: 4 | Batch_idx: 700 |  Loss: (0.6329) | Acc: (77.82%) (16366/21030)\n",
      "Epoch: 4 | Batch_idx: 710 |  Loss: (0.6336) | Acc: (77.75%) (16585/21330)\n",
      "Epoch: 4 | Batch_idx: 720 |  Loss: (0.6325) | Acc: (77.82%) (16833/21630)\n",
      "Epoch: 4 | Batch_idx: 730 |  Loss: (0.6327) | Acc: (77.81%) (17063/21930)\n",
      "Epoch: 4 | Batch_idx: 740 |  Loss: (0.6327) | Acc: (77.80%) (17296/22230)\n",
      "Epoch: 4 | Batch_idx: 750 |  Loss: (0.6326) | Acc: (77.79%) (17526/22530)\n",
      "Epoch: 4 | Batch_idx: 760 |  Loss: (0.6320) | Acc: (77.82%) (17767/22830)\n",
      "Epoch: 4 | Batch_idx: 770 |  Loss: (0.6314) | Acc: (77.84%) (18005/23130)\n",
      "Epoch: 4 | Batch_idx: 780 |  Loss: (0.6312) | Acc: (77.84%) (18238/23430)\n",
      "Epoch: 4 | Batch_idx: 790 |  Loss: (0.6305) | Acc: (77.88%) (18481/23730)\n",
      "Epoch: 4 | Batch_idx: 800 |  Loss: (0.6307) | Acc: (77.89%) (18717/24030)\n",
      "Epoch: 4 | Batch_idx: 810 |  Loss: (0.6307) | Acc: (77.90%) (18953/24330)\n",
      "Epoch: 4 | Batch_idx: 820 |  Loss: (0.6320) | Acc: (77.87%) (19180/24630)\n",
      "Epoch: 4 | Batch_idx: 830 |  Loss: (0.6319) | Acc: (77.84%) (19405/24930)\n",
      "Epoch: 4 | Batch_idx: 840 |  Loss: (0.6331) | Acc: (77.78%) (19624/25230)\n",
      "Epoch: 4 | Batch_idx: 850 |  Loss: (0.6322) | Acc: (77.84%) (19873/25530)\n",
      "Epoch: 4 | Batch_idx: 860 |  Loss: (0.6321) | Acc: (77.87%) (20115/25830)\n",
      "Epoch: 4 | Batch_idx: 870 |  Loss: (0.6325) | Acc: (77.87%) (20347/26130)\n",
      "Epoch: 4 | Batch_idx: 880 |  Loss: (0.6323) | Acc: (77.89%) (20586/26430)\n",
      "Epoch: 4 | Batch_idx: 890 |  Loss: (0.6320) | Acc: (77.91%) (20826/26730)\n",
      "Epoch: 4 | Batch_idx: 900 |  Loss: (0.6313) | Acc: (77.95%) (21070/27030)\n",
      "Epoch: 4 | Batch_idx: 910 |  Loss: (0.6306) | Acc: (77.98%) (21312/27330)\n",
      "Epoch: 4 | Batch_idx: 920 |  Loss: (0.6310) | Acc: (77.96%) (21541/27630)\n",
      "Epoch: 4 | Batch_idx: 930 |  Loss: (0.6316) | Acc: (77.96%) (21775/27930)\n",
      "Epoch: 4 | Batch_idx: 940 |  Loss: (0.6311) | Acc: (77.99%) (22016/28230)\n",
      "Epoch: 4 | Batch_idx: 950 |  Loss: (0.6308) | Acc: (77.99%) (22250/28530)\n",
      "Epoch: 4 | Batch_idx: 960 |  Loss: (0.6302) | Acc: (78.00%) (22486/28830)\n",
      "Epoch: 4 | Batch_idx: 970 |  Loss: (0.6302) | Acc: (78.00%) (22721/29130)\n",
      "Epoch: 4 | Batch_idx: 980 |  Loss: (0.6298) | Acc: (78.01%) (22958/29430)\n",
      "Epoch: 4 | Batch_idx: 990 |  Loss: (0.6294) | Acc: (78.03%) (23197/29730)\n",
      "Epoch: 4 | Batch_idx: 1000 |  Loss: (0.6283) | Acc: (78.06%) (23442/30030)\n",
      "Epoch: 4 | Batch_idx: 1010 |  Loss: (0.6289) | Acc: (78.04%) (23669/30330)\n",
      "Epoch: 4 | Batch_idx: 1020 |  Loss: (0.6286) | Acc: (78.07%) (23912/30630)\n",
      "Epoch: 4 | Batch_idx: 1030 |  Loss: (0.6282) | Acc: (78.10%) (24157/30930)\n",
      "Epoch: 4 | Batch_idx: 1040 |  Loss: (0.6270) | Acc: (78.14%) (24404/31230)\n",
      "Epoch: 4 | Batch_idx: 1050 |  Loss: (0.6260) | Acc: (78.18%) (24649/31530)\n",
      "Epoch: 4 | Batch_idx: 1060 |  Loss: (0.6265) | Acc: (78.15%) (24874/31830)\n",
      "Epoch: 4 | Batch_idx: 1070 |  Loss: (0.6272) | Acc: (78.12%) (25100/32130)\n",
      "Epoch: 4 | Batch_idx: 1080 |  Loss: (0.6265) | Acc: (78.16%) (25348/32430)\n",
      "Epoch: 4 | Batch_idx: 1090 |  Loss: (0.6259) | Acc: (78.17%) (25584/32730)\n",
      "Epoch: 4 | Batch_idx: 1100 |  Loss: (0.6268) | Acc: (78.14%) (25808/33030)\n",
      "Epoch: 4 | Batch_idx: 1110 |  Loss: (0.6271) | Acc: (78.15%) (26049/33330)\n",
      "Epoch: 4 | Batch_idx: 1120 |  Loss: (0.6261) | Acc: (78.20%) (26298/33630)\n",
      "Epoch: 4 | Batch_idx: 1130 |  Loss: (0.6263) | Acc: (78.19%) (26531/33930)\n",
      "Epoch: 4 | Batch_idx: 1140 |  Loss: (0.6258) | Acc: (78.22%) (26773/34230)\n",
      "Epoch: 4 | Batch_idx: 1150 |  Loss: (0.6253) | Acc: (78.22%) (27011/34530)\n",
      "Epoch: 4 | Batch_idx: 1160 |  Loss: (0.6249) | Acc: (78.23%) (27249/34830)\n",
      "Epoch: 4 | Batch_idx: 1170 |  Loss: (0.6251) | Acc: (78.23%) (27481/35130)\n",
      "Epoch: 4 | Batch_idx: 1180 |  Loss: (0.6245) | Acc: (78.26%) (27727/35430)\n",
      "Epoch: 4 | Batch_idx: 1190 |  Loss: (0.6235) | Acc: (78.28%) (27970/35730)\n",
      "Epoch: 4 | Batch_idx: 1200 |  Loss: (0.6228) | Acc: (78.31%) (28216/36030)\n",
      "Epoch: 4 | Batch_idx: 1210 |  Loss: (0.6226) | Acc: (78.33%) (28459/36330)\n",
      "Epoch: 4 | Batch_idx: 1220 |  Loss: (0.6220) | Acc: (78.36%) (28705/36630)\n",
      "Epoch: 4 | Batch_idx: 1230 |  Loss: (0.6216) | Acc: (78.38%) (28946/36930)\n",
      "Epoch: 4 | Batch_idx: 1240 |  Loss: (0.6210) | Acc: (78.39%) (29185/37230)\n",
      "Epoch: 4 | Batch_idx: 1250 |  Loss: (0.6211) | Acc: (78.39%) (29419/37530)\n",
      "Epoch: 4 | Batch_idx: 1260 |  Loss: (0.6205) | Acc: (78.43%) (29669/37830)\n",
      "Epoch: 4 | Batch_idx: 1270 |  Loss: (0.6205) | Acc: (78.43%) (29907/38130)\n",
      "Epoch: 4 | Batch_idx: 1280 |  Loss: (0.6214) | Acc: (78.41%) (30134/38430)\n",
      "Epoch: 4 | Batch_idx: 1290 |  Loss: (0.6207) | Acc: (78.45%) (30383/38730)\n",
      "Epoch: 4 | Batch_idx: 1300 |  Loss: (0.6204) | Acc: (78.44%) (30617/39030)\n",
      "Epoch: 4 | Batch_idx: 1310 |  Loss: (0.6203) | Acc: (78.47%) (30861/39330)\n",
      "Epoch: 4 | Batch_idx: 1320 |  Loss: (0.6198) | Acc: (78.48%) (31101/39630)\n",
      "Epoch: 4 | Batch_idx: 1330 |  Loss: (0.6192) | Acc: (78.49%) (31341/39930)\n",
      "Epoch: 4 | Batch_idx: 1340 |  Loss: (0.6190) | Acc: (78.50%) (31579/40230)\n",
      "Epoch: 4 | Batch_idx: 1350 |  Loss: (0.6184) | Acc: (78.51%) (31820/40530)\n",
      "Epoch: 4 | Batch_idx: 1360 |  Loss: (0.6182) | Acc: (78.51%) (32054/40830)\n",
      "Epoch: 4 | Batch_idx: 1370 |  Loss: (0.6182) | Acc: (78.51%) (32292/41130)\n",
      "Epoch: 4 | Batch_idx: 1380 |  Loss: (0.6178) | Acc: (78.53%) (32534/41430)\n",
      "Epoch: 4 | Batch_idx: 1390 |  Loss: (0.6174) | Acc: (78.55%) (32777/41730)\n",
      "Epoch: 4 | Batch_idx: 1400 |  Loss: (0.6174) | Acc: (78.55%) (33016/42030)\n",
      "Epoch: 4 | Batch_idx: 1410 |  Loss: (0.6178) | Acc: (78.55%) (33250/42330)\n",
      "Epoch: 4 | Batch_idx: 1420 |  Loss: (0.6173) | Acc: (78.57%) (33493/42630)\n",
      "Epoch: 4 | Batch_idx: 1430 |  Loss: (0.6174) | Acc: (78.57%) (33732/42930)\n",
      "Epoch: 4 | Batch_idx: 1440 |  Loss: (0.6175) | Acc: (78.56%) (33963/43230)\n",
      "Epoch: 4 | Batch_idx: 1450 |  Loss: (0.6172) | Acc: (78.59%) (34211/43530)\n",
      "Epoch: 4 | Batch_idx: 1460 |  Loss: (0.6166) | Acc: (78.62%) (34457/43830)\n",
      "Epoch: 4 | Batch_idx: 1470 |  Loss: (0.6168) | Acc: (78.62%) (34693/44130)\n",
      "Epoch: 4 | Batch_idx: 1480 |  Loss: (0.6163) | Acc: (78.65%) (34942/44430)\n",
      "Epoch: 4 | Batch_idx: 1490 |  Loss: (0.6162) | Acc: (78.64%) (35175/44730)\n",
      "Epoch: 4 | Batch_idx: 1500 |  Loss: (0.6162) | Acc: (78.65%) (35415/45030)\n",
      "Epoch: 4 | Batch_idx: 1510 |  Loss: (0.6168) | Acc: (78.61%) (35636/45330)\n",
      "Epoch: 4 | Batch_idx: 1520 |  Loss: (0.6157) | Acc: (78.65%) (35890/45630)\n",
      "Epoch: 4 | Batch_idx: 1530 |  Loss: (0.6148) | Acc: (78.68%) (36139/45930)\n",
      "Epoch: 4 | Batch_idx: 1540 |  Loss: (0.6147) | Acc: (78.70%) (36381/46230)\n",
      "Epoch: 4 | Batch_idx: 1550 |  Loss: (0.6151) | Acc: (78.68%) (36609/46530)\n",
      "Epoch: 4 | Batch_idx: 1560 |  Loss: (0.6146) | Acc: (78.70%) (36855/46830)\n",
      "Epoch: 4 | Batch_idx: 1570 |  Loss: (0.6148) | Acc: (78.70%) (37089/47130)\n",
      "Epoch: 4 | Batch_idx: 1580 |  Loss: (0.6152) | Acc: (78.68%) (37319/47430)\n",
      "Epoch: 4 | Batch_idx: 1590 |  Loss: (0.6148) | Acc: (78.69%) (37560/47730)\n",
      "Epoch: 4 | Batch_idx: 1600 |  Loss: (0.6145) | Acc: (78.70%) (37802/48030)\n",
      "Epoch: 4 | Batch_idx: 1610 |  Loss: (0.6148) | Acc: (78.69%) (38033/48330)\n",
      "Epoch: 4 | Batch_idx: 1620 |  Loss: (0.6149) | Acc: (78.71%) (38276/48630)\n",
      "Epoch: 4 | Batch_idx: 1630 |  Loss: (0.6150) | Acc: (78.70%) (38507/48930)\n",
      "Epoch: 4 | Batch_idx: 1640 |  Loss: (0.6142) | Acc: (78.73%) (38760/49230)\n",
      "Epoch: 4 | Batch_idx: 1650 |  Loss: (0.6136) | Acc: (78.74%) (38999/49530)\n",
      "Epoch: 4 | Batch_idx: 1660 |  Loss: (0.6131) | Acc: (78.75%) (39242/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5692) | Acc: (80.22%) (8022/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (0.4347) | Acc: (86.67%) (26/30)\n",
      "Epoch: 5 | Batch_idx: 10 |  Loss: (0.4985) | Acc: (82.42%) (272/330)\n",
      "Epoch: 5 | Batch_idx: 20 |  Loss: (0.5272) | Acc: (80.79%) (509/630)\n",
      "Epoch: 5 | Batch_idx: 30 |  Loss: (0.5422) | Acc: (80.43%) (748/930)\n",
      "Epoch: 5 | Batch_idx: 40 |  Loss: (0.5464) | Acc: (80.41%) (989/1230)\n",
      "Epoch: 5 | Batch_idx: 50 |  Loss: (0.5259) | Acc: (81.50%) (1247/1530)\n",
      "Epoch: 5 | Batch_idx: 60 |  Loss: (0.5211) | Acc: (81.48%) (1491/1830)\n",
      "Epoch: 5 | Batch_idx: 70 |  Loss: (0.5225) | Acc: (81.83%) (1743/2130)\n",
      "Epoch: 5 | Batch_idx: 80 |  Loss: (0.5206) | Acc: (82.35%) (2001/2430)\n",
      "Epoch: 5 | Batch_idx: 90 |  Loss: (0.5205) | Acc: (82.31%) (2247/2730)\n",
      "Epoch: 5 | Batch_idx: 100 |  Loss: (0.5253) | Acc: (81.95%) (2483/3030)\n",
      "Epoch: 5 | Batch_idx: 110 |  Loss: (0.5302) | Acc: (81.56%) (2716/3330)\n",
      "Epoch: 5 | Batch_idx: 120 |  Loss: (0.5374) | Acc: (81.35%) (2953/3630)\n",
      "Epoch: 5 | Batch_idx: 130 |  Loss: (0.5382) | Acc: (81.32%) (3196/3930)\n",
      "Epoch: 5 | Batch_idx: 140 |  Loss: (0.5320) | Acc: (81.47%) (3446/4230)\n",
      "Epoch: 5 | Batch_idx: 150 |  Loss: (0.5283) | Acc: (81.52%) (3693/4530)\n",
      "Epoch: 5 | Batch_idx: 160 |  Loss: (0.5228) | Acc: (81.76%) (3949/4830)\n",
      "Epoch: 5 | Batch_idx: 170 |  Loss: (0.5243) | Acc: (81.73%) (4193/5130)\n",
      "Epoch: 5 | Batch_idx: 180 |  Loss: (0.5229) | Acc: (81.82%) (4443/5430)\n",
      "Epoch: 5 | Batch_idx: 190 |  Loss: (0.5239) | Acc: (81.82%) (4688/5730)\n",
      "Epoch: 5 | Batch_idx: 200 |  Loss: (0.5218) | Acc: (81.94%) (4941/6030)\n",
      "Epoch: 5 | Batch_idx: 210 |  Loss: (0.5235) | Acc: (81.97%) (5189/6330)\n",
      "Epoch: 5 | Batch_idx: 220 |  Loss: (0.5252) | Acc: (81.92%) (5431/6630)\n",
      "Epoch: 5 | Batch_idx: 230 |  Loss: (0.5261) | Acc: (81.85%) (5672/6930)\n",
      "Epoch: 5 | Batch_idx: 240 |  Loss: (0.5238) | Acc: (81.92%) (5923/7230)\n",
      "Epoch: 5 | Batch_idx: 250 |  Loss: (0.5246) | Acc: (81.93%) (6169/7530)\n",
      "Epoch: 5 | Batch_idx: 260 |  Loss: (0.5230) | Acc: (81.97%) (6418/7830)\n",
      "Epoch: 5 | Batch_idx: 270 |  Loss: (0.5223) | Acc: (81.98%) (6665/8130)\n",
      "Epoch: 5 | Batch_idx: 280 |  Loss: (0.5217) | Acc: (81.99%) (6912/8430)\n",
      "Epoch: 5 | Batch_idx: 290 |  Loss: (0.5223) | Acc: (81.92%) (7152/8730)\n",
      "Epoch: 5 | Batch_idx: 300 |  Loss: (0.5228) | Acc: (81.98%) (7403/9030)\n",
      "Epoch: 5 | Batch_idx: 310 |  Loss: (0.5242) | Acc: (81.96%) (7647/9330)\n",
      "Epoch: 5 | Batch_idx: 320 |  Loss: (0.5245) | Acc: (81.99%) (7896/9630)\n",
      "Epoch: 5 | Batch_idx: 330 |  Loss: (0.5252) | Acc: (81.91%) (8134/9930)\n",
      "Epoch: 5 | Batch_idx: 340 |  Loss: (0.5241) | Acc: (82.00%) (8389/10230)\n",
      "Epoch: 5 | Batch_idx: 350 |  Loss: (0.5237) | Acc: (82.06%) (8641/10530)\n",
      "Epoch: 5 | Batch_idx: 360 |  Loss: (0.5264) | Acc: (81.99%) (8879/10830)\n",
      "Epoch: 5 | Batch_idx: 370 |  Loss: (0.5246) | Acc: (82.06%) (9133/11130)\n",
      "Epoch: 5 | Batch_idx: 380 |  Loss: (0.5242) | Acc: (82.08%) (9382/11430)\n",
      "Epoch: 5 | Batch_idx: 390 |  Loss: (0.5237) | Acc: (82.09%) (9629/11730)\n",
      "Epoch: 5 | Batch_idx: 400 |  Loss: (0.5257) | Acc: (82.01%) (9866/12030)\n",
      "Epoch: 5 | Batch_idx: 410 |  Loss: (0.5252) | Acc: (82.07%) (10119/12330)\n",
      "Epoch: 5 | Batch_idx: 420 |  Loss: (0.5249) | Acc: (82.08%) (10367/12630)\n",
      "Epoch: 5 | Batch_idx: 430 |  Loss: (0.5239) | Acc: (82.10%) (10615/12930)\n",
      "Epoch: 5 | Batch_idx: 440 |  Loss: (0.5234) | Acc: (82.10%) (10862/13230)\n",
      "Epoch: 5 | Batch_idx: 450 |  Loss: (0.5230) | Acc: (82.09%) (11107/13530)\n",
      "Epoch: 5 | Batch_idx: 460 |  Loss: (0.5229) | Acc: (82.10%) (11354/13830)\n",
      "Epoch: 5 | Batch_idx: 470 |  Loss: (0.5235) | Acc: (82.02%) (11590/14130)\n",
      "Epoch: 5 | Batch_idx: 480 |  Loss: (0.5246) | Acc: (81.95%) (11826/14430)\n",
      "Epoch: 5 | Batch_idx: 490 |  Loss: (0.5238) | Acc: (81.96%) (12073/14730)\n",
      "Epoch: 5 | Batch_idx: 500 |  Loss: (0.5252) | Acc: (81.90%) (12310/15030)\n",
      "Epoch: 5 | Batch_idx: 510 |  Loss: (0.5266) | Acc: (81.89%) (12553/15330)\n",
      "Epoch: 5 | Batch_idx: 520 |  Loss: (0.5278) | Acc: (81.80%) (12785/15630)\n",
      "Epoch: 5 | Batch_idx: 530 |  Loss: (0.5292) | Acc: (81.78%) (13028/15930)\n",
      "Epoch: 5 | Batch_idx: 540 |  Loss: (0.5280) | Acc: (81.82%) (13280/16230)\n",
      "Epoch: 5 | Batch_idx: 550 |  Loss: (0.5273) | Acc: (81.88%) (13535/16530)\n",
      "Epoch: 5 | Batch_idx: 560 |  Loss: (0.5282) | Acc: (81.80%) (13767/16830)\n",
      "Epoch: 5 | Batch_idx: 570 |  Loss: (0.5288) | Acc: (81.80%) (14012/17130)\n",
      "Epoch: 5 | Batch_idx: 580 |  Loss: (0.5292) | Acc: (81.76%) (14251/17430)\n",
      "Epoch: 5 | Batch_idx: 590 |  Loss: (0.5289) | Acc: (81.77%) (14498/17730)\n",
      "Epoch: 5 | Batch_idx: 600 |  Loss: (0.5288) | Acc: (81.79%) (14746/18030)\n",
      "Epoch: 5 | Batch_idx: 610 |  Loss: (0.5305) | Acc: (81.75%) (14985/18330)\n",
      "Epoch: 5 | Batch_idx: 620 |  Loss: (0.5314) | Acc: (81.73%) (15226/18630)\n",
      "Epoch: 5 | Batch_idx: 630 |  Loss: (0.5316) | Acc: (81.73%) (15471/18930)\n",
      "Epoch: 5 | Batch_idx: 640 |  Loss: (0.5309) | Acc: (81.76%) (15723/19230)\n",
      "Epoch: 5 | Batch_idx: 650 |  Loss: (0.5301) | Acc: (81.80%) (15976/19530)\n",
      "Epoch: 5 | Batch_idx: 660 |  Loss: (0.5302) | Acc: (81.83%) (16226/19830)\n",
      "Epoch: 5 | Batch_idx: 670 |  Loss: (0.5298) | Acc: (81.83%) (16472/20130)\n",
      "Epoch: 5 | Batch_idx: 680 |  Loss: (0.5297) | Acc: (81.84%) (16719/20430)\n",
      "Epoch: 5 | Batch_idx: 690 |  Loss: (0.5288) | Acc: (81.88%) (16973/20730)\n",
      "Epoch: 5 | Batch_idx: 700 |  Loss: (0.5288) | Acc: (81.87%) (17218/21030)\n",
      "Epoch: 5 | Batch_idx: 710 |  Loss: (0.5276) | Acc: (81.93%) (17475/21330)\n",
      "Epoch: 5 | Batch_idx: 720 |  Loss: (0.5273) | Acc: (81.92%) (17719/21630)\n",
      "Epoch: 5 | Batch_idx: 730 |  Loss: (0.5282) | Acc: (81.88%) (17956/21930)\n",
      "Epoch: 5 | Batch_idx: 740 |  Loss: (0.5269) | Acc: (81.93%) (18213/22230)\n",
      "Epoch: 5 | Batch_idx: 750 |  Loss: (0.5256) | Acc: (81.98%) (18469/22530)\n",
      "Epoch: 5 | Batch_idx: 760 |  Loss: (0.5248) | Acc: (82.00%) (18720/22830)\n",
      "Epoch: 5 | Batch_idx: 770 |  Loss: (0.5243) | Acc: (82.00%) (18967/23130)\n",
      "Epoch: 5 | Batch_idx: 780 |  Loss: (0.5234) | Acc: (82.02%) (19217/23430)\n",
      "Epoch: 5 | Batch_idx: 790 |  Loss: (0.5228) | Acc: (82.04%) (19469/23730)\n",
      "Epoch: 5 | Batch_idx: 800 |  Loss: (0.5222) | Acc: (82.06%) (19720/24030)\n",
      "Epoch: 5 | Batch_idx: 810 |  Loss: (0.5231) | Acc: (82.06%) (19964/24330)\n",
      "Epoch: 5 | Batch_idx: 820 |  Loss: (0.5239) | Acc: (82.03%) (20204/24630)\n",
      "Epoch: 5 | Batch_idx: 830 |  Loss: (0.5239) | Acc: (82.03%) (20449/24930)\n",
      "Epoch: 5 | Batch_idx: 840 |  Loss: (0.5247) | Acc: (82.00%) (20688/25230)\n",
      "Epoch: 5 | Batch_idx: 850 |  Loss: (0.5250) | Acc: (81.99%) (20933/25530)\n",
      "Epoch: 5 | Batch_idx: 860 |  Loss: (0.5246) | Acc: (82.02%) (21185/25830)\n",
      "Epoch: 5 | Batch_idx: 870 |  Loss: (0.5240) | Acc: (82.04%) (21437/26130)\n",
      "Epoch: 5 | Batch_idx: 880 |  Loss: (0.5238) | Acc: (82.03%) (21681/26430)\n",
      "Epoch: 5 | Batch_idx: 890 |  Loss: (0.5240) | Acc: (82.02%) (21923/26730)\n",
      "Epoch: 5 | Batch_idx: 900 |  Loss: (0.5245) | Acc: (81.99%) (22163/27030)\n",
      "Epoch: 5 | Batch_idx: 910 |  Loss: (0.5247) | Acc: (81.99%) (22409/27330)\n",
      "Epoch: 5 | Batch_idx: 920 |  Loss: (0.5241) | Acc: (82.01%) (22659/27630)\n",
      "Epoch: 5 | Batch_idx: 930 |  Loss: (0.5238) | Acc: (82.03%) (22910/27930)\n",
      "Epoch: 5 | Batch_idx: 940 |  Loss: (0.5237) | Acc: (82.04%) (23160/28230)\n",
      "Epoch: 5 | Batch_idx: 950 |  Loss: (0.5246) | Acc: (82.04%) (23406/28530)\n",
      "Epoch: 5 | Batch_idx: 960 |  Loss: (0.5240) | Acc: (82.04%) (23651/28830)\n",
      "Epoch: 5 | Batch_idx: 970 |  Loss: (0.5234) | Acc: (82.07%) (23908/29130)\n",
      "Epoch: 5 | Batch_idx: 980 |  Loss: (0.5237) | Acc: (82.07%) (24153/29430)\n",
      "Epoch: 5 | Batch_idx: 990 |  Loss: (0.5234) | Acc: (82.08%) (24402/29730)\n",
      "Epoch: 5 | Batch_idx: 1000 |  Loss: (0.5230) | Acc: (82.10%) (24655/30030)\n",
      "Epoch: 5 | Batch_idx: 1010 |  Loss: (0.5231) | Acc: (82.11%) (24904/30330)\n",
      "Epoch: 5 | Batch_idx: 1020 |  Loss: (0.5237) | Acc: (82.11%) (25149/30630)\n",
      "Epoch: 5 | Batch_idx: 1030 |  Loss: (0.5234) | Acc: (82.10%) (25393/30930)\n",
      "Epoch: 5 | Batch_idx: 1040 |  Loss: (0.5238) | Acc: (82.07%) (25629/31230)\n",
      "Epoch: 5 | Batch_idx: 1050 |  Loss: (0.5239) | Acc: (82.06%) (25874/31530)\n",
      "Epoch: 5 | Batch_idx: 1060 |  Loss: (0.5237) | Acc: (82.07%) (26122/31830)\n",
      "Epoch: 5 | Batch_idx: 1070 |  Loss: (0.5235) | Acc: (82.06%) (26366/32130)\n",
      "Epoch: 5 | Batch_idx: 1080 |  Loss: (0.5236) | Acc: (82.06%) (26611/32430)\n",
      "Epoch: 5 | Batch_idx: 1090 |  Loss: (0.5239) | Acc: (82.04%) (26851/32730)\n",
      "Epoch: 5 | Batch_idx: 1100 |  Loss: (0.5239) | Acc: (82.04%) (27099/33030)\n",
      "Epoch: 5 | Batch_idx: 1110 |  Loss: (0.5232) | Acc: (82.06%) (27352/33330)\n",
      "Epoch: 5 | Batch_idx: 1120 |  Loss: (0.5230) | Acc: (82.07%) (27600/33630)\n",
      "Epoch: 5 | Batch_idx: 1130 |  Loss: (0.5231) | Acc: (82.08%) (27849/33930)\n",
      "Epoch: 5 | Batch_idx: 1140 |  Loss: (0.5236) | Acc: (82.05%) (28086/34230)\n",
      "Epoch: 5 | Batch_idx: 1150 |  Loss: (0.5246) | Acc: (82.01%) (28318/34530)\n",
      "Epoch: 5 | Batch_idx: 1160 |  Loss: (0.5251) | Acc: (81.98%) (28553/34830)\n",
      "Epoch: 5 | Batch_idx: 1170 |  Loss: (0.5240) | Acc: (82.02%) (28814/35130)\n",
      "Epoch: 5 | Batch_idx: 1180 |  Loss: (0.5235) | Acc: (82.04%) (29067/35430)\n",
      "Epoch: 5 | Batch_idx: 1190 |  Loss: (0.5233) | Acc: (82.04%) (29312/35730)\n",
      "Epoch: 5 | Batch_idx: 1200 |  Loss: (0.5230) | Acc: (82.04%) (29558/36030)\n",
      "Epoch: 5 | Batch_idx: 1210 |  Loss: (0.5233) | Acc: (82.04%) (29806/36330)\n",
      "Epoch: 5 | Batch_idx: 1220 |  Loss: (0.5234) | Acc: (82.02%) (30044/36630)\n",
      "Epoch: 5 | Batch_idx: 1230 |  Loss: (0.5229) | Acc: (82.03%) (30294/36930)\n",
      "Epoch: 5 | Batch_idx: 1240 |  Loss: (0.5230) | Acc: (82.02%) (30537/37230)\n",
      "Epoch: 5 | Batch_idx: 1250 |  Loss: (0.5226) | Acc: (82.03%) (30786/37530)\n",
      "Epoch: 5 | Batch_idx: 1260 |  Loss: (0.5222) | Acc: (82.04%) (31036/37830)\n",
      "Epoch: 5 | Batch_idx: 1270 |  Loss: (0.5226) | Acc: (82.04%) (31280/38130)\n",
      "Epoch: 5 | Batch_idx: 1280 |  Loss: (0.5222) | Acc: (82.06%) (31535/38430)\n",
      "Epoch: 5 | Batch_idx: 1290 |  Loss: (0.5223) | Acc: (82.05%) (31779/38730)\n",
      "Epoch: 5 | Batch_idx: 1300 |  Loss: (0.5224) | Acc: (82.05%) (32025/39030)\n",
      "Epoch: 5 | Batch_idx: 1310 |  Loss: (0.5215) | Acc: (82.07%) (32278/39330)\n",
      "Epoch: 5 | Batch_idx: 1320 |  Loss: (0.5215) | Acc: (82.07%) (32523/39630)\n",
      "Epoch: 5 | Batch_idx: 1330 |  Loss: (0.5220) | Acc: (82.06%) (32765/39930)\n",
      "Epoch: 5 | Batch_idx: 1340 |  Loss: (0.5221) | Acc: (82.05%) (33009/40230)\n",
      "Epoch: 5 | Batch_idx: 1350 |  Loss: (0.5222) | Acc: (82.06%) (33258/40530)\n",
      "Epoch: 5 | Batch_idx: 1360 |  Loss: (0.5224) | Acc: (82.05%) (33501/40830)\n",
      "Epoch: 5 | Batch_idx: 1370 |  Loss: (0.5216) | Acc: (82.08%) (33758/41130)\n",
      "Epoch: 5 | Batch_idx: 1380 |  Loss: (0.5206) | Acc: (82.10%) (34014/41430)\n",
      "Epoch: 5 | Batch_idx: 1390 |  Loss: (0.5202) | Acc: (82.12%) (34270/41730)\n",
      "Epoch: 5 | Batch_idx: 1400 |  Loss: (0.5199) | Acc: (82.13%) (34519/42030)\n",
      "Epoch: 5 | Batch_idx: 1410 |  Loss: (0.5193) | Acc: (82.13%) (34766/42330)\n",
      "Epoch: 5 | Batch_idx: 1420 |  Loss: (0.5191) | Acc: (82.13%) (35010/42630)\n",
      "Epoch: 5 | Batch_idx: 1430 |  Loss: (0.5194) | Acc: (82.12%) (35256/42930)\n",
      "Epoch: 5 | Batch_idx: 1440 |  Loss: (0.5188) | Acc: (82.16%) (35519/43230)\n",
      "Epoch: 5 | Batch_idx: 1450 |  Loss: (0.5185) | Acc: (82.17%) (35769/43530)\n",
      "Epoch: 5 | Batch_idx: 1460 |  Loss: (0.5180) | Acc: (82.18%) (36021/43830)\n",
      "Epoch: 5 | Batch_idx: 1470 |  Loss: (0.5174) | Acc: (82.20%) (36273/44130)\n",
      "Epoch: 5 | Batch_idx: 1480 |  Loss: (0.5175) | Acc: (82.20%) (36521/44430)\n",
      "Epoch: 5 | Batch_idx: 1490 |  Loss: (0.5177) | Acc: (82.20%) (36768/44730)\n",
      "Epoch: 5 | Batch_idx: 1500 |  Loss: (0.5175) | Acc: (82.20%) (37015/45030)\n",
      "Epoch: 5 | Batch_idx: 1510 |  Loss: (0.5176) | Acc: (82.18%) (37251/45330)\n",
      "Epoch: 5 | Batch_idx: 1520 |  Loss: (0.5175) | Acc: (82.18%) (37497/45630)\n",
      "Epoch: 5 | Batch_idx: 1530 |  Loss: (0.5174) | Acc: (82.18%) (37745/45930)\n",
      "Epoch: 5 | Batch_idx: 1540 |  Loss: (0.5168) | Acc: (82.20%) (38000/46230)\n",
      "Epoch: 5 | Batch_idx: 1550 |  Loss: (0.5165) | Acc: (82.20%) (38248/46530)\n",
      "Epoch: 5 | Batch_idx: 1560 |  Loss: (0.5166) | Acc: (82.20%) (38492/46830)\n",
      "Epoch: 5 | Batch_idx: 1570 |  Loss: (0.5158) | Acc: (82.22%) (38749/47130)\n",
      "Epoch: 5 | Batch_idx: 1580 |  Loss: (0.5156) | Acc: (82.23%) (39001/47430)\n",
      "Epoch: 5 | Batch_idx: 1590 |  Loss: (0.5153) | Acc: (82.24%) (39255/47730)\n",
      "Epoch: 5 | Batch_idx: 1600 |  Loss: (0.5152) | Acc: (82.25%) (39505/48030)\n",
      "Epoch: 5 | Batch_idx: 1610 |  Loss: (0.5158) | Acc: (82.23%) (39740/48330)\n",
      "Epoch: 5 | Batch_idx: 1620 |  Loss: (0.5158) | Acc: (82.23%) (39990/48630)\n",
      "Epoch: 5 | Batch_idx: 1630 |  Loss: (0.5160) | Acc: (82.24%) (40238/48930)\n",
      "Epoch: 5 | Batch_idx: 1640 |  Loss: (0.5160) | Acc: (82.25%) (40493/49230)\n",
      "Epoch: 5 | Batch_idx: 1650 |  Loss: (0.5161) | Acc: (82.25%) (40739/49530)\n",
      "Epoch: 5 | Batch_idx: 1660 |  Loss: (0.5159) | Acc: (82.27%) (40993/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.5291) | Acc: (82.02%) (8202/10000)\n",
      "Epoch: 6 | Batch_idx: 0 |  Loss: (0.3627) | Acc: (86.67%) (26/30)\n",
      "Epoch: 6 | Batch_idx: 10 |  Loss: (0.5044) | Acc: (82.73%) (273/330)\n",
      "Epoch: 6 | Batch_idx: 20 |  Loss: (0.5013) | Acc: (82.86%) (522/630)\n",
      "Epoch: 6 | Batch_idx: 30 |  Loss: (0.4812) | Acc: (83.12%) (773/930)\n",
      "Epoch: 6 | Batch_idx: 40 |  Loss: (0.4822) | Acc: (83.09%) (1022/1230)\n",
      "Epoch: 6 | Batch_idx: 50 |  Loss: (0.4654) | Acc: (83.79%) (1282/1530)\n",
      "Epoch: 6 | Batch_idx: 60 |  Loss: (0.4617) | Acc: (83.99%) (1537/1830)\n",
      "Epoch: 6 | Batch_idx: 70 |  Loss: (0.4599) | Acc: (83.94%) (1788/2130)\n",
      "Epoch: 6 | Batch_idx: 80 |  Loss: (0.4489) | Acc: (84.73%) (2059/2430)\n",
      "Epoch: 6 | Batch_idx: 90 |  Loss: (0.4481) | Acc: (84.76%) (2314/2730)\n",
      "Epoch: 6 | Batch_idx: 100 |  Loss: (0.4577) | Acc: (84.55%) (2562/3030)\n",
      "Epoch: 6 | Batch_idx: 110 |  Loss: (0.4705) | Acc: (84.20%) (2804/3330)\n",
      "Epoch: 6 | Batch_idx: 120 |  Loss: (0.4645) | Acc: (84.38%) (3063/3630)\n",
      "Epoch: 6 | Batch_idx: 130 |  Loss: (0.4633) | Acc: (84.35%) (3315/3930)\n",
      "Epoch: 6 | Batch_idx: 140 |  Loss: (0.4620) | Acc: (84.30%) (3566/4230)\n",
      "Epoch: 6 | Batch_idx: 150 |  Loss: (0.4601) | Acc: (84.26%) (3817/4530)\n",
      "Epoch: 6 | Batch_idx: 160 |  Loss: (0.4623) | Acc: (84.10%) (4062/4830)\n",
      "Epoch: 6 | Batch_idx: 170 |  Loss: (0.4618) | Acc: (84.07%) (4313/5130)\n",
      "Epoch: 6 | Batch_idx: 180 |  Loss: (0.4577) | Acc: (84.22%) (4573/5430)\n",
      "Epoch: 6 | Batch_idx: 190 |  Loss: (0.4580) | Acc: (84.24%) (4827/5730)\n",
      "Epoch: 6 | Batch_idx: 200 |  Loss: (0.4585) | Acc: (84.31%) (5084/6030)\n",
      "Epoch: 6 | Batch_idx: 210 |  Loss: (0.4539) | Acc: (84.41%) (5343/6330)\n",
      "Epoch: 6 | Batch_idx: 220 |  Loss: (0.4581) | Acc: (84.28%) (5588/6630)\n",
      "Epoch: 6 | Batch_idx: 230 |  Loss: (0.4567) | Acc: (84.31%) (5843/6930)\n",
      "Epoch: 6 | Batch_idx: 240 |  Loss: (0.4579) | Acc: (84.26%) (6092/7230)\n",
      "Epoch: 6 | Batch_idx: 250 |  Loss: (0.4576) | Acc: (84.26%) (6345/7530)\n",
      "Epoch: 6 | Batch_idx: 260 |  Loss: (0.4566) | Acc: (84.30%) (6601/7830)\n",
      "Epoch: 6 | Batch_idx: 270 |  Loss: (0.4557) | Acc: (84.28%) (6852/8130)\n",
      "Epoch: 6 | Batch_idx: 280 |  Loss: (0.4555) | Acc: (84.28%) (7105/8430)\n",
      "Epoch: 6 | Batch_idx: 290 |  Loss: (0.4563) | Acc: (84.23%) (7353/8730)\n",
      "Epoch: 6 | Batch_idx: 300 |  Loss: (0.4578) | Acc: (84.17%) (7601/9030)\n",
      "Epoch: 6 | Batch_idx: 310 |  Loss: (0.4567) | Acc: (84.20%) (7856/9330)\n",
      "Epoch: 6 | Batch_idx: 320 |  Loss: (0.4537) | Acc: (84.36%) (8124/9630)\n",
      "Epoch: 6 | Batch_idx: 330 |  Loss: (0.4529) | Acc: (84.43%) (8384/9930)\n",
      "Epoch: 6 | Batch_idx: 340 |  Loss: (0.4530) | Acc: (84.47%) (8641/10230)\n",
      "Epoch: 6 | Batch_idx: 350 |  Loss: (0.4542) | Acc: (84.40%) (8887/10530)\n",
      "Epoch: 6 | Batch_idx: 360 |  Loss: (0.4538) | Acc: (84.37%) (9137/10830)\n",
      "Epoch: 6 | Batch_idx: 370 |  Loss: (0.4534) | Acc: (84.36%) (9389/11130)\n",
      "Epoch: 6 | Batch_idx: 380 |  Loss: (0.4531) | Acc: (84.36%) (9642/11430)\n",
      "Epoch: 6 | Batch_idx: 390 |  Loss: (0.4517) | Acc: (84.42%) (9903/11730)\n",
      "Epoch: 6 | Batch_idx: 400 |  Loss: (0.4528) | Acc: (84.35%) (10147/12030)\n",
      "Epoch: 6 | Batch_idx: 410 |  Loss: (0.4544) | Acc: (84.31%) (10395/12330)\n",
      "Epoch: 6 | Batch_idx: 420 |  Loss: (0.4555) | Acc: (84.32%) (10649/12630)\n",
      "Epoch: 6 | Batch_idx: 430 |  Loss: (0.4569) | Acc: (84.25%) (10893/12930)\n",
      "Epoch: 6 | Batch_idx: 440 |  Loss: (0.4576) | Acc: (84.19%) (11138/13230)\n",
      "Epoch: 6 | Batch_idx: 450 |  Loss: (0.4582) | Acc: (84.17%) (11388/13530)\n",
      "Epoch: 6 | Batch_idx: 460 |  Loss: (0.4573) | Acc: (84.19%) (11644/13830)\n",
      "Epoch: 6 | Batch_idx: 470 |  Loss: (0.4575) | Acc: (84.20%) (11898/14130)\n",
      "Epoch: 6 | Batch_idx: 480 |  Loss: (0.4564) | Acc: (84.27%) (12160/14430)\n",
      "Epoch: 6 | Batch_idx: 490 |  Loss: (0.4560) | Acc: (84.29%) (12416/14730)\n",
      "Epoch: 6 | Batch_idx: 500 |  Loss: (0.4570) | Acc: (84.26%) (12664/15030)\n",
      "Epoch: 6 | Batch_idx: 510 |  Loss: (0.4564) | Acc: (84.25%) (12916/15330)\n",
      "Epoch: 6 | Batch_idx: 520 |  Loss: (0.4575) | Acc: (84.20%) (13160/15630)\n",
      "Epoch: 6 | Batch_idx: 530 |  Loss: (0.4563) | Acc: (84.22%) (13417/15930)\n",
      "Epoch: 6 | Batch_idx: 540 |  Loss: (0.4581) | Acc: (84.14%) (13656/16230)\n",
      "Epoch: 6 | Batch_idx: 550 |  Loss: (0.4571) | Acc: (84.16%) (13911/16530)\n",
      "Epoch: 6 | Batch_idx: 560 |  Loss: (0.4575) | Acc: (84.12%) (14157/16830)\n",
      "Epoch: 6 | Batch_idx: 570 |  Loss: (0.4560) | Acc: (84.16%) (14417/17130)\n",
      "Epoch: 6 | Batch_idx: 580 |  Loss: (0.4579) | Acc: (84.08%) (14655/17430)\n",
      "Epoch: 6 | Batch_idx: 590 |  Loss: (0.4569) | Acc: (84.06%) (14904/17730)\n",
      "Epoch: 6 | Batch_idx: 600 |  Loss: (0.4567) | Acc: (84.09%) (15161/18030)\n",
      "Epoch: 6 | Batch_idx: 610 |  Loss: (0.4567) | Acc: (84.10%) (15416/18330)\n",
      "Epoch: 6 | Batch_idx: 620 |  Loss: (0.4564) | Acc: (84.13%) (15674/18630)\n",
      "Epoch: 6 | Batch_idx: 630 |  Loss: (0.4551) | Acc: (84.20%) (15940/18930)\n",
      "Epoch: 6 | Batch_idx: 640 |  Loss: (0.4556) | Acc: (84.21%) (16194/19230)\n",
      "Epoch: 6 | Batch_idx: 650 |  Loss: (0.4561) | Acc: (84.21%) (16447/19530)\n",
      "Epoch: 6 | Batch_idx: 660 |  Loss: (0.4551) | Acc: (84.28%) (16712/19830)\n",
      "Epoch: 6 | Batch_idx: 670 |  Loss: (0.4551) | Acc: (84.29%) (16967/20130)\n",
      "Epoch: 6 | Batch_idx: 680 |  Loss: (0.4539) | Acc: (84.34%) (17230/20430)\n",
      "Epoch: 6 | Batch_idx: 690 |  Loss: (0.4542) | Acc: (84.31%) (17477/20730)\n",
      "Epoch: 6 | Batch_idx: 700 |  Loss: (0.4550) | Acc: (84.30%) (17728/21030)\n",
      "Epoch: 6 | Batch_idx: 710 |  Loss: (0.4546) | Acc: (84.31%) (17984/21330)\n",
      "Epoch: 6 | Batch_idx: 720 |  Loss: (0.4548) | Acc: (84.28%) (18230/21630)\n",
      "Epoch: 6 | Batch_idx: 730 |  Loss: (0.4553) | Acc: (84.28%) (18482/21930)\n",
      "Epoch: 6 | Batch_idx: 740 |  Loss: (0.4551) | Acc: (84.26%) (18732/22230)\n",
      "Epoch: 6 | Batch_idx: 750 |  Loss: (0.4547) | Acc: (84.28%) (18988/22530)\n",
      "Epoch: 6 | Batch_idx: 760 |  Loss: (0.4537) | Acc: (84.30%) (19246/22830)\n",
      "Epoch: 6 | Batch_idx: 770 |  Loss: (0.4527) | Acc: (84.35%) (19510/23130)\n",
      "Epoch: 6 | Batch_idx: 780 |  Loss: (0.4519) | Acc: (84.39%) (19773/23430)\n",
      "Epoch: 6 | Batch_idx: 790 |  Loss: (0.4520) | Acc: (84.39%) (20026/23730)\n",
      "Epoch: 6 | Batch_idx: 800 |  Loss: (0.4512) | Acc: (84.42%) (20285/24030)\n",
      "Epoch: 6 | Batch_idx: 810 |  Loss: (0.4504) | Acc: (84.45%) (20547/24330)\n",
      "Epoch: 6 | Batch_idx: 820 |  Loss: (0.4503) | Acc: (84.48%) (20807/24630)\n",
      "Epoch: 6 | Batch_idx: 830 |  Loss: (0.4499) | Acc: (84.48%) (21062/24930)\n",
      "Epoch: 6 | Batch_idx: 840 |  Loss: (0.4497) | Acc: (84.50%) (21319/25230)\n",
      "Epoch: 6 | Batch_idx: 850 |  Loss: (0.4495) | Acc: (84.50%) (21574/25530)\n",
      "Epoch: 6 | Batch_idx: 860 |  Loss: (0.4493) | Acc: (84.52%) (21831/25830)\n",
      "Epoch: 6 | Batch_idx: 870 |  Loss: (0.4505) | Acc: (84.49%) (22077/26130)\n",
      "Epoch: 6 | Batch_idx: 880 |  Loss: (0.4508) | Acc: (84.49%) (22332/26430)\n",
      "Epoch: 6 | Batch_idx: 890 |  Loss: (0.4503) | Acc: (84.52%) (22592/26730)\n",
      "Epoch: 6 | Batch_idx: 900 |  Loss: (0.4503) | Acc: (84.52%) (22846/27030)\n",
      "Epoch: 6 | Batch_idx: 910 |  Loss: (0.4505) | Acc: (84.49%) (23091/27330)\n",
      "Epoch: 6 | Batch_idx: 920 |  Loss: (0.4517) | Acc: (84.48%) (23342/27630)\n",
      "Epoch: 6 | Batch_idx: 930 |  Loss: (0.4523) | Acc: (84.46%) (23589/27930)\n",
      "Epoch: 6 | Batch_idx: 940 |  Loss: (0.4528) | Acc: (84.43%) (23836/28230)\n",
      "Epoch: 6 | Batch_idx: 950 |  Loss: (0.4525) | Acc: (84.43%) (24089/28530)\n",
      "Epoch: 6 | Batch_idx: 960 |  Loss: (0.4534) | Acc: (84.40%) (24332/28830)\n",
      "Epoch: 6 | Batch_idx: 970 |  Loss: (0.4533) | Acc: (84.41%) (24590/29130)\n",
      "Epoch: 6 | Batch_idx: 980 |  Loss: (0.4530) | Acc: (84.43%) (24848/29430)\n",
      "Epoch: 6 | Batch_idx: 990 |  Loss: (0.4525) | Acc: (84.46%) (25111/29730)\n",
      "Epoch: 6 | Batch_idx: 1000 |  Loss: (0.4523) | Acc: (84.47%) (25367/30030)\n",
      "Epoch: 6 | Batch_idx: 1010 |  Loss: (0.4520) | Acc: (84.46%) (25616/30330)\n",
      "Epoch: 6 | Batch_idx: 1020 |  Loss: (0.4515) | Acc: (84.50%) (25881/30630)\n",
      "Epoch: 6 | Batch_idx: 1030 |  Loss: (0.4508) | Acc: (84.53%) (26144/30930)\n",
      "Epoch: 6 | Batch_idx: 1040 |  Loss: (0.4501) | Acc: (84.56%) (26409/31230)\n",
      "Epoch: 6 | Batch_idx: 1050 |  Loss: (0.4493) | Acc: (84.59%) (26671/31530)\n",
      "Epoch: 6 | Batch_idx: 1060 |  Loss: (0.4485) | Acc: (84.60%) (26928/31830)\n",
      "Epoch: 6 | Batch_idx: 1070 |  Loss: (0.4490) | Acc: (84.58%) (27174/32130)\n",
      "Epoch: 6 | Batch_idx: 1080 |  Loss: (0.4486) | Acc: (84.59%) (27431/32430)\n",
      "Epoch: 6 | Batch_idx: 1090 |  Loss: (0.4484) | Acc: (84.58%) (27684/32730)\n",
      "Epoch: 6 | Batch_idx: 1100 |  Loss: (0.4488) | Acc: (84.57%) (27934/33030)\n",
      "Epoch: 6 | Batch_idx: 1110 |  Loss: (0.4487) | Acc: (84.59%) (28194/33330)\n",
      "Epoch: 6 | Batch_idx: 1120 |  Loss: (0.4492) | Acc: (84.56%) (28438/33630)\n",
      "Epoch: 6 | Batch_idx: 1130 |  Loss: (0.4498) | Acc: (84.54%) (28685/33930)\n",
      "Epoch: 6 | Batch_idx: 1140 |  Loss: (0.4494) | Acc: (84.55%) (28941/34230)\n",
      "Epoch: 6 | Batch_idx: 1150 |  Loss: (0.4498) | Acc: (84.56%) (29198/34530)\n",
      "Epoch: 6 | Batch_idx: 1160 |  Loss: (0.4490) | Acc: (84.58%) (29458/34830)\n",
      "Epoch: 6 | Batch_idx: 1170 |  Loss: (0.4488) | Acc: (84.58%) (29712/35130)\n",
      "Epoch: 6 | Batch_idx: 1180 |  Loss: (0.4481) | Acc: (84.61%) (29977/35430)\n",
      "Epoch: 6 | Batch_idx: 1190 |  Loss: (0.4480) | Acc: (84.60%) (30228/35730)\n",
      "Epoch: 6 | Batch_idx: 1200 |  Loss: (0.4481) | Acc: (84.59%) (30478/36030)\n",
      "Epoch: 6 | Batch_idx: 1210 |  Loss: (0.4480) | Acc: (84.61%) (30737/36330)\n",
      "Epoch: 6 | Batch_idx: 1220 |  Loss: (0.4476) | Acc: (84.62%) (30998/36630)\n",
      "Epoch: 6 | Batch_idx: 1230 |  Loss: (0.4469) | Acc: (84.66%) (31265/36930)\n",
      "Epoch: 6 | Batch_idx: 1240 |  Loss: (0.4469) | Acc: (84.66%) (31519/37230)\n",
      "Epoch: 6 | Batch_idx: 1250 |  Loss: (0.4464) | Acc: (84.68%) (31780/37530)\n",
      "Epoch: 6 | Batch_idx: 1260 |  Loss: (0.4464) | Acc: (84.69%) (32037/37830)\n",
      "Epoch: 6 | Batch_idx: 1270 |  Loss: (0.4460) | Acc: (84.70%) (32297/38130)\n",
      "Epoch: 6 | Batch_idx: 1280 |  Loss: (0.4456) | Acc: (84.72%) (32559/38430)\n",
      "Epoch: 6 | Batch_idx: 1290 |  Loss: (0.4450) | Acc: (84.76%) (32826/38730)\n",
      "Epoch: 6 | Batch_idx: 1300 |  Loss: (0.4450) | Acc: (84.75%) (33077/39030)\n",
      "Epoch: 6 | Batch_idx: 1310 |  Loss: (0.4462) | Acc: (84.72%) (33321/39330)\n",
      "Epoch: 6 | Batch_idx: 1320 |  Loss: (0.4466) | Acc: (84.72%) (33574/39630)\n",
      "Epoch: 6 | Batch_idx: 1330 |  Loss: (0.4464) | Acc: (84.72%) (33830/39930)\n",
      "Epoch: 6 | Batch_idx: 1340 |  Loss: (0.4465) | Acc: (84.73%) (34087/40230)\n",
      "Epoch: 6 | Batch_idx: 1350 |  Loss: (0.4467) | Acc: (84.73%) (34340/40530)\n",
      "Epoch: 6 | Batch_idx: 1360 |  Loss: (0.4463) | Acc: (84.74%) (34598/40830)\n",
      "Epoch: 6 | Batch_idx: 1370 |  Loss: (0.4460) | Acc: (84.73%) (34851/41130)\n",
      "Epoch: 6 | Batch_idx: 1380 |  Loss: (0.4462) | Acc: (84.73%) (35102/41430)\n",
      "Epoch: 6 | Batch_idx: 1390 |  Loss: (0.4459) | Acc: (84.72%) (35352/41730)\n",
      "Epoch: 6 | Batch_idx: 1400 |  Loss: (0.4455) | Acc: (84.73%) (35612/42030)\n",
      "Epoch: 6 | Batch_idx: 1410 |  Loss: (0.4455) | Acc: (84.74%) (35870/42330)\n",
      "Epoch: 6 | Batch_idx: 1420 |  Loss: (0.4456) | Acc: (84.73%) (36120/42630)\n",
      "Epoch: 6 | Batch_idx: 1430 |  Loss: (0.4456) | Acc: (84.72%) (36372/42930)\n",
      "Epoch: 6 | Batch_idx: 1440 |  Loss: (0.4451) | Acc: (84.73%) (36627/43230)\n",
      "Epoch: 6 | Batch_idx: 1450 |  Loss: (0.4450) | Acc: (84.74%) (36887/43530)\n",
      "Epoch: 6 | Batch_idx: 1460 |  Loss: (0.4448) | Acc: (84.75%) (37145/43830)\n",
      "Epoch: 6 | Batch_idx: 1470 |  Loss: (0.4450) | Acc: (84.75%) (37398/44130)\n",
      "Epoch: 6 | Batch_idx: 1480 |  Loss: (0.4448) | Acc: (84.76%) (37657/44430)\n",
      "Epoch: 6 | Batch_idx: 1490 |  Loss: (0.4445) | Acc: (84.78%) (37921/44730)\n",
      "Epoch: 6 | Batch_idx: 1500 |  Loss: (0.4451) | Acc: (84.74%) (38160/45030)\n",
      "Epoch: 6 | Batch_idx: 1510 |  Loss: (0.4448) | Acc: (84.76%) (38420/45330)\n",
      "Epoch: 6 | Batch_idx: 1520 |  Loss: (0.4447) | Acc: (84.74%) (38669/45630)\n",
      "Epoch: 6 | Batch_idx: 1530 |  Loss: (0.4451) | Acc: (84.72%) (38914/45930)\n",
      "Epoch: 6 | Batch_idx: 1540 |  Loss: (0.4445) | Acc: (84.73%) (39169/46230)\n",
      "Epoch: 6 | Batch_idx: 1550 |  Loss: (0.4446) | Acc: (84.72%) (39422/46530)\n",
      "Epoch: 6 | Batch_idx: 1560 |  Loss: (0.4438) | Acc: (84.74%) (39684/46830)\n",
      "Epoch: 6 | Batch_idx: 1570 |  Loss: (0.4442) | Acc: (84.73%) (39933/47130)\n",
      "Epoch: 6 | Batch_idx: 1580 |  Loss: (0.4445) | Acc: (84.72%) (40182/47430)\n",
      "Epoch: 6 | Batch_idx: 1590 |  Loss: (0.4441) | Acc: (84.74%) (40447/47730)\n",
      "Epoch: 6 | Batch_idx: 1600 |  Loss: (0.4441) | Acc: (84.75%) (40704/48030)\n",
      "Epoch: 6 | Batch_idx: 1610 |  Loss: (0.4449) | Acc: (84.71%) (40938/48330)\n",
      "Epoch: 6 | Batch_idx: 1620 |  Loss: (0.4446) | Acc: (84.72%) (41200/48630)\n",
      "Epoch: 6 | Batch_idx: 1630 |  Loss: (0.4445) | Acc: (84.73%) (41459/48930)\n",
      "Epoch: 6 | Batch_idx: 1640 |  Loss: (0.4440) | Acc: (84.75%) (41720/49230)\n",
      "Epoch: 6 | Batch_idx: 1650 |  Loss: (0.4447) | Acc: (84.72%) (41960/49530)\n",
      "Epoch: 6 | Batch_idx: 1660 |  Loss: (0.4450) | Acc: (84.71%) (42212/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4938) | Acc: (83.75%) (8375/10000)\n",
      "Epoch: 7 | Batch_idx: 0 |  Loss: (0.5631) | Acc: (80.00%) (24/30)\n",
      "Epoch: 7 | Batch_idx: 10 |  Loss: (0.4703) | Acc: (85.15%) (281/330)\n",
      "Epoch: 7 | Batch_idx: 20 |  Loss: (0.4538) | Acc: (85.08%) (536/630)\n",
      "Epoch: 7 | Batch_idx: 30 |  Loss: (0.4364) | Acc: (85.59%) (796/930)\n",
      "Epoch: 7 | Batch_idx: 40 |  Loss: (0.4200) | Acc: (85.77%) (1055/1230)\n",
      "Epoch: 7 | Batch_idx: 50 |  Loss: (0.4068) | Acc: (86.21%) (1319/1530)\n",
      "Epoch: 7 | Batch_idx: 60 |  Loss: (0.3963) | Acc: (86.56%) (1584/1830)\n",
      "Epoch: 7 | Batch_idx: 70 |  Loss: (0.3999) | Acc: (86.48%) (1842/2130)\n",
      "Epoch: 7 | Batch_idx: 80 |  Loss: (0.3954) | Acc: (86.46%) (2101/2430)\n",
      "Epoch: 7 | Batch_idx: 90 |  Loss: (0.3911) | Acc: (86.70%) (2367/2730)\n",
      "Epoch: 7 | Batch_idx: 100 |  Loss: (0.3893) | Acc: (86.70%) (2627/3030)\n",
      "Epoch: 7 | Batch_idx: 110 |  Loss: (0.3868) | Acc: (86.97%) (2896/3330)\n",
      "Epoch: 7 | Batch_idx: 120 |  Loss: (0.3834) | Acc: (87.05%) (3160/3630)\n",
      "Epoch: 7 | Batch_idx: 130 |  Loss: (0.3792) | Acc: (87.18%) (3426/3930)\n",
      "Epoch: 7 | Batch_idx: 140 |  Loss: (0.3819) | Acc: (86.90%) (3676/4230)\n",
      "Epoch: 7 | Batch_idx: 150 |  Loss: (0.3792) | Acc: (87.04%) (3943/4530)\n",
      "Epoch: 7 | Batch_idx: 160 |  Loss: (0.3743) | Acc: (87.29%) (4216/4830)\n",
      "Epoch: 7 | Batch_idx: 170 |  Loss: (0.3814) | Acc: (87.10%) (4468/5130)\n",
      "Epoch: 7 | Batch_idx: 180 |  Loss: (0.3904) | Acc: (86.91%) (4719/5430)\n",
      "Epoch: 7 | Batch_idx: 190 |  Loss: (0.3869) | Acc: (87.05%) (4988/5730)\n",
      "Epoch: 7 | Batch_idx: 200 |  Loss: (0.3872) | Acc: (87.06%) (5250/6030)\n",
      "Epoch: 7 | Batch_idx: 210 |  Loss: (0.3872) | Acc: (86.94%) (5503/6330)\n",
      "Epoch: 7 | Batch_idx: 220 |  Loss: (0.3927) | Acc: (86.62%) (5743/6630)\n",
      "Epoch: 7 | Batch_idx: 230 |  Loss: (0.3935) | Acc: (86.62%) (6003/6930)\n",
      "Epoch: 7 | Batch_idx: 240 |  Loss: (0.3944) | Acc: (86.57%) (6259/7230)\n",
      "Epoch: 7 | Batch_idx: 250 |  Loss: (0.3944) | Acc: (86.52%) (6515/7530)\n",
      "Epoch: 7 | Batch_idx: 260 |  Loss: (0.3932) | Acc: (86.56%) (6778/7830)\n",
      "Epoch: 7 | Batch_idx: 270 |  Loss: (0.3949) | Acc: (86.52%) (7034/8130)\n",
      "Epoch: 7 | Batch_idx: 280 |  Loss: (0.3948) | Acc: (86.49%) (7291/8430)\n",
      "Epoch: 7 | Batch_idx: 290 |  Loss: (0.3937) | Acc: (86.53%) (7554/8730)\n",
      "Epoch: 7 | Batch_idx: 300 |  Loss: (0.3918) | Acc: (86.60%) (7820/9030)\n",
      "Epoch: 7 | Batch_idx: 310 |  Loss: (0.3927) | Acc: (86.61%) (8081/9330)\n",
      "Epoch: 7 | Batch_idx: 320 |  Loss: (0.3912) | Acc: (86.65%) (8344/9630)\n",
      "Epoch: 7 | Batch_idx: 330 |  Loss: (0.3888) | Acc: (86.74%) (8613/9930)\n",
      "Epoch: 7 | Batch_idx: 340 |  Loss: (0.3891) | Acc: (86.75%) (8875/10230)\n",
      "Epoch: 7 | Batch_idx: 350 |  Loss: (0.3886) | Acc: (86.81%) (9141/10530)\n",
      "Epoch: 7 | Batch_idx: 360 |  Loss: (0.3870) | Acc: (86.86%) (9407/10830)\n",
      "Epoch: 7 | Batch_idx: 370 |  Loss: (0.3869) | Acc: (86.86%) (9668/11130)\n",
      "Epoch: 7 | Batch_idx: 380 |  Loss: (0.3853) | Acc: (86.96%) (9939/11430)\n",
      "Epoch: 7 | Batch_idx: 390 |  Loss: (0.3840) | Acc: (87.03%) (10209/11730)\n",
      "Epoch: 7 | Batch_idx: 400 |  Loss: (0.3844) | Acc: (87.00%) (10466/12030)\n",
      "Epoch: 7 | Batch_idx: 410 |  Loss: (0.3851) | Acc: (86.98%) (10725/12330)\n",
      "Epoch: 7 | Batch_idx: 420 |  Loss: (0.3846) | Acc: (86.97%) (10984/12630)\n",
      "Epoch: 7 | Batch_idx: 430 |  Loss: (0.3834) | Acc: (87.04%) (11254/12930)\n",
      "Epoch: 7 | Batch_idx: 440 |  Loss: (0.3814) | Acc: (87.11%) (11524/13230)\n",
      "Epoch: 7 | Batch_idx: 450 |  Loss: (0.3813) | Acc: (87.09%) (11783/13530)\n",
      "Epoch: 7 | Batch_idx: 460 |  Loss: (0.3816) | Acc: (87.07%) (12042/13830)\n",
      "Epoch: 7 | Batch_idx: 470 |  Loss: (0.3809) | Acc: (87.08%) (12304/14130)\n",
      "Epoch: 7 | Batch_idx: 480 |  Loss: (0.3800) | Acc: (87.14%) (12575/14430)\n",
      "Epoch: 7 | Batch_idx: 490 |  Loss: (0.3808) | Acc: (87.11%) (12832/14730)\n",
      "Epoch: 7 | Batch_idx: 500 |  Loss: (0.3826) | Acc: (87.09%) (13089/15030)\n",
      "Epoch: 7 | Batch_idx: 510 |  Loss: (0.3825) | Acc: (87.10%) (13352/15330)\n",
      "Epoch: 7 | Batch_idx: 520 |  Loss: (0.3844) | Acc: (87.02%) (13601/15630)\n",
      "Epoch: 7 | Batch_idx: 530 |  Loss: (0.3850) | Acc: (87.00%) (13859/15930)\n",
      "Epoch: 7 | Batch_idx: 540 |  Loss: (0.3856) | Acc: (86.97%) (14116/16230)\n",
      "Epoch: 7 | Batch_idx: 550 |  Loss: (0.3862) | Acc: (86.98%) (14377/16530)\n",
      "Epoch: 7 | Batch_idx: 560 |  Loss: (0.3881) | Acc: (86.92%) (14628/16830)\n",
      "Epoch: 7 | Batch_idx: 570 |  Loss: (0.3892) | Acc: (86.87%) (14881/17130)\n",
      "Epoch: 7 | Batch_idx: 580 |  Loss: (0.3887) | Acc: (86.87%) (15142/17430)\n",
      "Epoch: 7 | Batch_idx: 590 |  Loss: (0.3884) | Acc: (86.86%) (15401/17730)\n",
      "Epoch: 7 | Batch_idx: 600 |  Loss: (0.3893) | Acc: (86.81%) (15652/18030)\n",
      "Epoch: 7 | Batch_idx: 610 |  Loss: (0.3896) | Acc: (86.80%) (15910/18330)\n",
      "Epoch: 7 | Batch_idx: 620 |  Loss: (0.3911) | Acc: (86.74%) (16160/18630)\n",
      "Epoch: 7 | Batch_idx: 630 |  Loss: (0.3904) | Acc: (86.74%) (16420/18930)\n",
      "Epoch: 7 | Batch_idx: 640 |  Loss: (0.3898) | Acc: (86.78%) (16687/19230)\n",
      "Epoch: 7 | Batch_idx: 650 |  Loss: (0.3910) | Acc: (86.69%) (16931/19530)\n",
      "Epoch: 7 | Batch_idx: 660 |  Loss: (0.3922) | Acc: (86.65%) (17183/19830)\n",
      "Epoch: 7 | Batch_idx: 670 |  Loss: (0.3922) | Acc: (86.66%) (17445/20130)\n",
      "Epoch: 7 | Batch_idx: 680 |  Loss: (0.3917) | Acc: (86.66%) (17704/20430)\n",
      "Epoch: 7 | Batch_idx: 690 |  Loss: (0.3931) | Acc: (86.63%) (17958/20730)\n",
      "Epoch: 7 | Batch_idx: 700 |  Loss: (0.3942) | Acc: (86.59%) (18209/21030)\n",
      "Epoch: 7 | Batch_idx: 710 |  Loss: (0.3951) | Acc: (86.60%) (18471/21330)\n",
      "Epoch: 7 | Batch_idx: 720 |  Loss: (0.3955) | Acc: (86.56%) (18722/21630)\n",
      "Epoch: 7 | Batch_idx: 730 |  Loss: (0.3954) | Acc: (86.53%) (18977/21930)\n",
      "Epoch: 7 | Batch_idx: 740 |  Loss: (0.3952) | Acc: (86.57%) (19245/22230)\n",
      "Epoch: 7 | Batch_idx: 750 |  Loss: (0.3955) | Acc: (86.53%) (19496/22530)\n",
      "Epoch: 7 | Batch_idx: 760 |  Loss: (0.3951) | Acc: (86.54%) (19758/22830)\n",
      "Epoch: 7 | Batch_idx: 770 |  Loss: (0.3948) | Acc: (86.58%) (20025/23130)\n",
      "Epoch: 7 | Batch_idx: 780 |  Loss: (0.3950) | Acc: (86.56%) (20280/23430)\n",
      "Epoch: 7 | Batch_idx: 790 |  Loss: (0.3958) | Acc: (86.54%) (20535/23730)\n",
      "Epoch: 7 | Batch_idx: 800 |  Loss: (0.3953) | Acc: (86.55%) (20798/24030)\n",
      "Epoch: 7 | Batch_idx: 810 |  Loss: (0.3944) | Acc: (86.58%) (21065/24330)\n",
      "Epoch: 7 | Batch_idx: 820 |  Loss: (0.3941) | Acc: (86.58%) (21325/24630)\n",
      "Epoch: 7 | Batch_idx: 830 |  Loss: (0.3939) | Acc: (86.59%) (21586/24930)\n",
      "Epoch: 7 | Batch_idx: 840 |  Loss: (0.3938) | Acc: (86.61%) (21851/25230)\n",
      "Epoch: 7 | Batch_idx: 850 |  Loss: (0.3937) | Acc: (86.61%) (22112/25530)\n",
      "Epoch: 7 | Batch_idx: 860 |  Loss: (0.3947) | Acc: (86.58%) (22363/25830)\n",
      "Epoch: 7 | Batch_idx: 870 |  Loss: (0.3953) | Acc: (86.55%) (22615/26130)\n",
      "Epoch: 7 | Batch_idx: 880 |  Loss: (0.3949) | Acc: (86.54%) (22872/26430)\n",
      "Epoch: 7 | Batch_idx: 890 |  Loss: (0.3951) | Acc: (86.54%) (23132/26730)\n",
      "Epoch: 7 | Batch_idx: 900 |  Loss: (0.3949) | Acc: (86.54%) (23392/27030)\n",
      "Epoch: 7 | Batch_idx: 910 |  Loss: (0.3947) | Acc: (86.55%) (23655/27330)\n",
      "Epoch: 7 | Batch_idx: 920 |  Loss: (0.3951) | Acc: (86.56%) (23916/27630)\n",
      "Epoch: 7 | Batch_idx: 930 |  Loss: (0.3951) | Acc: (86.57%) (24180/27930)\n",
      "Epoch: 7 | Batch_idx: 940 |  Loss: (0.3955) | Acc: (86.56%) (24435/28230)\n",
      "Epoch: 7 | Batch_idx: 950 |  Loss: (0.3957) | Acc: (86.55%) (24694/28530)\n",
      "Epoch: 7 | Batch_idx: 960 |  Loss: (0.3955) | Acc: (86.57%) (24959/28830)\n",
      "Epoch: 7 | Batch_idx: 970 |  Loss: (0.3955) | Acc: (86.56%) (25216/29130)\n",
      "Epoch: 7 | Batch_idx: 980 |  Loss: (0.3954) | Acc: (86.57%) (25478/29430)\n",
      "Epoch: 7 | Batch_idx: 990 |  Loss: (0.3958) | Acc: (86.55%) (25732/29730)\n",
      "Epoch: 7 | Batch_idx: 1000 |  Loss: (0.3956) | Acc: (86.57%) (25997/30030)\n",
      "Epoch: 7 | Batch_idx: 1010 |  Loss: (0.3952) | Acc: (86.60%) (26265/30330)\n",
      "Epoch: 7 | Batch_idx: 1020 |  Loss: (0.3957) | Acc: (86.58%) (26518/30630)\n",
      "Epoch: 7 | Batch_idx: 1030 |  Loss: (0.3958) | Acc: (86.55%) (26769/30930)\n",
      "Epoch: 7 | Batch_idx: 1040 |  Loss: (0.3954) | Acc: (86.56%) (27033/31230)\n",
      "Epoch: 7 | Batch_idx: 1050 |  Loss: (0.3948) | Acc: (86.58%) (27298/31530)\n",
      "Epoch: 7 | Batch_idx: 1060 |  Loss: (0.3946) | Acc: (86.57%) (27556/31830)\n",
      "Epoch: 7 | Batch_idx: 1070 |  Loss: (0.3949) | Acc: (86.56%) (27812/32130)\n",
      "Epoch: 7 | Batch_idx: 1080 |  Loss: (0.3945) | Acc: (86.56%) (28072/32430)\n",
      "Epoch: 7 | Batch_idx: 1090 |  Loss: (0.3942) | Acc: (86.57%) (28333/32730)\n",
      "Epoch: 7 | Batch_idx: 1100 |  Loss: (0.3941) | Acc: (86.57%) (28593/33030)\n",
      "Epoch: 7 | Batch_idx: 1110 |  Loss: (0.3937) | Acc: (86.59%) (28862/33330)\n",
      "Epoch: 7 | Batch_idx: 1120 |  Loss: (0.3935) | Acc: (86.62%) (29129/33630)\n",
      "Epoch: 7 | Batch_idx: 1130 |  Loss: (0.3936) | Acc: (86.63%) (29393/33930)\n",
      "Epoch: 7 | Batch_idx: 1140 |  Loss: (0.3933) | Acc: (86.63%) (29653/34230)\n",
      "Epoch: 7 | Batch_idx: 1150 |  Loss: (0.3937) | Acc: (86.61%) (29906/34530)\n",
      "Epoch: 7 | Batch_idx: 1160 |  Loss: (0.3934) | Acc: (86.61%) (30166/34830)\n",
      "Epoch: 7 | Batch_idx: 1170 |  Loss: (0.3936) | Acc: (86.58%) (30417/35130)\n",
      "Epoch: 7 | Batch_idx: 1180 |  Loss: (0.3933) | Acc: (86.60%) (30683/35430)\n",
      "Epoch: 7 | Batch_idx: 1190 |  Loss: (0.3932) | Acc: (86.60%) (30943/35730)\n",
      "Epoch: 7 | Batch_idx: 1200 |  Loss: (0.3929) | Acc: (86.61%) (31207/36030)\n",
      "Epoch: 7 | Batch_idx: 1210 |  Loss: (0.3929) | Acc: (86.61%) (31465/36330)\n",
      "Epoch: 7 | Batch_idx: 1220 |  Loss: (0.3930) | Acc: (86.63%) (31733/36630)\n",
      "Epoch: 7 | Batch_idx: 1230 |  Loss: (0.3931) | Acc: (86.61%) (31985/36930)\n",
      "Epoch: 7 | Batch_idx: 1240 |  Loss: (0.3935) | Acc: (86.59%) (32238/37230)\n",
      "Epoch: 7 | Batch_idx: 1250 |  Loss: (0.3932) | Acc: (86.61%) (32503/37530)\n",
      "Epoch: 7 | Batch_idx: 1260 |  Loss: (0.3941) | Acc: (86.57%) (32750/37830)\n",
      "Epoch: 7 | Batch_idx: 1270 |  Loss: (0.3951) | Acc: (86.55%) (33001/38130)\n",
      "Epoch: 7 | Batch_idx: 1280 |  Loss: (0.3947) | Acc: (86.54%) (33258/38430)\n",
      "Epoch: 7 | Batch_idx: 1290 |  Loss: (0.3950) | Acc: (86.54%) (33517/38730)\n",
      "Epoch: 7 | Batch_idx: 1300 |  Loss: (0.3954) | Acc: (86.54%) (33778/39030)\n",
      "Epoch: 7 | Batch_idx: 1310 |  Loss: (0.3954) | Acc: (86.55%) (34039/39330)\n",
      "Epoch: 7 | Batch_idx: 1320 |  Loss: (0.3953) | Acc: (86.55%) (34299/39630)\n",
      "Epoch: 7 | Batch_idx: 1330 |  Loss: (0.3954) | Acc: (86.53%) (34550/39930)\n",
      "Epoch: 7 | Batch_idx: 1340 |  Loss: (0.3953) | Acc: (86.52%) (34807/40230)\n",
      "Epoch: 7 | Batch_idx: 1350 |  Loss: (0.3950) | Acc: (86.52%) (35067/40530)\n",
      "Epoch: 7 | Batch_idx: 1360 |  Loss: (0.3952) | Acc: (86.52%) (35325/40830)\n",
      "Epoch: 7 | Batch_idx: 1370 |  Loss: (0.3949) | Acc: (86.52%) (35587/41130)\n",
      "Epoch: 7 | Batch_idx: 1380 |  Loss: (0.3944) | Acc: (86.55%) (35858/41430)\n",
      "Epoch: 7 | Batch_idx: 1390 |  Loss: (0.3942) | Acc: (86.57%) (36127/41730)\n",
      "Epoch: 7 | Batch_idx: 1400 |  Loss: (0.3941) | Acc: (86.58%) (36390/42030)\n",
      "Epoch: 7 | Batch_idx: 1410 |  Loss: (0.3941) | Acc: (86.58%) (36651/42330)\n",
      "Epoch: 7 | Batch_idx: 1420 |  Loss: (0.3941) | Acc: (86.59%) (36913/42630)\n",
      "Epoch: 7 | Batch_idx: 1430 |  Loss: (0.3950) | Acc: (86.56%) (37160/42930)\n",
      "Epoch: 7 | Batch_idx: 1440 |  Loss: (0.3957) | Acc: (86.54%) (37412/43230)\n",
      "Epoch: 7 | Batch_idx: 1450 |  Loss: (0.3962) | Acc: (86.52%) (37662/43530)\n",
      "Epoch: 7 | Batch_idx: 1460 |  Loss: (0.3958) | Acc: (86.52%) (37923/43830)\n",
      "Epoch: 7 | Batch_idx: 1470 |  Loss: (0.3957) | Acc: (86.52%) (38183/44130)\n",
      "Epoch: 7 | Batch_idx: 1480 |  Loss: (0.3955) | Acc: (86.52%) (38443/44430)\n",
      "Epoch: 7 | Batch_idx: 1490 |  Loss: (0.3955) | Acc: (86.52%) (38699/44730)\n",
      "Epoch: 7 | Batch_idx: 1500 |  Loss: (0.3953) | Acc: (86.52%) (38960/45030)\n",
      "Epoch: 7 | Batch_idx: 1510 |  Loss: (0.3953) | Acc: (86.52%) (39221/45330)\n",
      "Epoch: 7 | Batch_idx: 1520 |  Loss: (0.3953) | Acc: (86.52%) (39479/45630)\n",
      "Epoch: 7 | Batch_idx: 1530 |  Loss: (0.3953) | Acc: (86.52%) (39737/45930)\n",
      "Epoch: 7 | Batch_idx: 1540 |  Loss: (0.3953) | Acc: (86.52%) (39998/46230)\n",
      "Epoch: 7 | Batch_idx: 1550 |  Loss: (0.3957) | Acc: (86.51%) (40254/46530)\n",
      "Epoch: 7 | Batch_idx: 1560 |  Loss: (0.3958) | Acc: (86.50%) (40507/46830)\n",
      "Epoch: 7 | Batch_idx: 1570 |  Loss: (0.3956) | Acc: (86.49%) (40761/47130)\n",
      "Epoch: 7 | Batch_idx: 1580 |  Loss: (0.3957) | Acc: (86.49%) (41020/47430)\n",
      "Epoch: 7 | Batch_idx: 1590 |  Loss: (0.3958) | Acc: (86.48%) (41278/47730)\n",
      "Epoch: 7 | Batch_idx: 1600 |  Loss: (0.3958) | Acc: (86.48%) (41536/48030)\n",
      "Epoch: 7 | Batch_idx: 1610 |  Loss: (0.3953) | Acc: (86.50%) (41804/48330)\n",
      "Epoch: 7 | Batch_idx: 1620 |  Loss: (0.3955) | Acc: (86.48%) (42057/48630)\n",
      "Epoch: 7 | Batch_idx: 1630 |  Loss: (0.3952) | Acc: (86.48%) (42315/48930)\n",
      "Epoch: 7 | Batch_idx: 1640 |  Loss: (0.3948) | Acc: (86.49%) (42581/49230)\n",
      "Epoch: 7 | Batch_idx: 1650 |  Loss: (0.3949) | Acc: (86.50%) (42841/49530)\n",
      "Epoch: 7 | Batch_idx: 1660 |  Loss: (0.3950) | Acc: (86.50%) (43101/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4196) | Acc: (86.04%) (8604/10000)\n",
      "Epoch: 8 | Batch_idx: 0 |  Loss: (0.1945) | Acc: (93.33%) (28/30)\n",
      "Epoch: 8 | Batch_idx: 10 |  Loss: (0.2365) | Acc: (91.52%) (302/330)\n",
      "Epoch: 8 | Batch_idx: 20 |  Loss: (0.2823) | Acc: (90.48%) (570/630)\n",
      "Epoch: 8 | Batch_idx: 30 |  Loss: (0.3078) | Acc: (89.46%) (832/930)\n",
      "Epoch: 8 | Batch_idx: 40 |  Loss: (0.3194) | Acc: (89.27%) (1098/1230)\n",
      "Epoch: 8 | Batch_idx: 50 |  Loss: (0.3214) | Acc: (89.15%) (1364/1530)\n",
      "Epoch: 8 | Batch_idx: 60 |  Loss: (0.3316) | Acc: (88.42%) (1618/1830)\n",
      "Epoch: 8 | Batch_idx: 70 |  Loss: (0.3364) | Acc: (88.31%) (1881/2130)\n",
      "Epoch: 8 | Batch_idx: 80 |  Loss: (0.3398) | Acc: (88.19%) (2143/2430)\n",
      "Epoch: 8 | Batch_idx: 90 |  Loss: (0.3396) | Acc: (88.21%) (2408/2730)\n",
      "Epoch: 8 | Batch_idx: 100 |  Loss: (0.3376) | Acc: (88.35%) (2677/3030)\n",
      "Epoch: 8 | Batch_idx: 110 |  Loss: (0.3407) | Acc: (88.32%) (2941/3330)\n",
      "Epoch: 8 | Batch_idx: 120 |  Loss: (0.3357) | Acc: (88.46%) (3211/3630)\n",
      "Epoch: 8 | Batch_idx: 130 |  Loss: (0.3417) | Acc: (88.30%) (3470/3930)\n",
      "Epoch: 8 | Batch_idx: 140 |  Loss: (0.3464) | Acc: (88.04%) (3724/4230)\n",
      "Epoch: 8 | Batch_idx: 150 |  Loss: (0.3452) | Acc: (88.01%) (3987/4530)\n",
      "Epoch: 8 | Batch_idx: 160 |  Loss: (0.3500) | Acc: (87.89%) (4245/4830)\n",
      "Epoch: 8 | Batch_idx: 170 |  Loss: (0.3458) | Acc: (88.03%) (4516/5130)\n",
      "Epoch: 8 | Batch_idx: 180 |  Loss: (0.3438) | Acc: (88.03%) (4780/5430)\n",
      "Epoch: 8 | Batch_idx: 190 |  Loss: (0.3450) | Acc: (87.96%) (5040/5730)\n",
      "Epoch: 8 | Batch_idx: 200 |  Loss: (0.3436) | Acc: (88.04%) (5309/6030)\n",
      "Epoch: 8 | Batch_idx: 210 |  Loss: (0.3410) | Acc: (88.10%) (5577/6330)\n",
      "Epoch: 8 | Batch_idx: 220 |  Loss: (0.3399) | Acc: (88.16%) (5845/6630)\n",
      "Epoch: 8 | Batch_idx: 230 |  Loss: (0.3381) | Acc: (88.23%) (6114/6930)\n",
      "Epoch: 8 | Batch_idx: 240 |  Loss: (0.3400) | Acc: (88.16%) (6374/7230)\n",
      "Epoch: 8 | Batch_idx: 250 |  Loss: (0.3398) | Acc: (88.19%) (6641/7530)\n",
      "Epoch: 8 | Batch_idx: 260 |  Loss: (0.3406) | Acc: (88.17%) (6904/7830)\n",
      "Epoch: 8 | Batch_idx: 270 |  Loss: (0.3367) | Acc: (88.35%) (7183/8130)\n",
      "Epoch: 8 | Batch_idx: 280 |  Loss: (0.3389) | Acc: (88.30%) (7444/8430)\n",
      "Epoch: 8 | Batch_idx: 290 |  Loss: (0.3389) | Acc: (88.28%) (7707/8730)\n",
      "Epoch: 8 | Batch_idx: 300 |  Loss: (0.3404) | Acc: (88.24%) (7968/9030)\n",
      "Epoch: 8 | Batch_idx: 310 |  Loss: (0.3411) | Acc: (88.22%) (8231/9330)\n",
      "Epoch: 8 | Batch_idx: 320 |  Loss: (0.3412) | Acc: (88.27%) (8500/9630)\n",
      "Epoch: 8 | Batch_idx: 330 |  Loss: (0.3428) | Acc: (88.30%) (8768/9930)\n",
      "Epoch: 8 | Batch_idx: 340 |  Loss: (0.3403) | Acc: (88.38%) (9041/10230)\n",
      "Epoch: 8 | Batch_idx: 350 |  Loss: (0.3404) | Acc: (88.39%) (9307/10530)\n",
      "Epoch: 8 | Batch_idx: 360 |  Loss: (0.3425) | Acc: (88.33%) (9566/10830)\n",
      "Epoch: 8 | Batch_idx: 370 |  Loss: (0.3450) | Acc: (88.27%) (9825/11130)\n",
      "Epoch: 8 | Batch_idx: 380 |  Loss: (0.3461) | Acc: (88.21%) (10082/11430)\n",
      "Epoch: 8 | Batch_idx: 390 |  Loss: (0.3456) | Acc: (88.24%) (10351/11730)\n",
      "Epoch: 8 | Batch_idx: 400 |  Loss: (0.3460) | Acc: (88.22%) (10613/12030)\n",
      "Epoch: 8 | Batch_idx: 410 |  Loss: (0.3468) | Acc: (88.21%) (10876/12330)\n",
      "Epoch: 8 | Batch_idx: 420 |  Loss: (0.3480) | Acc: (88.19%) (11139/12630)\n",
      "Epoch: 8 | Batch_idx: 430 |  Loss: (0.3486) | Acc: (88.16%) (11399/12930)\n",
      "Epoch: 8 | Batch_idx: 440 |  Loss: (0.3478) | Acc: (88.18%) (11666/13230)\n",
      "Epoch: 8 | Batch_idx: 450 |  Loss: (0.3491) | Acc: (88.14%) (11925/13530)\n",
      "Epoch: 8 | Batch_idx: 460 |  Loss: (0.3510) | Acc: (88.03%) (12175/13830)\n",
      "Epoch: 8 | Batch_idx: 470 |  Loss: (0.3487) | Acc: (88.13%) (12453/14130)\n",
      "Epoch: 8 | Batch_idx: 480 |  Loss: (0.3482) | Acc: (88.07%) (12708/14430)\n",
      "Epoch: 8 | Batch_idx: 490 |  Loss: (0.3487) | Acc: (88.07%) (12972/14730)\n",
      "Epoch: 8 | Batch_idx: 500 |  Loss: (0.3488) | Acc: (88.08%) (13238/15030)\n",
      "Epoch: 8 | Batch_idx: 510 |  Loss: (0.3490) | Acc: (88.04%) (13497/15330)\n",
      "Epoch: 8 | Batch_idx: 520 |  Loss: (0.3492) | Acc: (88.02%) (13758/15630)\n",
      "Epoch: 8 | Batch_idx: 530 |  Loss: (0.3503) | Acc: (87.95%) (14011/15930)\n",
      "Epoch: 8 | Batch_idx: 540 |  Loss: (0.3510) | Acc: (87.95%) (14274/16230)\n",
      "Epoch: 8 | Batch_idx: 550 |  Loss: (0.3500) | Acc: (88.00%) (14546/16530)\n",
      "Epoch: 8 | Batch_idx: 560 |  Loss: (0.3489) | Acc: (88.03%) (14816/16830)\n",
      "Epoch: 8 | Batch_idx: 570 |  Loss: (0.3490) | Acc: (87.97%) (15070/17130)\n",
      "Epoch: 8 | Batch_idx: 580 |  Loss: (0.3503) | Acc: (87.91%) (15323/17430)\n",
      "Epoch: 8 | Batch_idx: 590 |  Loss: (0.3496) | Acc: (87.94%) (15591/17730)\n",
      "Epoch: 8 | Batch_idx: 600 |  Loss: (0.3503) | Acc: (87.93%) (15854/18030)\n",
      "Epoch: 8 | Batch_idx: 610 |  Loss: (0.3509) | Acc: (87.90%) (16112/18330)\n",
      "Epoch: 8 | Batch_idx: 620 |  Loss: (0.3512) | Acc: (87.87%) (16371/18630)\n",
      "Epoch: 8 | Batch_idx: 630 |  Loss: (0.3515) | Acc: (87.84%) (16628/18930)\n",
      "Epoch: 8 | Batch_idx: 640 |  Loss: (0.3523) | Acc: (87.80%) (16884/19230)\n",
      "Epoch: 8 | Batch_idx: 650 |  Loss: (0.3520) | Acc: (87.83%) (17154/19530)\n",
      "Epoch: 8 | Batch_idx: 660 |  Loss: (0.3523) | Acc: (87.83%) (17417/19830)\n",
      "Epoch: 8 | Batch_idx: 670 |  Loss: (0.3517) | Acc: (87.85%) (17684/20130)\n",
      "Epoch: 8 | Batch_idx: 680 |  Loss: (0.3519) | Acc: (87.84%) (17945/20430)\n",
      "Epoch: 8 | Batch_idx: 690 |  Loss: (0.3515) | Acc: (87.86%) (18214/20730)\n",
      "Epoch: 8 | Batch_idx: 700 |  Loss: (0.3523) | Acc: (87.86%) (18478/21030)\n",
      "Epoch: 8 | Batch_idx: 710 |  Loss: (0.3520) | Acc: (87.86%) (18740/21330)\n",
      "Epoch: 8 | Batch_idx: 720 |  Loss: (0.3515) | Acc: (87.88%) (19008/21630)\n",
      "Epoch: 8 | Batch_idx: 730 |  Loss: (0.3518) | Acc: (87.88%) (19272/21930)\n",
      "Epoch: 8 | Batch_idx: 740 |  Loss: (0.3515) | Acc: (87.87%) (19534/22230)\n",
      "Epoch: 8 | Batch_idx: 750 |  Loss: (0.3531) | Acc: (87.82%) (19785/22530)\n",
      "Epoch: 8 | Batch_idx: 760 |  Loss: (0.3533) | Acc: (87.82%) (20049/22830)\n",
      "Epoch: 8 | Batch_idx: 770 |  Loss: (0.3531) | Acc: (87.83%) (20314/23130)\n",
      "Epoch: 8 | Batch_idx: 780 |  Loss: (0.3529) | Acc: (87.81%) (20573/23430)\n",
      "Epoch: 8 | Batch_idx: 790 |  Loss: (0.3535) | Acc: (87.79%) (20832/23730)\n",
      "Epoch: 8 | Batch_idx: 800 |  Loss: (0.3539) | Acc: (87.79%) (21095/24030)\n",
      "Epoch: 8 | Batch_idx: 810 |  Loss: (0.3535) | Acc: (87.79%) (21360/24330)\n",
      "Epoch: 8 | Batch_idx: 820 |  Loss: (0.3524) | Acc: (87.82%) (21630/24630)\n",
      "Epoch: 8 | Batch_idx: 830 |  Loss: (0.3519) | Acc: (87.85%) (21902/24930)\n",
      "Epoch: 8 | Batch_idx: 840 |  Loss: (0.3514) | Acc: (87.88%) (22171/25230)\n",
      "Epoch: 8 | Batch_idx: 850 |  Loss: (0.3528) | Acc: (87.87%) (22432/25530)\n",
      "Epoch: 8 | Batch_idx: 860 |  Loss: (0.3535) | Acc: (87.84%) (22690/25830)\n",
      "Epoch: 8 | Batch_idx: 870 |  Loss: (0.3547) | Acc: (87.80%) (22941/26130)\n",
      "Epoch: 8 | Batch_idx: 880 |  Loss: (0.3541) | Acc: (87.84%) (23215/26430)\n",
      "Epoch: 8 | Batch_idx: 890 |  Loss: (0.3545) | Acc: (87.84%) (23479/26730)\n",
      "Epoch: 8 | Batch_idx: 900 |  Loss: (0.3545) | Acc: (87.83%) (23741/27030)\n",
      "Epoch: 8 | Batch_idx: 910 |  Loss: (0.3546) | Acc: (87.83%) (24004/27330)\n",
      "Epoch: 8 | Batch_idx: 920 |  Loss: (0.3548) | Acc: (87.82%) (24265/27630)\n",
      "Epoch: 8 | Batch_idx: 930 |  Loss: (0.3548) | Acc: (87.81%) (24526/27930)\n",
      "Epoch: 8 | Batch_idx: 940 |  Loss: (0.3550) | Acc: (87.79%) (24782/28230)\n",
      "Epoch: 8 | Batch_idx: 950 |  Loss: (0.3557) | Acc: (87.77%) (25041/28530)\n",
      "Epoch: 8 | Batch_idx: 960 |  Loss: (0.3557) | Acc: (87.78%) (25306/28830)\n",
      "Epoch: 8 | Batch_idx: 970 |  Loss: (0.3563) | Acc: (87.76%) (25564/29130)\n",
      "Epoch: 8 | Batch_idx: 980 |  Loss: (0.3561) | Acc: (87.76%) (25828/29430)\n",
      "Epoch: 8 | Batch_idx: 990 |  Loss: (0.3571) | Acc: (87.75%) (26089/29730)\n",
      "Epoch: 8 | Batch_idx: 1000 |  Loss: (0.3578) | Acc: (87.71%) (26338/30030)\n",
      "Epoch: 8 | Batch_idx: 1010 |  Loss: (0.3580) | Acc: (87.71%) (26602/30330)\n",
      "Epoch: 8 | Batch_idx: 1020 |  Loss: (0.3578) | Acc: (87.71%) (26867/30630)\n",
      "Epoch: 8 | Batch_idx: 1030 |  Loss: (0.3574) | Acc: (87.73%) (27136/30930)\n",
      "Epoch: 8 | Batch_idx: 1040 |  Loss: (0.3581) | Acc: (87.73%) (27399/31230)\n",
      "Epoch: 8 | Batch_idx: 1050 |  Loss: (0.3581) | Acc: (87.72%) (27659/31530)\n",
      "Epoch: 8 | Batch_idx: 1060 |  Loss: (0.3579) | Acc: (87.74%) (27929/31830)\n",
      "Epoch: 8 | Batch_idx: 1070 |  Loss: (0.3579) | Acc: (87.76%) (28197/32130)\n",
      "Epoch: 8 | Batch_idx: 1080 |  Loss: (0.3575) | Acc: (87.79%) (28470/32430)\n",
      "Epoch: 8 | Batch_idx: 1090 |  Loss: (0.3568) | Acc: (87.80%) (28737/32730)\n",
      "Epoch: 8 | Batch_idx: 1100 |  Loss: (0.3564) | Acc: (87.82%) (29007/33030)\n",
      "Epoch: 8 | Batch_idx: 1110 |  Loss: (0.3561) | Acc: (87.82%) (29272/33330)\n",
      "Epoch: 8 | Batch_idx: 1120 |  Loss: (0.3559) | Acc: (87.83%) (29537/33630)\n",
      "Epoch: 8 | Batch_idx: 1130 |  Loss: (0.3557) | Acc: (87.85%) (29806/33930)\n",
      "Epoch: 8 | Batch_idx: 1140 |  Loss: (0.3552) | Acc: (87.87%) (30079/34230)\n",
      "Epoch: 8 | Batch_idx: 1150 |  Loss: (0.3551) | Acc: (87.89%) (30348/34530)\n",
      "Epoch: 8 | Batch_idx: 1160 |  Loss: (0.3558) | Acc: (87.86%) (30603/34830)\n",
      "Epoch: 8 | Batch_idx: 1170 |  Loss: (0.3556) | Acc: (87.87%) (30868/35130)\n",
      "Epoch: 8 | Batch_idx: 1180 |  Loss: (0.3560) | Acc: (87.86%) (31128/35430)\n",
      "Epoch: 8 | Batch_idx: 1190 |  Loss: (0.3555) | Acc: (87.86%) (31392/35730)\n",
      "Epoch: 8 | Batch_idx: 1200 |  Loss: (0.3553) | Acc: (87.87%) (31661/36030)\n",
      "Epoch: 8 | Batch_idx: 1210 |  Loss: (0.3551) | Acc: (87.88%) (31925/36330)\n",
      "Epoch: 8 | Batch_idx: 1220 |  Loss: (0.3546) | Acc: (87.90%) (32196/36630)\n",
      "Epoch: 8 | Batch_idx: 1230 |  Loss: (0.3545) | Acc: (87.89%) (32458/36930)\n",
      "Epoch: 8 | Batch_idx: 1240 |  Loss: (0.3541) | Acc: (87.91%) (32728/37230)\n",
      "Epoch: 8 | Batch_idx: 1250 |  Loss: (0.3544) | Acc: (87.90%) (32989/37530)\n",
      "Epoch: 8 | Batch_idx: 1260 |  Loss: (0.3540) | Acc: (87.92%) (33259/37830)\n",
      "Epoch: 8 | Batch_idx: 1270 |  Loss: (0.3542) | Acc: (87.91%) (33521/38130)\n",
      "Epoch: 8 | Batch_idx: 1280 |  Loss: (0.3543) | Acc: (87.90%) (33781/38430)\n",
      "Epoch: 8 | Batch_idx: 1290 |  Loss: (0.3541) | Acc: (87.91%) (34047/38730)\n",
      "Epoch: 8 | Batch_idx: 1300 |  Loss: (0.3538) | Acc: (87.91%) (34313/39030)\n",
      "Epoch: 8 | Batch_idx: 1310 |  Loss: (0.3537) | Acc: (87.92%) (34579/39330)\n",
      "Epoch: 8 | Batch_idx: 1320 |  Loss: (0.3533) | Acc: (87.94%) (34852/39630)\n",
      "Epoch: 8 | Batch_idx: 1330 |  Loss: (0.3534) | Acc: (87.94%) (35116/39930)\n",
      "Epoch: 8 | Batch_idx: 1340 |  Loss: (0.3527) | Acc: (87.98%) (35393/40230)\n",
      "Epoch: 8 | Batch_idx: 1350 |  Loss: (0.3524) | Acc: (87.99%) (35661/40530)\n",
      "Epoch: 8 | Batch_idx: 1360 |  Loss: (0.3526) | Acc: (87.99%) (35928/40830)\n",
      "Epoch: 8 | Batch_idx: 1370 |  Loss: (0.3525) | Acc: (87.99%) (36191/41130)\n",
      "Epoch: 8 | Batch_idx: 1380 |  Loss: (0.3527) | Acc: (87.98%) (36451/41430)\n",
      "Epoch: 8 | Batch_idx: 1390 |  Loss: (0.3533) | Acc: (87.97%) (36708/41730)\n",
      "Epoch: 8 | Batch_idx: 1400 |  Loss: (0.3532) | Acc: (87.96%) (36971/42030)\n",
      "Epoch: 8 | Batch_idx: 1410 |  Loss: (0.3530) | Acc: (87.96%) (37234/42330)\n",
      "Epoch: 8 | Batch_idx: 1420 |  Loss: (0.3529) | Acc: (87.96%) (37497/42630)\n",
      "Epoch: 8 | Batch_idx: 1430 |  Loss: (0.3531) | Acc: (87.94%) (37754/42930)\n",
      "Epoch: 8 | Batch_idx: 1440 |  Loss: (0.3539) | Acc: (87.94%) (38015/43230)\n",
      "Epoch: 8 | Batch_idx: 1450 |  Loss: (0.3536) | Acc: (87.94%) (38279/43530)\n",
      "Epoch: 8 | Batch_idx: 1460 |  Loss: (0.3536) | Acc: (87.93%) (38539/43830)\n",
      "Epoch: 8 | Batch_idx: 1470 |  Loss: (0.3537) | Acc: (87.93%) (38805/44130)\n",
      "Epoch: 8 | Batch_idx: 1480 |  Loss: (0.3532) | Acc: (87.94%) (39073/44430)\n",
      "Epoch: 8 | Batch_idx: 1490 |  Loss: (0.3529) | Acc: (87.95%) (39339/44730)\n",
      "Epoch: 8 | Batch_idx: 1500 |  Loss: (0.3525) | Acc: (87.96%) (39609/45030)\n",
      "Epoch: 8 | Batch_idx: 1510 |  Loss: (0.3526) | Acc: (87.96%) (39873/45330)\n",
      "Epoch: 8 | Batch_idx: 1520 |  Loss: (0.3529) | Acc: (87.95%) (40130/45630)\n",
      "Epoch: 8 | Batch_idx: 1530 |  Loss: (0.3531) | Acc: (87.93%) (40384/45930)\n",
      "Epoch: 8 | Batch_idx: 1540 |  Loss: (0.3532) | Acc: (87.92%) (40646/46230)\n",
      "Epoch: 8 | Batch_idx: 1550 |  Loss: (0.3531) | Acc: (87.93%) (40912/46530)\n",
      "Epoch: 8 | Batch_idx: 1560 |  Loss: (0.3531) | Acc: (87.91%) (41170/46830)\n",
      "Epoch: 8 | Batch_idx: 1570 |  Loss: (0.3530) | Acc: (87.91%) (41432/47130)\n",
      "Epoch: 8 | Batch_idx: 1580 |  Loss: (0.3529) | Acc: (87.92%) (41701/47430)\n",
      "Epoch: 8 | Batch_idx: 1590 |  Loss: (0.3529) | Acc: (87.93%) (41968/47730)\n",
      "Epoch: 8 | Batch_idx: 1600 |  Loss: (0.3528) | Acc: (87.93%) (42235/48030)\n",
      "Epoch: 8 | Batch_idx: 1610 |  Loss: (0.3526) | Acc: (87.96%) (42509/48330)\n",
      "Epoch: 8 | Batch_idx: 1620 |  Loss: (0.3527) | Acc: (87.95%) (42770/48630)\n",
      "Epoch: 8 | Batch_idx: 1630 |  Loss: (0.3521) | Acc: (87.96%) (43040/48930)\n",
      "Epoch: 8 | Batch_idx: 1640 |  Loss: (0.3521) | Acc: (87.96%) (43305/49230)\n",
      "Epoch: 8 | Batch_idx: 1650 |  Loss: (0.3526) | Acc: (87.95%) (43562/49530)\n",
      "Epoch: 8 | Batch_idx: 1660 |  Loss: (0.3529) | Acc: (87.95%) (43826/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4606) | Acc: (85.19%) (8519/10000)\n",
      "Epoch: 9 | Batch_idx: 0 |  Loss: (0.2300) | Acc: (93.33%) (28/30)\n",
      "Epoch: 9 | Batch_idx: 10 |  Loss: (0.3117) | Acc: (90.91%) (300/330)\n",
      "Epoch: 9 | Batch_idx: 20 |  Loss: (0.2684) | Acc: (91.90%) (579/630)\n",
      "Epoch: 9 | Batch_idx: 30 |  Loss: (0.2732) | Acc: (91.51%) (851/930)\n",
      "Epoch: 9 | Batch_idx: 40 |  Loss: (0.2790) | Acc: (91.06%) (1120/1230)\n",
      "Epoch: 9 | Batch_idx: 50 |  Loss: (0.2757) | Acc: (90.78%) (1389/1530)\n",
      "Epoch: 9 | Batch_idx: 60 |  Loss: (0.2821) | Acc: (90.60%) (1658/1830)\n",
      "Epoch: 9 | Batch_idx: 70 |  Loss: (0.2891) | Acc: (90.33%) (1924/2130)\n",
      "Epoch: 9 | Batch_idx: 80 |  Loss: (0.2854) | Acc: (90.33%) (2195/2430)\n",
      "Epoch: 9 | Batch_idx: 90 |  Loss: (0.2902) | Acc: (90.15%) (2461/2730)\n",
      "Epoch: 9 | Batch_idx: 100 |  Loss: (0.2928) | Acc: (90.07%) (2729/3030)\n",
      "Epoch: 9 | Batch_idx: 110 |  Loss: (0.3069) | Acc: (89.67%) (2986/3330)\n",
      "Epoch: 9 | Batch_idx: 120 |  Loss: (0.3048) | Acc: (89.64%) (3254/3630)\n",
      "Epoch: 9 | Batch_idx: 130 |  Loss: (0.3079) | Acc: (89.57%) (3520/3930)\n",
      "Epoch: 9 | Batch_idx: 140 |  Loss: (0.3086) | Acc: (89.43%) (3783/4230)\n",
      "Epoch: 9 | Batch_idx: 150 |  Loss: (0.3128) | Acc: (89.36%) (4048/4530)\n",
      "Epoch: 9 | Batch_idx: 160 |  Loss: (0.3195) | Acc: (89.13%) (4305/4830)\n",
      "Epoch: 9 | Batch_idx: 170 |  Loss: (0.3177) | Acc: (89.22%) (4577/5130)\n",
      "Epoch: 9 | Batch_idx: 180 |  Loss: (0.3152) | Acc: (89.28%) (4848/5430)\n",
      "Epoch: 9 | Batch_idx: 190 |  Loss: (0.3170) | Acc: (89.18%) (5110/5730)\n",
      "Epoch: 9 | Batch_idx: 200 |  Loss: (0.3163) | Acc: (89.10%) (5373/6030)\n",
      "Epoch: 9 | Batch_idx: 210 |  Loss: (0.3218) | Acc: (88.93%) (5629/6330)\n",
      "Epoch: 9 | Batch_idx: 220 |  Loss: (0.3206) | Acc: (88.97%) (5899/6630)\n",
      "Epoch: 9 | Batch_idx: 230 |  Loss: (0.3216) | Acc: (89.05%) (6171/6930)\n",
      "Epoch: 9 | Batch_idx: 240 |  Loss: (0.3213) | Acc: (89.07%) (6440/7230)\n",
      "Epoch: 9 | Batch_idx: 250 |  Loss: (0.3246) | Acc: (88.99%) (6701/7530)\n",
      "Epoch: 9 | Batch_idx: 260 |  Loss: (0.3237) | Acc: (89.00%) (6969/7830)\n",
      "Epoch: 9 | Batch_idx: 270 |  Loss: (0.3237) | Acc: (89.00%) (7236/8130)\n",
      "Epoch: 9 | Batch_idx: 280 |  Loss: (0.3225) | Acc: (89.04%) (7506/8430)\n",
      "Epoch: 9 | Batch_idx: 290 |  Loss: (0.3247) | Acc: (88.92%) (7763/8730)\n",
      "Epoch: 9 | Batch_idx: 300 |  Loss: (0.3255) | Acc: (88.88%) (8026/9030)\n",
      "Epoch: 9 | Batch_idx: 310 |  Loss: (0.3264) | Acc: (88.91%) (8295/9330)\n",
      "Epoch: 9 | Batch_idx: 320 |  Loss: (0.3247) | Acc: (88.90%) (8561/9630)\n",
      "Epoch: 9 | Batch_idx: 330 |  Loss: (0.3231) | Acc: (88.96%) (8834/9930)\n",
      "Epoch: 9 | Batch_idx: 340 |  Loss: (0.3239) | Acc: (88.95%) (9100/10230)\n",
      "Epoch: 9 | Batch_idx: 350 |  Loss: (0.3243) | Acc: (88.98%) (9370/10530)\n",
      "Epoch: 9 | Batch_idx: 360 |  Loss: (0.3260) | Acc: (88.94%) (9632/10830)\n",
      "Epoch: 9 | Batch_idx: 370 |  Loss: (0.3247) | Acc: (88.99%) (9905/11130)\n",
      "Epoch: 9 | Batch_idx: 380 |  Loss: (0.3239) | Acc: (89.06%) (10180/11430)\n",
      "Epoch: 9 | Batch_idx: 390 |  Loss: (0.3211) | Acc: (89.11%) (10453/11730)\n",
      "Epoch: 9 | Batch_idx: 400 |  Loss: (0.3207) | Acc: (89.09%) (10718/12030)\n",
      "Epoch: 9 | Batch_idx: 410 |  Loss: (0.3190) | Acc: (89.16%) (10994/12330)\n",
      "Epoch: 9 | Batch_idx: 420 |  Loss: (0.3184) | Acc: (89.20%) (11266/12630)\n",
      "Epoch: 9 | Batch_idx: 430 |  Loss: (0.3164) | Acc: (89.25%) (11540/12930)\n",
      "Epoch: 9 | Batch_idx: 440 |  Loss: (0.3154) | Acc: (89.29%) (11813/13230)\n",
      "Epoch: 9 | Batch_idx: 450 |  Loss: (0.3157) | Acc: (89.25%) (12075/13530)\n",
      "Epoch: 9 | Batch_idx: 460 |  Loss: (0.3172) | Acc: (89.21%) (12338/13830)\n",
      "Epoch: 9 | Batch_idx: 470 |  Loss: (0.3190) | Acc: (89.15%) (12597/14130)\n",
      "Epoch: 9 | Batch_idx: 480 |  Loss: (0.3200) | Acc: (89.13%) (12862/14430)\n",
      "Epoch: 9 | Batch_idx: 490 |  Loss: (0.3187) | Acc: (89.18%) (13136/14730)\n",
      "Epoch: 9 | Batch_idx: 500 |  Loss: (0.3180) | Acc: (89.19%) (13406/15030)\n",
      "Epoch: 9 | Batch_idx: 510 |  Loss: (0.3175) | Acc: (89.19%) (13673/15330)\n",
      "Epoch: 9 | Batch_idx: 520 |  Loss: (0.3186) | Acc: (89.16%) (13936/15630)\n",
      "Epoch: 9 | Batch_idx: 530 |  Loss: (0.3182) | Acc: (89.15%) (14202/15930)\n",
      "Epoch: 9 | Batch_idx: 540 |  Loss: (0.3183) | Acc: (89.17%) (14472/16230)\n",
      "Epoch: 9 | Batch_idx: 550 |  Loss: (0.3187) | Acc: (89.17%) (14739/16530)\n",
      "Epoch: 9 | Batch_idx: 560 |  Loss: (0.3184) | Acc: (89.15%) (15004/16830)\n",
      "Epoch: 9 | Batch_idx: 570 |  Loss: (0.3182) | Acc: (89.15%) (15272/17130)\n",
      "Epoch: 9 | Batch_idx: 580 |  Loss: (0.3194) | Acc: (89.13%) (15535/17430)\n",
      "Epoch: 9 | Batch_idx: 590 |  Loss: (0.3196) | Acc: (89.12%) (15801/17730)\n",
      "Epoch: 9 | Batch_idx: 600 |  Loss: (0.3196) | Acc: (89.13%) (16070/18030)\n",
      "Epoch: 9 | Batch_idx: 610 |  Loss: (0.3189) | Acc: (89.12%) (16335/18330)\n",
      "Epoch: 9 | Batch_idx: 620 |  Loss: (0.3185) | Acc: (89.13%) (16605/18630)\n",
      "Epoch: 9 | Batch_idx: 630 |  Loss: (0.3180) | Acc: (89.14%) (16875/18930)\n",
      "Epoch: 9 | Batch_idx: 640 |  Loss: (0.3183) | Acc: (89.18%) (17149/19230)\n",
      "Epoch: 9 | Batch_idx: 650 |  Loss: (0.3186) | Acc: (89.17%) (17414/19530)\n",
      "Epoch: 9 | Batch_idx: 660 |  Loss: (0.3186) | Acc: (89.17%) (17682/19830)\n",
      "Epoch: 9 | Batch_idx: 670 |  Loss: (0.3198) | Acc: (89.12%) (17940/20130)\n",
      "Epoch: 9 | Batch_idx: 680 |  Loss: (0.3192) | Acc: (89.15%) (18214/20430)\n",
      "Epoch: 9 | Batch_idx: 690 |  Loss: (0.3190) | Acc: (89.19%) (18489/20730)\n",
      "Epoch: 9 | Batch_idx: 700 |  Loss: (0.3193) | Acc: (89.17%) (18752/21030)\n",
      "Epoch: 9 | Batch_idx: 710 |  Loss: (0.3208) | Acc: (89.11%) (19008/21330)\n",
      "Epoch: 9 | Batch_idx: 720 |  Loss: (0.3196) | Acc: (89.14%) (19282/21630)\n",
      "Epoch: 9 | Batch_idx: 730 |  Loss: (0.3195) | Acc: (89.17%) (19554/21930)\n",
      "Epoch: 9 | Batch_idx: 740 |  Loss: (0.3203) | Acc: (89.14%) (19815/22230)\n",
      "Epoch: 9 | Batch_idx: 750 |  Loss: (0.3197) | Acc: (89.15%) (20086/22530)\n",
      "Epoch: 9 | Batch_idx: 760 |  Loss: (0.3199) | Acc: (89.14%) (20351/22830)\n",
      "Epoch: 9 | Batch_idx: 770 |  Loss: (0.3206) | Acc: (89.13%) (20615/23130)\n",
      "Epoch: 9 | Batch_idx: 780 |  Loss: (0.3202) | Acc: (89.12%) (20880/23430)\n",
      "Epoch: 9 | Batch_idx: 790 |  Loss: (0.3200) | Acc: (89.13%) (21150/23730)\n",
      "Epoch: 9 | Batch_idx: 800 |  Loss: (0.3197) | Acc: (89.12%) (21415/24030)\n",
      "Epoch: 9 | Batch_idx: 810 |  Loss: (0.3201) | Acc: (89.12%) (21682/24330)\n",
      "Epoch: 9 | Batch_idx: 820 |  Loss: (0.3205) | Acc: (89.10%) (21945/24630)\n",
      "Epoch: 9 | Batch_idx: 830 |  Loss: (0.3195) | Acc: (89.13%) (22220/24930)\n",
      "Epoch: 9 | Batch_idx: 840 |  Loss: (0.3197) | Acc: (89.12%) (22484/25230)\n",
      "Epoch: 9 | Batch_idx: 850 |  Loss: (0.3204) | Acc: (89.11%) (22750/25530)\n",
      "Epoch: 9 | Batch_idx: 860 |  Loss: (0.3207) | Acc: (89.09%) (23013/25830)\n",
      "Epoch: 9 | Batch_idx: 870 |  Loss: (0.3213) | Acc: (89.07%) (23275/26130)\n",
      "Epoch: 9 | Batch_idx: 880 |  Loss: (0.3215) | Acc: (89.07%) (23541/26430)\n",
      "Epoch: 9 | Batch_idx: 890 |  Loss: (0.3219) | Acc: (89.05%) (23804/26730)\n",
      "Epoch: 9 | Batch_idx: 900 |  Loss: (0.3221) | Acc: (89.05%) (24069/27030)\n",
      "Epoch: 9 | Batch_idx: 910 |  Loss: (0.3225) | Acc: (89.03%) (24333/27330)\n",
      "Epoch: 9 | Batch_idx: 920 |  Loss: (0.3226) | Acc: (89.04%) (24601/27630)\n",
      "Epoch: 9 | Batch_idx: 930 |  Loss: (0.3228) | Acc: (89.02%) (24863/27930)\n",
      "Epoch: 9 | Batch_idx: 940 |  Loss: (0.3218) | Acc: (89.04%) (25135/28230)\n",
      "Epoch: 9 | Batch_idx: 950 |  Loss: (0.3220) | Acc: (89.04%) (25403/28530)\n",
      "Epoch: 9 | Batch_idx: 960 |  Loss: (0.3221) | Acc: (89.02%) (25665/28830)\n",
      "Epoch: 9 | Batch_idx: 970 |  Loss: (0.3220) | Acc: (89.01%) (25930/29130)\n",
      "Epoch: 9 | Batch_idx: 980 |  Loss: (0.3223) | Acc: (89.00%) (26194/29430)\n",
      "Epoch: 9 | Batch_idx: 990 |  Loss: (0.3217) | Acc: (89.02%) (26465/29730)\n",
      "Epoch: 9 | Batch_idx: 1000 |  Loss: (0.3213) | Acc: (89.04%) (26740/30030)\n",
      "Epoch: 9 | Batch_idx: 1010 |  Loss: (0.3207) | Acc: (89.05%) (27010/30330)\n",
      "Epoch: 9 | Batch_idx: 1020 |  Loss: (0.3207) | Acc: (89.04%) (27274/30630)\n",
      "Epoch: 9 | Batch_idx: 1030 |  Loss: (0.3210) | Acc: (89.03%) (27537/30930)\n",
      "Epoch: 9 | Batch_idx: 1040 |  Loss: (0.3220) | Acc: (89.00%) (27796/31230)\n",
      "Epoch: 9 | Batch_idx: 1050 |  Loss: (0.3213) | Acc: (89.04%) (28074/31530)\n",
      "Epoch: 9 | Batch_idx: 1060 |  Loss: (0.3213) | Acc: (89.03%) (28339/31830)\n",
      "Epoch: 9 | Batch_idx: 1070 |  Loss: (0.3214) | Acc: (89.02%) (28602/32130)\n",
      "Epoch: 9 | Batch_idx: 1080 |  Loss: (0.3215) | Acc: (89.01%) (28865/32430)\n",
      "Epoch: 9 | Batch_idx: 1090 |  Loss: (0.3223) | Acc: (88.99%) (29127/32730)\n",
      "Epoch: 9 | Batch_idx: 1100 |  Loss: (0.3226) | Acc: (88.98%) (29389/33030)\n",
      "Epoch: 9 | Batch_idx: 1110 |  Loss: (0.3221) | Acc: (89.01%) (29666/33330)\n",
      "Epoch: 9 | Batch_idx: 1120 |  Loss: (0.3221) | Acc: (89.00%) (29932/33630)\n",
      "Epoch: 9 | Batch_idx: 1130 |  Loss: (0.3217) | Acc: (89.01%) (30201/33930)\n",
      "Epoch: 9 | Batch_idx: 1140 |  Loss: (0.3212) | Acc: (89.02%) (30472/34230)\n",
      "Epoch: 9 | Batch_idx: 1150 |  Loss: (0.3211) | Acc: (89.01%) (30735/34530)\n",
      "Epoch: 9 | Batch_idx: 1160 |  Loss: (0.3205) | Acc: (89.04%) (31013/34830)\n",
      "Epoch: 9 | Batch_idx: 1170 |  Loss: (0.3209) | Acc: (89.02%) (31273/35130)\n",
      "Epoch: 9 | Batch_idx: 1180 |  Loss: (0.3208) | Acc: (89.02%) (31541/35430)\n",
      "Epoch: 9 | Batch_idx: 1190 |  Loss: (0.3209) | Acc: (89.02%) (31806/35730)\n",
      "Epoch: 9 | Batch_idx: 1200 |  Loss: (0.3211) | Acc: (89.01%) (32071/36030)\n",
      "Epoch: 9 | Batch_idx: 1210 |  Loss: (0.3208) | Acc: (89.01%) (32339/36330)\n",
      "Epoch: 9 | Batch_idx: 1220 |  Loss: (0.3203) | Acc: (89.03%) (32611/36630)\n",
      "Epoch: 9 | Batch_idx: 1230 |  Loss: (0.3200) | Acc: (89.03%) (32878/36930)\n",
      "Epoch: 9 | Batch_idx: 1240 |  Loss: (0.3199) | Acc: (89.03%) (33145/37230)\n",
      "Epoch: 9 | Batch_idx: 1250 |  Loss: (0.3200) | Acc: (89.02%) (33408/37530)\n",
      "Epoch: 9 | Batch_idx: 1260 |  Loss: (0.3200) | Acc: (89.01%) (33673/37830)\n",
      "Epoch: 9 | Batch_idx: 1270 |  Loss: (0.3199) | Acc: (89.01%) (33940/38130)\n",
      "Epoch: 9 | Batch_idx: 1280 |  Loss: (0.3199) | Acc: (89.00%) (34202/38430)\n",
      "Epoch: 9 | Batch_idx: 1290 |  Loss: (0.3203) | Acc: (88.97%) (34458/38730)\n",
      "Epoch: 9 | Batch_idx: 1300 |  Loss: (0.3200) | Acc: (88.99%) (34731/39030)\n",
      "Epoch: 9 | Batch_idx: 1310 |  Loss: (0.3202) | Acc: (88.98%) (34995/39330)\n",
      "Epoch: 9 | Batch_idx: 1320 |  Loss: (0.3198) | Acc: (89.00%) (35270/39630)\n",
      "Epoch: 9 | Batch_idx: 1330 |  Loss: (0.3195) | Acc: (89.01%) (35541/39930)\n",
      "Epoch: 9 | Batch_idx: 1340 |  Loss: (0.3193) | Acc: (89.03%) (35817/40230)\n",
      "Epoch: 9 | Batch_idx: 1350 |  Loss: (0.3194) | Acc: (89.02%) (36079/40530)\n",
      "Epoch: 9 | Batch_idx: 1360 |  Loss: (0.3191) | Acc: (89.02%) (36348/40830)\n",
      "Epoch: 9 | Batch_idx: 1370 |  Loss: (0.3186) | Acc: (89.04%) (36622/41130)\n",
      "Epoch: 9 | Batch_idx: 1380 |  Loss: (0.3191) | Acc: (89.03%) (36885/41430)\n",
      "Epoch: 9 | Batch_idx: 1390 |  Loss: (0.3189) | Acc: (89.04%) (37155/41730)\n",
      "Epoch: 9 | Batch_idx: 1400 |  Loss: (0.3185) | Acc: (89.05%) (37428/42030)\n",
      "Epoch: 9 | Batch_idx: 1410 |  Loss: (0.3185) | Acc: (89.03%) (37687/42330)\n",
      "Epoch: 9 | Batch_idx: 1420 |  Loss: (0.3182) | Acc: (89.04%) (37959/42630)\n",
      "Epoch: 9 | Batch_idx: 1430 |  Loss: (0.3182) | Acc: (89.03%) (38222/42930)\n",
      "Epoch: 9 | Batch_idx: 1440 |  Loss: (0.3183) | Acc: (89.04%) (38491/43230)\n",
      "Epoch: 9 | Batch_idx: 1450 |  Loss: (0.3176) | Acc: (89.06%) (38769/43530)\n",
      "Epoch: 9 | Batch_idx: 1460 |  Loss: (0.3172) | Acc: (89.08%) (39042/43830)\n",
      "Epoch: 9 | Batch_idx: 1470 |  Loss: (0.3167) | Acc: (89.10%) (39318/44130)\n",
      "Epoch: 9 | Batch_idx: 1480 |  Loss: (0.3165) | Acc: (89.10%) (39587/44430)\n",
      "Epoch: 9 | Batch_idx: 1490 |  Loss: (0.3166) | Acc: (89.09%) (39851/44730)\n",
      "Epoch: 9 | Batch_idx: 1500 |  Loss: (0.3170) | Acc: (89.07%) (40109/45030)\n",
      "Epoch: 9 | Batch_idx: 1510 |  Loss: (0.3171) | Acc: (89.06%) (40372/45330)\n",
      "Epoch: 9 | Batch_idx: 1520 |  Loss: (0.3173) | Acc: (89.06%) (40636/45630)\n",
      "Epoch: 9 | Batch_idx: 1530 |  Loss: (0.3169) | Acc: (89.07%) (40911/45930)\n",
      "Epoch: 9 | Batch_idx: 1540 |  Loss: (0.3170) | Acc: (89.07%) (41175/46230)\n",
      "Epoch: 9 | Batch_idx: 1550 |  Loss: (0.3166) | Acc: (89.07%) (41443/46530)\n",
      "Epoch: 9 | Batch_idx: 1560 |  Loss: (0.3169) | Acc: (89.06%) (41705/46830)\n",
      "Epoch: 9 | Batch_idx: 1570 |  Loss: (0.3177) | Acc: (89.03%) (41959/47130)\n",
      "Epoch: 9 | Batch_idx: 1580 |  Loss: (0.3173) | Acc: (89.04%) (42232/47430)\n",
      "Epoch: 9 | Batch_idx: 1590 |  Loss: (0.3167) | Acc: (89.06%) (42510/47730)\n",
      "Epoch: 9 | Batch_idx: 1600 |  Loss: (0.3170) | Acc: (89.06%) (42774/48030)\n",
      "Epoch: 9 | Batch_idx: 1610 |  Loss: (0.3172) | Acc: (89.04%) (43035/48330)\n",
      "Epoch: 9 | Batch_idx: 1620 |  Loss: (0.3174) | Acc: (89.04%) (43299/48630)\n",
      "Epoch: 9 | Batch_idx: 1630 |  Loss: (0.3174) | Acc: (89.05%) (43571/48930)\n",
      "Epoch: 9 | Batch_idx: 1640 |  Loss: (0.3176) | Acc: (89.05%) (43838/49230)\n",
      "Epoch: 9 | Batch_idx: 1650 |  Loss: (0.3175) | Acc: (89.05%) (44106/49530)\n",
      "Epoch: 9 | Batch_idx: 1660 |  Loss: (0.3173) | Acc: (89.05%) (44374/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3956) | Acc: (86.74%) (8674/10000)\n",
      "Epoch: 10 | Batch_idx: 0 |  Loss: (0.3152) | Acc: (90.00%) (27/30)\n",
      "Epoch: 10 | Batch_idx: 10 |  Loss: (0.3135) | Acc: (89.39%) (295/330)\n",
      "Epoch: 10 | Batch_idx: 20 |  Loss: (0.3515) | Acc: (87.94%) (554/630)\n",
      "Epoch: 10 | Batch_idx: 30 |  Loss: (0.3365) | Acc: (88.82%) (826/930)\n",
      "Epoch: 10 | Batch_idx: 40 |  Loss: (0.3191) | Acc: (89.19%) (1097/1230)\n",
      "Epoch: 10 | Batch_idx: 50 |  Loss: (0.3116) | Acc: (89.08%) (1363/1530)\n",
      "Epoch: 10 | Batch_idx: 60 |  Loss: (0.3257) | Acc: (88.31%) (1616/1830)\n",
      "Epoch: 10 | Batch_idx: 70 |  Loss: (0.3209) | Acc: (88.45%) (1884/2130)\n",
      "Epoch: 10 | Batch_idx: 80 |  Loss: (0.3158) | Acc: (88.81%) (2158/2430)\n",
      "Epoch: 10 | Batch_idx: 90 |  Loss: (0.3171) | Acc: (88.97%) (2429/2730)\n",
      "Epoch: 10 | Batch_idx: 100 |  Loss: (0.3162) | Acc: (89.08%) (2699/3030)\n",
      "Epoch: 10 | Batch_idx: 110 |  Loss: (0.3149) | Acc: (89.13%) (2968/3330)\n",
      "Epoch: 10 | Batch_idx: 120 |  Loss: (0.3141) | Acc: (89.04%) (3232/3630)\n",
      "Epoch: 10 | Batch_idx: 130 |  Loss: (0.3136) | Acc: (88.93%) (3495/3930)\n",
      "Epoch: 10 | Batch_idx: 140 |  Loss: (0.3131) | Acc: (88.98%) (3764/4230)\n",
      "Epoch: 10 | Batch_idx: 150 |  Loss: (0.3113) | Acc: (89.05%) (4034/4530)\n",
      "Epoch: 10 | Batch_idx: 160 |  Loss: (0.3078) | Acc: (89.25%) (4311/4830)\n",
      "Epoch: 10 | Batch_idx: 170 |  Loss: (0.3045) | Acc: (89.34%) (4583/5130)\n",
      "Epoch: 10 | Batch_idx: 180 |  Loss: (0.3010) | Acc: (89.56%) (4863/5430)\n",
      "Epoch: 10 | Batch_idx: 190 |  Loss: (0.2986) | Acc: (89.65%) (5137/5730)\n",
      "Epoch: 10 | Batch_idx: 200 |  Loss: (0.2952) | Acc: (89.75%) (5412/6030)\n",
      "Epoch: 10 | Batch_idx: 210 |  Loss: (0.2924) | Acc: (89.91%) (5691/6330)\n",
      "Epoch: 10 | Batch_idx: 220 |  Loss: (0.2963) | Acc: (89.74%) (5950/6630)\n",
      "Epoch: 10 | Batch_idx: 230 |  Loss: (0.2964) | Acc: (89.73%) (6218/6930)\n",
      "Epoch: 10 | Batch_idx: 240 |  Loss: (0.2952) | Acc: (89.76%) (6490/7230)\n",
      "Epoch: 10 | Batch_idx: 250 |  Loss: (0.2939) | Acc: (89.83%) (6764/7530)\n",
      "Epoch: 10 | Batch_idx: 260 |  Loss: (0.2940) | Acc: (89.80%) (7031/7830)\n",
      "Epoch: 10 | Batch_idx: 270 |  Loss: (0.2952) | Acc: (89.82%) (7302/8130)\n",
      "Epoch: 10 | Batch_idx: 280 |  Loss: (0.2938) | Acc: (89.87%) (7576/8430)\n",
      "Epoch: 10 | Batch_idx: 290 |  Loss: (0.2940) | Acc: (89.90%) (7848/8730)\n",
      "Epoch: 10 | Batch_idx: 300 |  Loss: (0.2922) | Acc: (89.96%) (8123/9030)\n",
      "Epoch: 10 | Batch_idx: 310 |  Loss: (0.2929) | Acc: (89.87%) (8385/9330)\n",
      "Epoch: 10 | Batch_idx: 320 |  Loss: (0.2933) | Acc: (89.91%) (8658/9630)\n",
      "Epoch: 10 | Batch_idx: 330 |  Loss: (0.2919) | Acc: (89.94%) (8931/9930)\n",
      "Epoch: 10 | Batch_idx: 340 |  Loss: (0.2906) | Acc: (90.00%) (9207/10230)\n",
      "Epoch: 10 | Batch_idx: 350 |  Loss: (0.2904) | Acc: (90.00%) (9477/10530)\n",
      "Epoch: 10 | Batch_idx: 360 |  Loss: (0.2903) | Acc: (90.02%) (9749/10830)\n",
      "Epoch: 10 | Batch_idx: 370 |  Loss: (0.2918) | Acc: (89.96%) (10012/11130)\n",
      "Epoch: 10 | Batch_idx: 380 |  Loss: (0.2905) | Acc: (89.97%) (10283/11430)\n",
      "Epoch: 10 | Batch_idx: 390 |  Loss: (0.2896) | Acc: (90.01%) (10558/11730)\n",
      "Epoch: 10 | Batch_idx: 400 |  Loss: (0.2906) | Acc: (89.99%) (10826/12030)\n",
      "Epoch: 10 | Batch_idx: 410 |  Loss: (0.2906) | Acc: (90.03%) (11101/12330)\n",
      "Epoch: 10 | Batch_idx: 420 |  Loss: (0.2897) | Acc: (90.03%) (11371/12630)\n",
      "Epoch: 10 | Batch_idx: 430 |  Loss: (0.2893) | Acc: (90.05%) (11644/12930)\n",
      "Epoch: 10 | Batch_idx: 440 |  Loss: (0.2884) | Acc: (90.05%) (11913/13230)\n",
      "Epoch: 10 | Batch_idx: 450 |  Loss: (0.2895) | Acc: (90.04%) (12182/13530)\n",
      "Epoch: 10 | Batch_idx: 460 |  Loss: (0.2894) | Acc: (90.01%) (12449/13830)\n",
      "Epoch: 10 | Batch_idx: 470 |  Loss: (0.2899) | Acc: (90.01%) (12719/14130)\n",
      "Epoch: 10 | Batch_idx: 480 |  Loss: (0.2885) | Acc: (90.08%) (12998/14430)\n",
      "Epoch: 10 | Batch_idx: 490 |  Loss: (0.2888) | Acc: (90.01%) (13258/14730)\n",
      "Epoch: 10 | Batch_idx: 500 |  Loss: (0.2890) | Acc: (90.03%) (13531/15030)\n",
      "Epoch: 10 | Batch_idx: 510 |  Loss: (0.2890) | Acc: (90.04%) (13803/15330)\n",
      "Epoch: 10 | Batch_idx: 520 |  Loss: (0.2882) | Acc: (90.06%) (14076/15630)\n",
      "Epoch: 10 | Batch_idx: 530 |  Loss: (0.2882) | Acc: (90.07%) (14348/15930)\n",
      "Epoch: 10 | Batch_idx: 540 |  Loss: (0.2881) | Acc: (90.07%) (14619/16230)\n",
      "Epoch: 10 | Batch_idx: 550 |  Loss: (0.2881) | Acc: (90.07%) (14888/16530)\n",
      "Epoch: 10 | Batch_idx: 560 |  Loss: (0.2876) | Acc: (90.09%) (15162/16830)\n",
      "Epoch: 10 | Batch_idx: 570 |  Loss: (0.2873) | Acc: (90.06%) (15427/17130)\n",
      "Epoch: 10 | Batch_idx: 580 |  Loss: (0.2880) | Acc: (90.03%) (15693/17430)\n",
      "Epoch: 10 | Batch_idx: 590 |  Loss: (0.2879) | Acc: (90.05%) (15965/17730)\n",
      "Epoch: 10 | Batch_idx: 600 |  Loss: (0.2870) | Acc: (90.10%) (16245/18030)\n",
      "Epoch: 10 | Batch_idx: 610 |  Loss: (0.2872) | Acc: (90.09%) (16513/18330)\n",
      "Epoch: 10 | Batch_idx: 620 |  Loss: (0.2877) | Acc: (90.07%) (16780/18630)\n",
      "Epoch: 10 | Batch_idx: 630 |  Loss: (0.2869) | Acc: (90.08%) (17053/18930)\n",
      "Epoch: 10 | Batch_idx: 640 |  Loss: (0.2872) | Acc: (90.06%) (17319/19230)\n",
      "Epoch: 10 | Batch_idx: 650 |  Loss: (0.2870) | Acc: (90.08%) (17592/19530)\n",
      "Epoch: 10 | Batch_idx: 660 |  Loss: (0.2867) | Acc: (90.11%) (17868/19830)\n",
      "Epoch: 10 | Batch_idx: 670 |  Loss: (0.2864) | Acc: (90.09%) (18135/20130)\n",
      "Epoch: 10 | Batch_idx: 680 |  Loss: (0.2873) | Acc: (90.05%) (18397/20430)\n",
      "Epoch: 10 | Batch_idx: 690 |  Loss: (0.2878) | Acc: (90.04%) (18666/20730)\n",
      "Epoch: 10 | Batch_idx: 700 |  Loss: (0.2890) | Acc: (90.00%) (18926/21030)\n",
      "Epoch: 10 | Batch_idx: 710 |  Loss: (0.2886) | Acc: (90.00%) (19197/21330)\n",
      "Epoch: 10 | Batch_idx: 720 |  Loss: (0.2878) | Acc: (90.02%) (19472/21630)\n",
      "Epoch: 10 | Batch_idx: 730 |  Loss: (0.2869) | Acc: (90.05%) (19749/21930)\n",
      "Epoch: 10 | Batch_idx: 740 |  Loss: (0.2877) | Acc: (90.01%) (20009/22230)\n",
      "Epoch: 10 | Batch_idx: 750 |  Loss: (0.2881) | Acc: (89.99%) (20275/22530)\n",
      "Epoch: 10 | Batch_idx: 760 |  Loss: (0.2878) | Acc: (90.00%) (20547/22830)\n",
      "Epoch: 10 | Batch_idx: 770 |  Loss: (0.2874) | Acc: (90.00%) (20816/23130)\n",
      "Epoch: 10 | Batch_idx: 780 |  Loss: (0.2871) | Acc: (89.99%) (21084/23430)\n",
      "Epoch: 10 | Batch_idx: 790 |  Loss: (0.2861) | Acc: (90.02%) (21361/23730)\n",
      "Epoch: 10 | Batch_idx: 800 |  Loss: (0.2864) | Acc: (90.01%) (21629/24030)\n",
      "Epoch: 10 | Batch_idx: 810 |  Loss: (0.2861) | Acc: (90.02%) (21901/24330)\n",
      "Epoch: 10 | Batch_idx: 820 |  Loss: (0.2848) | Acc: (90.08%) (22186/24630)\n",
      "Epoch: 10 | Batch_idx: 830 |  Loss: (0.2837) | Acc: (90.11%) (22464/24930)\n",
      "Epoch: 10 | Batch_idx: 840 |  Loss: (0.2838) | Acc: (90.08%) (22728/25230)\n",
      "Epoch: 10 | Batch_idx: 850 |  Loss: (0.2840) | Acc: (90.06%) (22993/25530)\n",
      "Epoch: 10 | Batch_idx: 860 |  Loss: (0.2844) | Acc: (90.06%) (23263/25830)\n",
      "Epoch: 10 | Batch_idx: 870 |  Loss: (0.2852) | Acc: (90.04%) (23528/26130)\n",
      "Epoch: 10 | Batch_idx: 880 |  Loss: (0.2855) | Acc: (90.03%) (23795/26430)\n",
      "Epoch: 10 | Batch_idx: 890 |  Loss: (0.2857) | Acc: (90.02%) (24062/26730)\n",
      "Epoch: 10 | Batch_idx: 900 |  Loss: (0.2863) | Acc: (89.99%) (24323/27030)\n",
      "Epoch: 10 | Batch_idx: 910 |  Loss: (0.2864) | Acc: (89.99%) (24595/27330)\n",
      "Epoch: 10 | Batch_idx: 920 |  Loss: (0.2864) | Acc: (89.98%) (24862/27630)\n",
      "Epoch: 10 | Batch_idx: 930 |  Loss: (0.2868) | Acc: (89.95%) (25124/27930)\n",
      "Epoch: 10 | Batch_idx: 940 |  Loss: (0.2867) | Acc: (89.97%) (25399/28230)\n",
      "Epoch: 10 | Batch_idx: 950 |  Loss: (0.2861) | Acc: (89.99%) (25675/28530)\n",
      "Epoch: 10 | Batch_idx: 960 |  Loss: (0.2854) | Acc: (90.01%) (25951/28830)\n",
      "Epoch: 10 | Batch_idx: 970 |  Loss: (0.2853) | Acc: (90.02%) (26223/29130)\n",
      "Epoch: 10 | Batch_idx: 980 |  Loss: (0.2857) | Acc: (90.03%) (26496/29430)\n",
      "Epoch: 10 | Batch_idx: 990 |  Loss: (0.2862) | Acc: (90.01%) (26761/29730)\n",
      "Epoch: 10 | Batch_idx: 1000 |  Loss: (0.2871) | Acc: (89.99%) (27024/30030)\n",
      "Epoch: 10 | Batch_idx: 1010 |  Loss: (0.2875) | Acc: (89.96%) (27286/30330)\n",
      "Epoch: 10 | Batch_idx: 1020 |  Loss: (0.2871) | Acc: (89.98%) (27561/30630)\n",
      "Epoch: 10 | Batch_idx: 1030 |  Loss: (0.2875) | Acc: (89.98%) (27831/30930)\n",
      "Epoch: 10 | Batch_idx: 1040 |  Loss: (0.2870) | Acc: (90.00%) (28106/31230)\n",
      "Epoch: 10 | Batch_idx: 1050 |  Loss: (0.2866) | Acc: (90.02%) (28382/31530)\n",
      "Epoch: 10 | Batch_idx: 1060 |  Loss: (0.2872) | Acc: (89.98%) (28642/31830)\n",
      "Epoch: 10 | Batch_idx: 1070 |  Loss: (0.2871) | Acc: (90.00%) (28916/32130)\n",
      "Epoch: 10 | Batch_idx: 1080 |  Loss: (0.2869) | Acc: (89.99%) (29185/32430)\n",
      "Epoch: 10 | Batch_idx: 1090 |  Loss: (0.2870) | Acc: (89.99%) (29454/32730)\n",
      "Epoch: 10 | Batch_idx: 1100 |  Loss: (0.2872) | Acc: (89.98%) (29721/33030)\n",
      "Epoch: 10 | Batch_idx: 1110 |  Loss: (0.2875) | Acc: (89.97%) (29988/33330)\n",
      "Epoch: 10 | Batch_idx: 1120 |  Loss: (0.2887) | Acc: (89.93%) (30245/33630)\n",
      "Epoch: 10 | Batch_idx: 1130 |  Loss: (0.2898) | Acc: (89.90%) (30503/33930)\n",
      "Epoch: 10 | Batch_idx: 1140 |  Loss: (0.2900) | Acc: (89.88%) (30767/34230)\n",
      "Epoch: 10 | Batch_idx: 1150 |  Loss: (0.2903) | Acc: (89.88%) (31035/34530)\n",
      "Epoch: 10 | Batch_idx: 1160 |  Loss: (0.2910) | Acc: (89.84%) (31293/34830)\n",
      "Epoch: 10 | Batch_idx: 1170 |  Loss: (0.2910) | Acc: (89.84%) (31562/35130)\n",
      "Epoch: 10 | Batch_idx: 1180 |  Loss: (0.2907) | Acc: (89.85%) (31834/35430)\n",
      "Epoch: 10 | Batch_idx: 1190 |  Loss: (0.2912) | Acc: (89.85%) (32103/35730)\n",
      "Epoch: 10 | Batch_idx: 1200 |  Loss: (0.2910) | Acc: (89.86%) (32377/36030)\n",
      "Epoch: 10 | Batch_idx: 1210 |  Loss: (0.2909) | Acc: (89.86%) (32647/36330)\n",
      "Epoch: 10 | Batch_idx: 1220 |  Loss: (0.2908) | Acc: (89.86%) (32917/36630)\n",
      "Epoch: 10 | Batch_idx: 1230 |  Loss: (0.2905) | Acc: (89.88%) (33193/36930)\n",
      "Epoch: 10 | Batch_idx: 1240 |  Loss: (0.2904) | Acc: (89.87%) (33460/37230)\n",
      "Epoch: 10 | Batch_idx: 1250 |  Loss: (0.2897) | Acc: (89.90%) (33738/37530)\n",
      "Epoch: 10 | Batch_idx: 1260 |  Loss: (0.2891) | Acc: (89.91%) (34014/37830)\n",
      "Epoch: 10 | Batch_idx: 1270 |  Loss: (0.2894) | Acc: (89.91%) (34281/38130)\n",
      "Epoch: 10 | Batch_idx: 1280 |  Loss: (0.2897) | Acc: (89.89%) (34545/38430)\n",
      "Epoch: 10 | Batch_idx: 1290 |  Loss: (0.2893) | Acc: (89.90%) (34820/38730)\n",
      "Epoch: 10 | Batch_idx: 1300 |  Loss: (0.2891) | Acc: (89.90%) (35089/39030)\n",
      "Epoch: 10 | Batch_idx: 1310 |  Loss: (0.2893) | Acc: (89.90%) (35358/39330)\n",
      "Epoch: 10 | Batch_idx: 1320 |  Loss: (0.2891) | Acc: (89.91%) (35630/39630)\n",
      "Epoch: 10 | Batch_idx: 1330 |  Loss: (0.2889) | Acc: (89.91%) (35903/39930)\n",
      "Epoch: 10 | Batch_idx: 1340 |  Loss: (0.2886) | Acc: (89.93%) (36177/40230)\n",
      "Epoch: 10 | Batch_idx: 1350 |  Loss: (0.2888) | Acc: (89.93%) (36449/40530)\n",
      "Epoch: 10 | Batch_idx: 1360 |  Loss: (0.2895) | Acc: (89.92%) (36716/40830)\n",
      "Epoch: 10 | Batch_idx: 1370 |  Loss: (0.2892) | Acc: (89.94%) (36992/41130)\n",
      "Epoch: 10 | Batch_idx: 1380 |  Loss: (0.2891) | Acc: (89.94%) (37263/41430)\n",
      "Epoch: 10 | Batch_idx: 1390 |  Loss: (0.2890) | Acc: (89.94%) (37534/41730)\n",
      "Epoch: 10 | Batch_idx: 1400 |  Loss: (0.2895) | Acc: (89.93%) (37799/42030)\n",
      "Epoch: 10 | Batch_idx: 1410 |  Loss: (0.2894) | Acc: (89.93%) (38068/42330)\n",
      "Epoch: 10 | Batch_idx: 1420 |  Loss: (0.2899) | Acc: (89.92%) (38332/42630)\n",
      "Epoch: 10 | Batch_idx: 1430 |  Loss: (0.2896) | Acc: (89.93%) (38606/42930)\n",
      "Epoch: 10 | Batch_idx: 1440 |  Loss: (0.2901) | Acc: (89.92%) (38873/43230)\n",
      "Epoch: 10 | Batch_idx: 1450 |  Loss: (0.2901) | Acc: (89.91%) (39138/43530)\n",
      "Epoch: 10 | Batch_idx: 1460 |  Loss: (0.2898) | Acc: (89.92%) (39412/43830)\n",
      "Epoch: 10 | Batch_idx: 1470 |  Loss: (0.2897) | Acc: (89.93%) (39684/44130)\n",
      "Epoch: 10 | Batch_idx: 1480 |  Loss: (0.2894) | Acc: (89.94%) (39959/44430)\n",
      "Epoch: 10 | Batch_idx: 1490 |  Loss: (0.2894) | Acc: (89.94%) (40228/44730)\n",
      "Epoch: 10 | Batch_idx: 1500 |  Loss: (0.2896) | Acc: (89.93%) (40494/45030)\n",
      "Epoch: 10 | Batch_idx: 1510 |  Loss: (0.2898) | Acc: (89.93%) (40765/45330)\n",
      "Epoch: 10 | Batch_idx: 1520 |  Loss: (0.2896) | Acc: (89.94%) (41041/45630)\n",
      "Epoch: 10 | Batch_idx: 1530 |  Loss: (0.2898) | Acc: (89.93%) (41307/45930)\n",
      "Epoch: 10 | Batch_idx: 1540 |  Loss: (0.2898) | Acc: (89.94%) (41578/46230)\n",
      "Epoch: 10 | Batch_idx: 1550 |  Loss: (0.2894) | Acc: (89.95%) (41854/46530)\n",
      "Epoch: 10 | Batch_idx: 1560 |  Loss: (0.2895) | Acc: (89.94%) (42118/46830)\n",
      "Epoch: 10 | Batch_idx: 1570 |  Loss: (0.2897) | Acc: (89.93%) (42385/47130)\n",
      "Epoch: 10 | Batch_idx: 1580 |  Loss: (0.2893) | Acc: (89.95%) (42661/47430)\n",
      "Epoch: 10 | Batch_idx: 1590 |  Loss: (0.2891) | Acc: (89.94%) (42930/47730)\n",
      "Epoch: 10 | Batch_idx: 1600 |  Loss: (0.2895) | Acc: (89.93%) (43192/48030)\n",
      "Epoch: 10 | Batch_idx: 1610 |  Loss: (0.2892) | Acc: (89.94%) (43468/48330)\n",
      "Epoch: 10 | Batch_idx: 1620 |  Loss: (0.2892) | Acc: (89.94%) (43736/48630)\n",
      "Epoch: 10 | Batch_idx: 1630 |  Loss: (0.2892) | Acc: (89.95%) (44011/48930)\n",
      "Epoch: 10 | Batch_idx: 1640 |  Loss: (0.2888) | Acc: (89.97%) (44291/49230)\n",
      "Epoch: 10 | Batch_idx: 1650 |  Loss: (0.2889) | Acc: (89.97%) (44560/49530)\n",
      "Epoch: 10 | Batch_idx: 1660 |  Loss: (0.2890) | Acc: (89.95%) (44824/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4075) | Acc: (86.81%) (8681/10000)\n",
      "Epoch: 11 | Batch_idx: 0 |  Loss: (0.1408) | Acc: (96.67%) (29/30)\n",
      "Epoch: 11 | Batch_idx: 10 |  Loss: (0.2993) | Acc: (89.09%) (294/330)\n",
      "Epoch: 11 | Batch_idx: 20 |  Loss: (0.2622) | Acc: (90.63%) (571/630)\n",
      "Epoch: 11 | Batch_idx: 30 |  Loss: (0.2646) | Acc: (90.75%) (844/930)\n",
      "Epoch: 11 | Batch_idx: 40 |  Loss: (0.2686) | Acc: (90.81%) (1117/1230)\n",
      "Epoch: 11 | Batch_idx: 50 |  Loss: (0.2612) | Acc: (91.05%) (1393/1530)\n",
      "Epoch: 11 | Batch_idx: 60 |  Loss: (0.2597) | Acc: (91.15%) (1668/1830)\n",
      "Epoch: 11 | Batch_idx: 70 |  Loss: (0.2597) | Acc: (91.27%) (1944/2130)\n",
      "Epoch: 11 | Batch_idx: 80 |  Loss: (0.2566) | Acc: (91.44%) (2222/2430)\n",
      "Epoch: 11 | Batch_idx: 90 |  Loss: (0.2522) | Acc: (91.36%) (2494/2730)\n",
      "Epoch: 11 | Batch_idx: 100 |  Loss: (0.2485) | Acc: (91.45%) (2771/3030)\n",
      "Epoch: 11 | Batch_idx: 110 |  Loss: (0.2501) | Acc: (91.23%) (3038/3330)\n",
      "Epoch: 11 | Batch_idx: 120 |  Loss: (0.2488) | Acc: (91.38%) (3317/3630)\n",
      "Epoch: 11 | Batch_idx: 130 |  Loss: (0.2488) | Acc: (91.32%) (3589/3930)\n",
      "Epoch: 11 | Batch_idx: 140 |  Loss: (0.2487) | Acc: (91.35%) (3864/4230)\n",
      "Epoch: 11 | Batch_idx: 150 |  Loss: (0.2513) | Acc: (91.19%) (4131/4530)\n",
      "Epoch: 11 | Batch_idx: 160 |  Loss: (0.2509) | Acc: (91.16%) (4403/4830)\n",
      "Epoch: 11 | Batch_idx: 170 |  Loss: (0.2541) | Acc: (91.07%) (4672/5130)\n",
      "Epoch: 11 | Batch_idx: 180 |  Loss: (0.2518) | Acc: (91.20%) (4952/5430)\n",
      "Epoch: 11 | Batch_idx: 190 |  Loss: (0.2508) | Acc: (91.20%) (5226/5730)\n",
      "Epoch: 11 | Batch_idx: 200 |  Loss: (0.2521) | Acc: (91.11%) (5494/6030)\n",
      "Epoch: 11 | Batch_idx: 210 |  Loss: (0.2564) | Acc: (91.00%) (5760/6330)\n",
      "Epoch: 11 | Batch_idx: 220 |  Loss: (0.2589) | Acc: (90.92%) (6028/6630)\n",
      "Epoch: 11 | Batch_idx: 230 |  Loss: (0.2608) | Acc: (90.88%) (6298/6930)\n",
      "Epoch: 11 | Batch_idx: 240 |  Loss: (0.2596) | Acc: (90.84%) (6568/7230)\n",
      "Epoch: 11 | Batch_idx: 250 |  Loss: (0.2597) | Acc: (90.80%) (6837/7530)\n",
      "Epoch: 11 | Batch_idx: 260 |  Loss: (0.2617) | Acc: (90.66%) (7099/7830)\n",
      "Epoch: 11 | Batch_idx: 270 |  Loss: (0.2636) | Acc: (90.65%) (7370/8130)\n",
      "Epoch: 11 | Batch_idx: 280 |  Loss: (0.2610) | Acc: (90.78%) (7653/8430)\n",
      "Epoch: 11 | Batch_idx: 290 |  Loss: (0.2611) | Acc: (90.79%) (7926/8730)\n",
      "Epoch: 11 | Batch_idx: 300 |  Loss: (0.2603) | Acc: (90.82%) (8201/9030)\n",
      "Epoch: 11 | Batch_idx: 310 |  Loss: (0.2583) | Acc: (90.93%) (8484/9330)\n",
      "Epoch: 11 | Batch_idx: 320 |  Loss: (0.2590) | Acc: (90.96%) (8759/9630)\n",
      "Epoch: 11 | Batch_idx: 330 |  Loss: (0.2579) | Acc: (90.99%) (9035/9930)\n",
      "Epoch: 11 | Batch_idx: 340 |  Loss: (0.2567) | Acc: (91.04%) (9313/10230)\n",
      "Epoch: 11 | Batch_idx: 350 |  Loss: (0.2579) | Acc: (91.05%) (9588/10530)\n",
      "Epoch: 11 | Batch_idx: 360 |  Loss: (0.2575) | Acc: (91.02%) (9858/10830)\n",
      "Epoch: 11 | Batch_idx: 370 |  Loss: (0.2583) | Acc: (91.02%) (10130/11130)\n",
      "Epoch: 11 | Batch_idx: 380 |  Loss: (0.2574) | Acc: (91.03%) (10405/11430)\n",
      "Epoch: 11 | Batch_idx: 390 |  Loss: (0.2575) | Acc: (91.04%) (10679/11730)\n",
      "Epoch: 11 | Batch_idx: 400 |  Loss: (0.2581) | Acc: (91.01%) (10949/12030)\n",
      "Epoch: 11 | Batch_idx: 410 |  Loss: (0.2571) | Acc: (91.05%) (11226/12330)\n",
      "Epoch: 11 | Batch_idx: 420 |  Loss: (0.2573) | Acc: (91.00%) (11493/12630)\n",
      "Epoch: 11 | Batch_idx: 430 |  Loss: (0.2569) | Acc: (91.04%) (11771/12930)\n",
      "Epoch: 11 | Batch_idx: 440 |  Loss: (0.2561) | Acc: (91.09%) (12051/13230)\n",
      "Epoch: 11 | Batch_idx: 450 |  Loss: (0.2582) | Acc: (90.99%) (12311/13530)\n",
      "Epoch: 11 | Batch_idx: 460 |  Loss: (0.2601) | Acc: (90.92%) (12574/13830)\n",
      "Epoch: 11 | Batch_idx: 470 |  Loss: (0.2609) | Acc: (90.86%) (12839/14130)\n",
      "Epoch: 11 | Batch_idx: 480 |  Loss: (0.2617) | Acc: (90.87%) (13113/14430)\n",
      "Epoch: 11 | Batch_idx: 490 |  Loss: (0.2631) | Acc: (90.84%) (13380/14730)\n",
      "Epoch: 11 | Batch_idx: 500 |  Loss: (0.2636) | Acc: (90.80%) (13647/15030)\n",
      "Epoch: 11 | Batch_idx: 510 |  Loss: (0.2628) | Acc: (90.83%) (13925/15330)\n",
      "Epoch: 11 | Batch_idx: 520 |  Loss: (0.2629) | Acc: (90.82%) (14195/15630)\n",
      "Epoch: 11 | Batch_idx: 530 |  Loss: (0.2630) | Acc: (90.82%) (14468/15930)\n",
      "Epoch: 11 | Batch_idx: 540 |  Loss: (0.2639) | Acc: (90.83%) (14741/16230)\n",
      "Epoch: 11 | Batch_idx: 550 |  Loss: (0.2647) | Acc: (90.80%) (15010/16530)\n",
      "Epoch: 11 | Batch_idx: 560 |  Loss: (0.2653) | Acc: (90.81%) (15284/16830)\n",
      "Epoch: 11 | Batch_idx: 570 |  Loss: (0.2658) | Acc: (90.78%) (15551/17130)\n",
      "Epoch: 11 | Batch_idx: 580 |  Loss: (0.2650) | Acc: (90.79%) (15825/17430)\n",
      "Epoch: 11 | Batch_idx: 590 |  Loss: (0.2647) | Acc: (90.81%) (16100/17730)\n",
      "Epoch: 11 | Batch_idx: 600 |  Loss: (0.2644) | Acc: (90.83%) (16377/18030)\n",
      "Epoch: 11 | Batch_idx: 610 |  Loss: (0.2637) | Acc: (90.86%) (16655/18330)\n",
      "Epoch: 11 | Batch_idx: 620 |  Loss: (0.2624) | Acc: (90.91%) (16936/18630)\n",
      "Epoch: 11 | Batch_idx: 630 |  Loss: (0.2618) | Acc: (90.94%) (17215/18930)\n",
      "Epoch: 11 | Batch_idx: 640 |  Loss: (0.2607) | Acc: (90.99%) (17498/19230)\n",
      "Epoch: 11 | Batch_idx: 650 |  Loss: (0.2605) | Acc: (90.97%) (17767/19530)\n",
      "Epoch: 11 | Batch_idx: 660 |  Loss: (0.2601) | Acc: (91.00%) (18045/19830)\n",
      "Epoch: 11 | Batch_idx: 670 |  Loss: (0.2612) | Acc: (90.94%) (18306/20130)\n",
      "Epoch: 11 | Batch_idx: 680 |  Loss: (0.2615) | Acc: (90.93%) (18578/20430)\n",
      "Epoch: 11 | Batch_idx: 690 |  Loss: (0.2611) | Acc: (90.95%) (18853/20730)\n",
      "Epoch: 11 | Batch_idx: 700 |  Loss: (0.2609) | Acc: (90.96%) (19129/21030)\n",
      "Epoch: 11 | Batch_idx: 710 |  Loss: (0.2604) | Acc: (90.98%) (19405/21330)\n",
      "Epoch: 11 | Batch_idx: 720 |  Loss: (0.2600) | Acc: (91.01%) (19685/21630)\n",
      "Epoch: 11 | Batch_idx: 730 |  Loss: (0.2600) | Acc: (91.02%) (19961/21930)\n",
      "Epoch: 11 | Batch_idx: 740 |  Loss: (0.2598) | Acc: (91.03%) (20235/22230)\n",
      "Epoch: 11 | Batch_idx: 750 |  Loss: (0.2605) | Acc: (90.99%) (20500/22530)\n",
      "Epoch: 11 | Batch_idx: 760 |  Loss: (0.2611) | Acc: (90.98%) (20770/22830)\n",
      "Epoch: 11 | Batch_idx: 770 |  Loss: (0.2608) | Acc: (91.00%) (21048/23130)\n",
      "Epoch: 11 | Batch_idx: 780 |  Loss: (0.2610) | Acc: (90.99%) (21318/23430)\n",
      "Epoch: 11 | Batch_idx: 790 |  Loss: (0.2608) | Acc: (90.99%) (21591/23730)\n",
      "Epoch: 11 | Batch_idx: 800 |  Loss: (0.2614) | Acc: (90.96%) (21858/24030)\n",
      "Epoch: 11 | Batch_idx: 810 |  Loss: (0.2616) | Acc: (90.95%) (22128/24330)\n",
      "Epoch: 11 | Batch_idx: 820 |  Loss: (0.2611) | Acc: (90.95%) (22400/24630)\n",
      "Epoch: 11 | Batch_idx: 830 |  Loss: (0.2614) | Acc: (90.93%) (22669/24930)\n",
      "Epoch: 11 | Batch_idx: 840 |  Loss: (0.2607) | Acc: (90.96%) (22948/25230)\n",
      "Epoch: 11 | Batch_idx: 850 |  Loss: (0.2604) | Acc: (90.96%) (23222/25530)\n",
      "Epoch: 11 | Batch_idx: 860 |  Loss: (0.2600) | Acc: (90.99%) (23503/25830)\n",
      "Epoch: 11 | Batch_idx: 870 |  Loss: (0.2606) | Acc: (90.98%) (23772/26130)\n",
      "Epoch: 11 | Batch_idx: 880 |  Loss: (0.2613) | Acc: (90.97%) (24044/26430)\n",
      "Epoch: 11 | Batch_idx: 890 |  Loss: (0.2610) | Acc: (90.98%) (24319/26730)\n",
      "Epoch: 11 | Batch_idx: 900 |  Loss: (0.2607) | Acc: (91.00%) (24596/27030)\n",
      "Epoch: 11 | Batch_idx: 910 |  Loss: (0.2610) | Acc: (90.99%) (24867/27330)\n",
      "Epoch: 11 | Batch_idx: 920 |  Loss: (0.2615) | Acc: (90.98%) (25137/27630)\n",
      "Epoch: 11 | Batch_idx: 930 |  Loss: (0.2619) | Acc: (90.95%) (25401/27930)\n",
      "Epoch: 11 | Batch_idx: 940 |  Loss: (0.2622) | Acc: (90.92%) (25667/28230)\n",
      "Epoch: 11 | Batch_idx: 950 |  Loss: (0.2630) | Acc: (90.91%) (25937/28530)\n",
      "Epoch: 11 | Batch_idx: 960 |  Loss: (0.2634) | Acc: (90.90%) (26206/28830)\n",
      "Epoch: 11 | Batch_idx: 970 |  Loss: (0.2646) | Acc: (90.85%) (26465/29130)\n",
      "Epoch: 11 | Batch_idx: 980 |  Loss: (0.2643) | Acc: (90.87%) (26744/29430)\n",
      "Epoch: 11 | Batch_idx: 990 |  Loss: (0.2644) | Acc: (90.87%) (27016/29730)\n",
      "Epoch: 11 | Batch_idx: 1000 |  Loss: (0.2643) | Acc: (90.87%) (27288/30030)\n",
      "Epoch: 11 | Batch_idx: 1010 |  Loss: (0.2640) | Acc: (90.88%) (27565/30330)\n",
      "Epoch: 11 | Batch_idx: 1020 |  Loss: (0.2640) | Acc: (90.89%) (27839/30630)\n",
      "Epoch: 11 | Batch_idx: 1030 |  Loss: (0.2636) | Acc: (90.93%) (28124/30930)\n",
      "Epoch: 11 | Batch_idx: 1040 |  Loss: (0.2638) | Acc: (90.92%) (28395/31230)\n",
      "Epoch: 11 | Batch_idx: 1050 |  Loss: (0.2635) | Acc: (90.95%) (28676/31530)\n",
      "Epoch: 11 | Batch_idx: 1060 |  Loss: (0.2633) | Acc: (90.94%) (28946/31830)\n",
      "Epoch: 11 | Batch_idx: 1070 |  Loss: (0.2626) | Acc: (90.97%) (29229/32130)\n",
      "Epoch: 11 | Batch_idx: 1080 |  Loss: (0.2620) | Acc: (90.99%) (29507/32430)\n",
      "Epoch: 11 | Batch_idx: 1090 |  Loss: (0.2625) | Acc: (90.97%) (29774/32730)\n",
      "Epoch: 11 | Batch_idx: 1100 |  Loss: (0.2626) | Acc: (90.96%) (30044/33030)\n",
      "Epoch: 11 | Batch_idx: 1110 |  Loss: (0.2626) | Acc: (90.95%) (30315/33330)\n",
      "Epoch: 11 | Batch_idx: 1120 |  Loss: (0.2619) | Acc: (90.98%) (30597/33630)\n",
      "Epoch: 11 | Batch_idx: 1130 |  Loss: (0.2627) | Acc: (90.96%) (30862/33930)\n",
      "Epoch: 11 | Batch_idx: 1140 |  Loss: (0.2628) | Acc: (90.95%) (31132/34230)\n",
      "Epoch: 11 | Batch_idx: 1150 |  Loss: (0.2630) | Acc: (90.93%) (31398/34530)\n",
      "Epoch: 11 | Batch_idx: 1160 |  Loss: (0.2627) | Acc: (90.94%) (31674/34830)\n",
      "Epoch: 11 | Batch_idx: 1170 |  Loss: (0.2622) | Acc: (90.95%) (31951/35130)\n",
      "Epoch: 11 | Batch_idx: 1180 |  Loss: (0.2625) | Acc: (90.95%) (32223/35430)\n",
      "Epoch: 11 | Batch_idx: 1190 |  Loss: (0.2623) | Acc: (90.95%) (32497/35730)\n",
      "Epoch: 11 | Batch_idx: 1200 |  Loss: (0.2622) | Acc: (90.96%) (32772/36030)\n",
      "Epoch: 11 | Batch_idx: 1210 |  Loss: (0.2624) | Acc: (90.96%) (33045/36330)\n",
      "Epoch: 11 | Batch_idx: 1220 |  Loss: (0.2623) | Acc: (90.95%) (33316/36630)\n",
      "Epoch: 11 | Batch_idx: 1230 |  Loss: (0.2621) | Acc: (90.95%) (33586/36930)\n",
      "Epoch: 11 | Batch_idx: 1240 |  Loss: (0.2617) | Acc: (90.96%) (33866/37230)\n",
      "Epoch: 11 | Batch_idx: 1250 |  Loss: (0.2621) | Acc: (90.93%) (34126/37530)\n",
      "Epoch: 11 | Batch_idx: 1260 |  Loss: (0.2621) | Acc: (90.91%) (34392/37830)\n",
      "Epoch: 11 | Batch_idx: 1270 |  Loss: (0.2620) | Acc: (90.91%) (34664/38130)\n",
      "Epoch: 11 | Batch_idx: 1280 |  Loss: (0.2621) | Acc: (90.91%) (34936/38430)\n",
      "Epoch: 11 | Batch_idx: 1290 |  Loss: (0.2624) | Acc: (90.90%) (35204/38730)\n",
      "Epoch: 11 | Batch_idx: 1300 |  Loss: (0.2631) | Acc: (90.88%) (35469/39030)\n",
      "Epoch: 11 | Batch_idx: 1310 |  Loss: (0.2638) | Acc: (90.87%) (35738/39330)\n",
      "Epoch: 11 | Batch_idx: 1320 |  Loss: (0.2638) | Acc: (90.87%) (36010/39630)\n",
      "Epoch: 11 | Batch_idx: 1330 |  Loss: (0.2642) | Acc: (90.85%) (36277/39930)\n",
      "Epoch: 11 | Batch_idx: 1340 |  Loss: (0.2641) | Acc: (90.85%) (36548/40230)\n",
      "Epoch: 11 | Batch_idx: 1350 |  Loss: (0.2639) | Acc: (90.86%) (36824/40530)\n",
      "Epoch: 11 | Batch_idx: 1360 |  Loss: (0.2642) | Acc: (90.84%) (37091/40830)\n",
      "Epoch: 11 | Batch_idx: 1370 |  Loss: (0.2636) | Acc: (90.86%) (37371/41130)\n",
      "Epoch: 11 | Batch_idx: 1380 |  Loss: (0.2637) | Acc: (90.86%) (37644/41430)\n",
      "Epoch: 11 | Batch_idx: 1390 |  Loss: (0.2633) | Acc: (90.88%) (37925/41730)\n",
      "Epoch: 11 | Batch_idx: 1400 |  Loss: (0.2635) | Acc: (90.89%) (38199/42030)\n",
      "Epoch: 11 | Batch_idx: 1410 |  Loss: (0.2637) | Acc: (90.87%) (38467/42330)\n",
      "Epoch: 11 | Batch_idx: 1420 |  Loss: (0.2634) | Acc: (90.89%) (38747/42630)\n",
      "Epoch: 11 | Batch_idx: 1430 |  Loss: (0.2631) | Acc: (90.90%) (39022/42930)\n",
      "Epoch: 11 | Batch_idx: 1440 |  Loss: (0.2632) | Acc: (90.89%) (39293/43230)\n",
      "Epoch: 11 | Batch_idx: 1450 |  Loss: (0.2631) | Acc: (90.90%) (39567/43530)\n",
      "Epoch: 11 | Batch_idx: 1460 |  Loss: (0.2630) | Acc: (90.90%) (39842/43830)\n",
      "Epoch: 11 | Batch_idx: 1470 |  Loss: (0.2631) | Acc: (90.90%) (40113/44130)\n",
      "Epoch: 11 | Batch_idx: 1480 |  Loss: (0.2631) | Acc: (90.90%) (40389/44430)\n",
      "Epoch: 11 | Batch_idx: 1490 |  Loss: (0.2628) | Acc: (90.91%) (40665/44730)\n",
      "Epoch: 11 | Batch_idx: 1500 |  Loss: (0.2625) | Acc: (90.92%) (40941/45030)\n",
      "Epoch: 11 | Batch_idx: 1510 |  Loss: (0.2623) | Acc: (90.93%) (41219/45330)\n",
      "Epoch: 11 | Batch_idx: 1520 |  Loss: (0.2625) | Acc: (90.92%) (41485/45630)\n",
      "Epoch: 11 | Batch_idx: 1530 |  Loss: (0.2624) | Acc: (90.92%) (41761/45930)\n",
      "Epoch: 11 | Batch_idx: 1540 |  Loss: (0.2627) | Acc: (90.91%) (42026/46230)\n",
      "Epoch: 11 | Batch_idx: 1550 |  Loss: (0.2629) | Acc: (90.90%) (42296/46530)\n",
      "Epoch: 11 | Batch_idx: 1560 |  Loss: (0.2636) | Acc: (90.88%) (42558/46830)\n",
      "Epoch: 11 | Batch_idx: 1570 |  Loss: (0.2638) | Acc: (90.88%) (42832/47130)\n",
      "Epoch: 11 | Batch_idx: 1580 |  Loss: (0.2639) | Acc: (90.88%) (43104/47430)\n",
      "Epoch: 11 | Batch_idx: 1590 |  Loss: (0.2634) | Acc: (90.90%) (43387/47730)\n",
      "Epoch: 11 | Batch_idx: 1600 |  Loss: (0.2632) | Acc: (90.91%) (43664/48030)\n",
      "Epoch: 11 | Batch_idx: 1610 |  Loss: (0.2637) | Acc: (90.89%) (43925/48330)\n",
      "Epoch: 11 | Batch_idx: 1620 |  Loss: (0.2638) | Acc: (90.88%) (44196/48630)\n",
      "Epoch: 11 | Batch_idx: 1630 |  Loss: (0.2637) | Acc: (90.89%) (44472/48930)\n",
      "Epoch: 11 | Batch_idx: 1640 |  Loss: (0.2636) | Acc: (90.89%) (44747/49230)\n",
      "Epoch: 11 | Batch_idx: 1650 |  Loss: (0.2634) | Acc: (90.91%) (45026/49530)\n",
      "Epoch: 11 | Batch_idx: 1660 |  Loss: (0.2630) | Acc: (90.92%) (45305/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3771) | Acc: (88.16%) (8816/10000)\n",
      "Epoch: 12 | Batch_idx: 0 |  Loss: (0.3497) | Acc: (86.67%) (26/30)\n",
      "Epoch: 12 | Batch_idx: 10 |  Loss: (0.1691) | Acc: (94.85%) (313/330)\n",
      "Epoch: 12 | Batch_idx: 20 |  Loss: (0.1821) | Acc: (93.33%) (588/630)\n",
      "Epoch: 12 | Batch_idx: 30 |  Loss: (0.1774) | Acc: (93.76%) (872/930)\n",
      "Epoch: 12 | Batch_idx: 40 |  Loss: (0.1897) | Acc: (93.33%) (1148/1230)\n",
      "Epoch: 12 | Batch_idx: 50 |  Loss: (0.1983) | Acc: (92.81%) (1420/1530)\n",
      "Epoch: 12 | Batch_idx: 60 |  Loss: (0.2004) | Acc: (93.06%) (1703/1830)\n",
      "Epoch: 12 | Batch_idx: 70 |  Loss: (0.2062) | Acc: (92.72%) (1975/2130)\n",
      "Epoch: 12 | Batch_idx: 80 |  Loss: (0.2110) | Acc: (92.67%) (2252/2430)\n",
      "Epoch: 12 | Batch_idx: 90 |  Loss: (0.2099) | Acc: (92.86%) (2535/2730)\n",
      "Epoch: 12 | Batch_idx: 100 |  Loss: (0.2074) | Acc: (93.00%) (2818/3030)\n",
      "Epoch: 12 | Batch_idx: 110 |  Loss: (0.2112) | Acc: (92.85%) (3092/3330)\n",
      "Epoch: 12 | Batch_idx: 120 |  Loss: (0.2117) | Acc: (92.87%) (3371/3630)\n",
      "Epoch: 12 | Batch_idx: 130 |  Loss: (0.2136) | Acc: (92.75%) (3645/3930)\n",
      "Epoch: 12 | Batch_idx: 140 |  Loss: (0.2112) | Acc: (92.88%) (3929/4230)\n",
      "Epoch: 12 | Batch_idx: 150 |  Loss: (0.2179) | Acc: (92.63%) (4196/4530)\n",
      "Epoch: 12 | Batch_idx: 160 |  Loss: (0.2184) | Acc: (92.65%) (4475/4830)\n",
      "Epoch: 12 | Batch_idx: 170 |  Loss: (0.2160) | Acc: (92.73%) (4757/5130)\n",
      "Epoch: 12 | Batch_idx: 180 |  Loss: (0.2160) | Acc: (92.74%) (5036/5430)\n",
      "Epoch: 12 | Batch_idx: 190 |  Loss: (0.2174) | Acc: (92.65%) (5309/5730)\n",
      "Epoch: 12 | Batch_idx: 200 |  Loss: (0.2197) | Acc: (92.54%) (5580/6030)\n",
      "Epoch: 12 | Batch_idx: 210 |  Loss: (0.2207) | Acc: (92.43%) (5851/6330)\n",
      "Epoch: 12 | Batch_idx: 220 |  Loss: (0.2208) | Acc: (92.40%) (6126/6630)\n",
      "Epoch: 12 | Batch_idx: 230 |  Loss: (0.2195) | Acc: (92.48%) (6409/6930)\n",
      "Epoch: 12 | Batch_idx: 240 |  Loss: (0.2195) | Acc: (92.42%) (6682/7230)\n",
      "Epoch: 12 | Batch_idx: 250 |  Loss: (0.2231) | Acc: (92.28%) (6949/7530)\n",
      "Epoch: 12 | Batch_idx: 260 |  Loss: (0.2230) | Acc: (92.27%) (7225/7830)\n",
      "Epoch: 12 | Batch_idx: 270 |  Loss: (0.2222) | Acc: (92.31%) (7505/8130)\n",
      "Epoch: 12 | Batch_idx: 280 |  Loss: (0.2232) | Acc: (92.28%) (7779/8430)\n",
      "Epoch: 12 | Batch_idx: 290 |  Loss: (0.2234) | Acc: (92.26%) (8054/8730)\n",
      "Epoch: 12 | Batch_idx: 300 |  Loss: (0.2226) | Acc: (92.29%) (8334/9030)\n",
      "Epoch: 12 | Batch_idx: 310 |  Loss: (0.2251) | Acc: (92.17%) (8599/9330)\n",
      "Epoch: 12 | Batch_idx: 320 |  Loss: (0.2284) | Acc: (92.08%) (8867/9630)\n",
      "Epoch: 12 | Batch_idx: 330 |  Loss: (0.2281) | Acc: (92.10%) (9146/9930)\n",
      "Epoch: 12 | Batch_idx: 340 |  Loss: (0.2289) | Acc: (92.08%) (9420/10230)\n",
      "Epoch: 12 | Batch_idx: 350 |  Loss: (0.2303) | Acc: (92.01%) (9689/10530)\n",
      "Epoch: 12 | Batch_idx: 360 |  Loss: (0.2285) | Acc: (92.06%) (9970/10830)\n",
      "Epoch: 12 | Batch_idx: 370 |  Loss: (0.2274) | Acc: (92.14%) (10255/11130)\n",
      "Epoch: 12 | Batch_idx: 380 |  Loss: (0.2272) | Acc: (92.13%) (10531/11430)\n",
      "Epoch: 12 | Batch_idx: 390 |  Loss: (0.2275) | Acc: (92.17%) (10811/11730)\n",
      "Epoch: 12 | Batch_idx: 400 |  Loss: (0.2272) | Acc: (92.18%) (11089/12030)\n",
      "Epoch: 12 | Batch_idx: 410 |  Loss: (0.2269) | Acc: (92.20%) (11368/12330)\n",
      "Epoch: 12 | Batch_idx: 420 |  Loss: (0.2282) | Acc: (92.19%) (11643/12630)\n",
      "Epoch: 12 | Batch_idx: 430 |  Loss: (0.2276) | Acc: (92.18%) (11919/12930)\n",
      "Epoch: 12 | Batch_idx: 440 |  Loss: (0.2273) | Acc: (92.19%) (12197/13230)\n",
      "Epoch: 12 | Batch_idx: 450 |  Loss: (0.2279) | Acc: (92.18%) (12472/13530)\n",
      "Epoch: 12 | Batch_idx: 460 |  Loss: (0.2284) | Acc: (92.16%) (12746/13830)\n",
      "Epoch: 12 | Batch_idx: 470 |  Loss: (0.2284) | Acc: (92.17%) (13023/14130)\n",
      "Epoch: 12 | Batch_idx: 480 |  Loss: (0.2287) | Acc: (92.13%) (13294/14430)\n",
      "Epoch: 12 | Batch_idx: 490 |  Loss: (0.2290) | Acc: (92.12%) (13569/14730)\n",
      "Epoch: 12 | Batch_idx: 500 |  Loss: (0.2284) | Acc: (92.12%) (13845/15030)\n",
      "Epoch: 12 | Batch_idx: 510 |  Loss: (0.2270) | Acc: (92.17%) (14129/15330)\n",
      "Epoch: 12 | Batch_idx: 520 |  Loss: (0.2272) | Acc: (92.16%) (14405/15630)\n",
      "Epoch: 12 | Batch_idx: 530 |  Loss: (0.2282) | Acc: (92.13%) (14677/15930)\n",
      "Epoch: 12 | Batch_idx: 540 |  Loss: (0.2280) | Acc: (92.14%) (14955/16230)\n",
      "Epoch: 12 | Batch_idx: 550 |  Loss: (0.2291) | Acc: (92.09%) (15223/16530)\n",
      "Epoch: 12 | Batch_idx: 560 |  Loss: (0.2286) | Acc: (92.10%) (15501/16830)\n",
      "Epoch: 12 | Batch_idx: 570 |  Loss: (0.2280) | Acc: (92.14%) (15783/17130)\n",
      "Epoch: 12 | Batch_idx: 580 |  Loss: (0.2282) | Acc: (92.13%) (16058/17430)\n",
      "Epoch: 12 | Batch_idx: 590 |  Loss: (0.2284) | Acc: (92.14%) (16337/17730)\n",
      "Epoch: 12 | Batch_idx: 600 |  Loss: (0.2286) | Acc: (92.15%) (16614/18030)\n",
      "Epoch: 12 | Batch_idx: 610 |  Loss: (0.2281) | Acc: (92.14%) (16889/18330)\n",
      "Epoch: 12 | Batch_idx: 620 |  Loss: (0.2281) | Acc: (92.17%) (17171/18630)\n",
      "Epoch: 12 | Batch_idx: 630 |  Loss: (0.2288) | Acc: (92.10%) (17435/18930)\n",
      "Epoch: 12 | Batch_idx: 640 |  Loss: (0.2287) | Acc: (92.07%) (17706/19230)\n",
      "Epoch: 12 | Batch_idx: 650 |  Loss: (0.2290) | Acc: (92.07%) (17982/19530)\n",
      "Epoch: 12 | Batch_idx: 660 |  Loss: (0.2289) | Acc: (92.07%) (18258/19830)\n",
      "Epoch: 12 | Batch_idx: 670 |  Loss: (0.2303) | Acc: (92.04%) (18527/20130)\n",
      "Epoch: 12 | Batch_idx: 680 |  Loss: (0.2303) | Acc: (92.05%) (18806/20430)\n",
      "Epoch: 12 | Batch_idx: 690 |  Loss: (0.2304) | Acc: (92.02%) (19076/20730)\n",
      "Epoch: 12 | Batch_idx: 700 |  Loss: (0.2309) | Acc: (92.02%) (19351/21030)\n",
      "Epoch: 12 | Batch_idx: 710 |  Loss: (0.2303) | Acc: (92.03%) (19629/21330)\n",
      "Epoch: 12 | Batch_idx: 720 |  Loss: (0.2309) | Acc: (92.03%) (19907/21630)\n",
      "Epoch: 12 | Batch_idx: 730 |  Loss: (0.2313) | Acc: (92.02%) (20179/21930)\n",
      "Epoch: 12 | Batch_idx: 740 |  Loss: (0.2320) | Acc: (91.97%) (20445/22230)\n",
      "Epoch: 12 | Batch_idx: 750 |  Loss: (0.2322) | Acc: (91.97%) (20720/22530)\n",
      "Epoch: 12 | Batch_idx: 760 |  Loss: (0.2319) | Acc: (91.96%) (20995/22830)\n",
      "Epoch: 12 | Batch_idx: 770 |  Loss: (0.2320) | Acc: (91.97%) (21272/23130)\n",
      "Epoch: 12 | Batch_idx: 780 |  Loss: (0.2312) | Acc: (91.98%) (21551/23430)\n",
      "Epoch: 12 | Batch_idx: 790 |  Loss: (0.2310) | Acc: (91.98%) (21827/23730)\n",
      "Epoch: 12 | Batch_idx: 800 |  Loss: (0.2323) | Acc: (91.92%) (22089/24030)\n",
      "Epoch: 12 | Batch_idx: 810 |  Loss: (0.2315) | Acc: (91.94%) (22370/24330)\n",
      "Epoch: 12 | Batch_idx: 820 |  Loss: (0.2318) | Acc: (91.94%) (22645/24630)\n",
      "Epoch: 12 | Batch_idx: 830 |  Loss: (0.2320) | Acc: (91.94%) (22921/24930)\n",
      "Epoch: 12 | Batch_idx: 840 |  Loss: (0.2318) | Acc: (91.93%) (23194/25230)\n",
      "Epoch: 12 | Batch_idx: 850 |  Loss: (0.2316) | Acc: (91.93%) (23469/25530)\n",
      "Epoch: 12 | Batch_idx: 860 |  Loss: (0.2321) | Acc: (91.89%) (23736/25830)\n",
      "Epoch: 12 | Batch_idx: 870 |  Loss: (0.2322) | Acc: (91.88%) (24009/26130)\n",
      "Epoch: 12 | Batch_idx: 880 |  Loss: (0.2324) | Acc: (91.86%) (24278/26430)\n",
      "Epoch: 12 | Batch_idx: 890 |  Loss: (0.2323) | Acc: (91.86%) (24555/26730)\n",
      "Epoch: 12 | Batch_idx: 900 |  Loss: (0.2323) | Acc: (91.85%) (24828/27030)\n",
      "Epoch: 12 | Batch_idx: 910 |  Loss: (0.2317) | Acc: (91.88%) (25110/27330)\n",
      "Epoch: 12 | Batch_idx: 920 |  Loss: (0.2318) | Acc: (91.88%) (25386/27630)\n",
      "Epoch: 12 | Batch_idx: 930 |  Loss: (0.2318) | Acc: (91.87%) (25659/27930)\n",
      "Epoch: 12 | Batch_idx: 940 |  Loss: (0.2321) | Acc: (91.85%) (25929/28230)\n",
      "Epoch: 12 | Batch_idx: 950 |  Loss: (0.2331) | Acc: (91.81%) (26194/28530)\n",
      "Epoch: 12 | Batch_idx: 960 |  Loss: (0.2333) | Acc: (91.82%) (26471/28830)\n",
      "Epoch: 12 | Batch_idx: 970 |  Loss: (0.2332) | Acc: (91.82%) (26748/29130)\n",
      "Epoch: 12 | Batch_idx: 980 |  Loss: (0.2336) | Acc: (91.80%) (27017/29430)\n",
      "Epoch: 12 | Batch_idx: 990 |  Loss: (0.2333) | Acc: (91.82%) (27299/29730)\n",
      "Epoch: 12 | Batch_idx: 1000 |  Loss: (0.2331) | Acc: (91.85%) (27582/30030)\n",
      "Epoch: 12 | Batch_idx: 1010 |  Loss: (0.2333) | Acc: (91.84%) (27854/30330)\n",
      "Epoch: 12 | Batch_idx: 1020 |  Loss: (0.2333) | Acc: (91.83%) (28129/30630)\n",
      "Epoch: 12 | Batch_idx: 1030 |  Loss: (0.2333) | Acc: (91.83%) (28404/30930)\n",
      "Epoch: 12 | Batch_idx: 1040 |  Loss: (0.2334) | Acc: (91.82%) (28674/31230)\n",
      "Epoch: 12 | Batch_idx: 1050 |  Loss: (0.2332) | Acc: (91.83%) (28955/31530)\n",
      "Epoch: 12 | Batch_idx: 1060 |  Loss: (0.2330) | Acc: (91.83%) (29231/31830)\n",
      "Epoch: 12 | Batch_idx: 1070 |  Loss: (0.2337) | Acc: (91.80%) (29495/32130)\n",
      "Epoch: 12 | Batch_idx: 1080 |  Loss: (0.2341) | Acc: (91.79%) (29768/32430)\n",
      "Epoch: 12 | Batch_idx: 1090 |  Loss: (0.2335) | Acc: (91.81%) (30048/32730)\n",
      "Epoch: 12 | Batch_idx: 1100 |  Loss: (0.2332) | Acc: (91.80%) (30323/33030)\n",
      "Epoch: 12 | Batch_idx: 1110 |  Loss: (0.2334) | Acc: (91.80%) (30596/33330)\n",
      "Epoch: 12 | Batch_idx: 1120 |  Loss: (0.2339) | Acc: (91.78%) (30866/33630)\n",
      "Epoch: 12 | Batch_idx: 1130 |  Loss: (0.2345) | Acc: (91.76%) (31133/33930)\n",
      "Epoch: 12 | Batch_idx: 1140 |  Loss: (0.2353) | Acc: (91.72%) (31397/34230)\n",
      "Epoch: 12 | Batch_idx: 1150 |  Loss: (0.2356) | Acc: (91.70%) (31665/34530)\n",
      "Epoch: 12 | Batch_idx: 1160 |  Loss: (0.2357) | Acc: (91.71%) (31943/34830)\n",
      "Epoch: 12 | Batch_idx: 1170 |  Loss: (0.2356) | Acc: (91.71%) (32217/35130)\n",
      "Epoch: 12 | Batch_idx: 1180 |  Loss: (0.2356) | Acc: (91.70%) (32489/35430)\n",
      "Epoch: 12 | Batch_idx: 1190 |  Loss: (0.2366) | Acc: (91.68%) (32757/35730)\n",
      "Epoch: 12 | Batch_idx: 1200 |  Loss: (0.2360) | Acc: (91.70%) (33041/36030)\n",
      "Epoch: 12 | Batch_idx: 1210 |  Loss: (0.2357) | Acc: (91.72%) (33322/36330)\n",
      "Epoch: 12 | Batch_idx: 1220 |  Loss: (0.2355) | Acc: (91.73%) (33602/36630)\n",
      "Epoch: 12 | Batch_idx: 1230 |  Loss: (0.2354) | Acc: (91.73%) (33875/36930)\n",
      "Epoch: 12 | Batch_idx: 1240 |  Loss: (0.2355) | Acc: (91.73%) (34152/37230)\n",
      "Epoch: 12 | Batch_idx: 1250 |  Loss: (0.2353) | Acc: (91.75%) (34434/37530)\n",
      "Epoch: 12 | Batch_idx: 1260 |  Loss: (0.2359) | Acc: (91.75%) (34710/37830)\n",
      "Epoch: 12 | Batch_idx: 1270 |  Loss: (0.2357) | Acc: (91.77%) (34990/38130)\n",
      "Epoch: 12 | Batch_idx: 1280 |  Loss: (0.2354) | Acc: (91.78%) (35270/38430)\n",
      "Epoch: 12 | Batch_idx: 1290 |  Loss: (0.2354) | Acc: (91.78%) (35545/38730)\n",
      "Epoch: 12 | Batch_idx: 1300 |  Loss: (0.2347) | Acc: (91.80%) (35831/39030)\n",
      "Epoch: 12 | Batch_idx: 1310 |  Loss: (0.2354) | Acc: (91.78%) (36099/39330)\n",
      "Epoch: 12 | Batch_idx: 1320 |  Loss: (0.2355) | Acc: (91.77%) (36369/39630)\n",
      "Epoch: 12 | Batch_idx: 1330 |  Loss: (0.2357) | Acc: (91.76%) (36640/39930)\n",
      "Epoch: 12 | Batch_idx: 1340 |  Loss: (0.2353) | Acc: (91.78%) (36922/40230)\n",
      "Epoch: 12 | Batch_idx: 1350 |  Loss: (0.2353) | Acc: (91.77%) (37196/40530)\n",
      "Epoch: 12 | Batch_idx: 1360 |  Loss: (0.2354) | Acc: (91.78%) (37472/40830)\n",
      "Epoch: 12 | Batch_idx: 1370 |  Loss: (0.2355) | Acc: (91.77%) (37745/41130)\n",
      "Epoch: 12 | Batch_idx: 1380 |  Loss: (0.2353) | Acc: (91.77%) (38022/41430)\n",
      "Epoch: 12 | Batch_idx: 1390 |  Loss: (0.2359) | Acc: (91.74%) (38285/41730)\n",
      "Epoch: 12 | Batch_idx: 1400 |  Loss: (0.2356) | Acc: (91.75%) (38563/42030)\n",
      "Epoch: 12 | Batch_idx: 1410 |  Loss: (0.2358) | Acc: (91.73%) (38831/42330)\n",
      "Epoch: 12 | Batch_idx: 1420 |  Loss: (0.2363) | Acc: (91.72%) (39101/42630)\n",
      "Epoch: 12 | Batch_idx: 1430 |  Loss: (0.2363) | Acc: (91.73%) (39379/42930)\n",
      "Epoch: 12 | Batch_idx: 1440 |  Loss: (0.2362) | Acc: (91.73%) (39654/43230)\n",
      "Epoch: 12 | Batch_idx: 1450 |  Loss: (0.2367) | Acc: (91.72%) (39926/43530)\n",
      "Epoch: 12 | Batch_idx: 1460 |  Loss: (0.2369) | Acc: (91.72%) (40199/43830)\n",
      "Epoch: 12 | Batch_idx: 1470 |  Loss: (0.2365) | Acc: (91.73%) (40481/44130)\n",
      "Epoch: 12 | Batch_idx: 1480 |  Loss: (0.2361) | Acc: (91.75%) (40765/44430)\n",
      "Epoch: 12 | Batch_idx: 1490 |  Loss: (0.2362) | Acc: (91.75%) (41039/44730)\n",
      "Epoch: 12 | Batch_idx: 1500 |  Loss: (0.2364) | Acc: (91.75%) (41313/45030)\n",
      "Epoch: 12 | Batch_idx: 1510 |  Loss: (0.2364) | Acc: (91.74%) (41587/45330)\n",
      "Epoch: 12 | Batch_idx: 1520 |  Loss: (0.2365) | Acc: (91.74%) (41863/45630)\n",
      "Epoch: 12 | Batch_idx: 1530 |  Loss: (0.2367) | Acc: (91.73%) (42131/45930)\n",
      "Epoch: 12 | Batch_idx: 1540 |  Loss: (0.2369) | Acc: (91.72%) (42400/46230)\n",
      "Epoch: 12 | Batch_idx: 1550 |  Loss: (0.2370) | Acc: (91.71%) (42674/46530)\n",
      "Epoch: 12 | Batch_idx: 1560 |  Loss: (0.2370) | Acc: (91.70%) (42945/46830)\n",
      "Epoch: 12 | Batch_idx: 1570 |  Loss: (0.2372) | Acc: (91.69%) (43213/47130)\n",
      "Epoch: 12 | Batch_idx: 1580 |  Loss: (0.2377) | Acc: (91.67%) (43480/47430)\n",
      "Epoch: 12 | Batch_idx: 1590 |  Loss: (0.2376) | Acc: (91.67%) (43753/47730)\n",
      "Epoch: 12 | Batch_idx: 1600 |  Loss: (0.2377) | Acc: (91.67%) (44030/48030)\n",
      "Epoch: 12 | Batch_idx: 1610 |  Loss: (0.2378) | Acc: (91.67%) (44303/48330)\n",
      "Epoch: 12 | Batch_idx: 1620 |  Loss: (0.2376) | Acc: (91.68%) (44583/48630)\n",
      "Epoch: 12 | Batch_idx: 1630 |  Loss: (0.2373) | Acc: (91.69%) (44864/48930)\n",
      "Epoch: 12 | Batch_idx: 1640 |  Loss: (0.2374) | Acc: (91.68%) (45134/49230)\n",
      "Epoch: 12 | Batch_idx: 1650 |  Loss: (0.2375) | Acc: (91.68%) (45408/49530)\n",
      "Epoch: 12 | Batch_idx: 1660 |  Loss: (0.2378) | Acc: (91.67%) (45679/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4540) | Acc: (85.91%) (8591/10000)\n",
      "Epoch: 13 | Batch_idx: 0 |  Loss: (0.1255) | Acc: (96.67%) (29/30)\n",
      "Epoch: 13 | Batch_idx: 10 |  Loss: (0.1752) | Acc: (95.15%) (314/330)\n",
      "Epoch: 13 | Batch_idx: 20 |  Loss: (0.2031) | Acc: (93.17%) (587/630)\n",
      "Epoch: 13 | Batch_idx: 30 |  Loss: (0.1885) | Acc: (93.87%) (873/930)\n",
      "Epoch: 13 | Batch_idx: 40 |  Loss: (0.2049) | Acc: (93.01%) (1144/1230)\n",
      "Epoch: 13 | Batch_idx: 50 |  Loss: (0.2068) | Acc: (93.07%) (1424/1530)\n",
      "Epoch: 13 | Batch_idx: 60 |  Loss: (0.2102) | Acc: (92.84%) (1699/1830)\n",
      "Epoch: 13 | Batch_idx: 70 |  Loss: (0.2146) | Acc: (92.54%) (1971/2130)\n",
      "Epoch: 13 | Batch_idx: 80 |  Loss: (0.2184) | Acc: (92.47%) (2247/2430)\n",
      "Epoch: 13 | Batch_idx: 90 |  Loss: (0.2156) | Acc: (92.60%) (2528/2730)\n",
      "Epoch: 13 | Batch_idx: 100 |  Loss: (0.2173) | Acc: (92.48%) (2802/3030)\n",
      "Epoch: 13 | Batch_idx: 110 |  Loss: (0.2179) | Acc: (92.31%) (3074/3330)\n",
      "Epoch: 13 | Batch_idx: 120 |  Loss: (0.2180) | Acc: (92.37%) (3353/3630)\n",
      "Epoch: 13 | Batch_idx: 130 |  Loss: (0.2196) | Acc: (92.42%) (3632/3930)\n",
      "Epoch: 13 | Batch_idx: 140 |  Loss: (0.2243) | Acc: (92.34%) (3906/4230)\n",
      "Epoch: 13 | Batch_idx: 150 |  Loss: (0.2227) | Acc: (92.43%) (4187/4530)\n",
      "Epoch: 13 | Batch_idx: 160 |  Loss: (0.2234) | Acc: (92.42%) (4464/4830)\n",
      "Epoch: 13 | Batch_idx: 170 |  Loss: (0.2224) | Acc: (92.51%) (4746/5130)\n",
      "Epoch: 13 | Batch_idx: 180 |  Loss: (0.2205) | Acc: (92.54%) (5025/5430)\n",
      "Epoch: 13 | Batch_idx: 190 |  Loss: (0.2167) | Acc: (92.69%) (5311/5730)\n",
      "Epoch: 13 | Batch_idx: 200 |  Loss: (0.2137) | Acc: (92.75%) (5593/6030)\n",
      "Epoch: 13 | Batch_idx: 210 |  Loss: (0.2113) | Acc: (92.84%) (5877/6330)\n",
      "Epoch: 13 | Batch_idx: 220 |  Loss: (0.2107) | Acc: (92.85%) (6156/6630)\n",
      "Epoch: 13 | Batch_idx: 230 |  Loss: (0.2109) | Acc: (92.81%) (6432/6930)\n",
      "Epoch: 13 | Batch_idx: 240 |  Loss: (0.2109) | Acc: (92.82%) (6711/7230)\n",
      "Epoch: 13 | Batch_idx: 250 |  Loss: (0.2132) | Acc: (92.66%) (6977/7530)\n",
      "Epoch: 13 | Batch_idx: 260 |  Loss: (0.2135) | Acc: (92.67%) (7256/7830)\n",
      "Epoch: 13 | Batch_idx: 270 |  Loss: (0.2125) | Acc: (92.76%) (7541/8130)\n",
      "Epoch: 13 | Batch_idx: 280 |  Loss: (0.2159) | Acc: (92.63%) (7809/8430)\n",
      "Epoch: 13 | Batch_idx: 290 |  Loss: (0.2140) | Acc: (92.71%) (8094/8730)\n",
      "Epoch: 13 | Batch_idx: 300 |  Loss: (0.2125) | Acc: (92.76%) (8376/9030)\n",
      "Epoch: 13 | Batch_idx: 310 |  Loss: (0.2139) | Acc: (92.68%) (8647/9330)\n",
      "Epoch: 13 | Batch_idx: 320 |  Loss: (0.2147) | Acc: (92.66%) (8923/9630)\n",
      "Epoch: 13 | Batch_idx: 330 |  Loss: (0.2155) | Acc: (92.59%) (9194/9930)\n",
      "Epoch: 13 | Batch_idx: 340 |  Loss: (0.2144) | Acc: (92.64%) (9477/10230)\n",
      "Epoch: 13 | Batch_idx: 350 |  Loss: (0.2152) | Acc: (92.61%) (9752/10530)\n",
      "Epoch: 13 | Batch_idx: 360 |  Loss: (0.2156) | Acc: (92.59%) (10028/10830)\n",
      "Epoch: 13 | Batch_idx: 370 |  Loss: (0.2143) | Acc: (92.68%) (10315/11130)\n",
      "Epoch: 13 | Batch_idx: 380 |  Loss: (0.2148) | Acc: (92.68%) (10593/11430)\n",
      "Epoch: 13 | Batch_idx: 390 |  Loss: (0.2145) | Acc: (92.68%) (10871/11730)\n",
      "Epoch: 13 | Batch_idx: 400 |  Loss: (0.2145) | Acc: (92.70%) (11152/12030)\n",
      "Epoch: 13 | Batch_idx: 410 |  Loss: (0.2156) | Acc: (92.68%) (11428/12330)\n",
      "Epoch: 13 | Batch_idx: 420 |  Loss: (0.2146) | Acc: (92.70%) (11708/12630)\n",
      "Epoch: 13 | Batch_idx: 430 |  Loss: (0.2151) | Acc: (92.65%) (11980/12930)\n",
      "Epoch: 13 | Batch_idx: 440 |  Loss: (0.2156) | Acc: (92.65%) (12258/13230)\n",
      "Epoch: 13 | Batch_idx: 450 |  Loss: (0.2166) | Acc: (92.59%) (12527/13530)\n",
      "Epoch: 13 | Batch_idx: 460 |  Loss: (0.2172) | Acc: (92.55%) (12800/13830)\n",
      "Epoch: 13 | Batch_idx: 470 |  Loss: (0.2180) | Acc: (92.54%) (13076/14130)\n",
      "Epoch: 13 | Batch_idx: 480 |  Loss: (0.2181) | Acc: (92.48%) (13345/14430)\n",
      "Epoch: 13 | Batch_idx: 490 |  Loss: (0.2182) | Acc: (92.44%) (13616/14730)\n",
      "Epoch: 13 | Batch_idx: 500 |  Loss: (0.2189) | Acc: (92.40%) (13887/15030)\n",
      "Epoch: 13 | Batch_idx: 510 |  Loss: (0.2189) | Acc: (92.40%) (14165/15330)\n",
      "Epoch: 13 | Batch_idx: 520 |  Loss: (0.2180) | Acc: (92.43%) (14447/15630)\n",
      "Epoch: 13 | Batch_idx: 530 |  Loss: (0.2176) | Acc: (92.44%) (14725/15930)\n",
      "Epoch: 13 | Batch_idx: 540 |  Loss: (0.2171) | Acc: (92.46%) (15007/16230)\n",
      "Epoch: 13 | Batch_idx: 550 |  Loss: (0.2172) | Acc: (92.46%) (15283/16530)\n",
      "Epoch: 13 | Batch_idx: 560 |  Loss: (0.2168) | Acc: (92.48%) (15565/16830)\n",
      "Epoch: 13 | Batch_idx: 570 |  Loss: (0.2167) | Acc: (92.49%) (15843/17130)\n",
      "Epoch: 13 | Batch_idx: 580 |  Loss: (0.2173) | Acc: (92.46%) (16116/17430)\n",
      "Epoch: 13 | Batch_idx: 590 |  Loss: (0.2165) | Acc: (92.48%) (16396/17730)\n",
      "Epoch: 13 | Batch_idx: 600 |  Loss: (0.2161) | Acc: (92.45%) (16669/18030)\n",
      "Epoch: 13 | Batch_idx: 610 |  Loss: (0.2153) | Acc: (92.45%) (16947/18330)\n",
      "Epoch: 13 | Batch_idx: 620 |  Loss: (0.2151) | Acc: (92.47%) (17228/18630)\n",
      "Epoch: 13 | Batch_idx: 630 |  Loss: (0.2149) | Acc: (92.48%) (17507/18930)\n",
      "Epoch: 13 | Batch_idx: 640 |  Loss: (0.2148) | Acc: (92.49%) (17785/19230)\n",
      "Epoch: 13 | Batch_idx: 650 |  Loss: (0.2145) | Acc: (92.49%) (18064/19530)\n",
      "Epoch: 13 | Batch_idx: 660 |  Loss: (0.2138) | Acc: (92.51%) (18344/19830)\n",
      "Epoch: 13 | Batch_idx: 670 |  Loss: (0.2146) | Acc: (92.47%) (18615/20130)\n",
      "Epoch: 13 | Batch_idx: 680 |  Loss: (0.2142) | Acc: (92.48%) (18893/20430)\n",
      "Epoch: 13 | Batch_idx: 690 |  Loss: (0.2141) | Acc: (92.47%) (19170/20730)\n",
      "Epoch: 13 | Batch_idx: 700 |  Loss: (0.2138) | Acc: (92.48%) (19448/21030)\n",
      "Epoch: 13 | Batch_idx: 710 |  Loss: (0.2132) | Acc: (92.51%) (19732/21330)\n",
      "Epoch: 13 | Batch_idx: 720 |  Loss: (0.2129) | Acc: (92.52%) (20011/21630)\n",
      "Epoch: 13 | Batch_idx: 730 |  Loss: (0.2126) | Acc: (92.53%) (20291/21930)\n",
      "Epoch: 13 | Batch_idx: 740 |  Loss: (0.2127) | Acc: (92.52%) (20568/22230)\n",
      "Epoch: 13 | Batch_idx: 750 |  Loss: (0.2126) | Acc: (92.53%) (20847/22530)\n",
      "Epoch: 13 | Batch_idx: 760 |  Loss: (0.2124) | Acc: (92.55%) (21129/22830)\n",
      "Epoch: 13 | Batch_idx: 770 |  Loss: (0.2133) | Acc: (92.49%) (21394/23130)\n",
      "Epoch: 13 | Batch_idx: 780 |  Loss: (0.2140) | Acc: (92.46%) (21663/23430)\n",
      "Epoch: 13 | Batch_idx: 790 |  Loss: (0.2139) | Acc: (92.47%) (21943/23730)\n",
      "Epoch: 13 | Batch_idx: 800 |  Loss: (0.2140) | Acc: (92.46%) (22218/24030)\n",
      "Epoch: 13 | Batch_idx: 810 |  Loss: (0.2140) | Acc: (92.46%) (22496/24330)\n",
      "Epoch: 13 | Batch_idx: 820 |  Loss: (0.2138) | Acc: (92.47%) (22775/24630)\n",
      "Epoch: 13 | Batch_idx: 830 |  Loss: (0.2139) | Acc: (92.46%) (23050/24930)\n",
      "Epoch: 13 | Batch_idx: 840 |  Loss: (0.2143) | Acc: (92.44%) (23323/25230)\n",
      "Epoch: 13 | Batch_idx: 850 |  Loss: (0.2148) | Acc: (92.41%) (23593/25530)\n",
      "Epoch: 13 | Batch_idx: 860 |  Loss: (0.2148) | Acc: (92.42%) (23871/25830)\n",
      "Epoch: 13 | Batch_idx: 870 |  Loss: (0.2147) | Acc: (92.41%) (24147/26130)\n",
      "Epoch: 13 | Batch_idx: 880 |  Loss: (0.2142) | Acc: (92.44%) (24431/26430)\n",
      "Epoch: 13 | Batch_idx: 890 |  Loss: (0.2141) | Acc: (92.45%) (24711/26730)\n",
      "Epoch: 13 | Batch_idx: 900 |  Loss: (0.2141) | Acc: (92.45%) (24989/27030)\n",
      "Epoch: 13 | Batch_idx: 910 |  Loss: (0.2148) | Acc: (92.43%) (25260/27330)\n",
      "Epoch: 13 | Batch_idx: 920 |  Loss: (0.2154) | Acc: (92.40%) (25530/27630)\n",
      "Epoch: 13 | Batch_idx: 930 |  Loss: (0.2152) | Acc: (92.42%) (25812/27930)\n",
      "Epoch: 13 | Batch_idx: 940 |  Loss: (0.2153) | Acc: (92.41%) (26088/28230)\n",
      "Epoch: 13 | Batch_idx: 950 |  Loss: (0.2161) | Acc: (92.40%) (26361/28530)\n",
      "Epoch: 13 | Batch_idx: 960 |  Loss: (0.2161) | Acc: (92.41%) (26642/28830)\n",
      "Epoch: 13 | Batch_idx: 970 |  Loss: (0.2159) | Acc: (92.44%) (26927/29130)\n",
      "Epoch: 13 | Batch_idx: 980 |  Loss: (0.2165) | Acc: (92.42%) (27199/29430)\n",
      "Epoch: 13 | Batch_idx: 990 |  Loss: (0.2166) | Acc: (92.42%) (27477/29730)\n",
      "Epoch: 13 | Batch_idx: 1000 |  Loss: (0.2166) | Acc: (92.41%) (27751/30030)\n",
      "Epoch: 13 | Batch_idx: 1010 |  Loss: (0.2167) | Acc: (92.41%) (28027/30330)\n",
      "Epoch: 13 | Batch_idx: 1020 |  Loss: (0.2163) | Acc: (92.42%) (28307/30630)\n",
      "Epoch: 13 | Batch_idx: 1030 |  Loss: (0.2166) | Acc: (92.42%) (28584/30930)\n",
      "Epoch: 13 | Batch_idx: 1040 |  Loss: (0.2164) | Acc: (92.42%) (28863/31230)\n",
      "Epoch: 13 | Batch_idx: 1050 |  Loss: (0.2167) | Acc: (92.41%) (29137/31530)\n",
      "Epoch: 13 | Batch_idx: 1060 |  Loss: (0.2167) | Acc: (92.42%) (29416/31830)\n",
      "Epoch: 13 | Batch_idx: 1070 |  Loss: (0.2170) | Acc: (92.41%) (29690/32130)\n",
      "Epoch: 13 | Batch_idx: 1080 |  Loss: (0.2174) | Acc: (92.40%) (29966/32430)\n",
      "Epoch: 13 | Batch_idx: 1090 |  Loss: (0.2174) | Acc: (92.40%) (30243/32730)\n",
      "Epoch: 13 | Batch_idx: 1100 |  Loss: (0.2177) | Acc: (92.39%) (30515/33030)\n",
      "Epoch: 13 | Batch_idx: 1110 |  Loss: (0.2176) | Acc: (92.39%) (30792/33330)\n",
      "Epoch: 13 | Batch_idx: 1120 |  Loss: (0.2175) | Acc: (92.39%) (31072/33630)\n",
      "Epoch: 13 | Batch_idx: 1130 |  Loss: (0.2181) | Acc: (92.38%) (31343/33930)\n",
      "Epoch: 13 | Batch_idx: 1140 |  Loss: (0.2186) | Acc: (92.36%) (31614/34230)\n",
      "Epoch: 13 | Batch_idx: 1150 |  Loss: (0.2181) | Acc: (92.37%) (31895/34530)\n",
      "Epoch: 13 | Batch_idx: 1160 |  Loss: (0.2178) | Acc: (92.37%) (32172/34830)\n",
      "Epoch: 13 | Batch_idx: 1170 |  Loss: (0.2172) | Acc: (92.39%) (32458/35130)\n",
      "Epoch: 13 | Batch_idx: 1180 |  Loss: (0.2176) | Acc: (92.38%) (32729/35430)\n",
      "Epoch: 13 | Batch_idx: 1190 |  Loss: (0.2180) | Acc: (92.36%) (33000/35730)\n",
      "Epoch: 13 | Batch_idx: 1200 |  Loss: (0.2183) | Acc: (92.35%) (33272/36030)\n",
      "Epoch: 13 | Batch_idx: 1210 |  Loss: (0.2183) | Acc: (92.35%) (33549/36330)\n",
      "Epoch: 13 | Batch_idx: 1220 |  Loss: (0.2190) | Acc: (92.31%) (33814/36630)\n",
      "Epoch: 13 | Batch_idx: 1230 |  Loss: (0.2191) | Acc: (92.31%) (34091/36930)\n",
      "Epoch: 13 | Batch_idx: 1240 |  Loss: (0.2193) | Acc: (92.30%) (34364/37230)\n",
      "Epoch: 13 | Batch_idx: 1250 |  Loss: (0.2196) | Acc: (92.30%) (34640/37530)\n",
      "Epoch: 13 | Batch_idx: 1260 |  Loss: (0.2194) | Acc: (92.30%) (34917/37830)\n",
      "Epoch: 13 | Batch_idx: 1270 |  Loss: (0.2197) | Acc: (92.29%) (35189/38130)\n",
      "Epoch: 13 | Batch_idx: 1280 |  Loss: (0.2193) | Acc: (92.30%) (35471/38430)\n",
      "Epoch: 13 | Batch_idx: 1290 |  Loss: (0.2198) | Acc: (92.30%) (35748/38730)\n",
      "Epoch: 13 | Batch_idx: 1300 |  Loss: (0.2196) | Acc: (92.30%) (36025/39030)\n",
      "Epoch: 13 | Batch_idx: 1310 |  Loss: (0.2193) | Acc: (92.31%) (36305/39330)\n",
      "Epoch: 13 | Batch_idx: 1320 |  Loss: (0.2196) | Acc: (92.30%) (36577/39630)\n",
      "Epoch: 13 | Batch_idx: 1330 |  Loss: (0.2196) | Acc: (92.30%) (36856/39930)\n",
      "Epoch: 13 | Batch_idx: 1340 |  Loss: (0.2202) | Acc: (92.29%) (37130/40230)\n",
      "Epoch: 13 | Batch_idx: 1350 |  Loss: (0.2203) | Acc: (92.28%) (37403/40530)\n",
      "Epoch: 13 | Batch_idx: 1360 |  Loss: (0.2206) | Acc: (92.28%) (37679/40830)\n",
      "Epoch: 13 | Batch_idx: 1370 |  Loss: (0.2207) | Acc: (92.28%) (37956/41130)\n",
      "Epoch: 13 | Batch_idx: 1380 |  Loss: (0.2208) | Acc: (92.28%) (38233/41430)\n",
      "Epoch: 13 | Batch_idx: 1390 |  Loss: (0.2210) | Acc: (92.29%) (38511/41730)\n",
      "Epoch: 13 | Batch_idx: 1400 |  Loss: (0.2205) | Acc: (92.30%) (38795/42030)\n",
      "Epoch: 13 | Batch_idx: 1410 |  Loss: (0.2203) | Acc: (92.31%) (39075/42330)\n",
      "Epoch: 13 | Batch_idx: 1420 |  Loss: (0.2206) | Acc: (92.30%) (39346/42630)\n",
      "Epoch: 13 | Batch_idx: 1430 |  Loss: (0.2206) | Acc: (92.29%) (39620/42930)\n",
      "Epoch: 13 | Batch_idx: 1440 |  Loss: (0.2208) | Acc: (92.28%) (39892/43230)\n",
      "Epoch: 13 | Batch_idx: 1450 |  Loss: (0.2203) | Acc: (92.29%) (40175/43530)\n",
      "Epoch: 13 | Batch_idx: 1460 |  Loss: (0.2204) | Acc: (92.29%) (40451/43830)\n",
      "Epoch: 13 | Batch_idx: 1470 |  Loss: (0.2204) | Acc: (92.28%) (40725/44130)\n",
      "Epoch: 13 | Batch_idx: 1480 |  Loss: (0.2201) | Acc: (92.30%) (41011/44430)\n",
      "Epoch: 13 | Batch_idx: 1490 |  Loss: (0.2199) | Acc: (92.31%) (41291/44730)\n",
      "Epoch: 13 | Batch_idx: 1500 |  Loss: (0.2197) | Acc: (92.32%) (41572/45030)\n",
      "Epoch: 13 | Batch_idx: 1510 |  Loss: (0.2197) | Acc: (92.32%) (41850/45330)\n",
      "Epoch: 13 | Batch_idx: 1520 |  Loss: (0.2198) | Acc: (92.32%) (42126/45630)\n",
      "Epoch: 13 | Batch_idx: 1530 |  Loss: (0.2197) | Acc: (92.33%) (42408/45930)\n",
      "Epoch: 13 | Batch_idx: 1540 |  Loss: (0.2194) | Acc: (92.33%) (42686/46230)\n",
      "Epoch: 13 | Batch_idx: 1550 |  Loss: (0.2191) | Acc: (92.35%) (42970/46530)\n",
      "Epoch: 13 | Batch_idx: 1560 |  Loss: (0.2192) | Acc: (92.34%) (43242/46830)\n",
      "Epoch: 13 | Batch_idx: 1570 |  Loss: (0.2194) | Acc: (92.33%) (43514/47130)\n",
      "Epoch: 13 | Batch_idx: 1580 |  Loss: (0.2196) | Acc: (92.32%) (43789/47430)\n",
      "Epoch: 13 | Batch_idx: 1590 |  Loss: (0.2197) | Acc: (92.33%) (44067/47730)\n",
      "Epoch: 13 | Batch_idx: 1600 |  Loss: (0.2196) | Acc: (92.33%) (44348/48030)\n",
      "Epoch: 13 | Batch_idx: 1610 |  Loss: (0.2193) | Acc: (92.34%) (44629/48330)\n",
      "Epoch: 13 | Batch_idx: 1620 |  Loss: (0.2195) | Acc: (92.34%) (44907/48630)\n",
      "Epoch: 13 | Batch_idx: 1630 |  Loss: (0.2194) | Acc: (92.35%) (45186/48930)\n",
      "Epoch: 13 | Batch_idx: 1640 |  Loss: (0.2192) | Acc: (92.36%) (45469/49230)\n",
      "Epoch: 13 | Batch_idx: 1650 |  Loss: (0.2194) | Acc: (92.36%) (45747/49530)\n",
      "Epoch: 13 | Batch_idx: 1660 |  Loss: (0.2196) | Acc: (92.36%) (46023/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3965) | Acc: (87.66%) (8766/10000)\n",
      "Epoch: 14 | Batch_idx: 0 |  Loss: (0.2521) | Acc: (90.00%) (27/30)\n",
      "Epoch: 14 | Batch_idx: 10 |  Loss: (0.1796) | Acc: (92.42%) (305/330)\n",
      "Epoch: 14 | Batch_idx: 20 |  Loss: (0.2114) | Acc: (92.06%) (580/630)\n",
      "Epoch: 14 | Batch_idx: 30 |  Loss: (0.1825) | Acc: (93.55%) (870/930)\n",
      "Epoch: 14 | Batch_idx: 40 |  Loss: (0.2049) | Acc: (93.25%) (1147/1230)\n",
      "Epoch: 14 | Batch_idx: 50 |  Loss: (0.1964) | Acc: (93.53%) (1431/1530)\n",
      "Epoch: 14 | Batch_idx: 60 |  Loss: (0.1926) | Acc: (93.66%) (1714/1830)\n",
      "Epoch: 14 | Batch_idx: 70 |  Loss: (0.1877) | Acc: (93.90%) (2000/2130)\n",
      "Epoch: 14 | Batch_idx: 80 |  Loss: (0.1852) | Acc: (93.83%) (2280/2430)\n",
      "Epoch: 14 | Batch_idx: 90 |  Loss: (0.1800) | Acc: (93.96%) (2565/2730)\n",
      "Epoch: 14 | Batch_idx: 100 |  Loss: (0.1823) | Acc: (93.89%) (2845/3030)\n",
      "Epoch: 14 | Batch_idx: 110 |  Loss: (0.1823) | Acc: (93.90%) (3127/3330)\n",
      "Epoch: 14 | Batch_idx: 120 |  Loss: (0.1793) | Acc: (94.05%) (3414/3630)\n",
      "Epoch: 14 | Batch_idx: 130 |  Loss: (0.1785) | Acc: (94.05%) (3696/3930)\n",
      "Epoch: 14 | Batch_idx: 140 |  Loss: (0.1827) | Acc: (93.81%) (3968/4230)\n",
      "Epoch: 14 | Batch_idx: 150 |  Loss: (0.1837) | Acc: (93.69%) (4244/4530)\n",
      "Epoch: 14 | Batch_idx: 160 |  Loss: (0.1810) | Acc: (93.85%) (4533/4830)\n",
      "Epoch: 14 | Batch_idx: 170 |  Loss: (0.1782) | Acc: (93.96%) (4820/5130)\n",
      "Epoch: 14 | Batch_idx: 180 |  Loss: (0.1799) | Acc: (93.90%) (5099/5430)\n",
      "Epoch: 14 | Batch_idx: 190 |  Loss: (0.1795) | Acc: (93.84%) (5377/5730)\n",
      "Epoch: 14 | Batch_idx: 200 |  Loss: (0.1845) | Acc: (93.71%) (5651/6030)\n",
      "Epoch: 14 | Batch_idx: 210 |  Loss: (0.1868) | Acc: (93.63%) (5927/6330)\n",
      "Epoch: 14 | Batch_idx: 220 |  Loss: (0.1869) | Acc: (93.63%) (6208/6630)\n",
      "Epoch: 14 | Batch_idx: 230 |  Loss: (0.1836) | Acc: (93.74%) (6496/6930)\n",
      "Epoch: 14 | Batch_idx: 240 |  Loss: (0.1840) | Acc: (93.71%) (6775/7230)\n",
      "Epoch: 14 | Batch_idx: 250 |  Loss: (0.1822) | Acc: (93.73%) (7058/7530)\n",
      "Epoch: 14 | Batch_idx: 260 |  Loss: (0.1824) | Acc: (93.73%) (7339/7830)\n",
      "Epoch: 14 | Batch_idx: 270 |  Loss: (0.1821) | Acc: (93.67%) (7615/8130)\n",
      "Epoch: 14 | Batch_idx: 280 |  Loss: (0.1818) | Acc: (93.72%) (7901/8430)\n",
      "Epoch: 14 | Batch_idx: 290 |  Loss: (0.1812) | Acc: (93.78%) (8187/8730)\n",
      "Epoch: 14 | Batch_idx: 300 |  Loss: (0.1821) | Acc: (93.79%) (8469/9030)\n",
      "Epoch: 14 | Batch_idx: 310 |  Loss: (0.1821) | Acc: (93.78%) (8750/9330)\n",
      "Epoch: 14 | Batch_idx: 320 |  Loss: (0.1813) | Acc: (93.82%) (9035/9630)\n",
      "Epoch: 14 | Batch_idx: 330 |  Loss: (0.1816) | Acc: (93.82%) (9316/9930)\n",
      "Epoch: 14 | Batch_idx: 340 |  Loss: (0.1826) | Acc: (93.77%) (9593/10230)\n",
      "Epoch: 14 | Batch_idx: 350 |  Loss: (0.1837) | Acc: (93.71%) (9868/10530)\n",
      "Epoch: 14 | Batch_idx: 360 |  Loss: (0.1839) | Acc: (93.69%) (10147/10830)\n",
      "Epoch: 14 | Batch_idx: 370 |  Loss: (0.1819) | Acc: (93.77%) (10437/11130)\n",
      "Epoch: 14 | Batch_idx: 380 |  Loss: (0.1831) | Acc: (93.73%) (10713/11430)\n",
      "Epoch: 14 | Batch_idx: 390 |  Loss: (0.1840) | Acc: (93.68%) (10989/11730)\n",
      "Epoch: 14 | Batch_idx: 400 |  Loss: (0.1844) | Acc: (93.71%) (11273/12030)\n",
      "Epoch: 14 | Batch_idx: 410 |  Loss: (0.1842) | Acc: (93.70%) (11553/12330)\n",
      "Epoch: 14 | Batch_idx: 420 |  Loss: (0.1852) | Acc: (93.66%) (11829/12630)\n",
      "Epoch: 14 | Batch_idx: 430 |  Loss: (0.1852) | Acc: (93.65%) (12109/12930)\n",
      "Epoch: 14 | Batch_idx: 440 |  Loss: (0.1866) | Acc: (93.58%) (12381/13230)\n",
      "Epoch: 14 | Batch_idx: 450 |  Loss: (0.1869) | Acc: (93.57%) (12660/13530)\n",
      "Epoch: 14 | Batch_idx: 460 |  Loss: (0.1863) | Acc: (93.58%) (12942/13830)\n",
      "Epoch: 14 | Batch_idx: 470 |  Loss: (0.1861) | Acc: (93.58%) (13223/14130)\n",
      "Epoch: 14 | Batch_idx: 480 |  Loss: (0.1865) | Acc: (93.58%) (13504/14430)\n",
      "Epoch: 14 | Batch_idx: 490 |  Loss: (0.1872) | Acc: (93.57%) (13783/14730)\n",
      "Epoch: 14 | Batch_idx: 500 |  Loss: (0.1885) | Acc: (93.53%) (14057/15030)\n",
      "Epoch: 14 | Batch_idx: 510 |  Loss: (0.1894) | Acc: (93.52%) (14336/15330)\n",
      "Epoch: 14 | Batch_idx: 520 |  Loss: (0.1896) | Acc: (93.51%) (14616/15630)\n",
      "Epoch: 14 | Batch_idx: 530 |  Loss: (0.1893) | Acc: (93.52%) (14897/15930)\n",
      "Epoch: 14 | Batch_idx: 540 |  Loss: (0.1894) | Acc: (93.48%) (15172/16230)\n",
      "Epoch: 14 | Batch_idx: 550 |  Loss: (0.1890) | Acc: (93.49%) (15454/16530)\n",
      "Epoch: 14 | Batch_idx: 560 |  Loss: (0.1886) | Acc: (93.52%) (15739/16830)\n",
      "Epoch: 14 | Batch_idx: 570 |  Loss: (0.1882) | Acc: (93.54%) (16023/17130)\n",
      "Epoch: 14 | Batch_idx: 580 |  Loss: (0.1867) | Acc: (93.60%) (16314/17430)\n",
      "Epoch: 14 | Batch_idx: 590 |  Loss: (0.1864) | Acc: (93.63%) (16600/17730)\n",
      "Epoch: 14 | Batch_idx: 600 |  Loss: (0.1856) | Acc: (93.66%) (16886/18030)\n",
      "Epoch: 14 | Batch_idx: 610 |  Loss: (0.1857) | Acc: (93.66%) (17168/18330)\n",
      "Epoch: 14 | Batch_idx: 620 |  Loss: (0.1873) | Acc: (93.63%) (17444/18630)\n",
      "Epoch: 14 | Batch_idx: 630 |  Loss: (0.1871) | Acc: (93.64%) (17726/18930)\n",
      "Epoch: 14 | Batch_idx: 640 |  Loss: (0.1879) | Acc: (93.61%) (18002/19230)\n",
      "Epoch: 14 | Batch_idx: 650 |  Loss: (0.1881) | Acc: (93.61%) (18283/19530)\n",
      "Epoch: 14 | Batch_idx: 660 |  Loss: (0.1889) | Acc: (93.58%) (18557/19830)\n",
      "Epoch: 14 | Batch_idx: 670 |  Loss: (0.1886) | Acc: (93.58%) (18838/20130)\n",
      "Epoch: 14 | Batch_idx: 680 |  Loss: (0.1894) | Acc: (93.56%) (19114/20430)\n",
      "Epoch: 14 | Batch_idx: 690 |  Loss: (0.1890) | Acc: (93.56%) (19395/20730)\n",
      "Epoch: 14 | Batch_idx: 700 |  Loss: (0.1892) | Acc: (93.56%) (19676/21030)\n",
      "Epoch: 14 | Batch_idx: 710 |  Loss: (0.1901) | Acc: (93.54%) (19953/21330)\n",
      "Epoch: 14 | Batch_idx: 720 |  Loss: (0.1913) | Acc: (93.50%) (20225/21630)\n",
      "Epoch: 14 | Batch_idx: 730 |  Loss: (0.1919) | Acc: (93.47%) (20498/21930)\n",
      "Epoch: 14 | Batch_idx: 740 |  Loss: (0.1927) | Acc: (93.43%) (20770/22230)\n",
      "Epoch: 14 | Batch_idx: 750 |  Loss: (0.1937) | Acc: (93.39%) (21041/22530)\n",
      "Epoch: 14 | Batch_idx: 760 |  Loss: (0.1938) | Acc: (93.38%) (21319/22830)\n",
      "Epoch: 14 | Batch_idx: 770 |  Loss: (0.1935) | Acc: (93.40%) (21604/23130)\n",
      "Epoch: 14 | Batch_idx: 780 |  Loss: (0.1938) | Acc: (93.40%) (21883/23430)\n",
      "Epoch: 14 | Batch_idx: 790 |  Loss: (0.1942) | Acc: (93.39%) (22162/23730)\n",
      "Epoch: 14 | Batch_idx: 800 |  Loss: (0.1946) | Acc: (93.36%) (22434/24030)\n",
      "Epoch: 14 | Batch_idx: 810 |  Loss: (0.1948) | Acc: (93.36%) (22714/24330)\n",
      "Epoch: 14 | Batch_idx: 820 |  Loss: (0.1950) | Acc: (93.35%) (22991/24630)\n",
      "Epoch: 14 | Batch_idx: 830 |  Loss: (0.1954) | Acc: (93.34%) (23270/24930)\n",
      "Epoch: 14 | Batch_idx: 840 |  Loss: (0.1955) | Acc: (93.34%) (23550/25230)\n",
      "Epoch: 14 | Batch_idx: 850 |  Loss: (0.1953) | Acc: (93.33%) (23828/25530)\n",
      "Epoch: 14 | Batch_idx: 860 |  Loss: (0.1945) | Acc: (93.38%) (24119/25830)\n",
      "Epoch: 14 | Batch_idx: 870 |  Loss: (0.1947) | Acc: (93.37%) (24398/26130)\n",
      "Epoch: 14 | Batch_idx: 880 |  Loss: (0.1941) | Acc: (93.37%) (24678/26430)\n",
      "Epoch: 14 | Batch_idx: 890 |  Loss: (0.1942) | Acc: (93.36%) (24954/26730)\n",
      "Epoch: 14 | Batch_idx: 900 |  Loss: (0.1942) | Acc: (93.34%) (25231/27030)\n",
      "Epoch: 14 | Batch_idx: 910 |  Loss: (0.1944) | Acc: (93.35%) (25513/27330)\n",
      "Epoch: 14 | Batch_idx: 920 |  Loss: (0.1944) | Acc: (93.33%) (25788/27630)\n",
      "Epoch: 14 | Batch_idx: 930 |  Loss: (0.1945) | Acc: (93.32%) (26065/27930)\n",
      "Epoch: 14 | Batch_idx: 940 |  Loss: (0.1939) | Acc: (93.35%) (26353/28230)\n",
      "Epoch: 14 | Batch_idx: 950 |  Loss: (0.1933) | Acc: (93.37%) (26638/28530)\n",
      "Epoch: 14 | Batch_idx: 960 |  Loss: (0.1937) | Acc: (93.35%) (26913/28830)\n",
      "Epoch: 14 | Batch_idx: 970 |  Loss: (0.1941) | Acc: (93.32%) (27184/29130)\n",
      "Epoch: 14 | Batch_idx: 980 |  Loss: (0.1948) | Acc: (93.31%) (27461/29430)\n",
      "Epoch: 14 | Batch_idx: 990 |  Loss: (0.1949) | Acc: (93.30%) (27739/29730)\n",
      "Epoch: 14 | Batch_idx: 1000 |  Loss: (0.1945) | Acc: (93.32%) (28024/30030)\n",
      "Epoch: 14 | Batch_idx: 1010 |  Loss: (0.1944) | Acc: (93.32%) (28303/30330)\n",
      "Epoch: 14 | Batch_idx: 1020 |  Loss: (0.1946) | Acc: (93.31%) (28581/30630)\n",
      "Epoch: 14 | Batch_idx: 1030 |  Loss: (0.1949) | Acc: (93.31%) (28860/30930)\n",
      "Epoch: 14 | Batch_idx: 1040 |  Loss: (0.1953) | Acc: (93.29%) (29134/31230)\n",
      "Epoch: 14 | Batch_idx: 1050 |  Loss: (0.1947) | Acc: (93.30%) (29416/31530)\n",
      "Epoch: 14 | Batch_idx: 1060 |  Loss: (0.1947) | Acc: (93.29%) (29695/31830)\n",
      "Epoch: 14 | Batch_idx: 1070 |  Loss: (0.1942) | Acc: (93.30%) (29978/32130)\n",
      "Epoch: 14 | Batch_idx: 1080 |  Loss: (0.1948) | Acc: (93.30%) (30256/32430)\n",
      "Epoch: 14 | Batch_idx: 1090 |  Loss: (0.1946) | Acc: (93.29%) (30535/32730)\n",
      "Epoch: 14 | Batch_idx: 1100 |  Loss: (0.1955) | Acc: (93.27%) (30807/33030)\n",
      "Epoch: 14 | Batch_idx: 1110 |  Loss: (0.1953) | Acc: (93.29%) (31092/33330)\n",
      "Epoch: 14 | Batch_idx: 1120 |  Loss: (0.1958) | Acc: (93.25%) (31359/33630)\n",
      "Epoch: 14 | Batch_idx: 1130 |  Loss: (0.1959) | Acc: (93.25%) (31640/33930)\n",
      "Epoch: 14 | Batch_idx: 1140 |  Loss: (0.1961) | Acc: (93.26%) (31922/34230)\n",
      "Epoch: 14 | Batch_idx: 1150 |  Loss: (0.1962) | Acc: (93.24%) (32196/34530)\n",
      "Epoch: 14 | Batch_idx: 1160 |  Loss: (0.1971) | Acc: (93.21%) (32464/34830)\n",
      "Epoch: 14 | Batch_idx: 1170 |  Loss: (0.1975) | Acc: (93.18%) (32735/35130)\n",
      "Epoch: 14 | Batch_idx: 1180 |  Loss: (0.1975) | Acc: (93.18%) (33015/35430)\n",
      "Epoch: 14 | Batch_idx: 1190 |  Loss: (0.1979) | Acc: (93.15%) (33281/35730)\n",
      "Epoch: 14 | Batch_idx: 1200 |  Loss: (0.1978) | Acc: (93.14%) (33560/36030)\n",
      "Epoch: 14 | Batch_idx: 1210 |  Loss: (0.1981) | Acc: (93.15%) (33842/36330)\n",
      "Epoch: 14 | Batch_idx: 1220 |  Loss: (0.1984) | Acc: (93.15%) (34120/36630)\n",
      "Epoch: 14 | Batch_idx: 1230 |  Loss: (0.1982) | Acc: (93.15%) (34399/36930)\n",
      "Epoch: 14 | Batch_idx: 1240 |  Loss: (0.1981) | Acc: (93.15%) (34680/37230)\n",
      "Epoch: 14 | Batch_idx: 1250 |  Loss: (0.1984) | Acc: (93.13%) (34951/37530)\n",
      "Epoch: 14 | Batch_idx: 1260 |  Loss: (0.1986) | Acc: (93.13%) (35230/37830)\n",
      "Epoch: 14 | Batch_idx: 1270 |  Loss: (0.1989) | Acc: (93.11%) (35504/38130)\n",
      "Epoch: 14 | Batch_idx: 1280 |  Loss: (0.1988) | Acc: (93.11%) (35783/38430)\n",
      "Epoch: 14 | Batch_idx: 1290 |  Loss: (0.1986) | Acc: (93.12%) (36065/38730)\n",
      "Epoch: 14 | Batch_idx: 1300 |  Loss: (0.1988) | Acc: (93.12%) (36343/39030)\n",
      "Epoch: 14 | Batch_idx: 1310 |  Loss: (0.1987) | Acc: (93.12%) (36625/39330)\n",
      "Epoch: 14 | Batch_idx: 1320 |  Loss: (0.1989) | Acc: (93.12%) (36902/39630)\n",
      "Epoch: 14 | Batch_idx: 1330 |  Loss: (0.1986) | Acc: (93.12%) (37183/39930)\n",
      "Epoch: 14 | Batch_idx: 1340 |  Loss: (0.1983) | Acc: (93.13%) (37466/40230)\n",
      "Epoch: 14 | Batch_idx: 1350 |  Loss: (0.1983) | Acc: (93.12%) (37740/40530)\n",
      "Epoch: 14 | Batch_idx: 1360 |  Loss: (0.1985) | Acc: (93.12%) (38019/40830)\n",
      "Epoch: 14 | Batch_idx: 1370 |  Loss: (0.1987) | Acc: (93.11%) (38297/41130)\n",
      "Epoch: 14 | Batch_idx: 1380 |  Loss: (0.1987) | Acc: (93.11%) (38577/41430)\n",
      "Epoch: 14 | Batch_idx: 1390 |  Loss: (0.1989) | Acc: (93.11%) (38854/41730)\n",
      "Epoch: 14 | Batch_idx: 1400 |  Loss: (0.1994) | Acc: (93.08%) (39120/42030)\n",
      "Epoch: 14 | Batch_idx: 1410 |  Loss: (0.1993) | Acc: (93.08%) (39402/42330)\n",
      "Epoch: 14 | Batch_idx: 1420 |  Loss: (0.1995) | Acc: (93.07%) (39676/42630)\n",
      "Epoch: 14 | Batch_idx: 1430 |  Loss: (0.1998) | Acc: (93.04%) (39942/42930)\n",
      "Epoch: 14 | Batch_idx: 1440 |  Loss: (0.1997) | Acc: (93.05%) (40226/43230)\n",
      "Epoch: 14 | Batch_idx: 1450 |  Loss: (0.1999) | Acc: (93.04%) (40502/43530)\n",
      "Epoch: 14 | Batch_idx: 1460 |  Loss: (0.1998) | Acc: (93.05%) (40782/43830)\n",
      "Epoch: 14 | Batch_idx: 1470 |  Loss: (0.1999) | Acc: (93.04%) (41058/44130)\n",
      "Epoch: 14 | Batch_idx: 1480 |  Loss: (0.2002) | Acc: (93.03%) (41332/44430)\n",
      "Epoch: 14 | Batch_idx: 1490 |  Loss: (0.2000) | Acc: (93.03%) (41612/44730)\n",
      "Epoch: 14 | Batch_idx: 1500 |  Loss: (0.2002) | Acc: (93.03%) (41890/45030)\n",
      "Epoch: 14 | Batch_idx: 1510 |  Loss: (0.1999) | Acc: (93.03%) (42171/45330)\n",
      "Epoch: 14 | Batch_idx: 1520 |  Loss: (0.1999) | Acc: (93.02%) (42446/45630)\n",
      "Epoch: 14 | Batch_idx: 1530 |  Loss: (0.2000) | Acc: (93.02%) (42723/45930)\n",
      "Epoch: 14 | Batch_idx: 1540 |  Loss: (0.2000) | Acc: (93.02%) (43002/46230)\n",
      "Epoch: 14 | Batch_idx: 1550 |  Loss: (0.2000) | Acc: (93.02%) (43281/46530)\n",
      "Epoch: 14 | Batch_idx: 1560 |  Loss: (0.1998) | Acc: (93.02%) (43562/46830)\n",
      "Epoch: 14 | Batch_idx: 1570 |  Loss: (0.2001) | Acc: (93.01%) (43834/47130)\n",
      "Epoch: 14 | Batch_idx: 1580 |  Loss: (0.2004) | Acc: (93.00%) (44110/47430)\n",
      "Epoch: 14 | Batch_idx: 1590 |  Loss: (0.2003) | Acc: (93.01%) (44396/47730)\n",
      "Epoch: 14 | Batch_idx: 1600 |  Loss: (0.2002) | Acc: (93.01%) (44671/48030)\n",
      "Epoch: 14 | Batch_idx: 1610 |  Loss: (0.2005) | Acc: (93.00%) (44946/48330)\n",
      "Epoch: 14 | Batch_idx: 1620 |  Loss: (0.2003) | Acc: (93.00%) (45227/48630)\n",
      "Epoch: 14 | Batch_idx: 1630 |  Loss: (0.2006) | Acc: (92.99%) (45502/48930)\n",
      "Epoch: 14 | Batch_idx: 1640 |  Loss: (0.2005) | Acc: (92.99%) (45779/49230)\n",
      "Epoch: 14 | Batch_idx: 1650 |  Loss: (0.2002) | Acc: (93.00%) (46065/49530)\n",
      "Epoch: 14 | Batch_idx: 1660 |  Loss: (0.2003) | Acc: (93.00%) (46340/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3663) | Acc: (88.72%) (8872/10000)\n",
      "Epoch: 15 | Batch_idx: 0 |  Loss: (0.3410) | Acc: (90.00%) (27/30)\n",
      "Epoch: 15 | Batch_idx: 10 |  Loss: (0.1667) | Acc: (94.85%) (313/330)\n",
      "Epoch: 15 | Batch_idx: 20 |  Loss: (0.1971) | Acc: (93.02%) (586/630)\n",
      "Epoch: 15 | Batch_idx: 30 |  Loss: (0.1820) | Acc: (93.66%) (871/930)\n",
      "Epoch: 15 | Batch_idx: 40 |  Loss: (0.1706) | Acc: (93.90%) (1155/1230)\n",
      "Epoch: 15 | Batch_idx: 50 |  Loss: (0.1662) | Acc: (94.31%) (1443/1530)\n",
      "Epoch: 15 | Batch_idx: 60 |  Loss: (0.1764) | Acc: (93.99%) (1720/1830)\n",
      "Epoch: 15 | Batch_idx: 70 |  Loss: (0.1726) | Acc: (94.13%) (2005/2130)\n",
      "Epoch: 15 | Batch_idx: 80 |  Loss: (0.1731) | Acc: (94.16%) (2288/2430)\n",
      "Epoch: 15 | Batch_idx: 90 |  Loss: (0.1743) | Acc: (94.21%) (2572/2730)\n",
      "Epoch: 15 | Batch_idx: 100 |  Loss: (0.1708) | Acc: (94.39%) (2860/3030)\n",
      "Epoch: 15 | Batch_idx: 110 |  Loss: (0.1694) | Acc: (94.44%) (3145/3330)\n",
      "Epoch: 15 | Batch_idx: 120 |  Loss: (0.1735) | Acc: (94.21%) (3420/3630)\n",
      "Epoch: 15 | Batch_idx: 130 |  Loss: (0.1768) | Acc: (94.20%) (3702/3930)\n",
      "Epoch: 15 | Batch_idx: 140 |  Loss: (0.1813) | Acc: (94.02%) (3977/4230)\n",
      "Epoch: 15 | Batch_idx: 150 |  Loss: (0.1788) | Acc: (94.06%) (4261/4530)\n",
      "Epoch: 15 | Batch_idx: 160 |  Loss: (0.1853) | Acc: (93.83%) (4532/4830)\n",
      "Epoch: 15 | Batch_idx: 170 |  Loss: (0.1831) | Acc: (93.86%) (4815/5130)\n",
      "Epoch: 15 | Batch_idx: 180 |  Loss: (0.1806) | Acc: (93.98%) (5103/5430)\n",
      "Epoch: 15 | Batch_idx: 190 |  Loss: (0.1816) | Acc: (93.84%) (5377/5730)\n",
      "Epoch: 15 | Batch_idx: 200 |  Loss: (0.1800) | Acc: (93.91%) (5663/6030)\n",
      "Epoch: 15 | Batch_idx: 210 |  Loss: (0.1827) | Acc: (93.85%) (5941/6330)\n",
      "Epoch: 15 | Batch_idx: 220 |  Loss: (0.1841) | Acc: (93.82%) (6220/6630)\n",
      "Epoch: 15 | Batch_idx: 230 |  Loss: (0.1863) | Acc: (93.77%) (6498/6930)\n",
      "Epoch: 15 | Batch_idx: 240 |  Loss: (0.1843) | Acc: (93.87%) (6787/7230)\n",
      "Epoch: 15 | Batch_idx: 250 |  Loss: (0.1829) | Acc: (93.93%) (7073/7530)\n",
      "Epoch: 15 | Batch_idx: 260 |  Loss: (0.1823) | Acc: (93.92%) (7354/7830)\n",
      "Epoch: 15 | Batch_idx: 270 |  Loss: (0.1809) | Acc: (93.92%) (7636/8130)\n",
      "Epoch: 15 | Batch_idx: 280 |  Loss: (0.1806) | Acc: (93.91%) (7917/8430)\n",
      "Epoch: 15 | Batch_idx: 290 |  Loss: (0.1808) | Acc: (93.89%) (8197/8730)\n",
      "Epoch: 15 | Batch_idx: 300 |  Loss: (0.1802) | Acc: (93.90%) (8479/9030)\n",
      "Epoch: 15 | Batch_idx: 310 |  Loss: (0.1784) | Acc: (93.97%) (8767/9330)\n",
      "Epoch: 15 | Batch_idx: 320 |  Loss: (0.1775) | Acc: (93.97%) (9049/9630)\n",
      "Epoch: 15 | Batch_idx: 330 |  Loss: (0.1790) | Acc: (93.93%) (9327/9930)\n",
      "Epoch: 15 | Batch_idx: 340 |  Loss: (0.1788) | Acc: (93.93%) (9609/10230)\n",
      "Epoch: 15 | Batch_idx: 350 |  Loss: (0.1785) | Acc: (93.93%) (9891/10530)\n",
      "Epoch: 15 | Batch_idx: 360 |  Loss: (0.1784) | Acc: (93.92%) (10171/10830)\n",
      "Epoch: 15 | Batch_idx: 370 |  Loss: (0.1789) | Acc: (93.88%) (10449/11130)\n",
      "Epoch: 15 | Batch_idx: 380 |  Loss: (0.1780) | Acc: (93.91%) (10734/11430)\n",
      "Epoch: 15 | Batch_idx: 390 |  Loss: (0.1778) | Acc: (93.93%) (11018/11730)\n",
      "Epoch: 15 | Batch_idx: 400 |  Loss: (0.1794) | Acc: (93.91%) (11297/12030)\n",
      "Epoch: 15 | Batch_idx: 410 |  Loss: (0.1794) | Acc: (93.91%) (11579/12330)\n",
      "Epoch: 15 | Batch_idx: 420 |  Loss: (0.1808) | Acc: (93.86%) (11855/12630)\n",
      "Epoch: 15 | Batch_idx: 430 |  Loss: (0.1811) | Acc: (93.84%) (12134/12930)\n",
      "Epoch: 15 | Batch_idx: 440 |  Loss: (0.1818) | Acc: (93.80%) (12410/13230)\n",
      "Epoch: 15 | Batch_idx: 450 |  Loss: (0.1823) | Acc: (93.76%) (12686/13530)\n",
      "Epoch: 15 | Batch_idx: 460 |  Loss: (0.1826) | Acc: (93.77%) (12968/13830)\n",
      "Epoch: 15 | Batch_idx: 470 |  Loss: (0.1824) | Acc: (93.75%) (13247/14130)\n",
      "Epoch: 15 | Batch_idx: 480 |  Loss: (0.1820) | Acc: (93.75%) (13528/14430)\n",
      "Epoch: 15 | Batch_idx: 490 |  Loss: (0.1824) | Acc: (93.73%) (13807/14730)\n",
      "Epoch: 15 | Batch_idx: 500 |  Loss: (0.1808) | Acc: (93.78%) (14095/15030)\n",
      "Epoch: 15 | Batch_idx: 510 |  Loss: (0.1794) | Acc: (93.84%) (14386/15330)\n",
      "Epoch: 15 | Batch_idx: 520 |  Loss: (0.1787) | Acc: (93.87%) (14672/15630)\n",
      "Epoch: 15 | Batch_idx: 530 |  Loss: (0.1788) | Acc: (93.86%) (14952/15930)\n",
      "Epoch: 15 | Batch_idx: 540 |  Loss: (0.1785) | Acc: (93.88%) (15236/16230)\n",
      "Epoch: 15 | Batch_idx: 550 |  Loss: (0.1783) | Acc: (93.90%) (15521/16530)\n",
      "Epoch: 15 | Batch_idx: 560 |  Loss: (0.1793) | Acc: (93.88%) (15800/16830)\n",
      "Epoch: 15 | Batch_idx: 570 |  Loss: (0.1799) | Acc: (93.86%) (16079/17130)\n",
      "Epoch: 15 | Batch_idx: 580 |  Loss: (0.1793) | Acc: (93.90%) (16367/17430)\n",
      "Epoch: 15 | Batch_idx: 590 |  Loss: (0.1800) | Acc: (93.88%) (16645/17730)\n",
      "Epoch: 15 | Batch_idx: 600 |  Loss: (0.1801) | Acc: (93.88%) (16927/18030)\n",
      "Epoch: 15 | Batch_idx: 610 |  Loss: (0.1810) | Acc: (93.84%) (17200/18330)\n",
      "Epoch: 15 | Batch_idx: 620 |  Loss: (0.1812) | Acc: (93.83%) (17480/18630)\n",
      "Epoch: 15 | Batch_idx: 630 |  Loss: (0.1819) | Acc: (93.81%) (17759/18930)\n",
      "Epoch: 15 | Batch_idx: 640 |  Loss: (0.1816) | Acc: (93.81%) (18040/19230)\n",
      "Epoch: 15 | Batch_idx: 650 |  Loss: (0.1814) | Acc: (93.82%) (18324/19530)\n",
      "Epoch: 15 | Batch_idx: 660 |  Loss: (0.1810) | Acc: (93.84%) (18609/19830)\n",
      "Epoch: 15 | Batch_idx: 670 |  Loss: (0.1819) | Acc: (93.81%) (18883/20130)\n",
      "Epoch: 15 | Batch_idx: 680 |  Loss: (0.1817) | Acc: (93.81%) (19165/20430)\n",
      "Epoch: 15 | Batch_idx: 690 |  Loss: (0.1817) | Acc: (93.82%) (19449/20730)\n",
      "Epoch: 15 | Batch_idx: 700 |  Loss: (0.1814) | Acc: (93.83%) (19733/21030)\n",
      "Epoch: 15 | Batch_idx: 710 |  Loss: (0.1815) | Acc: (93.83%) (20013/21330)\n",
      "Epoch: 15 | Batch_idx: 720 |  Loss: (0.1818) | Acc: (93.81%) (20291/21630)\n",
      "Epoch: 15 | Batch_idx: 730 |  Loss: (0.1818) | Acc: (93.78%) (20565/21930)\n",
      "Epoch: 15 | Batch_idx: 740 |  Loss: (0.1820) | Acc: (93.77%) (20846/22230)\n",
      "Epoch: 15 | Batch_idx: 750 |  Loss: (0.1817) | Acc: (93.78%) (21129/22530)\n",
      "Epoch: 15 | Batch_idx: 760 |  Loss: (0.1815) | Acc: (93.78%) (21411/22830)\n",
      "Epoch: 15 | Batch_idx: 770 |  Loss: (0.1811) | Acc: (93.79%) (21694/23130)\n",
      "Epoch: 15 | Batch_idx: 780 |  Loss: (0.1809) | Acc: (93.79%) (21974/23430)\n",
      "Epoch: 15 | Batch_idx: 790 |  Loss: (0.1810) | Acc: (93.78%) (22254/23730)\n",
      "Epoch: 15 | Batch_idx: 800 |  Loss: (0.1808) | Acc: (93.79%) (22538/24030)\n",
      "Epoch: 15 | Batch_idx: 810 |  Loss: (0.1805) | Acc: (93.79%) (22819/24330)\n",
      "Epoch: 15 | Batch_idx: 820 |  Loss: (0.1808) | Acc: (93.78%) (23099/24630)\n",
      "Epoch: 15 | Batch_idx: 830 |  Loss: (0.1803) | Acc: (93.81%) (23386/24930)\n",
      "Epoch: 15 | Batch_idx: 840 |  Loss: (0.1797) | Acc: (93.83%) (23674/25230)\n",
      "Epoch: 15 | Batch_idx: 850 |  Loss: (0.1799) | Acc: (93.80%) (23947/25530)\n",
      "Epoch: 15 | Batch_idx: 860 |  Loss: (0.1801) | Acc: (93.79%) (24225/25830)\n",
      "Epoch: 15 | Batch_idx: 870 |  Loss: (0.1793) | Acc: (93.81%) (24513/26130)\n",
      "Epoch: 15 | Batch_idx: 880 |  Loss: (0.1795) | Acc: (93.80%) (24791/26430)\n",
      "Epoch: 15 | Batch_idx: 890 |  Loss: (0.1792) | Acc: (93.80%) (25074/26730)\n",
      "Epoch: 15 | Batch_idx: 900 |  Loss: (0.1795) | Acc: (93.79%) (25351/27030)\n",
      "Epoch: 15 | Batch_idx: 910 |  Loss: (0.1793) | Acc: (93.79%) (25633/27330)\n",
      "Epoch: 15 | Batch_idx: 920 |  Loss: (0.1796) | Acc: (93.80%) (25916/27630)\n",
      "Epoch: 15 | Batch_idx: 930 |  Loss: (0.1792) | Acc: (93.81%) (26200/27930)\n",
      "Epoch: 15 | Batch_idx: 940 |  Loss: (0.1790) | Acc: (93.82%) (26486/28230)\n",
      "Epoch: 15 | Batch_idx: 950 |  Loss: (0.1791) | Acc: (93.82%) (26766/28530)\n",
      "Epoch: 15 | Batch_idx: 960 |  Loss: (0.1784) | Acc: (93.84%) (27055/28830)\n",
      "Epoch: 15 | Batch_idx: 970 |  Loss: (0.1782) | Acc: (93.84%) (27336/29130)\n",
      "Epoch: 15 | Batch_idx: 980 |  Loss: (0.1787) | Acc: (93.83%) (27614/29430)\n",
      "Epoch: 15 | Batch_idx: 990 |  Loss: (0.1787) | Acc: (93.82%) (27893/29730)\n",
      "Epoch: 15 | Batch_idx: 1000 |  Loss: (0.1798) | Acc: (93.79%) (28164/30030)\n",
      "Epoch: 15 | Batch_idx: 1010 |  Loss: (0.1797) | Acc: (93.79%) (28445/30330)\n",
      "Epoch: 15 | Batch_idx: 1020 |  Loss: (0.1797) | Acc: (93.78%) (28725/30630)\n",
      "Epoch: 15 | Batch_idx: 1030 |  Loss: (0.1798) | Acc: (93.77%) (29003/30930)\n",
      "Epoch: 15 | Batch_idx: 1040 |  Loss: (0.1802) | Acc: (93.78%) (29286/31230)\n",
      "Epoch: 15 | Batch_idx: 1050 |  Loss: (0.1805) | Acc: (93.76%) (29561/31530)\n",
      "Epoch: 15 | Batch_idx: 1060 |  Loss: (0.1809) | Acc: (93.74%) (29836/31830)\n",
      "Epoch: 15 | Batch_idx: 1070 |  Loss: (0.1815) | Acc: (93.71%) (30109/32130)\n",
      "Epoch: 15 | Batch_idx: 1080 |  Loss: (0.1814) | Acc: (93.71%) (30390/32430)\n",
      "Epoch: 15 | Batch_idx: 1090 |  Loss: (0.1821) | Acc: (93.68%) (30662/32730)\n",
      "Epoch: 15 | Batch_idx: 1100 |  Loss: (0.1817) | Acc: (93.69%) (30945/33030)\n",
      "Epoch: 15 | Batch_idx: 1110 |  Loss: (0.1824) | Acc: (93.66%) (31217/33330)\n",
      "Epoch: 15 | Batch_idx: 1120 |  Loss: (0.1823) | Acc: (93.66%) (31497/33630)\n",
      "Epoch: 15 | Batch_idx: 1130 |  Loss: (0.1824) | Acc: (93.65%) (31774/33930)\n",
      "Epoch: 15 | Batch_idx: 1140 |  Loss: (0.1824) | Acc: (93.66%) (32059/34230)\n",
      "Epoch: 15 | Batch_idx: 1150 |  Loss: (0.1824) | Acc: (93.65%) (32337/34530)\n",
      "Epoch: 15 | Batch_idx: 1160 |  Loss: (0.1827) | Acc: (93.62%) (32608/34830)\n",
      "Epoch: 15 | Batch_idx: 1170 |  Loss: (0.1824) | Acc: (93.63%) (32893/35130)\n",
      "Epoch: 15 | Batch_idx: 1180 |  Loss: (0.1821) | Acc: (93.63%) (33172/35430)\n",
      "Epoch: 15 | Batch_idx: 1190 |  Loss: (0.1822) | Acc: (93.63%) (33455/35730)\n",
      "Epoch: 15 | Batch_idx: 1200 |  Loss: (0.1821) | Acc: (93.64%) (33740/36030)\n",
      "Epoch: 15 | Batch_idx: 1210 |  Loss: (0.1821) | Acc: (93.64%) (34019/36330)\n",
      "Epoch: 15 | Batch_idx: 1220 |  Loss: (0.1822) | Acc: (93.64%) (34301/36630)\n",
      "Epoch: 15 | Batch_idx: 1230 |  Loss: (0.1825) | Acc: (93.64%) (34580/36930)\n",
      "Epoch: 15 | Batch_idx: 1240 |  Loss: (0.1826) | Acc: (93.64%) (34861/37230)\n",
      "Epoch: 15 | Batch_idx: 1250 |  Loss: (0.1828) | Acc: (93.63%) (35139/37530)\n",
      "Epoch: 15 | Batch_idx: 1260 |  Loss: (0.1829) | Acc: (93.62%) (35417/37830)\n",
      "Epoch: 15 | Batch_idx: 1270 |  Loss: (0.1829) | Acc: (93.62%) (35697/38130)\n",
      "Epoch: 15 | Batch_idx: 1280 |  Loss: (0.1826) | Acc: (93.63%) (35982/38430)\n",
      "Epoch: 15 | Batch_idx: 1290 |  Loss: (0.1827) | Acc: (93.64%) (36265/38730)\n",
      "Epoch: 15 | Batch_idx: 1300 |  Loss: (0.1825) | Acc: (93.65%) (36551/39030)\n",
      "Epoch: 15 | Batch_idx: 1310 |  Loss: (0.1829) | Acc: (93.63%) (36824/39330)\n",
      "Epoch: 15 | Batch_idx: 1320 |  Loss: (0.1839) | Acc: (93.59%) (37091/39630)\n",
      "Epoch: 15 | Batch_idx: 1330 |  Loss: (0.1837) | Acc: (93.61%) (37377/39930)\n",
      "Epoch: 15 | Batch_idx: 1340 |  Loss: (0.1839) | Acc: (93.59%) (37651/40230)\n",
      "Epoch: 15 | Batch_idx: 1350 |  Loss: (0.1843) | Acc: (93.58%) (37926/40530)\n",
      "Epoch: 15 | Batch_idx: 1360 |  Loss: (0.1840) | Acc: (93.59%) (38213/40830)\n",
      "Epoch: 15 | Batch_idx: 1370 |  Loss: (0.1844) | Acc: (93.56%) (38483/41130)\n",
      "Epoch: 15 | Batch_idx: 1380 |  Loss: (0.1843) | Acc: (93.56%) (38763/41430)\n",
      "Epoch: 15 | Batch_idx: 1390 |  Loss: (0.1849) | Acc: (93.55%) (39038/41730)\n",
      "Epoch: 15 | Batch_idx: 1400 |  Loss: (0.1854) | Acc: (93.53%) (39311/42030)\n",
      "Epoch: 15 | Batch_idx: 1410 |  Loss: (0.1855) | Acc: (93.52%) (39588/42330)\n",
      "Epoch: 15 | Batch_idx: 1420 |  Loss: (0.1857) | Acc: (93.51%) (39864/42630)\n",
      "Epoch: 15 | Batch_idx: 1430 |  Loss: (0.1855) | Acc: (93.52%) (40149/42930)\n",
      "Epoch: 15 | Batch_idx: 1440 |  Loss: (0.1858) | Acc: (93.51%) (40426/43230)\n",
      "Epoch: 15 | Batch_idx: 1450 |  Loss: (0.1857) | Acc: (93.52%) (40708/43530)\n",
      "Epoch: 15 | Batch_idx: 1460 |  Loss: (0.1858) | Acc: (93.51%) (40984/43830)\n",
      "Epoch: 15 | Batch_idx: 1470 |  Loss: (0.1862) | Acc: (93.49%) (41259/44130)\n",
      "Epoch: 15 | Batch_idx: 1480 |  Loss: (0.1861) | Acc: (93.50%) (41540/44430)\n",
      "Epoch: 15 | Batch_idx: 1490 |  Loss: (0.1860) | Acc: (93.50%) (41823/44730)\n",
      "Epoch: 15 | Batch_idx: 1500 |  Loss: (0.1859) | Acc: (93.50%) (42102/45030)\n",
      "Epoch: 15 | Batch_idx: 1510 |  Loss: (0.1859) | Acc: (93.51%) (42386/45330)\n",
      "Epoch: 15 | Batch_idx: 1520 |  Loss: (0.1859) | Acc: (93.52%) (42671/45630)\n",
      "Epoch: 15 | Batch_idx: 1530 |  Loss: (0.1862) | Acc: (93.51%) (42950/45930)\n",
      "Epoch: 15 | Batch_idx: 1540 |  Loss: (0.1864) | Acc: (93.51%) (43230/46230)\n",
      "Epoch: 15 | Batch_idx: 1550 |  Loss: (0.1863) | Acc: (93.51%) (43511/46530)\n",
      "Epoch: 15 | Batch_idx: 1560 |  Loss: (0.1868) | Acc: (93.51%) (43789/46830)\n",
      "Epoch: 15 | Batch_idx: 1570 |  Loss: (0.1871) | Acc: (93.51%) (44069/47130)\n",
      "Epoch: 15 | Batch_idx: 1580 |  Loss: (0.1873) | Acc: (93.50%) (44345/47430)\n",
      "Epoch: 15 | Batch_idx: 1590 |  Loss: (0.1872) | Acc: (93.51%) (44630/47730)\n",
      "Epoch: 15 | Batch_idx: 1600 |  Loss: (0.1871) | Acc: (93.50%) (44910/48030)\n",
      "Epoch: 15 | Batch_idx: 1610 |  Loss: (0.1872) | Acc: (93.51%) (45192/48330)\n",
      "Epoch: 15 | Batch_idx: 1620 |  Loss: (0.1870) | Acc: (93.51%) (45475/48630)\n",
      "Epoch: 15 | Batch_idx: 1630 |  Loss: (0.1870) | Acc: (93.51%) (45755/48930)\n",
      "Epoch: 15 | Batch_idx: 1640 |  Loss: (0.1873) | Acc: (93.51%) (46033/49230)\n",
      "Epoch: 15 | Batch_idx: 1650 |  Loss: (0.1874) | Acc: (93.50%) (46310/49530)\n",
      "Epoch: 15 | Batch_idx: 1660 |  Loss: (0.1875) | Acc: (93.50%) (46590/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3426) | Acc: (89.51%) (8951/10000)\n",
      "Epoch: 16 | Batch_idx: 0 |  Loss: (0.0286) | Acc: (100.00%) (30/30)\n",
      "Epoch: 16 | Batch_idx: 10 |  Loss: (0.1850) | Acc: (94.55%) (312/330)\n",
      "Epoch: 16 | Batch_idx: 20 |  Loss: (0.1824) | Acc: (93.65%) (590/630)\n",
      "Epoch: 16 | Batch_idx: 30 |  Loss: (0.2005) | Acc: (93.01%) (865/930)\n",
      "Epoch: 16 | Batch_idx: 40 |  Loss: (0.1911) | Acc: (93.74%) (1153/1230)\n",
      "Epoch: 16 | Batch_idx: 50 |  Loss: (0.1871) | Acc: (94.18%) (1441/1530)\n",
      "Epoch: 16 | Batch_idx: 60 |  Loss: (0.1844) | Acc: (94.32%) (1726/1830)\n",
      "Epoch: 16 | Batch_idx: 70 |  Loss: (0.1781) | Acc: (94.41%) (2011/2130)\n",
      "Epoch: 16 | Batch_idx: 80 |  Loss: (0.1700) | Acc: (94.77%) (2303/2430)\n",
      "Epoch: 16 | Batch_idx: 90 |  Loss: (0.1711) | Acc: (94.73%) (2586/2730)\n",
      "Epoch: 16 | Batch_idx: 100 |  Loss: (0.1697) | Acc: (94.55%) (2865/3030)\n",
      "Epoch: 16 | Batch_idx: 110 |  Loss: (0.1704) | Acc: (94.50%) (3147/3330)\n",
      "Epoch: 16 | Batch_idx: 120 |  Loss: (0.1718) | Acc: (94.46%) (3429/3630)\n",
      "Epoch: 16 | Batch_idx: 130 |  Loss: (0.1715) | Acc: (94.40%) (3710/3930)\n",
      "Epoch: 16 | Batch_idx: 140 |  Loss: (0.1685) | Acc: (94.42%) (3994/4230)\n",
      "Epoch: 16 | Batch_idx: 150 |  Loss: (0.1656) | Acc: (94.55%) (4283/4530)\n",
      "Epoch: 16 | Batch_idx: 160 |  Loss: (0.1675) | Acc: (94.37%) (4558/4830)\n",
      "Epoch: 16 | Batch_idx: 170 |  Loss: (0.1665) | Acc: (94.44%) (4845/5130)\n",
      "Epoch: 16 | Batch_idx: 180 |  Loss: (0.1686) | Acc: (94.31%) (5121/5430)\n",
      "Epoch: 16 | Batch_idx: 190 |  Loss: (0.1669) | Acc: (94.36%) (5407/5730)\n",
      "Epoch: 16 | Batch_idx: 200 |  Loss: (0.1674) | Acc: (94.30%) (5686/6030)\n",
      "Epoch: 16 | Batch_idx: 210 |  Loss: (0.1667) | Acc: (94.34%) (5972/6330)\n",
      "Epoch: 16 | Batch_idx: 220 |  Loss: (0.1660) | Acc: (94.40%) (6259/6630)\n",
      "Epoch: 16 | Batch_idx: 230 |  Loss: (0.1631) | Acc: (94.52%) (6550/6930)\n",
      "Epoch: 16 | Batch_idx: 240 |  Loss: (0.1626) | Acc: (94.44%) (6828/7230)\n",
      "Epoch: 16 | Batch_idx: 250 |  Loss: (0.1617) | Acc: (94.46%) (7113/7530)\n",
      "Epoch: 16 | Batch_idx: 260 |  Loss: (0.1632) | Acc: (94.48%) (7398/7830)\n",
      "Epoch: 16 | Batch_idx: 270 |  Loss: (0.1643) | Acc: (94.42%) (7676/8130)\n",
      "Epoch: 16 | Batch_idx: 280 |  Loss: (0.1651) | Acc: (94.39%) (7957/8430)\n",
      "Epoch: 16 | Batch_idx: 290 |  Loss: (0.1635) | Acc: (94.48%) (8248/8730)\n",
      "Epoch: 16 | Batch_idx: 300 |  Loss: (0.1644) | Acc: (94.45%) (8529/9030)\n",
      "Epoch: 16 | Batch_idx: 310 |  Loss: (0.1635) | Acc: (94.48%) (8815/9330)\n",
      "Epoch: 16 | Batch_idx: 320 |  Loss: (0.1639) | Acc: (94.45%) (9096/9630)\n",
      "Epoch: 16 | Batch_idx: 330 |  Loss: (0.1643) | Acc: (94.45%) (9379/9930)\n",
      "Epoch: 16 | Batch_idx: 340 |  Loss: (0.1644) | Acc: (94.41%) (9658/10230)\n",
      "Epoch: 16 | Batch_idx: 350 |  Loss: (0.1644) | Acc: (94.39%) (9939/10530)\n",
      "Epoch: 16 | Batch_idx: 360 |  Loss: (0.1642) | Acc: (94.41%) (10225/10830)\n",
      "Epoch: 16 | Batch_idx: 370 |  Loss: (0.1624) | Acc: (94.47%) (10515/11130)\n",
      "Epoch: 16 | Batch_idx: 380 |  Loss: (0.1615) | Acc: (94.51%) (10802/11430)\n",
      "Epoch: 16 | Batch_idx: 390 |  Loss: (0.1608) | Acc: (94.53%) (11088/11730)\n",
      "Epoch: 16 | Batch_idx: 400 |  Loss: (0.1598) | Acc: (94.56%) (11376/12030)\n",
      "Epoch: 16 | Batch_idx: 410 |  Loss: (0.1604) | Acc: (94.55%) (11658/12330)\n",
      "Epoch: 16 | Batch_idx: 420 |  Loss: (0.1606) | Acc: (94.54%) (11940/12630)\n",
      "Epoch: 16 | Batch_idx: 430 |  Loss: (0.1607) | Acc: (94.52%) (12222/12930)\n",
      "Epoch: 16 | Batch_idx: 440 |  Loss: (0.1608) | Acc: (94.53%) (12506/13230)\n",
      "Epoch: 16 | Batch_idx: 450 |  Loss: (0.1605) | Acc: (94.56%) (12794/13530)\n",
      "Epoch: 16 | Batch_idx: 460 |  Loss: (0.1589) | Acc: (94.61%) (13084/13830)\n",
      "Epoch: 16 | Batch_idx: 470 |  Loss: (0.1599) | Acc: (94.57%) (13363/14130)\n",
      "Epoch: 16 | Batch_idx: 480 |  Loss: (0.1593) | Acc: (94.59%) (13649/14430)\n",
      "Epoch: 16 | Batch_idx: 490 |  Loss: (0.1588) | Acc: (94.58%) (13932/14730)\n",
      "Epoch: 16 | Batch_idx: 500 |  Loss: (0.1585) | Acc: (94.58%) (14215/15030)\n",
      "Epoch: 16 | Batch_idx: 510 |  Loss: (0.1594) | Acc: (94.56%) (14496/15330)\n",
      "Epoch: 16 | Batch_idx: 520 |  Loss: (0.1600) | Acc: (94.52%) (14774/15630)\n",
      "Epoch: 16 | Batch_idx: 530 |  Loss: (0.1589) | Acc: (94.54%) (15061/15930)\n",
      "Epoch: 16 | Batch_idx: 540 |  Loss: (0.1591) | Acc: (94.55%) (15345/16230)\n",
      "Epoch: 16 | Batch_idx: 550 |  Loss: (0.1596) | Acc: (94.57%) (15632/16530)\n",
      "Epoch: 16 | Batch_idx: 560 |  Loss: (0.1604) | Acc: (94.55%) (15913/16830)\n",
      "Epoch: 16 | Batch_idx: 570 |  Loss: (0.1604) | Acc: (94.54%) (16194/17130)\n",
      "Epoch: 16 | Batch_idx: 580 |  Loss: (0.1603) | Acc: (94.55%) (16480/17430)\n",
      "Epoch: 16 | Batch_idx: 590 |  Loss: (0.1604) | Acc: (94.53%) (16761/17730)\n",
      "Epoch: 16 | Batch_idx: 600 |  Loss: (0.1600) | Acc: (94.56%) (17049/18030)\n",
      "Epoch: 16 | Batch_idx: 610 |  Loss: (0.1602) | Acc: (94.57%) (17334/18330)\n",
      "Epoch: 16 | Batch_idx: 620 |  Loss: (0.1611) | Acc: (94.54%) (17613/18630)\n",
      "Epoch: 16 | Batch_idx: 630 |  Loss: (0.1619) | Acc: (94.52%) (17892/18930)\n",
      "Epoch: 16 | Batch_idx: 640 |  Loss: (0.1613) | Acc: (94.53%) (18179/19230)\n",
      "Epoch: 16 | Batch_idx: 650 |  Loss: (0.1610) | Acc: (94.53%) (18461/19530)\n",
      "Epoch: 16 | Batch_idx: 660 |  Loss: (0.1610) | Acc: (94.53%) (18746/19830)\n",
      "Epoch: 16 | Batch_idx: 670 |  Loss: (0.1624) | Acc: (94.46%) (19014/20130)\n",
      "Epoch: 16 | Batch_idx: 680 |  Loss: (0.1624) | Acc: (94.44%) (19294/20430)\n",
      "Epoch: 16 | Batch_idx: 690 |  Loss: (0.1627) | Acc: (94.43%) (19575/20730)\n",
      "Epoch: 16 | Batch_idx: 700 |  Loss: (0.1631) | Acc: (94.42%) (19856/21030)\n",
      "Epoch: 16 | Batch_idx: 710 |  Loss: (0.1631) | Acc: (94.42%) (20139/21330)\n",
      "Epoch: 16 | Batch_idx: 720 |  Loss: (0.1635) | Acc: (94.40%) (20418/21630)\n",
      "Epoch: 16 | Batch_idx: 730 |  Loss: (0.1635) | Acc: (94.41%) (20705/21930)\n",
      "Epoch: 16 | Batch_idx: 740 |  Loss: (0.1636) | Acc: (94.43%) (20991/22230)\n",
      "Epoch: 16 | Batch_idx: 750 |  Loss: (0.1634) | Acc: (94.44%) (21278/22530)\n",
      "Epoch: 16 | Batch_idx: 760 |  Loss: (0.1631) | Acc: (94.45%) (21564/22830)\n",
      "Epoch: 16 | Batch_idx: 770 |  Loss: (0.1627) | Acc: (94.46%) (21848/23130)\n",
      "Epoch: 16 | Batch_idx: 780 |  Loss: (0.1630) | Acc: (94.45%) (22130/23430)\n",
      "Epoch: 16 | Batch_idx: 790 |  Loss: (0.1626) | Acc: (94.45%) (22413/23730)\n",
      "Epoch: 16 | Batch_idx: 800 |  Loss: (0.1625) | Acc: (94.44%) (22694/24030)\n",
      "Epoch: 16 | Batch_idx: 810 |  Loss: (0.1624) | Acc: (94.45%) (22980/24330)\n",
      "Epoch: 16 | Batch_idx: 820 |  Loss: (0.1633) | Acc: (94.44%) (23261/24630)\n",
      "Epoch: 16 | Batch_idx: 830 |  Loss: (0.1637) | Acc: (94.42%) (23540/24930)\n",
      "Epoch: 16 | Batch_idx: 840 |  Loss: (0.1633) | Acc: (94.45%) (23830/25230)\n",
      "Epoch: 16 | Batch_idx: 850 |  Loss: (0.1633) | Acc: (94.46%) (24115/25530)\n",
      "Epoch: 16 | Batch_idx: 860 |  Loss: (0.1629) | Acc: (94.48%) (24403/25830)\n",
      "Epoch: 16 | Batch_idx: 870 |  Loss: (0.1623) | Acc: (94.49%) (24691/26130)\n",
      "Epoch: 16 | Batch_idx: 880 |  Loss: (0.1622) | Acc: (94.51%) (24978/26430)\n",
      "Epoch: 16 | Batch_idx: 890 |  Loss: (0.1624) | Acc: (94.50%) (25259/26730)\n",
      "Epoch: 16 | Batch_idx: 900 |  Loss: (0.1626) | Acc: (94.49%) (25540/27030)\n",
      "Epoch: 16 | Batch_idx: 910 |  Loss: (0.1628) | Acc: (94.48%) (25822/27330)\n",
      "Epoch: 16 | Batch_idx: 920 |  Loss: (0.1631) | Acc: (94.48%) (26104/27630)\n",
      "Epoch: 16 | Batch_idx: 930 |  Loss: (0.1635) | Acc: (94.45%) (26380/27930)\n",
      "Epoch: 16 | Batch_idx: 940 |  Loss: (0.1638) | Acc: (94.43%) (26659/28230)\n",
      "Epoch: 16 | Batch_idx: 950 |  Loss: (0.1637) | Acc: (94.43%) (26940/28530)\n",
      "Epoch: 16 | Batch_idx: 960 |  Loss: (0.1640) | Acc: (94.41%) (27218/28830)\n",
      "Epoch: 16 | Batch_idx: 970 |  Loss: (0.1640) | Acc: (94.41%) (27501/29130)\n",
      "Epoch: 16 | Batch_idx: 980 |  Loss: (0.1636) | Acc: (94.42%) (27787/29430)\n",
      "Epoch: 16 | Batch_idx: 990 |  Loss: (0.1635) | Acc: (94.43%) (28074/29730)\n",
      "Epoch: 16 | Batch_idx: 1000 |  Loss: (0.1638) | Acc: (94.42%) (28353/30030)\n",
      "Epoch: 16 | Batch_idx: 1010 |  Loss: (0.1635) | Acc: (94.42%) (28638/30330)\n",
      "Epoch: 16 | Batch_idx: 1020 |  Loss: (0.1634) | Acc: (94.42%) (28920/30630)\n",
      "Epoch: 16 | Batch_idx: 1030 |  Loss: (0.1633) | Acc: (94.41%) (29201/30930)\n",
      "Epoch: 16 | Batch_idx: 1040 |  Loss: (0.1629) | Acc: (94.41%) (29484/31230)\n",
      "Epoch: 16 | Batch_idx: 1050 |  Loss: (0.1633) | Acc: (94.39%) (29762/31530)\n",
      "Epoch: 16 | Batch_idx: 1060 |  Loss: (0.1637) | Acc: (94.38%) (30040/31830)\n",
      "Epoch: 16 | Batch_idx: 1070 |  Loss: (0.1638) | Acc: (94.37%) (30320/32130)\n",
      "Epoch: 16 | Batch_idx: 1080 |  Loss: (0.1649) | Acc: (94.32%) (30587/32430)\n",
      "Epoch: 16 | Batch_idx: 1090 |  Loss: (0.1649) | Acc: (94.32%) (30872/32730)\n",
      "Epoch: 16 | Batch_idx: 1100 |  Loss: (0.1648) | Acc: (94.33%) (31156/33030)\n",
      "Epoch: 16 | Batch_idx: 1110 |  Loss: (0.1650) | Acc: (94.31%) (31432/33330)\n",
      "Epoch: 16 | Batch_idx: 1120 |  Loss: (0.1649) | Acc: (94.31%) (31717/33630)\n",
      "Epoch: 16 | Batch_idx: 1130 |  Loss: (0.1646) | Acc: (94.33%) (32007/33930)\n",
      "Epoch: 16 | Batch_idx: 1140 |  Loss: (0.1644) | Acc: (94.35%) (32297/34230)\n",
      "Epoch: 16 | Batch_idx: 1150 |  Loss: (0.1644) | Acc: (94.35%) (32579/34530)\n",
      "Epoch: 16 | Batch_idx: 1160 |  Loss: (0.1644) | Acc: (94.35%) (32863/34830)\n",
      "Epoch: 16 | Batch_idx: 1170 |  Loss: (0.1641) | Acc: (94.36%) (33148/35130)\n",
      "Epoch: 16 | Batch_idx: 1180 |  Loss: (0.1642) | Acc: (94.35%) (33428/35430)\n",
      "Epoch: 16 | Batch_idx: 1190 |  Loss: (0.1644) | Acc: (94.34%) (33709/35730)\n",
      "Epoch: 16 | Batch_idx: 1200 |  Loss: (0.1652) | Acc: (94.32%) (33983/36030)\n",
      "Epoch: 16 | Batch_idx: 1210 |  Loss: (0.1654) | Acc: (94.30%) (34261/36330)\n",
      "Epoch: 16 | Batch_idx: 1220 |  Loss: (0.1657) | Acc: (94.28%) (34536/36630)\n",
      "Epoch: 16 | Batch_idx: 1230 |  Loss: (0.1658) | Acc: (94.28%) (34818/36930)\n",
      "Epoch: 16 | Batch_idx: 1240 |  Loss: (0.1666) | Acc: (94.26%) (35094/37230)\n",
      "Epoch: 16 | Batch_idx: 1250 |  Loss: (0.1665) | Acc: (94.27%) (35379/37530)\n",
      "Epoch: 16 | Batch_idx: 1260 |  Loss: (0.1666) | Acc: (94.26%) (35658/37830)\n",
      "Epoch: 16 | Batch_idx: 1270 |  Loss: (0.1667) | Acc: (94.25%) (35936/38130)\n",
      "Epoch: 16 | Batch_idx: 1280 |  Loss: (0.1674) | Acc: (94.22%) (36208/38430)\n",
      "Epoch: 16 | Batch_idx: 1290 |  Loss: (0.1673) | Acc: (94.22%) (36493/38730)\n",
      "Epoch: 16 | Batch_idx: 1300 |  Loss: (0.1669) | Acc: (94.23%) (36779/39030)\n",
      "Epoch: 16 | Batch_idx: 1310 |  Loss: (0.1669) | Acc: (94.24%) (37063/39330)\n",
      "Epoch: 16 | Batch_idx: 1320 |  Loss: (0.1666) | Acc: (94.24%) (37347/39630)\n",
      "Epoch: 16 | Batch_idx: 1330 |  Loss: (0.1666) | Acc: (94.23%) (37627/39930)\n",
      "Epoch: 16 | Batch_idx: 1340 |  Loss: (0.1662) | Acc: (94.25%) (37915/40230)\n",
      "Epoch: 16 | Batch_idx: 1350 |  Loss: (0.1660) | Acc: (94.24%) (38197/40530)\n",
      "Epoch: 16 | Batch_idx: 1360 |  Loss: (0.1664) | Acc: (94.23%) (38473/40830)\n",
      "Epoch: 16 | Batch_idx: 1370 |  Loss: (0.1668) | Acc: (94.21%) (38748/41130)\n",
      "Epoch: 16 | Batch_idx: 1380 |  Loss: (0.1673) | Acc: (94.19%) (39023/41430)\n",
      "Epoch: 16 | Batch_idx: 1390 |  Loss: (0.1676) | Acc: (94.19%) (39307/41730)\n",
      "Epoch: 16 | Batch_idx: 1400 |  Loss: (0.1674) | Acc: (94.19%) (39588/42030)\n",
      "Epoch: 16 | Batch_idx: 1410 |  Loss: (0.1672) | Acc: (94.20%) (39873/42330)\n",
      "Epoch: 16 | Batch_idx: 1420 |  Loss: (0.1673) | Acc: (94.19%) (40152/42630)\n",
      "Epoch: 16 | Batch_idx: 1430 |  Loss: (0.1677) | Acc: (94.17%) (40428/42930)\n",
      "Epoch: 16 | Batch_idx: 1440 |  Loss: (0.1677) | Acc: (94.17%) (40709/43230)\n",
      "Epoch: 16 | Batch_idx: 1450 |  Loss: (0.1677) | Acc: (94.16%) (40990/43530)\n",
      "Epoch: 16 | Batch_idx: 1460 |  Loss: (0.1681) | Acc: (94.16%) (41269/43830)\n",
      "Epoch: 16 | Batch_idx: 1470 |  Loss: (0.1683) | Acc: (94.16%) (41551/44130)\n",
      "Epoch: 16 | Batch_idx: 1480 |  Loss: (0.1684) | Acc: (94.15%) (41832/44430)\n",
      "Epoch: 16 | Batch_idx: 1490 |  Loss: (0.1685) | Acc: (94.15%) (42115/44730)\n",
      "Epoch: 16 | Batch_idx: 1500 |  Loss: (0.1687) | Acc: (94.16%) (42399/45030)\n",
      "Epoch: 16 | Batch_idx: 1510 |  Loss: (0.1688) | Acc: (94.16%) (42684/45330)\n",
      "Epoch: 16 | Batch_idx: 1520 |  Loss: (0.1691) | Acc: (94.16%) (42963/45630)\n",
      "Epoch: 16 | Batch_idx: 1530 |  Loss: (0.1687) | Acc: (94.17%) (43252/45930)\n",
      "Epoch: 16 | Batch_idx: 1540 |  Loss: (0.1687) | Acc: (94.18%) (43540/46230)\n",
      "Epoch: 16 | Batch_idx: 1550 |  Loss: (0.1689) | Acc: (94.17%) (43815/46530)\n",
      "Epoch: 16 | Batch_idx: 1560 |  Loss: (0.1693) | Acc: (94.16%) (44094/46830)\n",
      "Epoch: 16 | Batch_idx: 1570 |  Loss: (0.1690) | Acc: (94.18%) (44386/47130)\n",
      "Epoch: 16 | Batch_idx: 1580 |  Loss: (0.1692) | Acc: (94.17%) (44665/47430)\n",
      "Epoch: 16 | Batch_idx: 1590 |  Loss: (0.1689) | Acc: (94.18%) (44951/47730)\n",
      "Epoch: 16 | Batch_idx: 1600 |  Loss: (0.1694) | Acc: (94.16%) (45225/48030)\n",
      "Epoch: 16 | Batch_idx: 1610 |  Loss: (0.1694) | Acc: (94.16%) (45508/48330)\n",
      "Epoch: 16 | Batch_idx: 1620 |  Loss: (0.1697) | Acc: (94.16%) (45789/48630)\n",
      "Epoch: 16 | Batch_idx: 1630 |  Loss: (0.1701) | Acc: (94.14%) (46063/48930)\n",
      "Epoch: 16 | Batch_idx: 1640 |  Loss: (0.1703) | Acc: (94.14%) (46343/49230)\n",
      "Epoch: 16 | Batch_idx: 1650 |  Loss: (0.1700) | Acc: (94.15%) (46632/49530)\n",
      "Epoch: 16 | Batch_idx: 1660 |  Loss: (0.1701) | Acc: (94.15%) (46913/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3566) | Acc: (89.29%) (8929/10000)\n",
      "Epoch: 17 | Batch_idx: 0 |  Loss: (0.2501) | Acc: (86.67%) (26/30)\n",
      "Epoch: 17 | Batch_idx: 10 |  Loss: (0.1384) | Acc: (94.55%) (312/330)\n",
      "Epoch: 17 | Batch_idx: 20 |  Loss: (0.1671) | Acc: (93.49%) (589/630)\n",
      "Epoch: 17 | Batch_idx: 30 |  Loss: (0.1554) | Acc: (94.09%) (875/930)\n",
      "Epoch: 17 | Batch_idx: 40 |  Loss: (0.1488) | Acc: (94.47%) (1162/1230)\n",
      "Epoch: 17 | Batch_idx: 50 |  Loss: (0.1557) | Acc: (94.18%) (1441/1530)\n",
      "Epoch: 17 | Batch_idx: 60 |  Loss: (0.1578) | Acc: (94.10%) (1722/1830)\n",
      "Epoch: 17 | Batch_idx: 70 |  Loss: (0.1521) | Acc: (94.41%) (2011/2130)\n",
      "Epoch: 17 | Batch_idx: 80 |  Loss: (0.1534) | Acc: (94.36%) (2293/2430)\n",
      "Epoch: 17 | Batch_idx: 90 |  Loss: (0.1492) | Acc: (94.47%) (2579/2730)\n",
      "Epoch: 17 | Batch_idx: 100 |  Loss: (0.1454) | Acc: (94.59%) (2866/3030)\n",
      "Epoch: 17 | Batch_idx: 110 |  Loss: (0.1466) | Acc: (94.53%) (3148/3330)\n",
      "Epoch: 17 | Batch_idx: 120 |  Loss: (0.1429) | Acc: (94.68%) (3437/3630)\n",
      "Epoch: 17 | Batch_idx: 130 |  Loss: (0.1460) | Acc: (94.66%) (3720/3930)\n",
      "Epoch: 17 | Batch_idx: 140 |  Loss: (0.1467) | Acc: (94.63%) (4003/4230)\n",
      "Epoch: 17 | Batch_idx: 150 |  Loss: (0.1457) | Acc: (94.75%) (4292/4530)\n",
      "Epoch: 17 | Batch_idx: 160 |  Loss: (0.1462) | Acc: (94.78%) (4578/4830)\n",
      "Epoch: 17 | Batch_idx: 170 |  Loss: (0.1445) | Acc: (94.89%) (4868/5130)\n",
      "Epoch: 17 | Batch_idx: 180 |  Loss: (0.1462) | Acc: (94.86%) (5151/5430)\n",
      "Epoch: 17 | Batch_idx: 190 |  Loss: (0.1484) | Acc: (94.76%) (5430/5730)\n",
      "Epoch: 17 | Batch_idx: 200 |  Loss: (0.1510) | Acc: (94.58%) (5703/6030)\n",
      "Epoch: 17 | Batch_idx: 210 |  Loss: (0.1506) | Acc: (94.60%) (5988/6330)\n",
      "Epoch: 17 | Batch_idx: 220 |  Loss: (0.1505) | Acc: (94.63%) (6274/6630)\n",
      "Epoch: 17 | Batch_idx: 230 |  Loss: (0.1482) | Acc: (94.73%) (6565/6930)\n",
      "Epoch: 17 | Batch_idx: 240 |  Loss: (0.1476) | Acc: (94.70%) (6847/7230)\n",
      "Epoch: 17 | Batch_idx: 250 |  Loss: (0.1472) | Acc: (94.78%) (7137/7530)\n",
      "Epoch: 17 | Batch_idx: 260 |  Loss: (0.1480) | Acc: (94.76%) (7420/7830)\n",
      "Epoch: 17 | Batch_idx: 270 |  Loss: (0.1479) | Acc: (94.72%) (7701/8130)\n",
      "Epoch: 17 | Batch_idx: 280 |  Loss: (0.1470) | Acc: (94.78%) (7990/8430)\n",
      "Epoch: 17 | Batch_idx: 290 |  Loss: (0.1481) | Acc: (94.78%) (8274/8730)\n",
      "Epoch: 17 | Batch_idx: 300 |  Loss: (0.1478) | Acc: (94.81%) (8561/9030)\n",
      "Epoch: 17 | Batch_idx: 310 |  Loss: (0.1482) | Acc: (94.79%) (8844/9330)\n",
      "Epoch: 17 | Batch_idx: 320 |  Loss: (0.1492) | Acc: (94.76%) (9125/9630)\n",
      "Epoch: 17 | Batch_idx: 330 |  Loss: (0.1484) | Acc: (94.79%) (9413/9930)\n",
      "Epoch: 17 | Batch_idx: 340 |  Loss: (0.1473) | Acc: (94.84%) (9702/10230)\n",
      "Epoch: 17 | Batch_idx: 350 |  Loss: (0.1464) | Acc: (94.88%) (9991/10530)\n",
      "Epoch: 17 | Batch_idx: 360 |  Loss: (0.1469) | Acc: (94.85%) (10272/10830)\n",
      "Epoch: 17 | Batch_idx: 370 |  Loss: (0.1466) | Acc: (94.86%) (10558/11130)\n",
      "Epoch: 17 | Batch_idx: 380 |  Loss: (0.1478) | Acc: (94.83%) (10839/11430)\n",
      "Epoch: 17 | Batch_idx: 390 |  Loss: (0.1468) | Acc: (94.88%) (11130/11730)\n",
      "Epoch: 17 | Batch_idx: 400 |  Loss: (0.1461) | Acc: (94.89%) (11415/12030)\n",
      "Epoch: 17 | Batch_idx: 410 |  Loss: (0.1458) | Acc: (94.90%) (11701/12330)\n",
      "Epoch: 17 | Batch_idx: 420 |  Loss: (0.1465) | Acc: (94.91%) (11987/12630)\n",
      "Epoch: 17 | Batch_idx: 430 |  Loss: (0.1458) | Acc: (94.93%) (12275/12930)\n",
      "Epoch: 17 | Batch_idx: 440 |  Loss: (0.1449) | Acc: (94.97%) (12564/13230)\n",
      "Epoch: 17 | Batch_idx: 450 |  Loss: (0.1443) | Acc: (94.97%) (12849/13530)\n",
      "Epoch: 17 | Batch_idx: 460 |  Loss: (0.1445) | Acc: (94.95%) (13132/13830)\n",
      "Epoch: 17 | Batch_idx: 470 |  Loss: (0.1439) | Acc: (94.97%) (13419/14130)\n",
      "Epoch: 17 | Batch_idx: 480 |  Loss: (0.1443) | Acc: (94.92%) (13697/14430)\n",
      "Epoch: 17 | Batch_idx: 490 |  Loss: (0.1444) | Acc: (94.94%) (13985/14730)\n",
      "Epoch: 17 | Batch_idx: 500 |  Loss: (0.1447) | Acc: (94.92%) (14266/15030)\n",
      "Epoch: 17 | Batch_idx: 510 |  Loss: (0.1447) | Acc: (94.91%) (14549/15330)\n",
      "Epoch: 17 | Batch_idx: 520 |  Loss: (0.1447) | Acc: (94.91%) (14834/15630)\n",
      "Epoch: 17 | Batch_idx: 530 |  Loss: (0.1442) | Acc: (94.92%) (15120/15930)\n",
      "Epoch: 17 | Batch_idx: 540 |  Loss: (0.1439) | Acc: (94.92%) (15406/16230)\n",
      "Epoch: 17 | Batch_idx: 550 |  Loss: (0.1436) | Acc: (94.94%) (15694/16530)\n",
      "Epoch: 17 | Batch_idx: 560 |  Loss: (0.1445) | Acc: (94.91%) (15974/16830)\n",
      "Epoch: 17 | Batch_idx: 570 |  Loss: (0.1447) | Acc: (94.88%) (16253/17130)\n",
      "Epoch: 17 | Batch_idx: 580 |  Loss: (0.1446) | Acc: (94.89%) (16540/17430)\n",
      "Epoch: 17 | Batch_idx: 590 |  Loss: (0.1447) | Acc: (94.87%) (16820/17730)\n",
      "Epoch: 17 | Batch_idx: 600 |  Loss: (0.1447) | Acc: (94.89%) (17108/18030)\n",
      "Epoch: 17 | Batch_idx: 610 |  Loss: (0.1442) | Acc: (94.92%) (17399/18330)\n",
      "Epoch: 17 | Batch_idx: 620 |  Loss: (0.1445) | Acc: (94.92%) (17684/18630)\n",
      "Epoch: 17 | Batch_idx: 630 |  Loss: (0.1446) | Acc: (94.90%) (17965/18930)\n",
      "Epoch: 17 | Batch_idx: 640 |  Loss: (0.1443) | Acc: (94.90%) (18249/19230)\n",
      "Epoch: 17 | Batch_idx: 650 |  Loss: (0.1441) | Acc: (94.88%) (18531/19530)\n",
      "Epoch: 17 | Batch_idx: 660 |  Loss: (0.1442) | Acc: (94.88%) (18815/19830)\n",
      "Epoch: 17 | Batch_idx: 670 |  Loss: (0.1442) | Acc: (94.90%) (19103/20130)\n",
      "Epoch: 17 | Batch_idx: 680 |  Loss: (0.1442) | Acc: (94.88%) (19385/20430)\n",
      "Epoch: 17 | Batch_idx: 690 |  Loss: (0.1443) | Acc: (94.89%) (19671/20730)\n",
      "Epoch: 17 | Batch_idx: 700 |  Loss: (0.1440) | Acc: (94.89%) (19956/21030)\n",
      "Epoch: 17 | Batch_idx: 710 |  Loss: (0.1436) | Acc: (94.91%) (20245/21330)\n",
      "Epoch: 17 | Batch_idx: 720 |  Loss: (0.1432) | Acc: (94.92%) (20532/21630)\n",
      "Epoch: 17 | Batch_idx: 730 |  Loss: (0.1437) | Acc: (94.93%) (20818/21930)\n",
      "Epoch: 17 | Batch_idx: 740 |  Loss: (0.1441) | Acc: (94.93%) (21103/22230)\n",
      "Epoch: 17 | Batch_idx: 750 |  Loss: (0.1442) | Acc: (94.93%) (21387/22530)\n",
      "Epoch: 17 | Batch_idx: 760 |  Loss: (0.1447) | Acc: (94.92%) (21671/22830)\n",
      "Epoch: 17 | Batch_idx: 770 |  Loss: (0.1444) | Acc: (94.94%) (21960/23130)\n",
      "Epoch: 17 | Batch_idx: 780 |  Loss: (0.1445) | Acc: (94.94%) (22245/23430)\n",
      "Epoch: 17 | Batch_idx: 790 |  Loss: (0.1447) | Acc: (94.96%) (22533/23730)\n",
      "Epoch: 17 | Batch_idx: 800 |  Loss: (0.1445) | Acc: (94.96%) (22820/24030)\n",
      "Epoch: 17 | Batch_idx: 810 |  Loss: (0.1446) | Acc: (94.96%) (23104/24330)\n",
      "Epoch: 17 | Batch_idx: 820 |  Loss: (0.1448) | Acc: (94.97%) (23390/24630)\n",
      "Epoch: 17 | Batch_idx: 830 |  Loss: (0.1445) | Acc: (94.98%) (23678/24930)\n",
      "Epoch: 17 | Batch_idx: 840 |  Loss: (0.1449) | Acc: (94.96%) (23959/25230)\n",
      "Epoch: 17 | Batch_idx: 850 |  Loss: (0.1451) | Acc: (94.95%) (24241/25530)\n",
      "Epoch: 17 | Batch_idx: 860 |  Loss: (0.1461) | Acc: (94.94%) (24522/25830)\n",
      "Epoch: 17 | Batch_idx: 870 |  Loss: (0.1464) | Acc: (94.92%) (24802/26130)\n",
      "Epoch: 17 | Batch_idx: 880 |  Loss: (0.1472) | Acc: (94.88%) (25076/26430)\n",
      "Epoch: 17 | Batch_idx: 890 |  Loss: (0.1475) | Acc: (94.87%) (25358/26730)\n",
      "Epoch: 17 | Batch_idx: 900 |  Loss: (0.1479) | Acc: (94.85%) (25638/27030)\n",
      "Epoch: 17 | Batch_idx: 910 |  Loss: (0.1477) | Acc: (94.86%) (25924/27330)\n",
      "Epoch: 17 | Batch_idx: 920 |  Loss: (0.1473) | Acc: (94.87%) (26212/27630)\n",
      "Epoch: 17 | Batch_idx: 930 |  Loss: (0.1479) | Acc: (94.85%) (26491/27930)\n",
      "Epoch: 17 | Batch_idx: 940 |  Loss: (0.1482) | Acc: (94.82%) (26769/28230)\n",
      "Epoch: 17 | Batch_idx: 950 |  Loss: (0.1481) | Acc: (94.82%) (27053/28530)\n",
      "Epoch: 17 | Batch_idx: 960 |  Loss: (0.1481) | Acc: (94.83%) (27340/28830)\n",
      "Epoch: 17 | Batch_idx: 970 |  Loss: (0.1480) | Acc: (94.84%) (27627/29130)\n",
      "Epoch: 17 | Batch_idx: 980 |  Loss: (0.1481) | Acc: (94.85%) (27913/29430)\n",
      "Epoch: 17 | Batch_idx: 990 |  Loss: (0.1483) | Acc: (94.83%) (28193/29730)\n",
      "Epoch: 17 | Batch_idx: 1000 |  Loss: (0.1487) | Acc: (94.82%) (28475/30030)\n",
      "Epoch: 17 | Batch_idx: 1010 |  Loss: (0.1485) | Acc: (94.83%) (28762/30330)\n",
      "Epoch: 17 | Batch_idx: 1020 |  Loss: (0.1488) | Acc: (94.83%) (29046/30630)\n",
      "Epoch: 17 | Batch_idx: 1030 |  Loss: (0.1489) | Acc: (94.83%) (29330/30930)\n",
      "Epoch: 17 | Batch_idx: 1040 |  Loss: (0.1491) | Acc: (94.82%) (29613/31230)\n",
      "Epoch: 17 | Batch_idx: 1050 |  Loss: (0.1493) | Acc: (94.82%) (29896/31530)\n",
      "Epoch: 17 | Batch_idx: 1060 |  Loss: (0.1489) | Acc: (94.82%) (30182/31830)\n",
      "Epoch: 17 | Batch_idx: 1070 |  Loss: (0.1494) | Acc: (94.79%) (30455/32130)\n",
      "Epoch: 17 | Batch_idx: 1080 |  Loss: (0.1501) | Acc: (94.77%) (30734/32430)\n",
      "Epoch: 17 | Batch_idx: 1090 |  Loss: (0.1500) | Acc: (94.78%) (31020/32730)\n",
      "Epoch: 17 | Batch_idx: 1100 |  Loss: (0.1508) | Acc: (94.76%) (31298/33030)\n",
      "Epoch: 17 | Batch_idx: 1110 |  Loss: (0.1507) | Acc: (94.76%) (31584/33330)\n",
      "Epoch: 17 | Batch_idx: 1120 |  Loss: (0.1508) | Acc: (94.75%) (31864/33630)\n",
      "Epoch: 17 | Batch_idx: 1130 |  Loss: (0.1514) | Acc: (94.73%) (32142/33930)\n",
      "Epoch: 17 | Batch_idx: 1140 |  Loss: (0.1519) | Acc: (94.72%) (32422/34230)\n",
      "Epoch: 17 | Batch_idx: 1150 |  Loss: (0.1516) | Acc: (94.72%) (32708/34530)\n",
      "Epoch: 17 | Batch_idx: 1160 |  Loss: (0.1514) | Acc: (94.73%) (32995/34830)\n",
      "Epoch: 17 | Batch_idx: 1170 |  Loss: (0.1513) | Acc: (94.73%) (33280/35130)\n",
      "Epoch: 17 | Batch_idx: 1180 |  Loss: (0.1520) | Acc: (94.70%) (33553/35430)\n",
      "Epoch: 17 | Batch_idx: 1190 |  Loss: (0.1524) | Acc: (94.70%) (33835/35730)\n",
      "Epoch: 17 | Batch_idx: 1200 |  Loss: (0.1528) | Acc: (94.67%) (34110/36030)\n",
      "Epoch: 17 | Batch_idx: 1210 |  Loss: (0.1537) | Acc: (94.64%) (34381/36330)\n",
      "Epoch: 17 | Batch_idx: 1220 |  Loss: (0.1541) | Acc: (94.61%) (34655/36630)\n",
      "Epoch: 17 | Batch_idx: 1230 |  Loss: (0.1543) | Acc: (94.61%) (34938/36930)\n",
      "Epoch: 17 | Batch_idx: 1240 |  Loss: (0.1553) | Acc: (94.57%) (35209/37230)\n",
      "Epoch: 17 | Batch_idx: 1250 |  Loss: (0.1557) | Acc: (94.56%) (35487/37530)\n",
      "Epoch: 17 | Batch_idx: 1260 |  Loss: (0.1555) | Acc: (94.58%) (35778/37830)\n",
      "Epoch: 17 | Batch_idx: 1270 |  Loss: (0.1553) | Acc: (94.57%) (36061/38130)\n",
      "Epoch: 17 | Batch_idx: 1280 |  Loss: (0.1554) | Acc: (94.58%) (36346/38430)\n",
      "Epoch: 17 | Batch_idx: 1290 |  Loss: (0.1554) | Acc: (94.57%) (36628/38730)\n",
      "Epoch: 17 | Batch_idx: 1300 |  Loss: (0.1553) | Acc: (94.57%) (36910/39030)\n",
      "Epoch: 17 | Batch_idx: 1310 |  Loss: (0.1553) | Acc: (94.57%) (37193/39330)\n",
      "Epoch: 17 | Batch_idx: 1320 |  Loss: (0.1554) | Acc: (94.55%) (37471/39630)\n",
      "Epoch: 17 | Batch_idx: 1330 |  Loss: (0.1553) | Acc: (94.56%) (37758/39930)\n",
      "Epoch: 17 | Batch_idx: 1340 |  Loss: (0.1553) | Acc: (94.56%) (38043/40230)\n",
      "Epoch: 17 | Batch_idx: 1350 |  Loss: (0.1551) | Acc: (94.58%) (38332/40530)\n",
      "Epoch: 17 | Batch_idx: 1360 |  Loss: (0.1549) | Acc: (94.58%) (38615/40830)\n",
      "Epoch: 17 | Batch_idx: 1370 |  Loss: (0.1551) | Acc: (94.57%) (38898/41130)\n",
      "Epoch: 17 | Batch_idx: 1380 |  Loss: (0.1553) | Acc: (94.57%) (39180/41430)\n",
      "Epoch: 17 | Batch_idx: 1390 |  Loss: (0.1554) | Acc: (94.56%) (39460/41730)\n",
      "Epoch: 17 | Batch_idx: 1400 |  Loss: (0.1558) | Acc: (94.55%) (39740/42030)\n",
      "Epoch: 17 | Batch_idx: 1410 |  Loss: (0.1555) | Acc: (94.56%) (40029/42330)\n",
      "Epoch: 17 | Batch_idx: 1420 |  Loss: (0.1555) | Acc: (94.56%) (40312/42630)\n",
      "Epoch: 17 | Batch_idx: 1430 |  Loss: (0.1558) | Acc: (94.55%) (40592/42930)\n",
      "Epoch: 17 | Batch_idx: 1440 |  Loss: (0.1558) | Acc: (94.55%) (40875/43230)\n",
      "Epoch: 17 | Batch_idx: 1450 |  Loss: (0.1561) | Acc: (94.54%) (41154/43530)\n",
      "Epoch: 17 | Batch_idx: 1460 |  Loss: (0.1563) | Acc: (94.54%) (41437/43830)\n",
      "Epoch: 17 | Batch_idx: 1470 |  Loss: (0.1563) | Acc: (94.54%) (41719/44130)\n",
      "Epoch: 17 | Batch_idx: 1480 |  Loss: (0.1561) | Acc: (94.54%) (42004/44430)\n",
      "Epoch: 17 | Batch_idx: 1490 |  Loss: (0.1561) | Acc: (94.54%) (42286/44730)\n",
      "Epoch: 17 | Batch_idx: 1500 |  Loss: (0.1565) | Acc: (94.53%) (42566/45030)\n",
      "Epoch: 17 | Batch_idx: 1510 |  Loss: (0.1565) | Acc: (94.53%) (42852/45330)\n",
      "Epoch: 17 | Batch_idx: 1520 |  Loss: (0.1565) | Acc: (94.54%) (43137/45630)\n",
      "Epoch: 17 | Batch_idx: 1530 |  Loss: (0.1564) | Acc: (94.54%) (43424/45930)\n",
      "Epoch: 17 | Batch_idx: 1540 |  Loss: (0.1563) | Acc: (94.55%) (43712/46230)\n",
      "Epoch: 17 | Batch_idx: 1550 |  Loss: (0.1564) | Acc: (94.55%) (43992/46530)\n",
      "Epoch: 17 | Batch_idx: 1560 |  Loss: (0.1567) | Acc: (94.53%) (44270/46830)\n",
      "Epoch: 17 | Batch_idx: 1570 |  Loss: (0.1565) | Acc: (94.54%) (44559/47130)\n",
      "Epoch: 17 | Batch_idx: 1580 |  Loss: (0.1565) | Acc: (94.54%) (44842/47430)\n",
      "Epoch: 17 | Batch_idx: 1590 |  Loss: (0.1566) | Acc: (94.54%) (45124/47730)\n",
      "Epoch: 17 | Batch_idx: 1600 |  Loss: (0.1572) | Acc: (94.51%) (45394/48030)\n",
      "Epoch: 17 | Batch_idx: 1610 |  Loss: (0.1573) | Acc: (94.51%) (45677/48330)\n",
      "Epoch: 17 | Batch_idx: 1620 |  Loss: (0.1572) | Acc: (94.52%) (45963/48630)\n",
      "Epoch: 17 | Batch_idx: 1630 |  Loss: (0.1572) | Acc: (94.51%) (46245/48930)\n",
      "Epoch: 17 | Batch_idx: 1640 |  Loss: (0.1572) | Acc: (94.52%) (46531/49230)\n",
      "Epoch: 17 | Batch_idx: 1650 |  Loss: (0.1571) | Acc: (94.52%) (46817/49530)\n",
      "Epoch: 17 | Batch_idx: 1660 |  Loss: (0.1568) | Acc: (94.53%) (47106/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3476) | Acc: (89.45%) (8945/10000)\n",
      "Epoch: 18 | Batch_idx: 0 |  Loss: (0.1590) | Acc: (93.33%) (28/30)\n",
      "Epoch: 18 | Batch_idx: 10 |  Loss: (0.1466) | Acc: (94.55%) (312/330)\n",
      "Epoch: 18 | Batch_idx: 20 |  Loss: (0.1600) | Acc: (94.29%) (594/630)\n",
      "Epoch: 18 | Batch_idx: 30 |  Loss: (0.1544) | Acc: (94.52%) (879/930)\n",
      "Epoch: 18 | Batch_idx: 40 |  Loss: (0.1411) | Acc: (94.96%) (1168/1230)\n",
      "Epoch: 18 | Batch_idx: 50 |  Loss: (0.1484) | Acc: (94.71%) (1449/1530)\n",
      "Epoch: 18 | Batch_idx: 60 |  Loss: (0.1469) | Acc: (94.70%) (1733/1830)\n",
      "Epoch: 18 | Batch_idx: 70 |  Loss: (0.1392) | Acc: (94.93%) (2022/2130)\n",
      "Epoch: 18 | Batch_idx: 80 |  Loss: (0.1408) | Acc: (94.94%) (2307/2430)\n",
      "Epoch: 18 | Batch_idx: 90 |  Loss: (0.1370) | Acc: (95.24%) (2600/2730)\n",
      "Epoch: 18 | Batch_idx: 100 |  Loss: (0.1410) | Acc: (94.98%) (2878/3030)\n",
      "Epoch: 18 | Batch_idx: 110 |  Loss: (0.1398) | Acc: (95.23%) (3171/3330)\n",
      "Epoch: 18 | Batch_idx: 120 |  Loss: (0.1446) | Acc: (95.15%) (3454/3630)\n",
      "Epoch: 18 | Batch_idx: 130 |  Loss: (0.1463) | Acc: (95.04%) (3735/3930)\n",
      "Epoch: 18 | Batch_idx: 140 |  Loss: (0.1484) | Acc: (94.94%) (4016/4230)\n",
      "Epoch: 18 | Batch_idx: 150 |  Loss: (0.1481) | Acc: (94.88%) (4298/4530)\n",
      "Epoch: 18 | Batch_idx: 160 |  Loss: (0.1482) | Acc: (94.80%) (4579/4830)\n",
      "Epoch: 18 | Batch_idx: 170 |  Loss: (0.1477) | Acc: (94.81%) (4864/5130)\n",
      "Epoch: 18 | Batch_idx: 180 |  Loss: (0.1462) | Acc: (94.92%) (5154/5430)\n",
      "Epoch: 18 | Batch_idx: 190 |  Loss: (0.1443) | Acc: (95.01%) (5444/5730)\n",
      "Epoch: 18 | Batch_idx: 200 |  Loss: (0.1421) | Acc: (95.12%) (5736/6030)\n",
      "Epoch: 18 | Batch_idx: 210 |  Loss: (0.1406) | Acc: (95.13%) (6022/6330)\n",
      "Epoch: 18 | Batch_idx: 220 |  Loss: (0.1388) | Acc: (95.19%) (6311/6630)\n",
      "Epoch: 18 | Batch_idx: 230 |  Loss: (0.1374) | Acc: (95.25%) (6601/6930)\n",
      "Epoch: 18 | Batch_idx: 240 |  Loss: (0.1357) | Acc: (95.33%) (6892/7230)\n",
      "Epoch: 18 | Batch_idx: 250 |  Loss: (0.1345) | Acc: (95.37%) (7181/7530)\n",
      "Epoch: 18 | Batch_idx: 260 |  Loss: (0.1339) | Acc: (95.40%) (7470/7830)\n",
      "Epoch: 18 | Batch_idx: 270 |  Loss: (0.1360) | Acc: (95.39%) (7755/8130)\n",
      "Epoch: 18 | Batch_idx: 280 |  Loss: (0.1361) | Acc: (95.40%) (8042/8430)\n",
      "Epoch: 18 | Batch_idx: 290 |  Loss: (0.1357) | Acc: (95.36%) (8325/8730)\n",
      "Epoch: 18 | Batch_idx: 300 |  Loss: (0.1353) | Acc: (95.40%) (8615/9030)\n",
      "Epoch: 18 | Batch_idx: 310 |  Loss: (0.1372) | Acc: (95.40%) (8901/9330)\n",
      "Epoch: 18 | Batch_idx: 320 |  Loss: (0.1370) | Acc: (95.40%) (9187/9630)\n",
      "Epoch: 18 | Batch_idx: 330 |  Loss: (0.1361) | Acc: (95.42%) (9475/9930)\n",
      "Epoch: 18 | Batch_idx: 340 |  Loss: (0.1363) | Acc: (95.42%) (9761/10230)\n",
      "Epoch: 18 | Batch_idx: 350 |  Loss: (0.1359) | Acc: (95.47%) (10053/10530)\n",
      "Epoch: 18 | Batch_idx: 360 |  Loss: (0.1358) | Acc: (95.49%) (10342/10830)\n",
      "Epoch: 18 | Batch_idx: 370 |  Loss: (0.1353) | Acc: (95.49%) (10628/11130)\n",
      "Epoch: 18 | Batch_idx: 380 |  Loss: (0.1354) | Acc: (95.49%) (10914/11430)\n",
      "Epoch: 18 | Batch_idx: 390 |  Loss: (0.1353) | Acc: (95.48%) (11200/11730)\n",
      "Epoch: 18 | Batch_idx: 400 |  Loss: (0.1352) | Acc: (95.47%) (11485/12030)\n",
      "Epoch: 18 | Batch_idx: 410 |  Loss: (0.1353) | Acc: (95.47%) (11772/12330)\n",
      "Epoch: 18 | Batch_idx: 420 |  Loss: (0.1352) | Acc: (95.46%) (12057/12630)\n",
      "Epoch: 18 | Batch_idx: 430 |  Loss: (0.1356) | Acc: (95.44%) (12341/12930)\n",
      "Epoch: 18 | Batch_idx: 440 |  Loss: (0.1352) | Acc: (95.42%) (12624/13230)\n",
      "Epoch: 18 | Batch_idx: 450 |  Loss: (0.1354) | Acc: (95.42%) (12910/13530)\n",
      "Epoch: 18 | Batch_idx: 460 |  Loss: (0.1362) | Acc: (95.38%) (13191/13830)\n",
      "Epoch: 18 | Batch_idx: 470 |  Loss: (0.1366) | Acc: (95.34%) (13472/14130)\n",
      "Epoch: 18 | Batch_idx: 480 |  Loss: (0.1360) | Acc: (95.36%) (13760/14430)\n",
      "Epoch: 18 | Batch_idx: 490 |  Loss: (0.1364) | Acc: (95.35%) (14045/14730)\n",
      "Epoch: 18 | Batch_idx: 500 |  Loss: (0.1369) | Acc: (95.34%) (14329/15030)\n",
      "Epoch: 18 | Batch_idx: 510 |  Loss: (0.1369) | Acc: (95.35%) (14617/15330)\n",
      "Epoch: 18 | Batch_idx: 520 |  Loss: (0.1367) | Acc: (95.34%) (14901/15630)\n",
      "Epoch: 18 | Batch_idx: 530 |  Loss: (0.1361) | Acc: (95.34%) (15187/15930)\n",
      "Epoch: 18 | Batch_idx: 540 |  Loss: (0.1363) | Acc: (95.33%) (15472/16230)\n",
      "Epoch: 18 | Batch_idx: 550 |  Loss: (0.1362) | Acc: (95.35%) (15762/16530)\n",
      "Epoch: 18 | Batch_idx: 560 |  Loss: (0.1361) | Acc: (95.35%) (16048/16830)\n",
      "Epoch: 18 | Batch_idx: 570 |  Loss: (0.1363) | Acc: (95.34%) (16332/17130)\n",
      "Epoch: 18 | Batch_idx: 580 |  Loss: (0.1356) | Acc: (95.38%) (16624/17430)\n",
      "Epoch: 18 | Batch_idx: 590 |  Loss: (0.1360) | Acc: (95.35%) (16905/17730)\n",
      "Epoch: 18 | Batch_idx: 600 |  Loss: (0.1362) | Acc: (95.34%) (17189/18030)\n",
      "Epoch: 18 | Batch_idx: 610 |  Loss: (0.1364) | Acc: (95.32%) (17473/18330)\n",
      "Epoch: 18 | Batch_idx: 620 |  Loss: (0.1360) | Acc: (95.35%) (17764/18630)\n",
      "Epoch: 18 | Batch_idx: 630 |  Loss: (0.1358) | Acc: (95.36%) (18051/18930)\n",
      "Epoch: 18 | Batch_idx: 640 |  Loss: (0.1363) | Acc: (95.34%) (18333/19230)\n",
      "Epoch: 18 | Batch_idx: 650 |  Loss: (0.1372) | Acc: (95.33%) (18618/19530)\n",
      "Epoch: 18 | Batch_idx: 660 |  Loss: (0.1366) | Acc: (95.35%) (18907/19830)\n",
      "Epoch: 18 | Batch_idx: 670 |  Loss: (0.1364) | Acc: (95.36%) (19195/20130)\n",
      "Epoch: 18 | Batch_idx: 680 |  Loss: (0.1364) | Acc: (95.36%) (19482/20430)\n",
      "Epoch: 18 | Batch_idx: 690 |  Loss: (0.1361) | Acc: (95.36%) (19768/20730)\n",
      "Epoch: 18 | Batch_idx: 700 |  Loss: (0.1366) | Acc: (95.34%) (20049/21030)\n",
      "Epoch: 18 | Batch_idx: 710 |  Loss: (0.1364) | Acc: (95.35%) (20338/21330)\n",
      "Epoch: 18 | Batch_idx: 720 |  Loss: (0.1359) | Acc: (95.36%) (20627/21630)\n",
      "Epoch: 18 | Batch_idx: 730 |  Loss: (0.1363) | Acc: (95.36%) (20912/21930)\n",
      "Epoch: 18 | Batch_idx: 740 |  Loss: (0.1358) | Acc: (95.38%) (21202/22230)\n",
      "Epoch: 18 | Batch_idx: 750 |  Loss: (0.1366) | Acc: (95.35%) (21482/22530)\n",
      "Epoch: 18 | Batch_idx: 760 |  Loss: (0.1366) | Acc: (95.33%) (21764/22830)\n",
      "Epoch: 18 | Batch_idx: 770 |  Loss: (0.1372) | Acc: (95.30%) (22043/23130)\n",
      "Epoch: 18 | Batch_idx: 780 |  Loss: (0.1376) | Acc: (95.28%) (22323/23430)\n",
      "Epoch: 18 | Batch_idx: 790 |  Loss: (0.1377) | Acc: (95.26%) (22606/23730)\n",
      "Epoch: 18 | Batch_idx: 800 |  Loss: (0.1379) | Acc: (95.26%) (22891/24030)\n",
      "Epoch: 18 | Batch_idx: 810 |  Loss: (0.1372) | Acc: (95.29%) (23185/24330)\n",
      "Epoch: 18 | Batch_idx: 820 |  Loss: (0.1374) | Acc: (95.29%) (23471/24630)\n",
      "Epoch: 18 | Batch_idx: 830 |  Loss: (0.1369) | Acc: (95.31%) (23760/24930)\n",
      "Epoch: 18 | Batch_idx: 840 |  Loss: (0.1378) | Acc: (95.28%) (24038/25230)\n",
      "Epoch: 18 | Batch_idx: 850 |  Loss: (0.1377) | Acc: (95.27%) (24323/25530)\n",
      "Epoch: 18 | Batch_idx: 860 |  Loss: (0.1376) | Acc: (95.27%) (24608/25830)\n",
      "Epoch: 18 | Batch_idx: 870 |  Loss: (0.1381) | Acc: (95.25%) (24888/26130)\n",
      "Epoch: 18 | Batch_idx: 880 |  Loss: (0.1383) | Acc: (95.24%) (25171/26430)\n",
      "Epoch: 18 | Batch_idx: 890 |  Loss: (0.1382) | Acc: (95.23%) (25456/26730)\n",
      "Epoch: 18 | Batch_idx: 900 |  Loss: (0.1382) | Acc: (95.23%) (25740/27030)\n",
      "Epoch: 18 | Batch_idx: 910 |  Loss: (0.1381) | Acc: (95.23%) (26025/27330)\n",
      "Epoch: 18 | Batch_idx: 920 |  Loss: (0.1385) | Acc: (95.22%) (26309/27630)\n",
      "Epoch: 18 | Batch_idx: 930 |  Loss: (0.1387) | Acc: (95.21%) (26592/27930)\n",
      "Epoch: 18 | Batch_idx: 940 |  Loss: (0.1385) | Acc: (95.20%) (26875/28230)\n",
      "Epoch: 18 | Batch_idx: 950 |  Loss: (0.1387) | Acc: (95.19%) (27157/28530)\n",
      "Epoch: 18 | Batch_idx: 960 |  Loss: (0.1388) | Acc: (95.16%) (27436/28830)\n",
      "Epoch: 18 | Batch_idx: 970 |  Loss: (0.1391) | Acc: (95.15%) (27717/29130)\n",
      "Epoch: 18 | Batch_idx: 980 |  Loss: (0.1397) | Acc: (95.13%) (27997/29430)\n",
      "Epoch: 18 | Batch_idx: 990 |  Loss: (0.1396) | Acc: (95.14%) (28284/29730)\n",
      "Epoch: 18 | Batch_idx: 1000 |  Loss: (0.1396) | Acc: (95.12%) (28566/30030)\n",
      "Epoch: 18 | Batch_idx: 1010 |  Loss: (0.1395) | Acc: (95.13%) (28852/30330)\n",
      "Epoch: 18 | Batch_idx: 1020 |  Loss: (0.1400) | Acc: (95.10%) (29130/30630)\n",
      "Epoch: 18 | Batch_idx: 1030 |  Loss: (0.1401) | Acc: (95.10%) (29414/30930)\n",
      "Epoch: 18 | Batch_idx: 1040 |  Loss: (0.1395) | Acc: (95.12%) (29705/31230)\n",
      "Epoch: 18 | Batch_idx: 1050 |  Loss: (0.1402) | Acc: (95.10%) (29985/31530)\n",
      "Epoch: 18 | Batch_idx: 1060 |  Loss: (0.1400) | Acc: (95.10%) (30270/31830)\n",
      "Epoch: 18 | Batch_idx: 1070 |  Loss: (0.1398) | Acc: (95.11%) (30558/32130)\n",
      "Epoch: 18 | Batch_idx: 1080 |  Loss: (0.1398) | Acc: (95.10%) (30841/32430)\n",
      "Epoch: 18 | Batch_idx: 1090 |  Loss: (0.1402) | Acc: (95.08%) (31119/32730)\n",
      "Epoch: 18 | Batch_idx: 1100 |  Loss: (0.1400) | Acc: (95.08%) (31405/33030)\n",
      "Epoch: 18 | Batch_idx: 1110 |  Loss: (0.1397) | Acc: (95.10%) (31698/33330)\n",
      "Epoch: 18 | Batch_idx: 1120 |  Loss: (0.1399) | Acc: (95.08%) (31976/33630)\n",
      "Epoch: 18 | Batch_idx: 1130 |  Loss: (0.1403) | Acc: (95.06%) (32254/33930)\n",
      "Epoch: 18 | Batch_idx: 1140 |  Loss: (0.1399) | Acc: (95.08%) (32546/34230)\n",
      "Epoch: 18 | Batch_idx: 1150 |  Loss: (0.1402) | Acc: (95.06%) (32824/34530)\n",
      "Epoch: 18 | Batch_idx: 1160 |  Loss: (0.1401) | Acc: (95.06%) (33109/34830)\n",
      "Epoch: 18 | Batch_idx: 1170 |  Loss: (0.1399) | Acc: (95.06%) (33396/35130)\n",
      "Epoch: 18 | Batch_idx: 1180 |  Loss: (0.1399) | Acc: (95.07%) (33683/35430)\n",
      "Epoch: 18 | Batch_idx: 1190 |  Loss: (0.1400) | Acc: (95.06%) (33965/35730)\n",
      "Epoch: 18 | Batch_idx: 1200 |  Loss: (0.1402) | Acc: (95.05%) (34246/36030)\n",
      "Epoch: 18 | Batch_idx: 1210 |  Loss: (0.1402) | Acc: (95.03%) (34526/36330)\n",
      "Epoch: 18 | Batch_idx: 1220 |  Loss: (0.1404) | Acc: (95.03%) (34808/36630)\n",
      "Epoch: 18 | Batch_idx: 1230 |  Loss: (0.1405) | Acc: (95.02%) (35091/36930)\n",
      "Epoch: 18 | Batch_idx: 1240 |  Loss: (0.1405) | Acc: (95.02%) (35376/37230)\n",
      "Epoch: 18 | Batch_idx: 1250 |  Loss: (0.1410) | Acc: (95.01%) (35658/37530)\n",
      "Epoch: 18 | Batch_idx: 1260 |  Loss: (0.1416) | Acc: (95.00%) (35937/37830)\n",
      "Epoch: 18 | Batch_idx: 1270 |  Loss: (0.1416) | Acc: (94.99%) (36220/38130)\n",
      "Epoch: 18 | Batch_idx: 1280 |  Loss: (0.1418) | Acc: (94.98%) (36502/38430)\n",
      "Epoch: 18 | Batch_idx: 1290 |  Loss: (0.1419) | Acc: (94.99%) (36788/38730)\n",
      "Epoch: 18 | Batch_idx: 1300 |  Loss: (0.1419) | Acc: (94.99%) (37074/39030)\n",
      "Epoch: 18 | Batch_idx: 1310 |  Loss: (0.1423) | Acc: (94.97%) (37351/39330)\n",
      "Epoch: 18 | Batch_idx: 1320 |  Loss: (0.1419) | Acc: (94.99%) (37644/39630)\n",
      "Epoch: 18 | Batch_idx: 1330 |  Loss: (0.1418) | Acc: (94.99%) (37928/39930)\n",
      "Epoch: 18 | Batch_idx: 1340 |  Loss: (0.1422) | Acc: (94.97%) (38205/40230)\n",
      "Epoch: 18 | Batch_idx: 1350 |  Loss: (0.1426) | Acc: (94.95%) (38484/40530)\n",
      "Epoch: 18 | Batch_idx: 1360 |  Loss: (0.1428) | Acc: (94.94%) (38765/40830)\n",
      "Epoch: 18 | Batch_idx: 1370 |  Loss: (0.1427) | Acc: (94.95%) (39052/41130)\n",
      "Epoch: 18 | Batch_idx: 1380 |  Loss: (0.1427) | Acc: (94.95%) (39336/41430)\n",
      "Epoch: 18 | Batch_idx: 1390 |  Loss: (0.1430) | Acc: (94.95%) (39621/41730)\n",
      "Epoch: 18 | Batch_idx: 1400 |  Loss: (0.1432) | Acc: (94.94%) (39905/42030)\n",
      "Epoch: 18 | Batch_idx: 1410 |  Loss: (0.1439) | Acc: (94.91%) (40176/42330)\n",
      "Epoch: 18 | Batch_idx: 1420 |  Loss: (0.1439) | Acc: (94.91%) (40460/42630)\n",
      "Epoch: 18 | Batch_idx: 1430 |  Loss: (0.1443) | Acc: (94.90%) (40742/42930)\n",
      "Epoch: 18 | Batch_idx: 1440 |  Loss: (0.1446) | Acc: (94.89%) (41022/43230)\n",
      "Epoch: 18 | Batch_idx: 1450 |  Loss: (0.1447) | Acc: (94.89%) (41307/43530)\n",
      "Epoch: 18 | Batch_idx: 1460 |  Loss: (0.1447) | Acc: (94.90%) (41596/43830)\n",
      "Epoch: 18 | Batch_idx: 1470 |  Loss: (0.1445) | Acc: (94.91%) (41884/44130)\n",
      "Epoch: 18 | Batch_idx: 1480 |  Loss: (0.1446) | Acc: (94.91%) (42168/44430)\n",
      "Epoch: 18 | Batch_idx: 1490 |  Loss: (0.1446) | Acc: (94.90%) (42451/44730)\n",
      "Epoch: 18 | Batch_idx: 1500 |  Loss: (0.1445) | Acc: (94.90%) (42735/45030)\n",
      "Epoch: 18 | Batch_idx: 1510 |  Loss: (0.1447) | Acc: (94.90%) (43018/45330)\n",
      "Epoch: 18 | Batch_idx: 1520 |  Loss: (0.1445) | Acc: (94.90%) (43301/45630)\n",
      "Epoch: 18 | Batch_idx: 1530 |  Loss: (0.1449) | Acc: (94.89%) (43583/45930)\n",
      "Epoch: 18 | Batch_idx: 1540 |  Loss: (0.1449) | Acc: (94.89%) (43869/46230)\n",
      "Epoch: 18 | Batch_idx: 1550 |  Loss: (0.1448) | Acc: (94.90%) (44158/46530)\n",
      "Epoch: 18 | Batch_idx: 1560 |  Loss: (0.1448) | Acc: (94.90%) (44441/46830)\n",
      "Epoch: 18 | Batch_idx: 1570 |  Loss: (0.1450) | Acc: (94.90%) (44725/47130)\n",
      "Epoch: 18 | Batch_idx: 1580 |  Loss: (0.1448) | Acc: (94.90%) (45011/47430)\n",
      "Epoch: 18 | Batch_idx: 1590 |  Loss: (0.1447) | Acc: (94.91%) (45299/47730)\n",
      "Epoch: 18 | Batch_idx: 1600 |  Loss: (0.1445) | Acc: (94.92%) (45589/48030)\n",
      "Epoch: 18 | Batch_idx: 1610 |  Loss: (0.1441) | Acc: (94.93%) (45879/48330)\n",
      "Epoch: 18 | Batch_idx: 1620 |  Loss: (0.1442) | Acc: (94.93%) (46165/48630)\n",
      "Epoch: 18 | Batch_idx: 1630 |  Loss: (0.1442) | Acc: (94.93%) (46448/48930)\n",
      "Epoch: 18 | Batch_idx: 1640 |  Loss: (0.1442) | Acc: (94.93%) (46733/49230)\n",
      "Epoch: 18 | Batch_idx: 1650 |  Loss: (0.1444) | Acc: (94.92%) (47015/49530)\n",
      "Epoch: 18 | Batch_idx: 1660 |  Loss: (0.1449) | Acc: (94.91%) (47294/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3339) | Acc: (89.69%) (8969/10000)\n",
      "Epoch: 19 | Batch_idx: 0 |  Loss: (0.2783) | Acc: (93.33%) (28/30)\n",
      "Epoch: 19 | Batch_idx: 10 |  Loss: (0.1971) | Acc: (93.33%) (308/330)\n",
      "Epoch: 19 | Batch_idx: 20 |  Loss: (0.1818) | Acc: (93.49%) (589/630)\n",
      "Epoch: 19 | Batch_idx: 30 |  Loss: (0.1562) | Acc: (94.09%) (875/930)\n",
      "Epoch: 19 | Batch_idx: 40 |  Loss: (0.1498) | Acc: (94.63%) (1164/1230)\n",
      "Epoch: 19 | Batch_idx: 50 |  Loss: (0.1513) | Acc: (94.84%) (1451/1530)\n",
      "Epoch: 19 | Batch_idx: 60 |  Loss: (0.1449) | Acc: (95.08%) (1740/1830)\n",
      "Epoch: 19 | Batch_idx: 70 |  Loss: (0.1441) | Acc: (95.02%) (2024/2130)\n",
      "Epoch: 19 | Batch_idx: 80 |  Loss: (0.1414) | Acc: (95.10%) (2311/2430)\n",
      "Epoch: 19 | Batch_idx: 90 |  Loss: (0.1415) | Acc: (95.02%) (2594/2730)\n",
      "Epoch: 19 | Batch_idx: 100 |  Loss: (0.1387) | Acc: (95.05%) (2880/3030)\n",
      "Epoch: 19 | Batch_idx: 110 |  Loss: (0.1383) | Acc: (94.98%) (3163/3330)\n",
      "Epoch: 19 | Batch_idx: 120 |  Loss: (0.1399) | Acc: (94.77%) (3440/3630)\n",
      "Epoch: 19 | Batch_idx: 130 |  Loss: (0.1401) | Acc: (94.73%) (3723/3930)\n",
      "Epoch: 19 | Batch_idx: 140 |  Loss: (0.1415) | Acc: (94.68%) (4005/4230)\n",
      "Epoch: 19 | Batch_idx: 150 |  Loss: (0.1408) | Acc: (94.81%) (4295/4530)\n",
      "Epoch: 19 | Batch_idx: 160 |  Loss: (0.1391) | Acc: (94.84%) (4581/4830)\n",
      "Epoch: 19 | Batch_idx: 170 |  Loss: (0.1390) | Acc: (94.81%) (4864/5130)\n",
      "Epoch: 19 | Batch_idx: 180 |  Loss: (0.1402) | Acc: (94.79%) (5147/5430)\n",
      "Epoch: 19 | Batch_idx: 190 |  Loss: (0.1409) | Acc: (94.76%) (5430/5730)\n",
      "Epoch: 19 | Batch_idx: 200 |  Loss: (0.1379) | Acc: (94.91%) (5723/6030)\n",
      "Epoch: 19 | Batch_idx: 210 |  Loss: (0.1369) | Acc: (94.91%) (6008/6330)\n",
      "Epoch: 19 | Batch_idx: 220 |  Loss: (0.1376) | Acc: (94.92%) (6293/6630)\n",
      "Epoch: 19 | Batch_idx: 230 |  Loss: (0.1366) | Acc: (94.98%) (6582/6930)\n",
      "Epoch: 19 | Batch_idx: 240 |  Loss: (0.1366) | Acc: (95.05%) (6872/7230)\n",
      "Epoch: 19 | Batch_idx: 250 |  Loss: (0.1363) | Acc: (95.07%) (7159/7530)\n",
      "Epoch: 19 | Batch_idx: 260 |  Loss: (0.1367) | Acc: (95.06%) (7443/7830)\n",
      "Epoch: 19 | Batch_idx: 270 |  Loss: (0.1368) | Acc: (95.04%) (7727/8130)\n",
      "Epoch: 19 | Batch_idx: 280 |  Loss: (0.1367) | Acc: (95.09%) (8016/8430)\n",
      "Epoch: 19 | Batch_idx: 290 |  Loss: (0.1376) | Acc: (95.09%) (8301/8730)\n",
      "Epoch: 19 | Batch_idx: 300 |  Loss: (0.1392) | Acc: (95.02%) (8580/9030)\n",
      "Epoch: 19 | Batch_idx: 310 |  Loss: (0.1376) | Acc: (95.07%) (8870/9330)\n",
      "Epoch: 19 | Batch_idx: 320 |  Loss: (0.1377) | Acc: (95.08%) (9156/9630)\n",
      "Epoch: 19 | Batch_idx: 330 |  Loss: (0.1371) | Acc: (95.12%) (9445/9930)\n",
      "Epoch: 19 | Batch_idx: 340 |  Loss: (0.1376) | Acc: (95.10%) (9729/10230)\n",
      "Epoch: 19 | Batch_idx: 350 |  Loss: (0.1374) | Acc: (95.10%) (10014/10530)\n",
      "Epoch: 19 | Batch_idx: 360 |  Loss: (0.1373) | Acc: (95.10%) (10299/10830)\n",
      "Epoch: 19 | Batch_idx: 370 |  Loss: (0.1376) | Acc: (95.05%) (10579/11130)\n",
      "Epoch: 19 | Batch_idx: 380 |  Loss: (0.1381) | Acc: (95.04%) (10863/11430)\n",
      "Epoch: 19 | Batch_idx: 390 |  Loss: (0.1384) | Acc: (95.04%) (11148/11730)\n",
      "Epoch: 19 | Batch_idx: 400 |  Loss: (0.1400) | Acc: (95.01%) (11430/12030)\n",
      "Epoch: 19 | Batch_idx: 410 |  Loss: (0.1396) | Acc: (95.02%) (11716/12330)\n",
      "Epoch: 19 | Batch_idx: 420 |  Loss: (0.1405) | Acc: (94.96%) (11994/12630)\n",
      "Epoch: 19 | Batch_idx: 430 |  Loss: (0.1406) | Acc: (94.97%) (12280/12930)\n",
      "Epoch: 19 | Batch_idx: 440 |  Loss: (0.1400) | Acc: (95.01%) (12570/13230)\n",
      "Epoch: 19 | Batch_idx: 450 |  Loss: (0.1404) | Acc: (94.99%) (12852/13530)\n",
      "Epoch: 19 | Batch_idx: 460 |  Loss: (0.1415) | Acc: (94.96%) (13133/13830)\n",
      "Epoch: 19 | Batch_idx: 470 |  Loss: (0.1413) | Acc: (94.98%) (13421/14130)\n",
      "Epoch: 19 | Batch_idx: 480 |  Loss: (0.1410) | Acc: (94.98%) (13706/14430)\n",
      "Epoch: 19 | Batch_idx: 490 |  Loss: (0.1403) | Acc: (95.00%) (13994/14730)\n",
      "Epoch: 19 | Batch_idx: 500 |  Loss: (0.1393) | Acc: (95.02%) (14282/15030)\n",
      "Epoch: 19 | Batch_idx: 510 |  Loss: (0.1390) | Acc: (95.04%) (14570/15330)\n",
      "Epoch: 19 | Batch_idx: 520 |  Loss: (0.1382) | Acc: (95.08%) (14861/15630)\n",
      "Epoch: 19 | Batch_idx: 530 |  Loss: (0.1375) | Acc: (95.12%) (15153/15930)\n",
      "Epoch: 19 | Batch_idx: 540 |  Loss: (0.1377) | Acc: (95.12%) (15438/16230)\n",
      "Epoch: 19 | Batch_idx: 550 |  Loss: (0.1374) | Acc: (95.12%) (15723/16530)\n",
      "Epoch: 19 | Batch_idx: 560 |  Loss: (0.1376) | Acc: (95.11%) (16007/16830)\n",
      "Epoch: 19 | Batch_idx: 570 |  Loss: (0.1384) | Acc: (95.09%) (16289/17130)\n",
      "Epoch: 19 | Batch_idx: 580 |  Loss: (0.1375) | Acc: (95.12%) (16579/17430)\n",
      "Epoch: 19 | Batch_idx: 590 |  Loss: (0.1377) | Acc: (95.11%) (16863/17730)\n",
      "Epoch: 19 | Batch_idx: 600 |  Loss: (0.1374) | Acc: (95.12%) (17151/18030)\n",
      "Epoch: 19 | Batch_idx: 610 |  Loss: (0.1381) | Acc: (95.11%) (17433/18330)\n",
      "Epoch: 19 | Batch_idx: 620 |  Loss: (0.1390) | Acc: (95.09%) (17716/18630)\n",
      "Epoch: 19 | Batch_idx: 630 |  Loss: (0.1396) | Acc: (95.06%) (17995/18930)\n",
      "Epoch: 19 | Batch_idx: 640 |  Loss: (0.1397) | Acc: (95.07%) (18282/19230)\n",
      "Epoch: 19 | Batch_idx: 650 |  Loss: (0.1395) | Acc: (95.07%) (18568/19530)\n",
      "Epoch: 19 | Batch_idx: 660 |  Loss: (0.1387) | Acc: (95.10%) (18858/19830)\n",
      "Epoch: 19 | Batch_idx: 670 |  Loss: (0.1384) | Acc: (95.10%) (19143/20130)\n",
      "Epoch: 19 | Batch_idx: 680 |  Loss: (0.1377) | Acc: (95.13%) (19436/20430)\n",
      "Epoch: 19 | Batch_idx: 690 |  Loss: (0.1384) | Acc: (95.12%) (19718/20730)\n",
      "Epoch: 19 | Batch_idx: 700 |  Loss: (0.1384) | Acc: (95.12%) (20003/21030)\n",
      "Epoch: 19 | Batch_idx: 710 |  Loss: (0.1385) | Acc: (95.12%) (20289/21330)\n",
      "Epoch: 19 | Batch_idx: 720 |  Loss: (0.1383) | Acc: (95.13%) (20576/21630)\n",
      "Epoch: 19 | Batch_idx: 730 |  Loss: (0.1382) | Acc: (95.14%) (20865/21930)\n",
      "Epoch: 19 | Batch_idx: 740 |  Loss: (0.1375) | Acc: (95.17%) (21156/22230)\n",
      "Epoch: 19 | Batch_idx: 750 |  Loss: (0.1372) | Acc: (95.17%) (21441/22530)\n",
      "Epoch: 19 | Batch_idx: 760 |  Loss: (0.1365) | Acc: (95.20%) (21734/22830)\n",
      "Epoch: 19 | Batch_idx: 770 |  Loss: (0.1362) | Acc: (95.21%) (22022/23130)\n",
      "Epoch: 19 | Batch_idx: 780 |  Loss: (0.1362) | Acc: (95.19%) (22303/23430)\n",
      "Epoch: 19 | Batch_idx: 790 |  Loss: (0.1359) | Acc: (95.20%) (22592/23730)\n",
      "Epoch: 19 | Batch_idx: 800 |  Loss: (0.1361) | Acc: (95.19%) (22875/24030)\n",
      "Epoch: 19 | Batch_idx: 810 |  Loss: (0.1360) | Acc: (95.19%) (23160/24330)\n",
      "Epoch: 19 | Batch_idx: 820 |  Loss: (0.1357) | Acc: (95.20%) (23447/24630)\n",
      "Epoch: 19 | Batch_idx: 830 |  Loss: (0.1360) | Acc: (95.19%) (23732/24930)\n",
      "Epoch: 19 | Batch_idx: 840 |  Loss: (0.1358) | Acc: (95.20%) (24019/25230)\n",
      "Epoch: 19 | Batch_idx: 850 |  Loss: (0.1358) | Acc: (95.20%) (24304/25530)\n",
      "Epoch: 19 | Batch_idx: 860 |  Loss: (0.1357) | Acc: (95.20%) (24590/25830)\n",
      "Epoch: 19 | Batch_idx: 870 |  Loss: (0.1355) | Acc: (95.20%) (24877/26130)\n",
      "Epoch: 19 | Batch_idx: 880 |  Loss: (0.1353) | Acc: (95.21%) (25165/26430)\n",
      "Epoch: 19 | Batch_idx: 890 |  Loss: (0.1351) | Acc: (95.23%) (25456/26730)\n",
      "Epoch: 19 | Batch_idx: 900 |  Loss: (0.1356) | Acc: (95.22%) (25737/27030)\n",
      "Epoch: 19 | Batch_idx: 910 |  Loss: (0.1355) | Acc: (95.23%) (26026/27330)\n",
      "Epoch: 19 | Batch_idx: 920 |  Loss: (0.1353) | Acc: (95.23%) (26313/27630)\n",
      "Epoch: 19 | Batch_idx: 930 |  Loss: (0.1352) | Acc: (95.24%) (26600/27930)\n",
      "Epoch: 19 | Batch_idx: 940 |  Loss: (0.1355) | Acc: (95.23%) (26884/28230)\n",
      "Epoch: 19 | Batch_idx: 950 |  Loss: (0.1357) | Acc: (95.21%) (27163/28530)\n",
      "Epoch: 19 | Batch_idx: 960 |  Loss: (0.1353) | Acc: (95.22%) (27451/28830)\n",
      "Epoch: 19 | Batch_idx: 970 |  Loss: (0.1354) | Acc: (95.22%) (27738/29130)\n",
      "Epoch: 19 | Batch_idx: 980 |  Loss: (0.1352) | Acc: (95.23%) (28025/29430)\n",
      "Epoch: 19 | Batch_idx: 990 |  Loss: (0.1348) | Acc: (95.24%) (28316/29730)\n",
      "Epoch: 19 | Batch_idx: 1000 |  Loss: (0.1347) | Acc: (95.25%) (28603/30030)\n",
      "Epoch: 19 | Batch_idx: 1010 |  Loss: (0.1347) | Acc: (95.25%) (28890/30330)\n",
      "Epoch: 19 | Batch_idx: 1020 |  Loss: (0.1347) | Acc: (95.27%) (29181/30630)\n",
      "Epoch: 19 | Batch_idx: 1030 |  Loss: (0.1342) | Acc: (95.29%) (29473/30930)\n",
      "Epoch: 19 | Batch_idx: 1040 |  Loss: (0.1340) | Acc: (95.30%) (29762/31230)\n",
      "Epoch: 19 | Batch_idx: 1050 |  Loss: (0.1343) | Acc: (95.30%) (30047/31530)\n",
      "Epoch: 19 | Batch_idx: 1060 |  Loss: (0.1344) | Acc: (95.29%) (30331/31830)\n",
      "Epoch: 19 | Batch_idx: 1070 |  Loss: (0.1346) | Acc: (95.28%) (30614/32130)\n",
      "Epoch: 19 | Batch_idx: 1080 |  Loss: (0.1346) | Acc: (95.29%) (30901/32430)\n",
      "Epoch: 19 | Batch_idx: 1090 |  Loss: (0.1348) | Acc: (95.27%) (31182/32730)\n",
      "Epoch: 19 | Batch_idx: 1100 |  Loss: (0.1345) | Acc: (95.28%) (31472/33030)\n",
      "Epoch: 19 | Batch_idx: 1110 |  Loss: (0.1345) | Acc: (95.29%) (31760/33330)\n",
      "Epoch: 19 | Batch_idx: 1120 |  Loss: (0.1345) | Acc: (95.29%) (32046/33630)\n",
      "Epoch: 19 | Batch_idx: 1130 |  Loss: (0.1347) | Acc: (95.28%) (32328/33930)\n",
      "Epoch: 19 | Batch_idx: 1140 |  Loss: (0.1349) | Acc: (95.27%) (32610/34230)\n",
      "Epoch: 19 | Batch_idx: 1150 |  Loss: (0.1351) | Acc: (95.26%) (32894/34530)\n",
      "Epoch: 19 | Batch_idx: 1160 |  Loss: (0.1357) | Acc: (95.25%) (33176/34830)\n",
      "Epoch: 19 | Batch_idx: 1170 |  Loss: (0.1358) | Acc: (95.24%) (33459/35130)\n",
      "Epoch: 19 | Batch_idx: 1180 |  Loss: (0.1361) | Acc: (95.23%) (33739/35430)\n",
      "Epoch: 19 | Batch_idx: 1190 |  Loss: (0.1363) | Acc: (95.22%) (34023/35730)\n",
      "Epoch: 19 | Batch_idx: 1200 |  Loss: (0.1363) | Acc: (95.23%) (34310/36030)\n",
      "Epoch: 19 | Batch_idx: 1210 |  Loss: (0.1366) | Acc: (95.21%) (34591/36330)\n",
      "Epoch: 19 | Batch_idx: 1220 |  Loss: (0.1367) | Acc: (95.21%) (34875/36630)\n",
      "Epoch: 19 | Batch_idx: 1230 |  Loss: (0.1367) | Acc: (95.22%) (35163/36930)\n",
      "Epoch: 19 | Batch_idx: 1240 |  Loss: (0.1368) | Acc: (95.21%) (35448/37230)\n",
      "Epoch: 19 | Batch_idx: 1250 |  Loss: (0.1369) | Acc: (95.21%) (35733/37530)\n",
      "Epoch: 19 | Batch_idx: 1260 |  Loss: (0.1372) | Acc: (95.20%) (36015/37830)\n",
      "Epoch: 19 | Batch_idx: 1270 |  Loss: (0.1372) | Acc: (95.20%) (36300/38130)\n",
      "Epoch: 19 | Batch_idx: 1280 |  Loss: (0.1372) | Acc: (95.19%) (36583/38430)\n",
      "Epoch: 19 | Batch_idx: 1290 |  Loss: (0.1373) | Acc: (95.19%) (36867/38730)\n",
      "Epoch: 19 | Batch_idx: 1300 |  Loss: (0.1373) | Acc: (95.18%) (37149/39030)\n",
      "Epoch: 19 | Batch_idx: 1310 |  Loss: (0.1374) | Acc: (95.17%) (37431/39330)\n",
      "Epoch: 19 | Batch_idx: 1320 |  Loss: (0.1377) | Acc: (95.17%) (37714/39630)\n",
      "Epoch: 19 | Batch_idx: 1330 |  Loss: (0.1377) | Acc: (95.16%) (37999/39930)\n",
      "Epoch: 19 | Batch_idx: 1340 |  Loss: (0.1379) | Acc: (95.15%) (38280/40230)\n",
      "Epoch: 19 | Batch_idx: 1350 |  Loss: (0.1378) | Acc: (95.16%) (38568/40530)\n",
      "Epoch: 19 | Batch_idx: 1360 |  Loss: (0.1378) | Acc: (95.16%) (38852/40830)\n",
      "Epoch: 19 | Batch_idx: 1370 |  Loss: (0.1380) | Acc: (95.14%) (39132/41130)\n",
      "Epoch: 19 | Batch_idx: 1380 |  Loss: (0.1382) | Acc: (95.12%) (39409/41430)\n",
      "Epoch: 19 | Batch_idx: 1390 |  Loss: (0.1383) | Acc: (95.13%) (39696/41730)\n",
      "Epoch: 19 | Batch_idx: 1400 |  Loss: (0.1384) | Acc: (95.12%) (39978/42030)\n",
      "Epoch: 19 | Batch_idx: 1410 |  Loss: (0.1384) | Acc: (95.12%) (40266/42330)\n",
      "Epoch: 19 | Batch_idx: 1420 |  Loss: (0.1383) | Acc: (95.12%) (40548/42630)\n",
      "Epoch: 19 | Batch_idx: 1430 |  Loss: (0.1383) | Acc: (95.12%) (40833/42930)\n",
      "Epoch: 19 | Batch_idx: 1440 |  Loss: (0.1386) | Acc: (95.10%) (41110/43230)\n",
      "Epoch: 19 | Batch_idx: 1450 |  Loss: (0.1386) | Acc: (95.09%) (41393/43530)\n",
      "Epoch: 19 | Batch_idx: 1460 |  Loss: (0.1385) | Acc: (95.10%) (41682/43830)\n",
      "Epoch: 19 | Batch_idx: 1470 |  Loss: (0.1386) | Acc: (95.11%) (41970/44130)\n",
      "Epoch: 19 | Batch_idx: 1480 |  Loss: (0.1386) | Acc: (95.10%) (42255/44430)\n",
      "Epoch: 19 | Batch_idx: 1490 |  Loss: (0.1388) | Acc: (95.11%) (42541/44730)\n",
      "Epoch: 19 | Batch_idx: 1500 |  Loss: (0.1388) | Acc: (95.11%) (42827/45030)\n",
      "Epoch: 19 | Batch_idx: 1510 |  Loss: (0.1388) | Acc: (95.11%) (43113/45330)\n",
      "Epoch: 19 | Batch_idx: 1520 |  Loss: (0.1391) | Acc: (95.11%) (43398/45630)\n",
      "Epoch: 19 | Batch_idx: 1530 |  Loss: (0.1390) | Acc: (95.11%) (43683/45930)\n",
      "Epoch: 19 | Batch_idx: 1540 |  Loss: (0.1392) | Acc: (95.10%) (43966/46230)\n",
      "Epoch: 19 | Batch_idx: 1550 |  Loss: (0.1394) | Acc: (95.08%) (44241/46530)\n",
      "Epoch: 19 | Batch_idx: 1560 |  Loss: (0.1393) | Acc: (95.09%) (44529/46830)\n",
      "Epoch: 19 | Batch_idx: 1570 |  Loss: (0.1397) | Acc: (95.08%) (44810/47130)\n",
      "Epoch: 19 | Batch_idx: 1580 |  Loss: (0.1395) | Acc: (95.09%) (45100/47430)\n",
      "Epoch: 19 | Batch_idx: 1590 |  Loss: (0.1394) | Acc: (95.09%) (45386/47730)\n",
      "Epoch: 19 | Batch_idx: 1600 |  Loss: (0.1393) | Acc: (95.10%) (45675/48030)\n",
      "Epoch: 19 | Batch_idx: 1610 |  Loss: (0.1395) | Acc: (95.09%) (45957/48330)\n",
      "Epoch: 19 | Batch_idx: 1620 |  Loss: (0.1396) | Acc: (95.09%) (46244/48630)\n",
      "Epoch: 19 | Batch_idx: 1630 |  Loss: (0.1396) | Acc: (95.10%) (46530/48930)\n",
      "Epoch: 19 | Batch_idx: 1640 |  Loss: (0.1395) | Acc: (95.10%) (46817/49230)\n",
      "Epoch: 19 | Batch_idx: 1650 |  Loss: (0.1395) | Acc: (95.10%) (47104/49530)\n",
      "Epoch: 19 | Batch_idx: 1660 |  Loss: (0.1396) | Acc: (95.10%) (47389/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3172) | Acc: (90.56%) (9056/10000)\n",
      "Epoch: 20 | Batch_idx: 0 |  Loss: (0.0696) | Acc: (96.67%) (29/30)\n",
      "Epoch: 20 | Batch_idx: 10 |  Loss: (0.1046) | Acc: (97.27%) (321/330)\n",
      "Epoch: 20 | Batch_idx: 20 |  Loss: (0.1360) | Acc: (96.51%) (608/630)\n",
      "Epoch: 20 | Batch_idx: 30 |  Loss: (0.1280) | Acc: (96.24%) (895/930)\n",
      "Epoch: 20 | Batch_idx: 40 |  Loss: (0.1263) | Acc: (96.26%) (1184/1230)\n",
      "Epoch: 20 | Batch_idx: 50 |  Loss: (0.1197) | Acc: (96.54%) (1477/1530)\n",
      "Epoch: 20 | Batch_idx: 60 |  Loss: (0.1243) | Acc: (96.34%) (1763/1830)\n",
      "Epoch: 20 | Batch_idx: 70 |  Loss: (0.1306) | Acc: (96.06%) (2046/2130)\n",
      "Epoch: 20 | Batch_idx: 80 |  Loss: (0.1306) | Acc: (95.84%) (2329/2430)\n",
      "Epoch: 20 | Batch_idx: 90 |  Loss: (0.1345) | Acc: (95.82%) (2616/2730)\n",
      "Epoch: 20 | Batch_idx: 100 |  Loss: (0.1322) | Acc: (95.87%) (2905/3030)\n",
      "Epoch: 20 | Batch_idx: 110 |  Loss: (0.1310) | Acc: (95.95%) (3195/3330)\n",
      "Epoch: 20 | Batch_idx: 120 |  Loss: (0.1292) | Acc: (95.90%) (3481/3630)\n",
      "Epoch: 20 | Batch_idx: 130 |  Loss: (0.1288) | Acc: (95.90%) (3769/3930)\n",
      "Epoch: 20 | Batch_idx: 140 |  Loss: (0.1270) | Acc: (95.93%) (4058/4230)\n",
      "Epoch: 20 | Batch_idx: 150 |  Loss: (0.1247) | Acc: (96.03%) (4350/4530)\n",
      "Epoch: 20 | Batch_idx: 160 |  Loss: (0.1233) | Acc: (96.07%) (4640/4830)\n",
      "Epoch: 20 | Batch_idx: 170 |  Loss: (0.1210) | Acc: (96.14%) (4932/5130)\n",
      "Epoch: 20 | Batch_idx: 180 |  Loss: (0.1189) | Acc: (96.26%) (5227/5430)\n",
      "Epoch: 20 | Batch_idx: 190 |  Loss: (0.1188) | Acc: (96.20%) (5512/5730)\n",
      "Epoch: 20 | Batch_idx: 200 |  Loss: (0.1202) | Acc: (96.10%) (5795/6030)\n",
      "Epoch: 20 | Batch_idx: 210 |  Loss: (0.1204) | Acc: (96.16%) (6087/6330)\n",
      "Epoch: 20 | Batch_idx: 220 |  Loss: (0.1208) | Acc: (96.08%) (6370/6630)\n",
      "Epoch: 20 | Batch_idx: 230 |  Loss: (0.1199) | Acc: (96.10%) (6660/6930)\n",
      "Epoch: 20 | Batch_idx: 240 |  Loss: (0.1225) | Acc: (95.98%) (6939/7230)\n",
      "Epoch: 20 | Batch_idx: 250 |  Loss: (0.1233) | Acc: (95.95%) (7225/7530)\n",
      "Epoch: 20 | Batch_idx: 260 |  Loss: (0.1232) | Acc: (95.94%) (7512/7830)\n",
      "Epoch: 20 | Batch_idx: 270 |  Loss: (0.1249) | Acc: (95.85%) (7793/8130)\n",
      "Epoch: 20 | Batch_idx: 280 |  Loss: (0.1245) | Acc: (95.88%) (8083/8430)\n",
      "Epoch: 20 | Batch_idx: 290 |  Loss: (0.1246) | Acc: (95.83%) (8366/8730)\n",
      "Epoch: 20 | Batch_idx: 300 |  Loss: (0.1239) | Acc: (95.87%) (8657/9030)\n",
      "Epoch: 20 | Batch_idx: 310 |  Loss: (0.1235) | Acc: (95.87%) (8945/9330)\n",
      "Epoch: 20 | Batch_idx: 320 |  Loss: (0.1229) | Acc: (95.92%) (9237/9630)\n",
      "Epoch: 20 | Batch_idx: 330 |  Loss: (0.1220) | Acc: (95.94%) (9527/9930)\n",
      "Epoch: 20 | Batch_idx: 340 |  Loss: (0.1225) | Acc: (95.91%) (9812/10230)\n",
      "Epoch: 20 | Batch_idx: 350 |  Loss: (0.1220) | Acc: (95.92%) (10100/10530)\n",
      "Epoch: 20 | Batch_idx: 360 |  Loss: (0.1207) | Acc: (95.95%) (10391/10830)\n",
      "Epoch: 20 | Batch_idx: 370 |  Loss: (0.1194) | Acc: (95.98%) (10683/11130)\n",
      "Epoch: 20 | Batch_idx: 380 |  Loss: (0.1188) | Acc: (96.01%) (10974/11430)\n",
      "Epoch: 20 | Batch_idx: 390 |  Loss: (0.1194) | Acc: (96.02%) (11263/11730)\n",
      "Epoch: 20 | Batch_idx: 400 |  Loss: (0.1194) | Acc: (96.03%) (11552/12030)\n",
      "Epoch: 20 | Batch_idx: 410 |  Loss: (0.1198) | Acc: (96.01%) (11838/12330)\n",
      "Epoch: 20 | Batch_idx: 420 |  Loss: (0.1202) | Acc: (95.97%) (12121/12630)\n",
      "Epoch: 20 | Batch_idx: 430 |  Loss: (0.1214) | Acc: (95.95%) (12406/12930)\n",
      "Epoch: 20 | Batch_idx: 440 |  Loss: (0.1201) | Acc: (95.98%) (12698/13230)\n",
      "Epoch: 20 | Batch_idx: 450 |  Loss: (0.1206) | Acc: (95.95%) (12982/13530)\n",
      "Epoch: 20 | Batch_idx: 460 |  Loss: (0.1212) | Acc: (95.94%) (13269/13830)\n",
      "Epoch: 20 | Batch_idx: 470 |  Loss: (0.1212) | Acc: (95.94%) (13557/14130)\n",
      "Epoch: 20 | Batch_idx: 480 |  Loss: (0.1206) | Acc: (95.95%) (13846/14430)\n",
      "Epoch: 20 | Batch_idx: 490 |  Loss: (0.1199) | Acc: (95.98%) (14138/14730)\n",
      "Epoch: 20 | Batch_idx: 500 |  Loss: (0.1199) | Acc: (95.97%) (14425/15030)\n",
      "Epoch: 20 | Batch_idx: 510 |  Loss: (0.1197) | Acc: (95.99%) (14715/15330)\n",
      "Epoch: 20 | Batch_idx: 520 |  Loss: (0.1195) | Acc: (95.99%) (15003/15630)\n",
      "Epoch: 20 | Batch_idx: 530 |  Loss: (0.1195) | Acc: (95.98%) (15290/15930)\n",
      "Epoch: 20 | Batch_idx: 540 |  Loss: (0.1193) | Acc: (95.97%) (15576/16230)\n",
      "Epoch: 20 | Batch_idx: 550 |  Loss: (0.1194) | Acc: (95.95%) (15861/16530)\n",
      "Epoch: 20 | Batch_idx: 560 |  Loss: (0.1190) | Acc: (95.97%) (16152/16830)\n",
      "Epoch: 20 | Batch_idx: 570 |  Loss: (0.1198) | Acc: (95.94%) (16435/17130)\n",
      "Epoch: 20 | Batch_idx: 580 |  Loss: (0.1194) | Acc: (95.97%) (16727/17430)\n",
      "Epoch: 20 | Batch_idx: 590 |  Loss: (0.1188) | Acc: (96.00%) (17021/17730)\n",
      "Epoch: 20 | Batch_idx: 600 |  Loss: (0.1185) | Acc: (96.00%) (17309/18030)\n",
      "Epoch: 20 | Batch_idx: 610 |  Loss: (0.1191) | Acc: (96.00%) (17596/18330)\n",
      "Epoch: 20 | Batch_idx: 620 |  Loss: (0.1197) | Acc: (95.97%) (17880/18630)\n",
      "Epoch: 20 | Batch_idx: 630 |  Loss: (0.1198) | Acc: (95.97%) (18167/18930)\n",
      "Epoch: 20 | Batch_idx: 640 |  Loss: (0.1197) | Acc: (95.96%) (18454/19230)\n",
      "Epoch: 20 | Batch_idx: 650 |  Loss: (0.1196) | Acc: (95.98%) (18745/19530)\n",
      "Epoch: 20 | Batch_idx: 660 |  Loss: (0.1201) | Acc: (95.97%) (19030/19830)\n",
      "Epoch: 20 | Batch_idx: 670 |  Loss: (0.1201) | Acc: (95.97%) (19318/20130)\n",
      "Epoch: 20 | Batch_idx: 680 |  Loss: (0.1201) | Acc: (95.97%) (19606/20430)\n",
      "Epoch: 20 | Batch_idx: 690 |  Loss: (0.1207) | Acc: (95.94%) (19889/20730)\n",
      "Epoch: 20 | Batch_idx: 700 |  Loss: (0.1218) | Acc: (95.91%) (20170/21030)\n",
      "Epoch: 20 | Batch_idx: 710 |  Loss: (0.1218) | Acc: (95.90%) (20456/21330)\n",
      "Epoch: 20 | Batch_idx: 720 |  Loss: (0.1216) | Acc: (95.91%) (20745/21630)\n",
      "Epoch: 20 | Batch_idx: 730 |  Loss: (0.1216) | Acc: (95.90%) (21030/21930)\n",
      "Epoch: 20 | Batch_idx: 740 |  Loss: (0.1215) | Acc: (95.90%) (21318/22230)\n",
      "Epoch: 20 | Batch_idx: 750 |  Loss: (0.1210) | Acc: (95.92%) (21610/22530)\n",
      "Epoch: 20 | Batch_idx: 760 |  Loss: (0.1210) | Acc: (95.90%) (21895/22830)\n",
      "Epoch: 20 | Batch_idx: 770 |  Loss: (0.1210) | Acc: (95.89%) (22180/23130)\n",
      "Epoch: 20 | Batch_idx: 780 |  Loss: (0.1209) | Acc: (95.90%) (22470/23430)\n",
      "Epoch: 20 | Batch_idx: 790 |  Loss: (0.1213) | Acc: (95.90%) (22756/23730)\n",
      "Epoch: 20 | Batch_idx: 800 |  Loss: (0.1215) | Acc: (95.89%) (23043/24030)\n",
      "Epoch: 20 | Batch_idx: 810 |  Loss: (0.1213) | Acc: (95.89%) (23330/24330)\n",
      "Epoch: 20 | Batch_idx: 820 |  Loss: (0.1213) | Acc: (95.88%) (23615/24630)\n",
      "Epoch: 20 | Batch_idx: 830 |  Loss: (0.1214) | Acc: (95.88%) (23903/24930)\n",
      "Epoch: 20 | Batch_idx: 840 |  Loss: (0.1215) | Acc: (95.90%) (24196/25230)\n",
      "Epoch: 20 | Batch_idx: 850 |  Loss: (0.1214) | Acc: (95.91%) (24485/25530)\n",
      "Epoch: 20 | Batch_idx: 860 |  Loss: (0.1212) | Acc: (95.93%) (24778/25830)\n",
      "Epoch: 20 | Batch_idx: 870 |  Loss: (0.1212) | Acc: (95.93%) (25067/26130)\n",
      "Epoch: 20 | Batch_idx: 880 |  Loss: (0.1212) | Acc: (95.92%) (25352/26430)\n",
      "Epoch: 20 | Batch_idx: 890 |  Loss: (0.1214) | Acc: (95.90%) (25635/26730)\n",
      "Epoch: 20 | Batch_idx: 900 |  Loss: (0.1210) | Acc: (95.90%) (25923/27030)\n",
      "Epoch: 20 | Batch_idx: 910 |  Loss: (0.1212) | Acc: (95.89%) (26208/27330)\n",
      "Epoch: 20 | Batch_idx: 920 |  Loss: (0.1228) | Acc: (95.86%) (26485/27630)\n",
      "Epoch: 20 | Batch_idx: 930 |  Loss: (0.1231) | Acc: (95.83%) (26766/27930)\n",
      "Epoch: 20 | Batch_idx: 940 |  Loss: (0.1232) | Acc: (95.83%) (27052/28230)\n",
      "Epoch: 20 | Batch_idx: 950 |  Loss: (0.1231) | Acc: (95.82%) (27337/28530)\n",
      "Epoch: 20 | Batch_idx: 960 |  Loss: (0.1236) | Acc: (95.80%) (27619/28830)\n",
      "Epoch: 20 | Batch_idx: 970 |  Loss: (0.1238) | Acc: (95.79%) (27903/29130)\n",
      "Epoch: 20 | Batch_idx: 980 |  Loss: (0.1235) | Acc: (95.80%) (28194/29430)\n",
      "Epoch: 20 | Batch_idx: 990 |  Loss: (0.1232) | Acc: (95.81%) (28484/29730)\n",
      "Epoch: 20 | Batch_idx: 1000 |  Loss: (0.1231) | Acc: (95.80%) (28770/30030)\n",
      "Epoch: 20 | Batch_idx: 1010 |  Loss: (0.1236) | Acc: (95.77%) (29046/30330)\n",
      "Epoch: 20 | Batch_idx: 1020 |  Loss: (0.1234) | Acc: (95.77%) (29335/30630)\n",
      "Epoch: 20 | Batch_idx: 1030 |  Loss: (0.1232) | Acc: (95.77%) (29622/30930)\n",
      "Epoch: 20 | Batch_idx: 1040 |  Loss: (0.1231) | Acc: (95.78%) (29911/31230)\n",
      "Epoch: 20 | Batch_idx: 1050 |  Loss: (0.1234) | Acc: (95.77%) (30197/31530)\n",
      "Epoch: 20 | Batch_idx: 1060 |  Loss: (0.1234) | Acc: (95.77%) (30484/31830)\n",
      "Epoch: 20 | Batch_idx: 1070 |  Loss: (0.1232) | Acc: (95.78%) (30773/32130)\n",
      "Epoch: 20 | Batch_idx: 1080 |  Loss: (0.1231) | Acc: (95.78%) (31061/32430)\n",
      "Epoch: 20 | Batch_idx: 1090 |  Loss: (0.1235) | Acc: (95.77%) (31346/32730)\n",
      "Epoch: 20 | Batch_idx: 1100 |  Loss: (0.1233) | Acc: (95.78%) (31635/33030)\n",
      "Epoch: 20 | Batch_idx: 1110 |  Loss: (0.1230) | Acc: (95.80%) (31929/33330)\n",
      "Epoch: 20 | Batch_idx: 1120 |  Loss: (0.1229) | Acc: (95.80%) (32217/33630)\n",
      "Epoch: 20 | Batch_idx: 1130 |  Loss: (0.1234) | Acc: (95.79%) (32500/33930)\n",
      "Epoch: 20 | Batch_idx: 1140 |  Loss: (0.1238) | Acc: (95.77%) (32781/34230)\n",
      "Epoch: 20 | Batch_idx: 1150 |  Loss: (0.1234) | Acc: (95.78%) (33073/34530)\n",
      "Epoch: 20 | Batch_idx: 1160 |  Loss: (0.1237) | Acc: (95.77%) (33358/34830)\n",
      "Epoch: 20 | Batch_idx: 1170 |  Loss: (0.1237) | Acc: (95.78%) (33647/35130)\n",
      "Epoch: 20 | Batch_idx: 1180 |  Loss: (0.1236) | Acc: (95.79%) (33937/35430)\n",
      "Epoch: 20 | Batch_idx: 1190 |  Loss: (0.1237) | Acc: (95.79%) (34224/35730)\n",
      "Epoch: 20 | Batch_idx: 1200 |  Loss: (0.1238) | Acc: (95.78%) (34508/36030)\n",
      "Epoch: 20 | Batch_idx: 1210 |  Loss: (0.1235) | Acc: (95.80%) (34803/36330)\n",
      "Epoch: 20 | Batch_idx: 1220 |  Loss: (0.1233) | Acc: (95.81%) (35094/36630)\n",
      "Epoch: 20 | Batch_idx: 1230 |  Loss: (0.1233) | Acc: (95.80%) (35378/36930)\n",
      "Epoch: 20 | Batch_idx: 1240 |  Loss: (0.1231) | Acc: (95.80%) (35665/37230)\n",
      "Epoch: 20 | Batch_idx: 1250 |  Loss: (0.1235) | Acc: (95.78%) (35945/37530)\n",
      "Epoch: 20 | Batch_idx: 1260 |  Loss: (0.1238) | Acc: (95.76%) (36225/37830)\n",
      "Epoch: 20 | Batch_idx: 1270 |  Loss: (0.1236) | Acc: (95.76%) (36514/38130)\n",
      "Epoch: 20 | Batch_idx: 1280 |  Loss: (0.1236) | Acc: (95.77%) (36803/38430)\n",
      "Epoch: 20 | Batch_idx: 1290 |  Loss: (0.1237) | Acc: (95.76%) (37086/38730)\n",
      "Epoch: 20 | Batch_idx: 1300 |  Loss: (0.1238) | Acc: (95.74%) (37369/39030)\n",
      "Epoch: 20 | Batch_idx: 1310 |  Loss: (0.1244) | Acc: (95.71%) (37643/39330)\n",
      "Epoch: 20 | Batch_idx: 1320 |  Loss: (0.1244) | Acc: (95.71%) (37928/39630)\n",
      "Epoch: 20 | Batch_idx: 1330 |  Loss: (0.1243) | Acc: (95.71%) (38216/39930)\n",
      "Epoch: 20 | Batch_idx: 1340 |  Loss: (0.1245) | Acc: (95.71%) (38504/40230)\n",
      "Epoch: 20 | Batch_idx: 1350 |  Loss: (0.1245) | Acc: (95.71%) (38793/40530)\n",
      "Epoch: 20 | Batch_idx: 1360 |  Loss: (0.1244) | Acc: (95.72%) (39082/40830)\n",
      "Epoch: 20 | Batch_idx: 1370 |  Loss: (0.1247) | Acc: (95.71%) (39364/41130)\n",
      "Epoch: 20 | Batch_idx: 1380 |  Loss: (0.1246) | Acc: (95.71%) (39652/41430)\n",
      "Epoch: 20 | Batch_idx: 1390 |  Loss: (0.1247) | Acc: (95.71%) (39940/41730)\n",
      "Epoch: 20 | Batch_idx: 1400 |  Loss: (0.1245) | Acc: (95.71%) (40229/42030)\n",
      "Epoch: 20 | Batch_idx: 1410 |  Loss: (0.1246) | Acc: (95.71%) (40513/42330)\n",
      "Epoch: 20 | Batch_idx: 1420 |  Loss: (0.1244) | Acc: (95.71%) (40802/42630)\n",
      "Epoch: 20 | Batch_idx: 1430 |  Loss: (0.1242) | Acc: (95.72%) (41092/42930)\n",
      "Epoch: 20 | Batch_idx: 1440 |  Loss: (0.1242) | Acc: (95.73%) (41382/43230)\n",
      "Epoch: 20 | Batch_idx: 1450 |  Loss: (0.1244) | Acc: (95.72%) (41665/43530)\n",
      "Epoch: 20 | Batch_idx: 1460 |  Loss: (0.1243) | Acc: (95.72%) (41954/43830)\n",
      "Epoch: 20 | Batch_idx: 1470 |  Loss: (0.1243) | Acc: (95.72%) (42240/44130)\n",
      "Epoch: 20 | Batch_idx: 1480 |  Loss: (0.1242) | Acc: (95.72%) (42527/44430)\n",
      "Epoch: 20 | Batch_idx: 1490 |  Loss: (0.1244) | Acc: (95.70%) (42806/44730)\n",
      "Epoch: 20 | Batch_idx: 1500 |  Loss: (0.1243) | Acc: (95.70%) (43093/45030)\n",
      "Epoch: 20 | Batch_idx: 1510 |  Loss: (0.1244) | Acc: (95.70%) (43379/45330)\n",
      "Epoch: 20 | Batch_idx: 1520 |  Loss: (0.1245) | Acc: (95.70%) (43667/45630)\n",
      "Epoch: 20 | Batch_idx: 1530 |  Loss: (0.1247) | Acc: (95.70%) (43955/45930)\n",
      "Epoch: 20 | Batch_idx: 1540 |  Loss: (0.1248) | Acc: (95.69%) (44239/46230)\n",
      "Epoch: 20 | Batch_idx: 1550 |  Loss: (0.1249) | Acc: (95.69%) (44526/46530)\n",
      "Epoch: 20 | Batch_idx: 1560 |  Loss: (0.1249) | Acc: (95.69%) (44811/46830)\n",
      "Epoch: 20 | Batch_idx: 1570 |  Loss: (0.1249) | Acc: (95.69%) (45099/47130)\n",
      "Epoch: 20 | Batch_idx: 1580 |  Loss: (0.1247) | Acc: (95.70%) (45389/47430)\n",
      "Epoch: 20 | Batch_idx: 1590 |  Loss: (0.1247) | Acc: (95.69%) (45675/47730)\n",
      "Epoch: 20 | Batch_idx: 1600 |  Loss: (0.1247) | Acc: (95.69%) (45959/48030)\n",
      "Epoch: 20 | Batch_idx: 1610 |  Loss: (0.1250) | Acc: (95.68%) (46243/48330)\n",
      "Epoch: 20 | Batch_idx: 1620 |  Loss: (0.1254) | Acc: (95.67%) (46524/48630)\n",
      "Epoch: 20 | Batch_idx: 1630 |  Loss: (0.1256) | Acc: (95.66%) (46805/48930)\n",
      "Epoch: 20 | Batch_idx: 1640 |  Loss: (0.1258) | Acc: (95.65%) (47088/49230)\n",
      "Epoch: 20 | Batch_idx: 1650 |  Loss: (0.1260) | Acc: (95.64%) (47369/49530)\n",
      "Epoch: 20 | Batch_idx: 1660 |  Loss: (0.1262) | Acc: (95.63%) (47652/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.4156) | Acc: (88.67%) (8867/10000)\n",
      "Epoch: 21 | Batch_idx: 0 |  Loss: (0.1627) | Acc: (93.33%) (28/30)\n",
      "Epoch: 21 | Batch_idx: 10 |  Loss: (0.1360) | Acc: (95.45%) (315/330)\n",
      "Epoch: 21 | Batch_idx: 20 |  Loss: (0.1238) | Acc: (95.71%) (603/630)\n",
      "Epoch: 21 | Batch_idx: 30 |  Loss: (0.1231) | Acc: (95.81%) (891/930)\n",
      "Epoch: 21 | Batch_idx: 40 |  Loss: (0.1117) | Acc: (96.10%) (1182/1230)\n",
      "Epoch: 21 | Batch_idx: 50 |  Loss: (0.1117) | Acc: (96.14%) (1471/1530)\n",
      "Epoch: 21 | Batch_idx: 60 |  Loss: (0.1161) | Acc: (95.90%) (1755/1830)\n",
      "Epoch: 21 | Batch_idx: 70 |  Loss: (0.1115) | Acc: (96.20%) (2049/2130)\n",
      "Epoch: 21 | Batch_idx: 80 |  Loss: (0.1127) | Acc: (96.01%) (2333/2430)\n",
      "Epoch: 21 | Batch_idx: 90 |  Loss: (0.1111) | Acc: (96.15%) (2625/2730)\n",
      "Epoch: 21 | Batch_idx: 100 |  Loss: (0.1117) | Acc: (96.14%) (2913/3030)\n",
      "Epoch: 21 | Batch_idx: 110 |  Loss: (0.1141) | Acc: (96.07%) (3199/3330)\n",
      "Epoch: 21 | Batch_idx: 120 |  Loss: (0.1117) | Acc: (96.23%) (3493/3630)\n",
      "Epoch: 21 | Batch_idx: 130 |  Loss: (0.1113) | Acc: (96.31%) (3785/3930)\n",
      "Epoch: 21 | Batch_idx: 140 |  Loss: (0.1111) | Acc: (96.26%) (4072/4230)\n",
      "Epoch: 21 | Batch_idx: 150 |  Loss: (0.1148) | Acc: (96.16%) (4356/4530)\n",
      "Epoch: 21 | Batch_idx: 160 |  Loss: (0.1136) | Acc: (96.23%) (4648/4830)\n",
      "Epoch: 21 | Batch_idx: 170 |  Loss: (0.1160) | Acc: (96.16%) (4933/5130)\n",
      "Epoch: 21 | Batch_idx: 180 |  Loss: (0.1156) | Acc: (96.17%) (5222/5430)\n",
      "Epoch: 21 | Batch_idx: 190 |  Loss: (0.1160) | Acc: (96.07%) (5505/5730)\n",
      "Epoch: 21 | Batch_idx: 200 |  Loss: (0.1169) | Acc: (96.02%) (5790/6030)\n",
      "Epoch: 21 | Batch_idx: 210 |  Loss: (0.1155) | Acc: (96.08%) (6082/6330)\n",
      "Epoch: 21 | Batch_idx: 220 |  Loss: (0.1144) | Acc: (96.14%) (6374/6630)\n",
      "Epoch: 21 | Batch_idx: 230 |  Loss: (0.1126) | Acc: (96.22%) (6668/6930)\n",
      "Epoch: 21 | Batch_idx: 240 |  Loss: (0.1137) | Acc: (96.11%) (6949/7230)\n",
      "Epoch: 21 | Batch_idx: 250 |  Loss: (0.1135) | Acc: (96.11%) (7237/7530)\n",
      "Epoch: 21 | Batch_idx: 260 |  Loss: (0.1109) | Acc: (96.23%) (7535/7830)\n",
      "Epoch: 21 | Batch_idx: 270 |  Loss: (0.1094) | Acc: (96.29%) (7828/8130)\n",
      "Epoch: 21 | Batch_idx: 280 |  Loss: (0.1089) | Acc: (96.31%) (8119/8430)\n",
      "Epoch: 21 | Batch_idx: 290 |  Loss: (0.1082) | Acc: (96.36%) (8412/8730)\n",
      "Epoch: 21 | Batch_idx: 300 |  Loss: (0.1083) | Acc: (96.37%) (8702/9030)\n",
      "Epoch: 21 | Batch_idx: 310 |  Loss: (0.1086) | Acc: (96.35%) (8989/9330)\n",
      "Epoch: 21 | Batch_idx: 320 |  Loss: (0.1090) | Acc: (96.34%) (9278/9630)\n",
      "Epoch: 21 | Batch_idx: 330 |  Loss: (0.1098) | Acc: (96.30%) (9563/9930)\n",
      "Epoch: 21 | Batch_idx: 340 |  Loss: (0.1101) | Acc: (96.30%) (9852/10230)\n",
      "Epoch: 21 | Batch_idx: 350 |  Loss: (0.1089) | Acc: (96.33%) (10144/10530)\n",
      "Epoch: 21 | Batch_idx: 360 |  Loss: (0.1088) | Acc: (96.33%) (10432/10830)\n",
      "Epoch: 21 | Batch_idx: 370 |  Loss: (0.1094) | Acc: (96.34%) (10723/11130)\n",
      "Epoch: 21 | Batch_idx: 380 |  Loss: (0.1085) | Acc: (96.39%) (11017/11430)\n",
      "Epoch: 21 | Batch_idx: 390 |  Loss: (0.1085) | Acc: (96.37%) (11304/11730)\n",
      "Epoch: 21 | Batch_idx: 400 |  Loss: (0.1082) | Acc: (96.37%) (11593/12030)\n",
      "Epoch: 21 | Batch_idx: 410 |  Loss: (0.1076) | Acc: (96.39%) (11885/12330)\n",
      "Epoch: 21 | Batch_idx: 420 |  Loss: (0.1077) | Acc: (96.40%) (12175/12630)\n",
      "Epoch: 21 | Batch_idx: 430 |  Loss: (0.1072) | Acc: (96.40%) (12464/12930)\n",
      "Epoch: 21 | Batch_idx: 440 |  Loss: (0.1069) | Acc: (96.36%) (12749/13230)\n",
      "Epoch: 21 | Batch_idx: 450 |  Loss: (0.1060) | Acc: (96.39%) (13042/13530)\n",
      "Epoch: 21 | Batch_idx: 460 |  Loss: (0.1059) | Acc: (96.40%) (13332/13830)\n",
      "Epoch: 21 | Batch_idx: 470 |  Loss: (0.1055) | Acc: (96.42%) (13624/14130)\n",
      "Epoch: 21 | Batch_idx: 480 |  Loss: (0.1079) | Acc: (96.35%) (13903/14430)\n",
      "Epoch: 21 | Batch_idx: 490 |  Loss: (0.1079) | Acc: (96.35%) (14193/14730)\n",
      "Epoch: 21 | Batch_idx: 500 |  Loss: (0.1079) | Acc: (96.35%) (14482/15030)\n",
      "Epoch: 21 | Batch_idx: 510 |  Loss: (0.1086) | Acc: (96.33%) (14768/15330)\n",
      "Epoch: 21 | Batch_idx: 520 |  Loss: (0.1088) | Acc: (96.33%) (15057/15630)\n",
      "Epoch: 21 | Batch_idx: 530 |  Loss: (0.1094) | Acc: (96.28%) (15337/15930)\n",
      "Epoch: 21 | Batch_idx: 540 |  Loss: (0.1102) | Acc: (96.23%) (15618/16230)\n",
      "Epoch: 21 | Batch_idx: 550 |  Loss: (0.1102) | Acc: (96.23%) (15907/16530)\n",
      "Epoch: 21 | Batch_idx: 560 |  Loss: (0.1103) | Acc: (96.22%) (16194/16830)\n",
      "Epoch: 21 | Batch_idx: 570 |  Loss: (0.1104) | Acc: (96.22%) (16483/17130)\n",
      "Epoch: 21 | Batch_idx: 580 |  Loss: (0.1100) | Acc: (96.22%) (16772/17430)\n",
      "Epoch: 21 | Batch_idx: 590 |  Loss: (0.1098) | Acc: (96.23%) (17061/17730)\n",
      "Epoch: 21 | Batch_idx: 600 |  Loss: (0.1098) | Acc: (96.23%) (17351/18030)\n",
      "Epoch: 21 | Batch_idx: 610 |  Loss: (0.1101) | Acc: (96.23%) (17639/18330)\n",
      "Epoch: 21 | Batch_idx: 620 |  Loss: (0.1099) | Acc: (96.23%) (17928/18630)\n",
      "Epoch: 21 | Batch_idx: 630 |  Loss: (0.1096) | Acc: (96.23%) (18217/18930)\n",
      "Epoch: 21 | Batch_idx: 640 |  Loss: (0.1098) | Acc: (96.22%) (18504/19230)\n",
      "Epoch: 21 | Batch_idx: 650 |  Loss: (0.1095) | Acc: (96.24%) (18796/19530)\n",
      "Epoch: 21 | Batch_idx: 660 |  Loss: (0.1091) | Acc: (96.26%) (19088/19830)\n",
      "Epoch: 21 | Batch_idx: 670 |  Loss: (0.1088) | Acc: (96.27%) (19380/20130)\n",
      "Epoch: 21 | Batch_idx: 680 |  Loss: (0.1082) | Acc: (96.29%) (19673/20430)\n",
      "Epoch: 21 | Batch_idx: 690 |  Loss: (0.1078) | Acc: (96.30%) (19964/20730)\n",
      "Epoch: 21 | Batch_idx: 700 |  Loss: (0.1078) | Acc: (96.31%) (20253/21030)\n",
      "Epoch: 21 | Batch_idx: 710 |  Loss: (0.1082) | Acc: (96.30%) (20540/21330)\n",
      "Epoch: 21 | Batch_idx: 720 |  Loss: (0.1080) | Acc: (96.31%) (20831/21630)\n",
      "Epoch: 21 | Batch_idx: 730 |  Loss: (0.1078) | Acc: (96.32%) (21122/21930)\n",
      "Epoch: 21 | Batch_idx: 740 |  Loss: (0.1079) | Acc: (96.31%) (21409/22230)\n",
      "Epoch: 21 | Batch_idx: 750 |  Loss: (0.1081) | Acc: (96.29%) (21695/22530)\n",
      "Epoch: 21 | Batch_idx: 760 |  Loss: (0.1077) | Acc: (96.31%) (21987/22830)\n",
      "Epoch: 21 | Batch_idx: 770 |  Loss: (0.1081) | Acc: (96.29%) (22273/23130)\n",
      "Epoch: 21 | Batch_idx: 780 |  Loss: (0.1081) | Acc: (96.28%) (22558/23430)\n",
      "Epoch: 21 | Batch_idx: 790 |  Loss: (0.1086) | Acc: (96.26%) (22842/23730)\n",
      "Epoch: 21 | Batch_idx: 800 |  Loss: (0.1083) | Acc: (96.26%) (23132/24030)\n",
      "Epoch: 21 | Batch_idx: 810 |  Loss: (0.1090) | Acc: (96.23%) (23412/24330)\n",
      "Epoch: 21 | Batch_idx: 820 |  Loss: (0.1090) | Acc: (96.22%) (23698/24630)\n",
      "Epoch: 21 | Batch_idx: 830 |  Loss: (0.1091) | Acc: (96.21%) (23984/24930)\n",
      "Epoch: 21 | Batch_idx: 840 |  Loss: (0.1088) | Acc: (96.23%) (24278/25230)\n",
      "Epoch: 21 | Batch_idx: 850 |  Loss: (0.1091) | Acc: (96.21%) (24563/25530)\n",
      "Epoch: 21 | Batch_idx: 860 |  Loss: (0.1093) | Acc: (96.22%) (24854/25830)\n",
      "Epoch: 21 | Batch_idx: 870 |  Loss: (0.1091) | Acc: (96.23%) (25145/26130)\n",
      "Epoch: 21 | Batch_idx: 880 |  Loss: (0.1088) | Acc: (96.24%) (25437/26430)\n",
      "Epoch: 21 | Batch_idx: 890 |  Loss: (0.1088) | Acc: (96.25%) (25728/26730)\n",
      "Epoch: 21 | Batch_idx: 900 |  Loss: (0.1095) | Acc: (96.22%) (26009/27030)\n",
      "Epoch: 21 | Batch_idx: 910 |  Loss: (0.1098) | Acc: (96.21%) (26294/27330)\n",
      "Epoch: 21 | Batch_idx: 920 |  Loss: (0.1101) | Acc: (96.20%) (26581/27630)\n",
      "Epoch: 21 | Batch_idx: 930 |  Loss: (0.1101) | Acc: (96.19%) (26867/27930)\n",
      "Epoch: 21 | Batch_idx: 940 |  Loss: (0.1105) | Acc: (96.17%) (27148/28230)\n",
      "Epoch: 21 | Batch_idx: 950 |  Loss: (0.1107) | Acc: (96.15%) (27433/28530)\n",
      "Epoch: 21 | Batch_idx: 960 |  Loss: (0.1106) | Acc: (96.16%) (27724/28830)\n",
      "Epoch: 21 | Batch_idx: 970 |  Loss: (0.1106) | Acc: (96.16%) (28012/29130)\n",
      "Epoch: 21 | Batch_idx: 980 |  Loss: (0.1106) | Acc: (96.16%) (28299/29430)\n",
      "Epoch: 21 | Batch_idx: 990 |  Loss: (0.1110) | Acc: (96.14%) (28582/29730)\n",
      "Epoch: 21 | Batch_idx: 1000 |  Loss: (0.1113) | Acc: (96.13%) (28868/30030)\n",
      "Epoch: 21 | Batch_idx: 1010 |  Loss: (0.1114) | Acc: (96.12%) (29154/30330)\n",
      "Epoch: 21 | Batch_idx: 1020 |  Loss: (0.1119) | Acc: (96.10%) (29435/30630)\n",
      "Epoch: 21 | Batch_idx: 1030 |  Loss: (0.1117) | Acc: (96.10%) (29724/30930)\n",
      "Epoch: 21 | Batch_idx: 1040 |  Loss: (0.1118) | Acc: (96.11%) (30014/31230)\n",
      "Epoch: 21 | Batch_idx: 1050 |  Loss: (0.1114) | Acc: (96.12%) (30306/31530)\n",
      "Epoch: 21 | Batch_idx: 1060 |  Loss: (0.1116) | Acc: (96.11%) (30593/31830)\n",
      "Epoch: 21 | Batch_idx: 1070 |  Loss: (0.1113) | Acc: (96.12%) (30884/32130)\n",
      "Epoch: 21 | Batch_idx: 1080 |  Loss: (0.1117) | Acc: (96.11%) (31167/32430)\n",
      "Epoch: 21 | Batch_idx: 1090 |  Loss: (0.1118) | Acc: (96.11%) (31456/32730)\n",
      "Epoch: 21 | Batch_idx: 1100 |  Loss: (0.1116) | Acc: (96.12%) (31747/33030)\n",
      "Epoch: 21 | Batch_idx: 1110 |  Loss: (0.1121) | Acc: (96.11%) (32032/33330)\n",
      "Epoch: 21 | Batch_idx: 1120 |  Loss: (0.1120) | Acc: (96.11%) (32321/33630)\n",
      "Epoch: 21 | Batch_idx: 1130 |  Loss: (0.1122) | Acc: (96.10%) (32608/33930)\n",
      "Epoch: 21 | Batch_idx: 1140 |  Loss: (0.1123) | Acc: (96.11%) (32898/34230)\n",
      "Epoch: 21 | Batch_idx: 1150 |  Loss: (0.1122) | Acc: (96.11%) (33186/34530)\n",
      "Epoch: 21 | Batch_idx: 1160 |  Loss: (0.1122) | Acc: (96.10%) (33472/34830)\n",
      "Epoch: 21 | Batch_idx: 1170 |  Loss: (0.1121) | Acc: (96.11%) (33763/35130)\n",
      "Epoch: 21 | Batch_idx: 1180 |  Loss: (0.1120) | Acc: (96.11%) (34053/35430)\n",
      "Epoch: 21 | Batch_idx: 1190 |  Loss: (0.1120) | Acc: (96.11%) (34339/35730)\n",
      "Epoch: 21 | Batch_idx: 1200 |  Loss: (0.1122) | Acc: (96.10%) (34625/36030)\n",
      "Epoch: 21 | Batch_idx: 1210 |  Loss: (0.1124) | Acc: (96.09%) (34910/36330)\n",
      "Epoch: 21 | Batch_idx: 1220 |  Loss: (0.1126) | Acc: (96.08%) (35195/36630)\n",
      "Epoch: 21 | Batch_idx: 1230 |  Loss: (0.1127) | Acc: (96.08%) (35484/36930)\n",
      "Epoch: 21 | Batch_idx: 1240 |  Loss: (0.1128) | Acc: (96.08%) (35771/37230)\n",
      "Epoch: 21 | Batch_idx: 1250 |  Loss: (0.1129) | Acc: (96.08%) (36059/37530)\n",
      "Epoch: 21 | Batch_idx: 1260 |  Loss: (0.1126) | Acc: (96.09%) (36351/37830)\n",
      "Epoch: 21 | Batch_idx: 1270 |  Loss: (0.1127) | Acc: (96.08%) (36637/38130)\n",
      "Epoch: 21 | Batch_idx: 1280 |  Loss: (0.1127) | Acc: (96.09%) (36927/38430)\n",
      "Epoch: 21 | Batch_idx: 1290 |  Loss: (0.1128) | Acc: (96.08%) (37213/38730)\n",
      "Epoch: 21 | Batch_idx: 1300 |  Loss: (0.1131) | Acc: (96.07%) (37498/39030)\n",
      "Epoch: 21 | Batch_idx: 1310 |  Loss: (0.1130) | Acc: (96.08%) (37788/39330)\n",
      "Epoch: 21 | Batch_idx: 1320 |  Loss: (0.1130) | Acc: (96.07%) (38074/39630)\n",
      "Epoch: 21 | Batch_idx: 1330 |  Loss: (0.1129) | Acc: (96.08%) (38365/39930)\n",
      "Epoch: 21 | Batch_idx: 1340 |  Loss: (0.1127) | Acc: (96.09%) (38656/40230)\n",
      "Epoch: 21 | Batch_idx: 1350 |  Loss: (0.1128) | Acc: (96.08%) (38943/40530)\n",
      "Epoch: 21 | Batch_idx: 1360 |  Loss: (0.1128) | Acc: (96.08%) (39228/40830)\n",
      "Epoch: 21 | Batch_idx: 1370 |  Loss: (0.1131) | Acc: (96.06%) (39510/41130)\n",
      "Epoch: 21 | Batch_idx: 1380 |  Loss: (0.1135) | Acc: (96.06%) (39796/41430)\n",
      "Epoch: 21 | Batch_idx: 1390 |  Loss: (0.1138) | Acc: (96.04%) (40079/41730)\n",
      "Epoch: 21 | Batch_idx: 1400 |  Loss: (0.1140) | Acc: (96.03%) (40363/42030)\n",
      "Epoch: 21 | Batch_idx: 1410 |  Loss: (0.1142) | Acc: (96.02%) (40647/42330)\n",
      "Epoch: 21 | Batch_idx: 1420 |  Loss: (0.1146) | Acc: (96.01%) (40930/42630)\n",
      "Epoch: 21 | Batch_idx: 1430 |  Loss: (0.1148) | Acc: (96.01%) (41215/42930)\n",
      "Epoch: 21 | Batch_idx: 1440 |  Loss: (0.1148) | Acc: (96.01%) (41504/43230)\n",
      "Epoch: 21 | Batch_idx: 1450 |  Loss: (0.1149) | Acc: (95.99%) (41786/43530)\n",
      "Epoch: 21 | Batch_idx: 1460 |  Loss: (0.1151) | Acc: (95.99%) (42072/43830)\n",
      "Epoch: 21 | Batch_idx: 1470 |  Loss: (0.1154) | Acc: (95.98%) (42356/44130)\n",
      "Epoch: 21 | Batch_idx: 1480 |  Loss: (0.1154) | Acc: (95.98%) (42642/44430)\n",
      "Epoch: 21 | Batch_idx: 1490 |  Loss: (0.1156) | Acc: (95.97%) (42928/44730)\n",
      "Epoch: 21 | Batch_idx: 1500 |  Loss: (0.1158) | Acc: (95.96%) (43210/45030)\n",
      "Epoch: 21 | Batch_idx: 1510 |  Loss: (0.1163) | Acc: (95.94%) (43489/45330)\n",
      "Epoch: 21 | Batch_idx: 1520 |  Loss: (0.1164) | Acc: (95.94%) (43777/45630)\n",
      "Epoch: 21 | Batch_idx: 1530 |  Loss: (0.1166) | Acc: (95.94%) (44063/45930)\n",
      "Epoch: 21 | Batch_idx: 1540 |  Loss: (0.1172) | Acc: (95.93%) (44347/46230)\n",
      "Epoch: 21 | Batch_idx: 1550 |  Loss: (0.1174) | Acc: (95.92%) (44633/46530)\n",
      "Epoch: 21 | Batch_idx: 1560 |  Loss: (0.1177) | Acc: (95.92%) (44918/46830)\n",
      "Epoch: 21 | Batch_idx: 1570 |  Loss: (0.1175) | Acc: (95.93%) (45212/47130)\n",
      "Epoch: 21 | Batch_idx: 1580 |  Loss: (0.1177) | Acc: (95.93%) (45500/47430)\n",
      "Epoch: 21 | Batch_idx: 1590 |  Loss: (0.1175) | Acc: (95.93%) (45789/47730)\n",
      "Epoch: 21 | Batch_idx: 1600 |  Loss: (0.1174) | Acc: (95.94%) (46080/48030)\n",
      "Epoch: 21 | Batch_idx: 1610 |  Loss: (0.1174) | Acc: (95.94%) (46366/48330)\n",
      "Epoch: 21 | Batch_idx: 1620 |  Loss: (0.1176) | Acc: (95.93%) (46651/48630)\n",
      "Epoch: 21 | Batch_idx: 1630 |  Loss: (0.1177) | Acc: (95.94%) (46941/48930)\n",
      "Epoch: 21 | Batch_idx: 1640 |  Loss: (0.1177) | Acc: (95.93%) (47226/49230)\n",
      "Epoch: 21 | Batch_idx: 1650 |  Loss: (0.1176) | Acc: (95.93%) (47516/49530)\n",
      "Epoch: 21 | Batch_idx: 1660 |  Loss: (0.1174) | Acc: (95.94%) (47808/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3470) | Acc: (90.24%) (9024/10000)\n",
      "Epoch: 22 | Batch_idx: 0 |  Loss: (0.1449) | Acc: (96.67%) (29/30)\n",
      "Epoch: 22 | Batch_idx: 10 |  Loss: (0.0876) | Acc: (96.97%) (320/330)\n",
      "Epoch: 22 | Batch_idx: 20 |  Loss: (0.1009) | Acc: (96.51%) (608/630)\n",
      "Epoch: 22 | Batch_idx: 30 |  Loss: (0.1041) | Acc: (96.67%) (899/930)\n",
      "Epoch: 22 | Batch_idx: 40 |  Loss: (0.0975) | Acc: (96.99%) (1193/1230)\n",
      "Epoch: 22 | Batch_idx: 50 |  Loss: (0.1078) | Acc: (96.60%) (1478/1530)\n",
      "Epoch: 22 | Batch_idx: 60 |  Loss: (0.1090) | Acc: (96.50%) (1766/1830)\n",
      "Epoch: 22 | Batch_idx: 70 |  Loss: (0.1056) | Acc: (96.67%) (2059/2130)\n",
      "Epoch: 22 | Batch_idx: 80 |  Loss: (0.1061) | Acc: (96.50%) (2345/2430)\n",
      "Epoch: 22 | Batch_idx: 90 |  Loss: (0.1060) | Acc: (96.52%) (2635/2730)\n",
      "Epoch: 22 | Batch_idx: 100 |  Loss: (0.1055) | Acc: (96.50%) (2924/3030)\n",
      "Epoch: 22 | Batch_idx: 110 |  Loss: (0.1027) | Acc: (96.55%) (3215/3330)\n",
      "Epoch: 22 | Batch_idx: 120 |  Loss: (0.1021) | Acc: (96.58%) (3506/3630)\n",
      "Epoch: 22 | Batch_idx: 130 |  Loss: (0.1036) | Acc: (96.49%) (3792/3930)\n",
      "Epoch: 22 | Batch_idx: 140 |  Loss: (0.1052) | Acc: (96.48%) (4081/4230)\n",
      "Epoch: 22 | Batch_idx: 150 |  Loss: (0.1036) | Acc: (96.53%) (4373/4530)\n",
      "Epoch: 22 | Batch_idx: 160 |  Loss: (0.1013) | Acc: (96.65%) (4668/4830)\n",
      "Epoch: 22 | Batch_idx: 170 |  Loss: (0.1002) | Acc: (96.73%) (4962/5130)\n",
      "Epoch: 22 | Batch_idx: 180 |  Loss: (0.1003) | Acc: (96.70%) (5251/5430)\n",
      "Epoch: 22 | Batch_idx: 190 |  Loss: (0.1001) | Acc: (96.70%) (5541/5730)\n",
      "Epoch: 22 | Batch_idx: 200 |  Loss: (0.1010) | Acc: (96.63%) (5827/6030)\n",
      "Epoch: 22 | Batch_idx: 210 |  Loss: (0.0995) | Acc: (96.71%) (6122/6330)\n",
      "Epoch: 22 | Batch_idx: 220 |  Loss: (0.0988) | Acc: (96.71%) (6412/6630)\n",
      "Epoch: 22 | Batch_idx: 230 |  Loss: (0.0978) | Acc: (96.72%) (6703/6930)\n",
      "Epoch: 22 | Batch_idx: 240 |  Loss: (0.0970) | Acc: (96.79%) (6998/7230)\n",
      "Epoch: 22 | Batch_idx: 250 |  Loss: (0.0971) | Acc: (96.81%) (7290/7530)\n",
      "Epoch: 22 | Batch_idx: 260 |  Loss: (0.0978) | Acc: (96.78%) (7578/7830)\n",
      "Epoch: 22 | Batch_idx: 270 |  Loss: (0.0987) | Acc: (96.75%) (7866/8130)\n",
      "Epoch: 22 | Batch_idx: 280 |  Loss: (0.0989) | Acc: (96.71%) (8153/8430)\n",
      "Epoch: 22 | Batch_idx: 290 |  Loss: (0.0981) | Acc: (96.74%) (8445/8730)\n",
      "Epoch: 22 | Batch_idx: 300 |  Loss: (0.0981) | Acc: (96.72%) (8734/9030)\n",
      "Epoch: 22 | Batch_idx: 310 |  Loss: (0.0984) | Acc: (96.69%) (9021/9330)\n",
      "Epoch: 22 | Batch_idx: 320 |  Loss: (0.0982) | Acc: (96.68%) (9310/9630)\n",
      "Epoch: 22 | Batch_idx: 330 |  Loss: (0.0985) | Acc: (96.67%) (9599/9930)\n",
      "Epoch: 22 | Batch_idx: 340 |  Loss: (0.0994) | Acc: (96.63%) (9885/10230)\n",
      "Epoch: 22 | Batch_idx: 350 |  Loss: (0.0986) | Acc: (96.66%) (10178/10530)\n",
      "Epoch: 22 | Batch_idx: 360 |  Loss: (0.1000) | Acc: (96.58%) (10460/10830)\n",
      "Epoch: 22 | Batch_idx: 370 |  Loss: (0.0997) | Acc: (96.59%) (10751/11130)\n",
      "Epoch: 22 | Batch_idx: 380 |  Loss: (0.0993) | Acc: (96.59%) (11040/11430)\n",
      "Epoch: 22 | Batch_idx: 390 |  Loss: (0.0992) | Acc: (96.61%) (11332/11730)\n",
      "Epoch: 22 | Batch_idx: 400 |  Loss: (0.0995) | Acc: (96.62%) (11623/12030)\n",
      "Epoch: 22 | Batch_idx: 410 |  Loss: (0.0999) | Acc: (96.59%) (11910/12330)\n",
      "Epoch: 22 | Batch_idx: 420 |  Loss: (0.1012) | Acc: (96.56%) (12195/12630)\n",
      "Epoch: 22 | Batch_idx: 430 |  Loss: (0.1008) | Acc: (96.57%) (12486/12930)\n",
      "Epoch: 22 | Batch_idx: 440 |  Loss: (0.1017) | Acc: (96.51%) (12768/13230)\n",
      "Epoch: 22 | Batch_idx: 450 |  Loss: (0.1019) | Acc: (96.50%) (13056/13530)\n",
      "Epoch: 22 | Batch_idx: 460 |  Loss: (0.1019) | Acc: (96.50%) (13346/13830)\n",
      "Epoch: 22 | Batch_idx: 470 |  Loss: (0.1015) | Acc: (96.49%) (13634/14130)\n",
      "Epoch: 22 | Batch_idx: 480 |  Loss: (0.1009) | Acc: (96.49%) (13924/14430)\n",
      "Epoch: 22 | Batch_idx: 490 |  Loss: (0.1009) | Acc: (96.50%) (14214/14730)\n",
      "Epoch: 22 | Batch_idx: 500 |  Loss: (0.1004) | Acc: (96.51%) (14506/15030)\n",
      "Epoch: 22 | Batch_idx: 510 |  Loss: (0.1006) | Acc: (96.50%) (14793/15330)\n",
      "Epoch: 22 | Batch_idx: 520 |  Loss: (0.1010) | Acc: (96.47%) (15079/15630)\n",
      "Epoch: 22 | Batch_idx: 530 |  Loss: (0.1009) | Acc: (96.48%) (15370/15930)\n",
      "Epoch: 22 | Batch_idx: 540 |  Loss: (0.1008) | Acc: (96.49%) (15661/16230)\n",
      "Epoch: 22 | Batch_idx: 550 |  Loss: (0.1000) | Acc: (96.53%) (15957/16530)\n",
      "Epoch: 22 | Batch_idx: 560 |  Loss: (0.0999) | Acc: (96.54%) (16248/16830)\n",
      "Epoch: 22 | Batch_idx: 570 |  Loss: (0.0993) | Acc: (96.56%) (16540/17130)\n",
      "Epoch: 22 | Batch_idx: 580 |  Loss: (0.0992) | Acc: (96.56%) (16831/17430)\n",
      "Epoch: 22 | Batch_idx: 590 |  Loss: (0.0992) | Acc: (96.57%) (17122/17730)\n",
      "Epoch: 22 | Batch_idx: 600 |  Loss: (0.0990) | Acc: (96.56%) (17410/18030)\n",
      "Epoch: 22 | Batch_idx: 610 |  Loss: (0.0990) | Acc: (96.56%) (17700/18330)\n",
      "Epoch: 22 | Batch_idx: 620 |  Loss: (0.0988) | Acc: (96.55%) (17988/18630)\n",
      "Epoch: 22 | Batch_idx: 630 |  Loss: (0.0994) | Acc: (96.54%) (18275/18930)\n",
      "Epoch: 22 | Batch_idx: 640 |  Loss: (0.0998) | Acc: (96.54%) (18565/19230)\n",
      "Epoch: 22 | Batch_idx: 650 |  Loss: (0.0993) | Acc: (96.56%) (18859/19530)\n",
      "Epoch: 22 | Batch_idx: 660 |  Loss: (0.1001) | Acc: (96.54%) (19144/19830)\n",
      "Epoch: 22 | Batch_idx: 670 |  Loss: (0.1004) | Acc: (96.51%) (19427/20130)\n",
      "Epoch: 22 | Batch_idx: 680 |  Loss: (0.1008) | Acc: (96.50%) (19714/20430)\n",
      "Epoch: 22 | Batch_idx: 690 |  Loss: (0.1009) | Acc: (96.49%) (20003/20730)\n",
      "Epoch: 22 | Batch_idx: 700 |  Loss: (0.1006) | Acc: (96.51%) (20296/21030)\n",
      "Epoch: 22 | Batch_idx: 710 |  Loss: (0.1005) | Acc: (96.53%) (20589/21330)\n",
      "Epoch: 22 | Batch_idx: 720 |  Loss: (0.1008) | Acc: (96.52%) (20878/21630)\n",
      "Epoch: 22 | Batch_idx: 730 |  Loss: (0.1001) | Acc: (96.56%) (21175/21930)\n",
      "Epoch: 22 | Batch_idx: 740 |  Loss: (0.1007) | Acc: (96.54%) (21460/22230)\n",
      "Epoch: 22 | Batch_idx: 750 |  Loss: (0.1008) | Acc: (96.52%) (21747/22530)\n",
      "Epoch: 22 | Batch_idx: 760 |  Loss: (0.1005) | Acc: (96.54%) (22040/22830)\n",
      "Epoch: 22 | Batch_idx: 770 |  Loss: (0.1003) | Acc: (96.55%) (22331/23130)\n",
      "Epoch: 22 | Batch_idx: 780 |  Loss: (0.1009) | Acc: (96.54%) (22619/23430)\n",
      "Epoch: 22 | Batch_idx: 790 |  Loss: (0.1007) | Acc: (96.54%) (22908/23730)\n",
      "Epoch: 22 | Batch_idx: 800 |  Loss: (0.1009) | Acc: (96.53%) (23197/24030)\n",
      "Epoch: 22 | Batch_idx: 810 |  Loss: (0.1009) | Acc: (96.54%) (23487/24330)\n",
      "Epoch: 22 | Batch_idx: 820 |  Loss: (0.1004) | Acc: (96.55%) (23780/24630)\n",
      "Epoch: 22 | Batch_idx: 830 |  Loss: (0.1005) | Acc: (96.56%) (24072/24930)\n",
      "Epoch: 22 | Batch_idx: 840 |  Loss: (0.1011) | Acc: (96.53%) (24354/25230)\n",
      "Epoch: 22 | Batch_idx: 850 |  Loss: (0.1014) | Acc: (96.52%) (24641/25530)\n",
      "Epoch: 22 | Batch_idx: 860 |  Loss: (0.1012) | Acc: (96.52%) (24932/25830)\n",
      "Epoch: 22 | Batch_idx: 870 |  Loss: (0.1012) | Acc: (96.53%) (25222/26130)\n",
      "Epoch: 22 | Batch_idx: 880 |  Loss: (0.1011) | Acc: (96.53%) (25514/26430)\n",
      "Epoch: 22 | Batch_idx: 890 |  Loss: (0.1009) | Acc: (96.55%) (25809/26730)\n",
      "Epoch: 22 | Batch_idx: 900 |  Loss: (0.1013) | Acc: (96.54%) (26095/27030)\n",
      "Epoch: 22 | Batch_idx: 910 |  Loss: (0.1015) | Acc: (96.54%) (26384/27330)\n",
      "Epoch: 22 | Batch_idx: 920 |  Loss: (0.1013) | Acc: (96.55%) (26676/27630)\n",
      "Epoch: 22 | Batch_idx: 930 |  Loss: (0.1013) | Acc: (96.53%) (26962/27930)\n",
      "Epoch: 22 | Batch_idx: 940 |  Loss: (0.1016) | Acc: (96.52%) (27247/28230)\n",
      "Epoch: 22 | Batch_idx: 950 |  Loss: (0.1017) | Acc: (96.50%) (27532/28530)\n",
      "Epoch: 22 | Batch_idx: 960 |  Loss: (0.1018) | Acc: (96.50%) (27821/28830)\n",
      "Epoch: 22 | Batch_idx: 970 |  Loss: (0.1017) | Acc: (96.51%) (28112/29130)\n",
      "Epoch: 22 | Batch_idx: 980 |  Loss: (0.1017) | Acc: (96.50%) (28399/29430)\n",
      "Epoch: 22 | Batch_idx: 990 |  Loss: (0.1016) | Acc: (96.51%) (28691/29730)\n",
      "Epoch: 22 | Batch_idx: 1000 |  Loss: (0.1019) | Acc: (96.50%) (28979/30030)\n",
      "Epoch: 22 | Batch_idx: 1010 |  Loss: (0.1024) | Acc: (96.49%) (29264/30330)\n",
      "Epoch: 22 | Batch_idx: 1020 |  Loss: (0.1022) | Acc: (96.50%) (29558/30630)\n",
      "Epoch: 22 | Batch_idx: 1030 |  Loss: (0.1022) | Acc: (96.50%) (29848/30930)\n",
      "Epoch: 22 | Batch_idx: 1040 |  Loss: (0.1018) | Acc: (96.52%) (30142/31230)\n",
      "Epoch: 22 | Batch_idx: 1050 |  Loss: (0.1016) | Acc: (96.52%) (30432/31530)\n",
      "Epoch: 22 | Batch_idx: 1060 |  Loss: (0.1016) | Acc: (96.51%) (30720/31830)\n",
      "Epoch: 22 | Batch_idx: 1070 |  Loss: (0.1019) | Acc: (96.51%) (31009/32130)\n",
      "Epoch: 22 | Batch_idx: 1080 |  Loss: (0.1019) | Acc: (96.51%) (31297/32430)\n",
      "Epoch: 22 | Batch_idx: 1090 |  Loss: (0.1017) | Acc: (96.51%) (31589/32730)\n",
      "Epoch: 22 | Batch_idx: 1100 |  Loss: (0.1019) | Acc: (96.50%) (31873/33030)\n",
      "Epoch: 22 | Batch_idx: 1110 |  Loss: (0.1020) | Acc: (96.49%) (32161/33330)\n",
      "Epoch: 22 | Batch_idx: 1120 |  Loss: (0.1021) | Acc: (96.49%) (32449/33630)\n",
      "Epoch: 22 | Batch_idx: 1130 |  Loss: (0.1020) | Acc: (96.49%) (32740/33930)\n",
      "Epoch: 22 | Batch_idx: 1140 |  Loss: (0.1019) | Acc: (96.49%) (33030/34230)\n",
      "Epoch: 22 | Batch_idx: 1150 |  Loss: (0.1023) | Acc: (96.49%) (33317/34530)\n",
      "Epoch: 22 | Batch_idx: 1160 |  Loss: (0.1022) | Acc: (96.48%) (33605/34830)\n",
      "Epoch: 22 | Batch_idx: 1170 |  Loss: (0.1027) | Acc: (96.46%) (33886/35130)\n",
      "Epoch: 22 | Batch_idx: 1180 |  Loss: (0.1030) | Acc: (96.45%) (34173/35430)\n",
      "Epoch: 22 | Batch_idx: 1190 |  Loss: (0.1030) | Acc: (96.45%) (34461/35730)\n",
      "Epoch: 22 | Batch_idx: 1200 |  Loss: (0.1032) | Acc: (96.44%) (34747/36030)\n",
      "Epoch: 22 | Batch_idx: 1210 |  Loss: (0.1030) | Acc: (96.44%) (35038/36330)\n",
      "Epoch: 22 | Batch_idx: 1220 |  Loss: (0.1034) | Acc: (96.43%) (35322/36630)\n",
      "Epoch: 22 | Batch_idx: 1230 |  Loss: (0.1037) | Acc: (96.42%) (35608/36930)\n",
      "Epoch: 22 | Batch_idx: 1240 |  Loss: (0.1036) | Acc: (96.42%) (35898/37230)\n",
      "Epoch: 22 | Batch_idx: 1250 |  Loss: (0.1038) | Acc: (96.41%) (36182/37530)\n",
      "Epoch: 22 | Batch_idx: 1260 |  Loss: (0.1037) | Acc: (96.40%) (36470/37830)\n",
      "Epoch: 22 | Batch_idx: 1270 |  Loss: (0.1035) | Acc: (96.42%) (36764/38130)\n",
      "Epoch: 22 | Batch_idx: 1280 |  Loss: (0.1039) | Acc: (96.41%) (37049/38430)\n",
      "Epoch: 22 | Batch_idx: 1290 |  Loss: (0.1037) | Acc: (96.42%) (37342/38730)\n",
      "Epoch: 22 | Batch_idx: 1300 |  Loss: (0.1036) | Acc: (96.42%) (37632/39030)\n",
      "Epoch: 22 | Batch_idx: 1310 |  Loss: (0.1036) | Acc: (96.42%) (37921/39330)\n",
      "Epoch: 22 | Batch_idx: 1320 |  Loss: (0.1037) | Acc: (96.41%) (38207/39630)\n",
      "Epoch: 22 | Batch_idx: 1330 |  Loss: (0.1039) | Acc: (96.40%) (38492/39930)\n",
      "Epoch: 22 | Batch_idx: 1340 |  Loss: (0.1041) | Acc: (96.39%) (38779/40230)\n",
      "Epoch: 22 | Batch_idx: 1350 |  Loss: (0.1038) | Acc: (96.41%) (39073/40530)\n",
      "Epoch: 22 | Batch_idx: 1360 |  Loss: (0.1042) | Acc: (96.39%) (39357/40830)\n",
      "Epoch: 22 | Batch_idx: 1370 |  Loss: (0.1040) | Acc: (96.40%) (39648/41130)\n",
      "Epoch: 22 | Batch_idx: 1380 |  Loss: (0.1042) | Acc: (96.39%) (39933/41430)\n",
      "Epoch: 22 | Batch_idx: 1390 |  Loss: (0.1042) | Acc: (96.38%) (40220/41730)\n",
      "Epoch: 22 | Batch_idx: 1400 |  Loss: (0.1045) | Acc: (96.37%) (40503/42030)\n",
      "Epoch: 22 | Batch_idx: 1410 |  Loss: (0.1047) | Acc: (96.35%) (40787/42330)\n",
      "Epoch: 22 | Batch_idx: 1420 |  Loss: (0.1046) | Acc: (96.37%) (41084/42630)\n",
      "Epoch: 22 | Batch_idx: 1430 |  Loss: (0.1044) | Acc: (96.38%) (41375/42930)\n",
      "Epoch: 22 | Batch_idx: 1440 |  Loss: (0.1047) | Acc: (96.36%) (41658/43230)\n",
      "Epoch: 22 | Batch_idx: 1450 |  Loss: (0.1049) | Acc: (96.36%) (41944/43530)\n",
      "Epoch: 22 | Batch_idx: 1460 |  Loss: (0.1055) | Acc: (96.33%) (42223/43830)\n",
      "Epoch: 22 | Batch_idx: 1470 |  Loss: (0.1057) | Acc: (96.33%) (42509/44130)\n",
      "Epoch: 22 | Batch_idx: 1480 |  Loss: (0.1058) | Acc: (96.32%) (42794/44430)\n",
      "Epoch: 22 | Batch_idx: 1490 |  Loss: (0.1060) | Acc: (96.31%) (43079/44730)\n",
      "Epoch: 22 | Batch_idx: 1500 |  Loss: (0.1062) | Acc: (96.30%) (43364/45030)\n",
      "Epoch: 22 | Batch_idx: 1510 |  Loss: (0.1062) | Acc: (96.30%) (43653/45330)\n",
      "Epoch: 22 | Batch_idx: 1520 |  Loss: (0.1065) | Acc: (96.29%) (43938/45630)\n",
      "Epoch: 22 | Batch_idx: 1530 |  Loss: (0.1066) | Acc: (96.29%) (44226/45930)\n",
      "Epoch: 22 | Batch_idx: 1540 |  Loss: (0.1066) | Acc: (96.29%) (44515/46230)\n",
      "Epoch: 22 | Batch_idx: 1550 |  Loss: (0.1070) | Acc: (96.29%) (44803/46530)\n",
      "Epoch: 22 | Batch_idx: 1560 |  Loss: (0.1074) | Acc: (96.28%) (45087/46830)\n",
      "Epoch: 22 | Batch_idx: 1570 |  Loss: (0.1076) | Acc: (96.27%) (45371/47130)\n",
      "Epoch: 22 | Batch_idx: 1580 |  Loss: (0.1081) | Acc: (96.25%) (45653/47430)\n",
      "Epoch: 22 | Batch_idx: 1590 |  Loss: (0.1086) | Acc: (96.23%) (45929/47730)\n",
      "Epoch: 22 | Batch_idx: 1600 |  Loss: (0.1086) | Acc: (96.23%) (46218/48030)\n",
      "Epoch: 22 | Batch_idx: 1610 |  Loss: (0.1086) | Acc: (96.22%) (46505/48330)\n",
      "Epoch: 22 | Batch_idx: 1620 |  Loss: (0.1085) | Acc: (96.23%) (46797/48630)\n",
      "Epoch: 22 | Batch_idx: 1630 |  Loss: (0.1082) | Acc: (96.24%) (47089/48930)\n",
      "Epoch: 22 | Batch_idx: 1640 |  Loss: (0.1083) | Acc: (96.23%) (47374/49230)\n",
      "Epoch: 22 | Batch_idx: 1650 |  Loss: (0.1083) | Acc: (96.23%) (47664/49530)\n",
      "Epoch: 22 | Batch_idx: 1660 |  Loss: (0.1083) | Acc: (96.24%) (47956/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3536) | Acc: (89.96%) (8996/10000)\n",
      "Epoch: 23 | Batch_idx: 0 |  Loss: (0.1587) | Acc: (90.00%) (27/30)\n",
      "Epoch: 23 | Batch_idx: 10 |  Loss: (0.0826) | Acc: (96.36%) (318/330)\n",
      "Epoch: 23 | Batch_idx: 20 |  Loss: (0.0891) | Acc: (96.35%) (607/630)\n",
      "Epoch: 23 | Batch_idx: 30 |  Loss: (0.0895) | Acc: (96.77%) (900/930)\n",
      "Epoch: 23 | Batch_idx: 40 |  Loss: (0.1000) | Acc: (96.02%) (1181/1230)\n",
      "Epoch: 23 | Batch_idx: 50 |  Loss: (0.1006) | Acc: (95.88%) (1467/1530)\n",
      "Epoch: 23 | Batch_idx: 60 |  Loss: (0.1015) | Acc: (95.85%) (1754/1830)\n",
      "Epoch: 23 | Batch_idx: 70 |  Loss: (0.0991) | Acc: (95.87%) (2042/2130)\n",
      "Epoch: 23 | Batch_idx: 80 |  Loss: (0.0992) | Acc: (95.76%) (2327/2430)\n",
      "Epoch: 23 | Batch_idx: 90 |  Loss: (0.0983) | Acc: (95.79%) (2615/2730)\n",
      "Epoch: 23 | Batch_idx: 100 |  Loss: (0.0983) | Acc: (95.81%) (2903/3030)\n",
      "Epoch: 23 | Batch_idx: 110 |  Loss: (0.0990) | Acc: (95.92%) (3194/3330)\n",
      "Epoch: 23 | Batch_idx: 120 |  Loss: (0.0949) | Acc: (96.17%) (3491/3630)\n",
      "Epoch: 23 | Batch_idx: 130 |  Loss: (0.0980) | Acc: (96.16%) (3779/3930)\n",
      "Epoch: 23 | Batch_idx: 140 |  Loss: (0.0966) | Acc: (96.34%) (4075/4230)\n",
      "Epoch: 23 | Batch_idx: 150 |  Loss: (0.0953) | Acc: (96.40%) (4367/4530)\n",
      "Epoch: 23 | Batch_idx: 160 |  Loss: (0.0971) | Acc: (96.31%) (4652/4830)\n",
      "Epoch: 23 | Batch_idx: 170 |  Loss: (0.0962) | Acc: (96.43%) (4947/5130)\n",
      "Epoch: 23 | Batch_idx: 180 |  Loss: (0.0978) | Acc: (96.35%) (5232/5430)\n",
      "Epoch: 23 | Batch_idx: 190 |  Loss: (0.0973) | Acc: (96.42%) (5525/5730)\n",
      "Epoch: 23 | Batch_idx: 200 |  Loss: (0.0968) | Acc: (96.45%) (5816/6030)\n",
      "Epoch: 23 | Batch_idx: 210 |  Loss: (0.0967) | Acc: (96.48%) (6107/6330)\n",
      "Epoch: 23 | Batch_idx: 220 |  Loss: (0.0974) | Acc: (96.47%) (6396/6630)\n",
      "Epoch: 23 | Batch_idx: 230 |  Loss: (0.0996) | Acc: (96.38%) (6679/6930)\n",
      "Epoch: 23 | Batch_idx: 240 |  Loss: (0.0986) | Acc: (96.45%) (6973/7230)\n",
      "Epoch: 23 | Batch_idx: 250 |  Loss: (0.0996) | Acc: (96.44%) (7262/7530)\n",
      "Epoch: 23 | Batch_idx: 260 |  Loss: (0.1008) | Acc: (96.44%) (7551/7830)\n",
      "Epoch: 23 | Batch_idx: 270 |  Loss: (0.1014) | Acc: (96.41%) (7838/8130)\n",
      "Epoch: 23 | Batch_idx: 280 |  Loss: (0.1009) | Acc: (96.42%) (8128/8430)\n",
      "Epoch: 23 | Batch_idx: 290 |  Loss: (0.0999) | Acc: (96.45%) (8420/8730)\n",
      "Epoch: 23 | Batch_idx: 300 |  Loss: (0.0994) | Acc: (96.45%) (8709/9030)\n",
      "Epoch: 23 | Batch_idx: 310 |  Loss: (0.1000) | Acc: (96.44%) (8998/9330)\n",
      "Epoch: 23 | Batch_idx: 320 |  Loss: (0.0986) | Acc: (96.51%) (9294/9630)\n",
      "Epoch: 23 | Batch_idx: 330 |  Loss: (0.0977) | Acc: (96.55%) (9587/9930)\n",
      "Epoch: 23 | Batch_idx: 340 |  Loss: (0.0978) | Acc: (96.55%) (9877/10230)\n",
      "Epoch: 23 | Batch_idx: 350 |  Loss: (0.0965) | Acc: (96.59%) (10171/10530)\n",
      "Epoch: 23 | Batch_idx: 360 |  Loss: (0.0979) | Acc: (96.52%) (10453/10830)\n",
      "Epoch: 23 | Batch_idx: 370 |  Loss: (0.0973) | Acc: (96.54%) (10745/11130)\n",
      "Epoch: 23 | Batch_idx: 380 |  Loss: (0.0975) | Acc: (96.52%) (11032/11430)\n",
      "Epoch: 23 | Batch_idx: 390 |  Loss: (0.0978) | Acc: (96.50%) (11320/11730)\n",
      "Epoch: 23 | Batch_idx: 400 |  Loss: (0.0966) | Acc: (96.56%) (11616/12030)\n",
      "Epoch: 23 | Batch_idx: 410 |  Loss: (0.0970) | Acc: (96.57%) (11907/12330)\n",
      "Epoch: 23 | Batch_idx: 420 |  Loss: (0.0964) | Acc: (96.58%) (12198/12630)\n",
      "Epoch: 23 | Batch_idx: 430 |  Loss: (0.0960) | Acc: (96.59%) (12489/12930)\n",
      "Epoch: 23 | Batch_idx: 440 |  Loss: (0.0955) | Acc: (96.60%) (12780/13230)\n",
      "Epoch: 23 | Batch_idx: 450 |  Loss: (0.0953) | Acc: (96.60%) (13070/13530)\n",
      "Epoch: 23 | Batch_idx: 460 |  Loss: (0.0949) | Acc: (96.62%) (13362/13830)\n",
      "Epoch: 23 | Batch_idx: 470 |  Loss: (0.0951) | Acc: (96.61%) (13651/14130)\n",
      "Epoch: 23 | Batch_idx: 480 |  Loss: (0.0942) | Acc: (96.66%) (13948/14430)\n",
      "Epoch: 23 | Batch_idx: 490 |  Loss: (0.0943) | Acc: (96.65%) (14237/14730)\n",
      "Epoch: 23 | Batch_idx: 500 |  Loss: (0.0941) | Acc: (96.65%) (14527/15030)\n",
      "Epoch: 23 | Batch_idx: 510 |  Loss: (0.0938) | Acc: (96.65%) (14817/15330)\n",
      "Epoch: 23 | Batch_idx: 520 |  Loss: (0.0932) | Acc: (96.68%) (15111/15630)\n",
      "Epoch: 23 | Batch_idx: 530 |  Loss: (0.0940) | Acc: (96.65%) (15397/15930)\n",
      "Epoch: 23 | Batch_idx: 540 |  Loss: (0.0937) | Acc: (96.69%) (15692/16230)\n",
      "Epoch: 23 | Batch_idx: 550 |  Loss: (0.0929) | Acc: (96.71%) (15986/16530)\n",
      "Epoch: 23 | Batch_idx: 560 |  Loss: (0.0929) | Acc: (96.71%) (16276/16830)\n",
      "Epoch: 23 | Batch_idx: 570 |  Loss: (0.0923) | Acc: (96.74%) (16571/17130)\n",
      "Epoch: 23 | Batch_idx: 580 |  Loss: (0.0918) | Acc: (96.76%) (16865/17430)\n",
      "Epoch: 23 | Batch_idx: 590 |  Loss: (0.0912) | Acc: (96.79%) (17161/17730)\n",
      "Epoch: 23 | Batch_idx: 600 |  Loss: (0.0911) | Acc: (96.79%) (17451/18030)\n",
      "Epoch: 23 | Batch_idx: 610 |  Loss: (0.0908) | Acc: (96.81%) (17745/18330)\n",
      "Epoch: 23 | Batch_idx: 620 |  Loss: (0.0912) | Acc: (96.78%) (18031/18630)\n",
      "Epoch: 23 | Batch_idx: 630 |  Loss: (0.0904) | Acc: (96.81%) (18327/18930)\n",
      "Epoch: 23 | Batch_idx: 640 |  Loss: (0.0899) | Acc: (96.84%) (18622/19230)\n",
      "Epoch: 23 | Batch_idx: 650 |  Loss: (0.0897) | Acc: (96.85%) (18915/19530)\n",
      "Epoch: 23 | Batch_idx: 660 |  Loss: (0.0894) | Acc: (96.86%) (19207/19830)\n",
      "Epoch: 23 | Batch_idx: 670 |  Loss: (0.0900) | Acc: (96.84%) (19493/20130)\n",
      "Epoch: 23 | Batch_idx: 680 |  Loss: (0.0901) | Acc: (96.85%) (19786/20430)\n",
      "Epoch: 23 | Batch_idx: 690 |  Loss: (0.0894) | Acc: (96.86%) (20080/20730)\n",
      "Epoch: 23 | Batch_idx: 700 |  Loss: (0.0898) | Acc: (96.85%) (20368/21030)\n",
      "Epoch: 23 | Batch_idx: 710 |  Loss: (0.0899) | Acc: (96.86%) (20660/21330)\n",
      "Epoch: 23 | Batch_idx: 720 |  Loss: (0.0896) | Acc: (96.87%) (20954/21630)\n",
      "Epoch: 23 | Batch_idx: 730 |  Loss: (0.0898) | Acc: (96.86%) (21242/21930)\n",
      "Epoch: 23 | Batch_idx: 740 |  Loss: (0.0900) | Acc: (96.85%) (21529/22230)\n",
      "Epoch: 23 | Batch_idx: 750 |  Loss: (0.0895) | Acc: (96.87%) (21825/22530)\n",
      "Epoch: 23 | Batch_idx: 760 |  Loss: (0.0897) | Acc: (96.87%) (22115/22830)\n",
      "Epoch: 23 | Batch_idx: 770 |  Loss: (0.0897) | Acc: (96.87%) (22406/23130)\n",
      "Epoch: 23 | Batch_idx: 780 |  Loss: (0.0900) | Acc: (96.85%) (22693/23430)\n",
      "Epoch: 23 | Batch_idx: 790 |  Loss: (0.0900) | Acc: (96.85%) (22982/23730)\n",
      "Epoch: 23 | Batch_idx: 800 |  Loss: (0.0902) | Acc: (96.83%) (23269/24030)\n",
      "Epoch: 23 | Batch_idx: 810 |  Loss: (0.0900) | Acc: (96.84%) (23561/24330)\n",
      "Epoch: 23 | Batch_idx: 820 |  Loss: (0.0900) | Acc: (96.84%) (23851/24630)\n",
      "Epoch: 23 | Batch_idx: 830 |  Loss: (0.0898) | Acc: (96.86%) (24146/24930)\n",
      "Epoch: 23 | Batch_idx: 840 |  Loss: (0.0899) | Acc: (96.86%) (24438/25230)\n",
      "Epoch: 23 | Batch_idx: 850 |  Loss: (0.0906) | Acc: (96.84%) (24722/25530)\n",
      "Epoch: 23 | Batch_idx: 860 |  Loss: (0.0909) | Acc: (96.83%) (25010/25830)\n",
      "Epoch: 23 | Batch_idx: 870 |  Loss: (0.0910) | Acc: (96.83%) (25301/26130)\n",
      "Epoch: 23 | Batch_idx: 880 |  Loss: (0.0910) | Acc: (96.83%) (25592/26430)\n",
      "Epoch: 23 | Batch_idx: 890 |  Loss: (0.0913) | Acc: (96.82%) (25881/26730)\n",
      "Epoch: 23 | Batch_idx: 900 |  Loss: (0.0923) | Acc: (96.81%) (26169/27030)\n",
      "Epoch: 23 | Batch_idx: 910 |  Loss: (0.0921) | Acc: (96.81%) (26458/27330)\n",
      "Epoch: 23 | Batch_idx: 920 |  Loss: (0.0919) | Acc: (96.82%) (26751/27630)\n",
      "Epoch: 23 | Batch_idx: 930 |  Loss: (0.0918) | Acc: (96.83%) (27044/27930)\n",
      "Epoch: 23 | Batch_idx: 940 |  Loss: (0.0917) | Acc: (96.83%) (27336/28230)\n",
      "Epoch: 23 | Batch_idx: 950 |  Loss: (0.0921) | Acc: (96.82%) (27623/28530)\n",
      "Epoch: 23 | Batch_idx: 960 |  Loss: (0.0917) | Acc: (96.84%) (27918/28830)\n",
      "Epoch: 23 | Batch_idx: 970 |  Loss: (0.0917) | Acc: (96.84%) (28210/29130)\n",
      "Epoch: 23 | Batch_idx: 980 |  Loss: (0.0914) | Acc: (96.85%) (28502/29430)\n",
      "Epoch: 23 | Batch_idx: 990 |  Loss: (0.0916) | Acc: (96.83%) (28789/29730)\n",
      "Epoch: 23 | Batch_idx: 1000 |  Loss: (0.0914) | Acc: (96.84%) (29081/30030)\n",
      "Epoch: 23 | Batch_idx: 1010 |  Loss: (0.0915) | Acc: (96.84%) (29372/30330)\n",
      "Epoch: 23 | Batch_idx: 1020 |  Loss: (0.0918) | Acc: (96.84%) (29661/30630)\n",
      "Epoch: 23 | Batch_idx: 1030 |  Loss: (0.0923) | Acc: (96.81%) (29944/30930)\n",
      "Epoch: 23 | Batch_idx: 1040 |  Loss: (0.0921) | Acc: (96.82%) (30236/31230)\n",
      "Epoch: 23 | Batch_idx: 1050 |  Loss: (0.0919) | Acc: (96.83%) (30529/31530)\n",
      "Epoch: 23 | Batch_idx: 1060 |  Loss: (0.0917) | Acc: (96.83%) (30822/31830)\n",
      "Epoch: 23 | Batch_idx: 1070 |  Loss: (0.0919) | Acc: (96.83%) (31110/32130)\n",
      "Epoch: 23 | Batch_idx: 1080 |  Loss: (0.0918) | Acc: (96.82%) (31400/32430)\n",
      "Epoch: 23 | Batch_idx: 1090 |  Loss: (0.0917) | Acc: (96.83%) (31692/32730)\n",
      "Epoch: 23 | Batch_idx: 1100 |  Loss: (0.0919) | Acc: (96.82%) (31980/33030)\n",
      "Epoch: 23 | Batch_idx: 1110 |  Loss: (0.0920) | Acc: (96.81%) (32268/33330)\n",
      "Epoch: 23 | Batch_idx: 1120 |  Loss: (0.0923) | Acc: (96.80%) (32554/33630)\n",
      "Epoch: 23 | Batch_idx: 1130 |  Loss: (0.0922) | Acc: (96.81%) (32847/33930)\n",
      "Epoch: 23 | Batch_idx: 1140 |  Loss: (0.0926) | Acc: (96.80%) (33133/34230)\n",
      "Epoch: 23 | Batch_idx: 1150 |  Loss: (0.0931) | Acc: (96.78%) (33418/34530)\n",
      "Epoch: 23 | Batch_idx: 1160 |  Loss: (0.0930) | Acc: (96.79%) (33712/34830)\n",
      "Epoch: 23 | Batch_idx: 1170 |  Loss: (0.0931) | Acc: (96.79%) (34002/35130)\n",
      "Epoch: 23 | Batch_idx: 1180 |  Loss: (0.0930) | Acc: (96.79%) (34292/35430)\n",
      "Epoch: 23 | Batch_idx: 1190 |  Loss: (0.0930) | Acc: (96.79%) (34582/35730)\n",
      "Epoch: 23 | Batch_idx: 1200 |  Loss: (0.0932) | Acc: (96.79%) (34872/36030)\n",
      "Epoch: 23 | Batch_idx: 1210 |  Loss: (0.0931) | Acc: (96.79%) (35164/36330)\n",
      "Epoch: 23 | Batch_idx: 1220 |  Loss: (0.0932) | Acc: (96.78%) (35450/36630)\n",
      "Epoch: 23 | Batch_idx: 1230 |  Loss: (0.0932) | Acc: (96.78%) (35740/36930)\n",
      "Epoch: 23 | Batch_idx: 1240 |  Loss: (0.0936) | Acc: (96.77%) (36028/37230)\n",
      "Epoch: 23 | Batch_idx: 1250 |  Loss: (0.0941) | Acc: (96.76%) (36313/37530)\n",
      "Epoch: 23 | Batch_idx: 1260 |  Loss: (0.0944) | Acc: (96.75%) (36599/37830)\n",
      "Epoch: 23 | Batch_idx: 1270 |  Loss: (0.0945) | Acc: (96.74%) (36888/38130)\n",
      "Epoch: 23 | Batch_idx: 1280 |  Loss: (0.0945) | Acc: (96.74%) (37178/38430)\n",
      "Epoch: 23 | Batch_idx: 1290 |  Loss: (0.0947) | Acc: (96.74%) (37466/38730)\n",
      "Epoch: 23 | Batch_idx: 1300 |  Loss: (0.0947) | Acc: (96.74%) (37758/39030)\n",
      "Epoch: 23 | Batch_idx: 1310 |  Loss: (0.0948) | Acc: (96.73%) (38044/39330)\n",
      "Epoch: 23 | Batch_idx: 1320 |  Loss: (0.0950) | Acc: (96.72%) (38329/39630)\n",
      "Epoch: 23 | Batch_idx: 1330 |  Loss: (0.0952) | Acc: (96.71%) (38618/39930)\n",
      "Epoch: 23 | Batch_idx: 1340 |  Loss: (0.0953) | Acc: (96.70%) (38904/40230)\n",
      "Epoch: 23 | Batch_idx: 1350 |  Loss: (0.0956) | Acc: (96.69%) (39189/40530)\n",
      "Epoch: 23 | Batch_idx: 1360 |  Loss: (0.0956) | Acc: (96.69%) (39479/40830)\n",
      "Epoch: 23 | Batch_idx: 1370 |  Loss: (0.0959) | Acc: (96.68%) (39766/41130)\n",
      "Epoch: 23 | Batch_idx: 1380 |  Loss: (0.0959) | Acc: (96.68%) (40054/41430)\n",
      "Epoch: 23 | Batch_idx: 1390 |  Loss: (0.0959) | Acc: (96.68%) (40343/41730)\n",
      "Epoch: 23 | Batch_idx: 1400 |  Loss: (0.0959) | Acc: (96.67%) (40629/42030)\n",
      "Epoch: 23 | Batch_idx: 1410 |  Loss: (0.0960) | Acc: (96.66%) (40918/42330)\n",
      "Epoch: 23 | Batch_idx: 1420 |  Loss: (0.0968) | Acc: (96.63%) (41194/42630)\n",
      "Epoch: 23 | Batch_idx: 1430 |  Loss: (0.0970) | Acc: (96.61%) (41476/42930)\n",
      "Epoch: 23 | Batch_idx: 1440 |  Loss: (0.0969) | Acc: (96.61%) (41764/43230)\n",
      "Epoch: 23 | Batch_idx: 1450 |  Loss: (0.0969) | Acc: (96.60%) (42052/43530)\n",
      "Epoch: 23 | Batch_idx: 1460 |  Loss: (0.0972) | Acc: (96.60%) (42338/43830)\n",
      "Epoch: 23 | Batch_idx: 1470 |  Loss: (0.0972) | Acc: (96.60%) (42628/44130)\n",
      "Epoch: 23 | Batch_idx: 1480 |  Loss: (0.0975) | Acc: (96.59%) (42914/44430)\n",
      "Epoch: 23 | Batch_idx: 1490 |  Loss: (0.0976) | Acc: (96.58%) (43200/44730)\n",
      "Epoch: 23 | Batch_idx: 1500 |  Loss: (0.0977) | Acc: (96.58%) (43489/45030)\n",
      "Epoch: 23 | Batch_idx: 1510 |  Loss: (0.0979) | Acc: (96.56%) (43771/45330)\n",
      "Epoch: 23 | Batch_idx: 1520 |  Loss: (0.0978) | Acc: (96.57%) (44063/45630)\n",
      "Epoch: 23 | Batch_idx: 1530 |  Loss: (0.0980) | Acc: (96.56%) (44350/45930)\n",
      "Epoch: 23 | Batch_idx: 1540 |  Loss: (0.0979) | Acc: (96.56%) (44639/46230)\n",
      "Epoch: 23 | Batch_idx: 1550 |  Loss: (0.0979) | Acc: (96.55%) (44927/46530)\n",
      "Epoch: 23 | Batch_idx: 1560 |  Loss: (0.0981) | Acc: (96.54%) (45211/46830)\n",
      "Epoch: 23 | Batch_idx: 1570 |  Loss: (0.0981) | Acc: (96.55%) (45505/47130)\n",
      "Epoch: 23 | Batch_idx: 1580 |  Loss: (0.0981) | Acc: (96.55%) (45796/47430)\n",
      "Epoch: 23 | Batch_idx: 1590 |  Loss: (0.0980) | Acc: (96.56%) (46088/47730)\n",
      "Epoch: 23 | Batch_idx: 1600 |  Loss: (0.0979) | Acc: (96.56%) (46376/48030)\n",
      "Epoch: 23 | Batch_idx: 1610 |  Loss: (0.0982) | Acc: (96.54%) (46659/48330)\n",
      "Epoch: 23 | Batch_idx: 1620 |  Loss: (0.0981) | Acc: (96.55%) (46951/48630)\n",
      "Epoch: 23 | Batch_idx: 1630 |  Loss: (0.0984) | Acc: (96.54%) (47238/48930)\n",
      "Epoch: 23 | Batch_idx: 1640 |  Loss: (0.0982) | Acc: (96.55%) (47530/49230)\n",
      "Epoch: 23 | Batch_idx: 1650 |  Loss: (0.0985) | Acc: (96.54%) (47817/49530)\n",
      "Epoch: 23 | Batch_idx: 1660 |  Loss: (0.0985) | Acc: (96.54%) (48107/49830)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.3545) | Acc: (90.00%) (9000/10000)\n",
      "Epoch: 24 | Batch_idx: 0 |  Loss: (0.0058) | Acc: (100.00%) (30/30)\n",
      "Epoch: 24 | Batch_idx: 10 |  Loss: (0.0662) | Acc: (97.27%) (321/330)\n",
      "Epoch: 24 | Batch_idx: 20 |  Loss: (0.0858) | Acc: (96.98%) (611/630)\n",
      "Epoch: 24 | Batch_idx: 30 |  Loss: (0.0880) | Acc: (96.77%) (900/930)\n",
      "Epoch: 24 | Batch_idx: 40 |  Loss: (0.0853) | Acc: (97.07%) (1194/1230)\n",
      "Epoch: 24 | Batch_idx: 50 |  Loss: (0.0892) | Acc: (96.73%) (1480/1530)\n",
      "Epoch: 24 | Batch_idx: 60 |  Loss: (0.0913) | Acc: (96.72%) (1770/1830)\n",
      "Epoch: 24 | Batch_idx: 70 |  Loss: (0.0961) | Acc: (96.67%) (2059/2130)\n",
      "Epoch: 24 | Batch_idx: 80 |  Loss: (0.0979) | Acc: (96.67%) (2349/2430)\n",
      "Epoch: 24 | Batch_idx: 90 |  Loss: (0.0956) | Acc: (96.74%) (2641/2730)\n",
      "Epoch: 24 | Batch_idx: 100 |  Loss: (0.0982) | Acc: (96.73%) (2931/3030)\n",
      "Epoch: 24 | Batch_idx: 110 |  Loss: (0.0964) | Acc: (96.73%) (3221/3330)\n",
      "Epoch: 24 | Batch_idx: 120 |  Loss: (0.0946) | Acc: (96.72%) (3511/3630)\n",
      "Epoch: 24 | Batch_idx: 130 |  Loss: (0.0945) | Acc: (96.67%) (3799/3930)\n",
      "Epoch: 24 | Batch_idx: 140 |  Loss: (0.0937) | Acc: (96.71%) (4091/4230)\n",
      "Epoch: 24 | Batch_idx: 150 |  Loss: (0.0983) | Acc: (96.60%) (4376/4530)\n",
      "Epoch: 24 | Batch_idx: 160 |  Loss: (0.0975) | Acc: (96.63%) (4667/4830)\n",
      "Epoch: 24 | Batch_idx: 170 |  Loss: (0.0952) | Acc: (96.71%) (4961/5130)\n",
      "Epoch: 24 | Batch_idx: 180 |  Loss: (0.0925) | Acc: (96.83%) (5258/5430)\n",
      "Epoch: 24 | Batch_idx: 190 |  Loss: (0.0908) | Acc: (96.84%) (5549/5730)\n",
      "Epoch: 24 | Batch_idx: 200 |  Loss: (0.0913) | Acc: (96.78%) (5836/6030)\n",
      "Epoch: 24 | Batch_idx: 210 |  Loss: (0.0894) | Acc: (96.87%) (6132/6330)\n",
      "Epoch: 24 | Batch_idx: 220 |  Loss: (0.0903) | Acc: (96.83%) (6420/6630)\n",
      "Epoch: 24 | Batch_idx: 230 |  Loss: (0.0899) | Acc: (96.84%) (6711/6930)\n",
      "Epoch: 24 | Batch_idx: 240 |  Loss: (0.0913) | Acc: (96.82%) (7000/7230)\n",
      "Epoch: 24 | Batch_idx: 250 |  Loss: (0.0914) | Acc: (96.84%) (7292/7530)\n",
      "Epoch: 24 | Batch_idx: 260 |  Loss: (0.0922) | Acc: (96.77%) (7577/7830)\n",
      "Epoch: 24 | Batch_idx: 270 |  Loss: (0.0919) | Acc: (96.78%) (7868/8130)\n",
      "Epoch: 24 | Batch_idx: 280 |  Loss: (0.0918) | Acc: (96.79%) (8159/8430)\n",
      "Epoch: 24 | Batch_idx: 290 |  Loss: (0.0913) | Acc: (96.80%) (8451/8730)\n",
      "Epoch: 24 | Batch_idx: 300 |  Loss: (0.0918) | Acc: (96.80%) (8741/9030)\n",
      "Epoch: 24 | Batch_idx: 310 |  Loss: (0.0921) | Acc: (96.81%) (9032/9330)\n",
      "Epoch: 24 | Batch_idx: 320 |  Loss: (0.0928) | Acc: (96.76%) (9318/9630)\n",
      "Epoch: 24 | Batch_idx: 330 |  Loss: (0.0926) | Acc: (96.78%) (9610/9930)\n",
      "Epoch: 24 | Batch_idx: 340 |  Loss: (0.0928) | Acc: (96.77%) (9900/10230)\n",
      "Epoch: 24 | Batch_idx: 350 |  Loss: (0.0924) | Acc: (96.77%) (10190/10530)\n",
      "Epoch: 24 | Batch_idx: 360 |  Loss: (0.0926) | Acc: (96.78%) (10481/10830)\n",
      "Epoch: 24 | Batch_idx: 370 |  Loss: (0.0927) | Acc: (96.74%) (10767/11130)\n",
      "Epoch: 24 | Batch_idx: 380 |  Loss: (0.0926) | Acc: (96.75%) (11058/11430)\n",
      "Epoch: 24 | Batch_idx: 390 |  Loss: (0.0928) | Acc: (96.73%) (11347/11730)\n",
      "Epoch: 24 | Batch_idx: 400 |  Loss: (0.0935) | Acc: (96.71%) (11634/12030)\n",
      "Epoch: 24 | Batch_idx: 410 |  Loss: (0.0940) | Acc: (96.70%) (11923/12330)\n",
      "Epoch: 24 | Batch_idx: 420 |  Loss: (0.0941) | Acc: (96.70%) (12213/12630)\n",
      "Epoch: 24 | Batch_idx: 430 |  Loss: (0.0931) | Acc: (96.74%) (12509/12930)\n",
      "Epoch: 24 | Batch_idx: 440 |  Loss: (0.0936) | Acc: (96.70%) (12794/13230)\n",
      "Epoch: 24 | Batch_idx: 450 |  Loss: (0.0936) | Acc: (96.70%) (13084/13530)\n",
      "Epoch: 24 | Batch_idx: 460 |  Loss: (0.0935) | Acc: (96.68%) (13371/13830)\n",
      "Epoch: 24 | Batch_idx: 470 |  Loss: (0.0939) | Acc: (96.67%) (13659/14130)\n",
      "Epoch: 24 | Batch_idx: 480 |  Loss: (0.0934) | Acc: (96.68%) (13951/14430)\n",
      "Epoch: 24 | Batch_idx: 490 |  Loss: (0.0927) | Acc: (96.70%) (14244/14730)\n",
      "Epoch: 24 | Batch_idx: 500 |  Loss: (0.0925) | Acc: (96.72%) (14537/15030)\n",
      "Epoch: 24 | Batch_idx: 510 |  Loss: (0.0924) | Acc: (96.73%) (14828/15330)\n",
      "Epoch: 24 | Batch_idx: 520 |  Loss: (0.0922) | Acc: (96.74%) (15121/15630)\n",
      "Epoch: 24 | Batch_idx: 530 |  Loss: (0.0919) | Acc: (96.75%) (15412/15930)\n",
      "Epoch: 24 | Batch_idx: 540 |  Loss: (0.0919) | Acc: (96.76%) (15704/16230)\n",
      "Epoch: 24 | Batch_idx: 550 |  Loss: (0.0914) | Acc: (96.79%) (15999/16530)\n",
      "Epoch: 24 | Batch_idx: 560 |  Loss: (0.0915) | Acc: (96.79%) (16290/16830)\n",
      "Epoch: 24 | Batch_idx: 570 |  Loss: (0.0919) | Acc: (96.78%) (16579/17130)\n",
      "Epoch: 24 | Batch_idx: 580 |  Loss: (0.0923) | Acc: (96.76%) (16866/17430)\n",
      "Epoch: 24 | Batch_idx: 590 |  Loss: (0.0927) | Acc: (96.76%) (17156/17730)\n",
      "Epoch: 24 | Batch_idx: 600 |  Loss: (0.0929) | Acc: (96.75%) (17444/18030)\n",
      "Epoch: 24 | Batch_idx: 610 |  Loss: (0.0926) | Acc: (96.75%) (17735/18330)\n",
      "Epoch: 24 | Batch_idx: 620 |  Loss: (0.0923) | Acc: (96.77%) (18029/18630)\n",
      "Epoch: 24 | Batch_idx: 630 |  Loss: (0.0917) | Acc: (96.79%) (18323/18930)\n",
      "Epoch: 24 | Batch_idx: 640 |  Loss: (0.0912) | Acc: (96.82%) (18618/19230)\n",
      "Epoch: 24 | Batch_idx: 650 |  Loss: (0.0914) | Acc: (96.80%) (18906/19530)\n",
      "Epoch: 24 | Batch_idx: 660 |  Loss: (0.0913) | Acc: (96.81%) (19197/19830)\n",
      "Epoch: 24 | Batch_idx: 670 |  Loss: (0.0910) | Acc: (96.82%) (19490/20130)\n",
      "Epoch: 24 | Batch_idx: 680 |  Loss: (0.0910) | Acc: (96.82%) (19780/20430)\n",
      "Epoch: 24 | Batch_idx: 690 |  Loss: (0.0907) | Acc: (96.83%) (20072/20730)\n",
      "Epoch: 24 | Batch_idx: 700 |  Loss: (0.0911) | Acc: (96.80%) (20357/21030)\n",
      "Epoch: 24 | Batch_idx: 710 |  Loss: (0.0918) | Acc: (96.77%) (20642/21330)\n",
      "Epoch: 24 | Batch_idx: 720 |  Loss: (0.0920) | Acc: (96.76%) (20930/21630)\n",
      "Epoch: 24 | Batch_idx: 730 |  Loss: (0.0922) | Acc: (96.75%) (21218/21930)\n",
      "Epoch: 24 | Batch_idx: 740 |  Loss: (0.0922) | Acc: (96.76%) (21509/22230)\n",
      "Epoch: 24 | Batch_idx: 750 |  Loss: (0.0925) | Acc: (96.73%) (21793/22530)\n",
      "Epoch: 24 | Batch_idx: 760 |  Loss: (0.0923) | Acc: (96.74%) (22085/22830)\n",
      "Epoch: 24 | Batch_idx: 770 |  Loss: (0.0926) | Acc: (96.74%) (22377/23130)\n",
      "Epoch: 24 | Batch_idx: 780 |  Loss: (0.0928) | Acc: (96.73%) (22663/23430)\n",
      "Epoch: 24 | Batch_idx: 790 |  Loss: (0.0931) | Acc: (96.71%) (22949/23730)\n",
      "Epoch: 24 | Batch_idx: 800 |  Loss: (0.0928) | Acc: (96.72%) (23243/24030)\n",
      "Epoch: 24 | Batch_idx: 810 |  Loss: (0.0929) | Acc: (96.72%) (23533/24330)\n",
      "Epoch: 24 | Batch_idx: 820 |  Loss: (0.0938) | Acc: (96.69%) (23814/24630)\n",
      "Epoch: 24 | Batch_idx: 830 |  Loss: (0.0937) | Acc: (96.69%) (24105/24930)\n",
      "Epoch: 24 | Batch_idx: 840 |  Loss: (0.0937) | Acc: (96.70%) (24397/25230)\n",
      "Epoch: 24 | Batch_idx: 850 |  Loss: (0.0943) | Acc: (96.68%) (24683/25530)\n",
      "Epoch: 24 | Batch_idx: 860 |  Loss: (0.0942) | Acc: (96.68%) (24973/25830)\n",
      "Epoch: 24 | Batch_idx: 870 |  Loss: (0.0952) | Acc: (96.66%) (25257/26130)\n",
      "Epoch: 24 | Batch_idx: 880 |  Loss: (0.0957) | Acc: (96.64%) (25543/26430)\n",
      "Epoch: 24 | Batch_idx: 890 |  Loss: (0.0960) | Acc: (96.64%) (25831/26730)\n",
      "Epoch: 24 | Batch_idx: 900 |  Loss: (0.0962) | Acc: (96.63%) (26118/27030)\n",
      "Epoch: 24 | Batch_idx: 910 |  Loss: (0.0961) | Acc: (96.64%) (26411/27330)\n",
      "Epoch: 24 | Batch_idx: 920 |  Loss: (0.0960) | Acc: (96.64%) (26703/27630)\n",
      "Epoch: 24 | Batch_idx: 930 |  Loss: (0.0960) | Acc: (96.64%) (26992/27930)\n",
      "Epoch: 24 | Batch_idx: 940 |  Loss: (0.0959) | Acc: (96.64%) (27282/28230)\n",
      "Epoch: 24 | Batch_idx: 950 |  Loss: (0.0958) | Acc: (96.65%) (27574/28530)\n",
      "Epoch: 24 | Batch_idx: 960 |  Loss: (0.0958) | Acc: (96.63%) (27858/28830)\n",
      "Epoch: 24 | Batch_idx: 970 |  Loss: (0.0957) | Acc: (96.63%) (28148/29130)\n",
      "Epoch: 24 | Batch_idx: 980 |  Loss: (0.0955) | Acc: (96.63%) (28439/29430)\n",
      "Epoch: 24 | Batch_idx: 990 |  Loss: (0.0953) | Acc: (96.64%) (28730/29730)\n",
      "Epoch: 24 | Batch_idx: 1000 |  Loss: (0.0957) | Acc: (96.62%) (29016/30030)\n",
      "Epoch: 24 | Batch_idx: 1010 |  Loss: (0.0961) | Acc: (96.62%) (29304/30330)\n",
      "Epoch: 24 | Batch_idx: 1020 |  Loss: (0.0961) | Acc: (96.61%) (29593/30630)\n",
      "Epoch: 24 | Batch_idx: 1030 |  Loss: (0.0959) | Acc: (96.61%) (29883/30930)\n",
      "Epoch: 24 | Batch_idx: 1040 |  Loss: (0.0958) | Acc: (96.61%) (30170/31230)\n",
      "Epoch: 24 | Batch_idx: 1050 |  Loss: (0.0957) | Acc: (96.61%) (30462/31530)\n",
      "Epoch: 24 | Batch_idx: 1060 |  Loss: (0.0955) | Acc: (96.63%) (30757/31830)\n",
      "Epoch: 24 | Batch_idx: 1070 |  Loss: (0.0956) | Acc: (96.63%) (31048/32130)\n",
      "Epoch: 24 | Batch_idx: 1080 |  Loss: (0.0958) | Acc: (96.62%) (31335/32430)\n",
      "Epoch: 24 | Batch_idx: 1090 |  Loss: (0.0956) | Acc: (96.63%) (31628/32730)\n",
      "Epoch: 24 | Batch_idx: 1100 |  Loss: (0.0956) | Acc: (96.63%) (31916/33030)\n",
      "Epoch: 24 | Batch_idx: 1110 |  Loss: (0.0958) | Acc: (96.63%) (32206/33330)\n",
      "Epoch: 24 | Batch_idx: 1120 |  Loss: (0.0959) | Acc: (96.63%) (32496/33630)\n",
      "Epoch: 24 | Batch_idx: 1130 |  Loss: (0.0961) | Acc: (96.62%) (32782/33930)\n",
      "Epoch: 24 | Batch_idx: 1140 |  Loss: (0.0957) | Acc: (96.63%) (33078/34230)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4,\n",
    "                                nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")\n",
    "\n",
    "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "for epoch in range(start_epoch, 165):\n",
    "\n",
    "    if epoch < 80:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 120:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0MS5J-vav4X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIktcn-TaKub"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "leArLijSaaWZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RBR48wh_Z9mt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b341tuJSaD1G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPdqZGzEaHmC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuRjzj_tZ1kP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1E-h3EqQ7W9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "densenet201.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
